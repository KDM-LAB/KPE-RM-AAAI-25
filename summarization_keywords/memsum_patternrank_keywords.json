{"9c61f5f51a232049635e6f3441e6397af4d91298": {"ta_keywords": "games;learning;introduction", "pdf_keywords": ""}, "a05c3e8bd6dacbd192ffa28543e60e2c93c66d76": {"ta_keywords": "trend analyzer;trend analysis;tweet retrieval;trends;twitter;tweets;popular social media platform;social media;hashtags;comparative popularity;latest topics;topics;data science industry;graph;technology era;product analysis;marketing;world;today;happenings;people;information;users;list;importance;opinions;several purposes;set", "pdf_keywords": ""}, "bfa10ea6a4c9fa585f21f39858da517c31a76343": {"ta_keywords": "persuasive dialogue systems;probabilistic dialogue modeling method;dialogue management;dialogue model;dialogue manager;conversation;persuasive power;candidate actions;system knowledge;decisions;task;preference;system;actions;specific goal;user;needs;method;research;baseline system;respect", "pdf_keywords": ""}, "0bf2a0a3216c79b62b3664c596f44d7a8add498a": {"ta_keywords": "fiction reviews;undergraduate computer science curriculum;research reviews;science fiction;science fiction book;technical papers;research literature;topic;much research;students;most students;tools;movie;recent research;imagination;tv show;gateway;field;skills", "pdf_keywords": ""}, "a4cb2a401c78bfafee69e823306b0cc9e4d673db": {"ta_keywords": "fair allocation problem;efficient ef1 allocations;reviewer round robin;reviewer assignment;allocations;art paper assignment methods;reviewer quality;real conference datasets;papers;fairness;ef1;envy;submodularity;order;robin mechanism;robin mechanisms;efficiency;maximum welfare;instance;relaxation;item;runtime;standard tool;subject area;rrr;approach outputs;extension;several state;experts", "pdf_keywords": "reviewer assignment setting;reviewer assignment;fair allocation problem;reviewer round robin;peer review;ef1 allocations;e\ufb03cient ef1 allocations;simple greedy approach;art paper assignment methods;greedy approach;ordering;papers;real conference datasets;fairness;submodularity;maximum welfare;order;robin mechanism;free;relaxation;keywords;usw;academia;runtime;introduction;instance;work;rrr;item;section"}, "242c73ea34833910ad2643ec3a1096bb18c6d04d": {"ta_keywords": "target speech extraction module;target speech extraction model;target speaker extraction;speech enhancement uncertainty measures;recurrent neural network transducer;speaker speech extraction;rnn transducer;neural uncertainty estimation;neural uncertainty module;relative character error rate;speaker identity;rnn;background noise;recognizer fine;residual noise;noisy condition;relative performance gain;cer;domain target;performance;joint framework;artifacts;time;clean condition;experiments;method;work", "pdf_keywords": "target speech extraction module;target speech extraction model;speaker speech extraction;recurrent neural network transducer;speaker speech recognition;speech extraction module;rnn transducer;neural uncertainty estimation;neural uncertainty module;speaker speech;speech enhancement;speaker identity;speakers;rnn;clean rnn;relative character error rate;recognizer \ufb01ne;tunes;background noise;training;target;uncertainty measures;noisy environments;extraction;joint framework;domain target;models;whole network;module;cer"}, "a4df5ff749d823905ff9c1a23b522d3f426a1bb6": {"ta_keywords": "pagerank similarity vectors;personalized pagerank measure;pagerank;similarity measures;similarity measure;graph nodes;discretevariable pairwise mrfs;nodes;similarity;mining research;markov;random fields;graphs;marginal probabilities;walks;tree;mrfs;graph;inference;vertices;data;formal connection;paper;evaluation;computation;limited postprocessing stage;connection;small set;active areas;development", "pdf_keywords": ""}, "f32108602fb0dbda29030cac780165a4b89048a3": {"ta_keywords": "comparison relation prediction;comparison relations;noun phrasing knowledge;external common knowledge;knowledge;sql;training data;adjective;text;split spider dataset;web;models;significant improvement;experimental results;approach;capabilities;problem;paper;art methods;state", "pdf_keywords": ""}, "04745fe1306d10c915d27a454c157c837dacefce": {"ta_keywords": "independent speaker separation;speech enhancement;source separation;source separation systems;channel speaker;phasebook;additional phase reconstruction steps;phase;mixture signal;phase difference;complex masks;mixture;corpus;mask;frequency representation;art mask;target source;2mix dataset;inference schemes;deep;end learning framework;various training;discrete representations;layer;quality;representations;performance;state;magnitude;discrete representation", "pdf_keywords": ""}, "20140fcf0bdd932c1886ff1c7674c23649b1e3b8": {"ta_keywords": "speech synthesis;synthetic speech;traditional parameter generation methods;rich context models;parameter generation;iterative parameter generation method;parameter generation method;generation method;initial parameters;parameters;discontinuous initial parameters;initialization method;improvements;spectral component;quality improvements;f0 components;f0 component;method;traditional method;hmm;limitations;effects;paper;effect;issues", "pdf_keywords": ""}, "e32177e38060637ac8a2ebc9990d43d1ab8bdb8a": {"ta_keywords": "recommendation systems;social networks;latent similarities;communities;community;similarities;recommendations;cold start problem;inferences;users;start;information;gap;cold;start problem;user;items;solution;paper;different dimensions;problem;little information;order;issue;study;inability", "pdf_keywords": ""}, "6680b1e863c394f00307cb3818f7c7d75c9919aa": {"ta_keywords": "network codes;data collector;interference alignment;network;storage problem;node;data;repair;new node;paper;failure;concept;task;approach;example;use", "pdf_keywords": ""}, "c096ec97ecc4f8325f6db7f32398445d6a39f959": {"ta_keywords": "multiple fairness metrics;fairness concerns;fairness assumptions;fairness;aware recommendation;recommender systems;dynamic lotteries;recommender;aware applications;recommendations;consequential applications;groups;design decisions;accuracy;performance;time horizon;systems;winner;world complexities;framework;trade;multiply;number;paper;previous literature;historical view;properties", "pdf_keywords": "recommendation fairness;ranking under fairness;algorithmic fairness;fairness concerns;recommendation domains;recommender systems;social choice;lottery;recommendation;preferences;different individual agents;scruf;single outcome;scruf framework;dynamic adaptation;ideas;novel framework;mechanisms;task;framework;performance;conclusion;paper;problem"}, "27636090a87fab750fccff4c6ede161ab62bcab4": {"ta_keywords": "mobile ad hoc networks;vanet;network visibility;vehicular ad;beacons;network;road junctions;oncoming vehicles;networks;neighbors;neighbor;vehicle;periodic safety messages;junction;collision;wider vision;prior knowledge;table;information;risk;challenging research areas;research;field;new mechanism", "pdf_keywords": "mobile ad hoc networks;coded repetition beacon piggybacking;vanet;beacon;beacons;network visibility;vehicular ad;visibility;neighbor tables;network;neighbors;networks;vehicle;1national advanced ipv6 centre;ghassan samara1;penang;performance;wider vision;extensive simulation study;universiti sains malaysia;malaysia;new technique;sureswaran ramadass3;table;conclusion;research;malaysia 2school;information;world applied sciences journal;order"}, "c3fc0b1041dcdd5b47ffaa0d584e40aa841628bf": {"ta_keywords": "set expansion;binary relational concepts;set expander;expansion;entities;level wrappers;partial set;seeds;complete set;seal;language;seed;resources;character;web;addition;construction;level analysis;detail;system;paper;semi;technique;mayor;independent fashion", "pdf_keywords": ""}, "7f79ac114d30c2c7dae91075210fbfda90c9d76f": {"ta_keywords": "adversarial games;press diplomacy bots;external regret minimization techniques;external regret minimization;anonymous games;human players;press diplomacy;diplomacy;prior ai breakthroughs;complex games;previous ai successes;equilibrium search;cooperation;popular diplomacy website;agent;poker;expert humans;scale games;cooperative settings;step lookahead search;supervised learning;human data;press variant;rank;paper;level performance;performance", "pdf_keywords": "diplomacy games;press diplomacy bots;games by expert human;press diplomacy;regret minimization search techniques;neural policies;diplomacy;human players;popular diplomacy website;regret minimization;imitation;benchmark game;anonymous games;agent;human play;expert humans;cooperation;world championship;press variant;competition;step lookahead search;longstanding benchmark;supervised learning;present commentary;human data;paper;time winner;blueprint policy;anecdotal analysis;research"}, "70dc18bb6607e408ec1cd3f71c0fdac3534c288d": {"ta_keywords": "lstm speech enhancement;speech enhancement;robust automatic speech recognition asr;recurrent neural network rnn;term memory lstm rnns;lstm recurrent neural networks;optimal speech reconstruction objective;robust asr;noise;long short;recent developments;end processing;competitive results;light;application;framework", "pdf_keywords": ""}, "6e07fb796c75cac6432cdf0c314b933d0f9f45e5": {"ta_keywords": "biomedical text mining;gene names;gene name;actual gene;actual genes;entities;way names;entity;similar ambiguity;other fields;trainable system;recognition;common task;task;many applications;approach;paper", "pdf_keywords": ""}, "24fcdaf969089e6a411f7cebc9274bbc53c25e42": {"ta_keywords": "causal thinking;causal features;augmented data;interventions;causal model;machine learning models;training data;models;human understanding;domain evaluation;efficacy;datasets;data;linear gaussian models;edits;irrelevant words;improvements;outcomes;interesting insights;toy analog;spurious patterns;attempts;researchers;paper;domain performance;domain;noise;human;analysis;principles", "pdf_keywords": "causal features;causal models;causal spans;feature attribution technique;domain generalization;style transfer methods;toy linear gaussian models;relative improvements;linear gaussian models;attention;models;nli tasks;sentiment analysis;rationale spans;domain performance;spans;spurious signals;original data;empirical study;toy analog;cad;noise;data;domain;augmentation;empirical investigation;ofdomain performance;analysis;paper;cases"}, "1d5c07e7415a7e9be078717197ddf9f3c70a2875": {"ta_keywords": "bert model;bert pretrained;electronic health records;predictive clinical tasks;personal health information;bert;clinical notes;sensitive data;sensitive information;ehr;clinicalbert;such models;models;data access;many researchers;mimic;utility motivates parameter sharing;iii corpus;phi;access;battery;large sets;performance;most efforts;release;necessity;approaches;methods;large transformers;cost", "pdf_keywords": "bert model weights;sensitive patient information;sensitive information;bert;personal health information;electronic health records;unique potential privacy concerns;patient ehr;potential privacy implications;language models;deidenti\ufb01ed data;language modeling objectives;ehr;model weights;models;data;notes;iii corpus;mimic;domain speci\ufb01c corpora;such research;context;attacks;model parameters;associations;patients;trainings;tasks;baseline condition frequencies;experiments"}, "ca9047c78d48b606c4e4f0c456b1dda550de28b2": {"ta_keywords": "recurrent neural networks;deep learning models;rnns;simple deep neural network;temporal convolutions;time memorization;sequential image classification;world healthcare regression tasks;difficult speech classification task;simple sequence model;time series benchmarks;lssl layers;range memory;neural differential equations;linear state;time state;shorter sequences;lssl;structured matrices;endow lssls;long dependencies;speech;modeling power;trainable subset;features;space layer;series data;control systems;state;ndes", "pdf_keywords": "recurrent neural networks;deep learning models;temporal convolutions;time memorization;combining recurrent;time models;term memory;rnns;modern time series models;neural di\ufb00erential equations;range memory;convolutional;krylov function;long sequences;structured matrices;computational speed;linear state;simple sequence model;trainable subset;computational e\ufb03ciency;time;modeling power;main limitations;space layers;ndes;di\ufb03cult tasks;endow lssls;recent theory;control systems;concrete algorithm"}, "b2a090506264bc9706dc9bcc5d61b4965ae919e7": {"ta_keywords": "knowledge graph;knowledge graph identification;probabilistic soft logic;synthetic linked data corpus;uncertain extractions;extraction graph;interrelated facts;useful knowledge;probabilistic modeling framework;facts;ontological relations;musicbrainz music community;extractions;entities;relations;candidate facts;information;scale information processing systems;massive collections;psl;millions;improved auc;task;nell project;f1;approach;world set;paper;noise;power", "pdf_keywords": ""}, "8ca5a1e6cec68ef515ac1eb28d069a23dc9c14df": {"ta_keywords": "global graph clustering;semantic class induction experiment datasets;frame induction;watset;computational linguistics journal;babelnet;dataset supplements;sense;induction experiment;ru;applications;article;licensing issues", "pdf_keywords": ""}, "a75c2d26ca6a06cbee62a8d1dad5993356d96793": {"ta_keywords": "various ranking algorithms;seed entities;good set expansion performance;named entities;many seeds;entities;iterative seal;seeds;iterative set expansion;iseal;seal;web;expander;expansion;larger set;better results;fewer user;resources;expansion method;language;performance;method;addition;system;version;self;user;manner;choice;mixture", "pdf_keywords": ""}, "a2ce385fc8d5068e8c87ebe4699c8f9b295cad5e": {"ta_keywords": "phonological subword representations;entity recognition;word embeddings;bilingual dictionaries;low resource languages;machine translation;natural language processing;new languages;parallel corpora;continuous word representations;motivated subword units;nlp;morphemes;rich languages;bengali;subwords;languages;phonemes;morphological;turkish;graphemes;hindi;transfer learning;generalization;resources;resource;boost;much work;previous methods;uyghur", "pdf_keywords": "phonological subword representations;word embeddings;entity recognition;lowresourced languages;morphemes;low resource languages;continuous word representations;machine translation;new languages;motivated subword units;natural language processing;morphological representations;subword information;rich languages;phonemes;languages;nlp;language technologies institute;bengali;entities;graphemes;morphological;hindi;turkish;categories;generalization;ner;downstream tasks;english;resource"}, "a0e92f6e9564b8c38b6649ae71b892ddfb988faa": {"ta_keywords": "controllable semantic parser;exemplar retrieval;semantic parsing;generative seq2seq model;exemplars;related exemplars;parser;certain targeted queries;output parse;generic generative model;queries;retrieval index;new training examples;input query;query;such behavior changes;casper;predictions;mechanism;target behavior;end;practical applications;behavior;control mechanism;new domain", "pdf_keywords": "semantic parser;controllable semantic parser;semantic parsing;new semantic schemas;new semantic schema;exemplar retrieval;semantic labels;parse guiding;parser;mapping input queries;retrieval;schema refactoring;retrieval index;schema;exemplars;augmented query;queries;casper;meaning representations;generative model;examples;other domains;task;domain;section;speci\ufb01ed patterns;mtop dataset;sections;performance;unseen labels"}, "a30d7a3aa5e50d0b7abb448b6692e419b84018b8": {"ta_keywords": "accurate prefix boosting;sequence asr;sequence;discriminative training technique;attention;accurate prefix;beam search;partial correct sequence;asr;seq2seq;training procedure;papb;training;score;other hypotheses;testing scheme;paper", "pdf_keywords": "softmax margin loss objectives;mbr objectives;mbr objective;better model predictions;training objectives;softmax margin;mbr;pre\ufb01x training;recognition performance;minimum bayes risk;performance;cer;papb;wer;ntr;pre\ufb01x information;pre\ufb01x level;datasets;next character;consistent gains;voxforge;nde;improvement;comparison;feed;experimental results;test;intuition;table;different beam sizes"}, "a41c81e5c3f86e18217069b94b44ceaf281e451c": {"ta_keywords": "simple heuristic placement policies;wireless sensor networks;path outage;deployment objective;wireless network;placement location;deployment agent;relays;algorithms;backtracking;deployment;protocols;previous relay;sensor;several consecutive steps;step cost function;link quality measurements;locations;cycling;line measurements;sleep;applications;earlier work;numerical study;line;measurements;insights;inclusion;paper;sink", "pdf_keywords": "wireless relay networks;simple heuristic placement policies;wireless sensor networks;relay;path outage;wireless network;several potential placement locations;deployment objective;placement location;backtracking;deployment;deployment agent;algorithms;protocols;step cost function;several consecutive steps;several approaches;cycling;sleep;link qualities;numerical study;earlier work;inclusion;line measurements;measurements;terms;insights;ii;advantage;paper"}, "f20654f481843ec9eb11bcd00e418aec2470dfa5": {"ta_keywords": "storage codes;storage systems;replication;storage;traditional erasure codes;binary mds array codes;erasure codes;fault tolerance;mds codes;piggybacking design framework;data centers;rebuilding;data access;unavailable nodes;smallest locality;mds;system considerations;codes;multiple instances;separability;data;code parameters;efficient;new framework;efficient manner;basic idea;framework;paper;distance;others", "pdf_keywords": "storage codes;binary mds codes;parity nodes;smallest repairlocality;mds codes;data centers;ef\ufb01cient repair;systematic nodes;smallest data;explicit codes;codes;repair;node;piggybacking design framework;new piggybacking framework;dataread;rich design space;mds;implementation;ieee department;constraints;computer sciences university;separable;read;distance;small number;solutions;california;classes;framework"}, "6e05d35d072cd73fa039fd60696a8fe110f1d6cd": {"ta_keywords": "contextual recommendation;recommendation tasks;recommendation systems;collaborative filtering approaches;publication databases;path constrained random walks;rich context information;recommendation;available context information;citation;graph representation;online documents;traditional content;random walk;pcrw;shopping opportunities;important research area;tasks posts challenges;abundance;data;study;history;approachs;restart;approach;experiments", "pdf_keywords": ""}, "3c4dfc252c214d559fadb5e3159bcc9c7db08fbc": {"ta_keywords": "dental fluorosis;caries lesions;mild fluorosis;tooth surface;study reflectance measurements;fluorosis;lesion surface zone thickness;lesions;higher water absorption;severe fluorosis;enamel;tooth development;teeth;wavelengths;lesion depth;lesion structure;mean surface zone thickness;high contrast;short wavelength;dehydration dynamics;faint white lines;intensity change;microct;surfaces;hypomineralization;significant correlation;swir;areas;rate;nm", "pdf_keywords": ""}, "294f8307f26eb3ec7bbf19f15092f3c473ece821": {"ta_keywords": "entity recognition;training relation extractors;entity classification;relation extractor;large textual corpus;distant supervision approaches;entity classifier;textbound annotation;knowledge base;structured prediction;stanford ner;imitation learning;classification learning;relations;nerc training;nerc;classification;relation arguments;web features results;web features;domain;nerc systems;imitation;stage classification model;appropriate domain;low performance;shelf;discrepancies;recent years;data", "pdf_keywords": ""}, "6a2c4a0f04c6ba2f6fbc171dcea8730423a298e5": {"ta_keywords": "approximate nearest neighbor retrieval;sensitive hashing;prune approaches;learned pruner;distance functions;bbtree;effective learning;data sets;tree;permutation methods;sampling;triangle inequality;spaces;density estimation;divergence;vp;lsh;methods;state;saito;art approaches;conditions;itakura;kl;focus", "pdf_keywords": ""}, "20d4105b276da6d6d38ed3c1bfc436f76198c240": {"ta_keywords": "political event dataset;such potential causal relationships;such large event datasets;event datasets;world event datasets;actor identities;event pairs;events;effect association;pairwise associations;human raters;actors;politics;synthetic data;conditional intensity rates;interaction;pairs;financial analysis;ground truth;health;additional knowledge;scores;assessments;related algorithms;performance;cause;general framework;several domains;use;suite", "pdf_keywords": ""}, "695d4c04f6e4f7ba5f771ac7853fdbaa81713ae8": {"ta_keywords": "latent topic space;latent topics;knowledge bases;online academic search system;network embeddings;knowledge base;online social networks;embeddings;social network users;genvector;researchers;knowledge concepts;datasets;live users;word;model;unlabeled data;network;concepts;experiments;data;modalities;method;aminer;error rate;scale;extent;art methods;state", "pdf_keywords": "social knowledge graphs;latent topic space;word embeddings;topic models;network embeddings;latent topics;embeddings;knowledge bases;online social networks;social network users;genvector;knowledge concepts;datasets;model;modalities;multi;unlabeled data;data;task;error rate;extent;apr;scale;state;art methods;advantages;abstract;cl;real system"}, "3b8494614903dc47579da30477b21b109b29f8cd": {"ta_keywords": "machine learning;rutgers university;nj;eleventh international conference;usa;new brunswick;july;proceedings", "pdf_keywords": ""}, "74c881830a9cd7ea49795faa5c582b7ec56bd0bf": {"ta_keywords": "end multichannel speech recognition;noisy speech recognition task;automatic speech recognition;s2s asr module;noisy reverberant tasks;conventional asr components;entire multichannel speech enhancement;field asr;reverb dataset;asr components;e2e asr;reverb;reverberant;asr;single differentiable neural network;sequence;neural extensions;s2s model;dirha english dataset;s2s;conventional pipeline methods;talk;field applications;e2e;modules;modeling;end;architecture;comparable performance;better performance", "pdf_keywords": "end multichannel speech recognition;end asr model;speech processing;automatic speech recognition;end asr objective;s2s asr module;asr network;entire multichannel speech enhancement;reverberant;conventional asr components;asr;asr components;e2e asr;multichannel end;reverb dataset;s2s model;beamforming;sequence;s2s;aswin;model;single differentiable neural network;end;mismatched environments;modeling;comparable performance;dereverberation components;ttaniguc;aswin shanmugam subramanian1;neural extensions"}, "3d3b1300c7cd6a820a6d08605248f875a3ad20b9": {"ta_keywords": "interpretable link prediction;global interpretability;interpretability evaluation;interpretability;interpretability scores;path recall;local interpretability;rule information;many paths;benchmark;models;approximate strategy;future research;rules;direction;multi;metrics;evaluation;representative baselines;rule;performance;unified framework;recent years;terms;development;experiments;paper;little work;experimental results", "pdf_keywords": "multihop reasoning model;rule mining methods;global interpretability;rule information;interpretability score;interpretability scores;interpretability;path recall;mined rules;link prediction performance;local interpretability;benchmarks;benchmark;generalization ability;manual annotation;models;automatic generation;rules;approximate strategy;model anyburl;future research;rule;model;evaluation;performance;direction;metrics;possible future research direction;similar results;terms"}, "e0c54e18cf2372414042bf67eed0272b0a432190": {"ta_keywords": "weblogs;social media;fourth international conference;icwsm;proceedings;usa;washington;may;dc", "pdf_keywords": ""}, "7da967be8f6367f6174bf99d0d019ff545ac5966": {"ta_keywords": "semantic annotation;lingvosemantic corpus;annotation;annotated data;computer tools;techniques;approach;methodology;results;process;forward style;set;comparison;recommendations;paper;sufficient amount;reasonable time frame;way;demands;efficiency;end", "pdf_keywords": ""}, "49db57f300b270f16cbcb1891ca39e16981d42b5": {"ta_keywords": "traditional public health surveillance signals;covidcast api;many public health data sources;covid activity;traditional public health reporting;historical data;medical claims data;data sources;epidemiological modelers;massive online surveys;enormous data challenges;relevant public behavior;health researchers;hospitalizations;cell phone mobility data;date data;present information;policy makers;internet search trends;many auxiliary indicators;deaths;signals;temporal resolution;activity;frequent revisions;research;need;revisions;modelers;open access", "pdf_keywords": ""}, "bad416f073a08086ee428e5a264eac3a7d3251e5": {"ta_keywords": "structured literature image finder;biomedical literature;text;figures", "pdf_keywords": ""}, "d9dbdd254b02ef1af2769af403cba373c1b1bcb1": {"ta_keywords": "speaker diarization;speaker diarization method;speaker diarization problem;speaker representations;domain adaptation;speaker;diarization error rate;diarization errors;single neural network;speech;callhome dataset;label permutation problem;clustering;conventional clustering;free objective function;separate modules;permutation;training;network;model;extraction;relative improvement;method;system;end;inference;methods;end simplicity;novel end;paper", "pdf_keywords": "neural speaker diarization method;speaker diarization model;speech mixtures;real speech data;diarization;domain adaptation;callhome dataset;conventional clustering;neural network;eend;baseline systems;end;method;novel end;methods;objective;error;conclusion;paper;signi\ufb01cant der reduction;experimental results"}, "5931c8ac145baf17cec9effc25c051049b7dfd4c": {"ta_keywords": "dialogue task;dialogue agent;neural dialogue model;observable reference game;recurrent memory;utterances;play evaluations;pragmatic generation procedure;human evaluations;agents;agent;successful task completion;referents;structured reference resolver;task;references;object;board;relative improvement;world context;positions;people;self;part;partner;dots;number;onecommon;art;aizawa", "pdf_keywords": "grounded collaborative dialogue;neural dialogue model;full dialogue task;observable reference game;centric models;human evaluations;human partners;pytorch;people;system;model;codebase;abstract;relus;system types;reference;udagawa;aggregate;reimplementation;success rate;computer science;implementation choices;aizawa;default initializations;pairs;sep;cornell tech;past work;parameters;uc berkeley"}, "6c4258f6a6a4bee7b9d914379c44aea6073cdc37": {"ta_keywords": "energy disaggregation;energy disaggregation problem;aggregate power consumption signal;device level power consumption signals;adaptive filtering;disaggregation problem;adaptive filtering problem;filter bank;optimality;building;paper", "pdf_keywords": "energy disaggregation;energy disaggregation problem;individual device power consumption patterns;power consumption data;device level power consumption signals;aggregate power consumption signal;whole building energy data;novel disaggregation algorithm;disaggregation;adaptive filtering;disaggregation problem;electricity grid;online adaptive \ufb01ltering algorithm;adaptive \ufb01ltering problem;dynamical models;individual devices;devices;\ufb01lter banks;\ufb01lter bank;likely inputs;optimality;algorithm;building;introduction;properties;costs;stat;ap;theoretical understanding;paper"}, "3dcf9c900f5f28e082a2fcdea4763b6063a76f09": {"ta_keywords": "defeasible reasoning;reasoning;mental model;question scenario;questions;cognitive science literature;conclusions;scenario;relevant influences;model;problem scenario;approach;additional input;new evidence;question;system;graph;person;performance;result;mode;account", "pdf_keywords": "defeasible reasoning datasets;reasoning tasks;different defeasible reasoning datasets;inference graphs formulation;defeasible reasoning;cognitive science literature;thinkaboutit;learning;explainability;data;pooling;curious;graph;moe;question scenario;scenario;question;gcn;experiments;alternative;paper;connections;method;art;performance;figure;system;new state;terms"}, "dbdb7f25f1538c2a2885d3992e5320e2ee5c23a1": {"ta_keywords": "cognitive tutors;cognitive tutor;cognitive tutor authoring tools;tutoring interface;tutor;first pedagogical teachable agent;computer agent;teaching;simstudent technology;students;simstudent;algebra equation;learning;authentic classroom settings;genuine inductive learning;platform;line game;like environment;ltb environment;social factors;effect", "pdf_keywords": ""}, "660119405bb48777cd71d85caa5ec2e90a336caf": {"ta_keywords": "historical text normalization systems;historical text normalization;normalization techniques;statistical machine translation;decoder models;neural encoder;languages;scale comparison;distance metrics;different datasets;different evaluation methods;literature;many techniques;rule;character;different conclusions;categories;data quantity;methods;studies;consensus;systems;experiments;art approach;effect;state", "pdf_keywords": "historical text normalization systems;historical text normalization;normalization techniques;normalization models;stemming;word accuracy;different languages;supervised learning;languages;datasets;error analysis;useful tool;categories;different evaluation methods;scale comparison;cer;literature;case study;abstract;different systems;systematic survey;computer science university;theart approach;systems;denmark;consensus;characteristics;experiments;marcel bollmann department;data quantity"}, "98554bd8a15172e9a6ef3cc3db3bc52504110fc9": {"ta_keywords": "stochastic bandits;regret minimization;wise optimal performance;optimal performance;bai objectives;exploitation;regret;pareto frontier;best arm identification;bai failure probability;latter objective;exploration;archetypal objectives;rm;bai;algorithm;horizon;order;bobw;balance;folklore;different values", "pdf_keywords": "stochastic bandits;adversarial bandits;regret minimization;exploitation;stochastic counterparts;pareto frontier;rm;exploration;single algorithm;\ufb01xed budget;\ufb01xed horizon;bai;algorithm;bartlett;best arm identi\ufb01cation;yadkori;\ufb01rst;valko;trade;iii;abbasi;references;gabillon;malek"}, "6b3fa9157a8120a6eb86ae06a93611a1fcd9e219": {"ta_keywords": "soft database;particular soft database;hard database;soft information sources;unknown hard database;structured information;databases;hardening problem;hardening;hard fact;noisy version;local optimum;object identi ers;duplication;many cases;linear time algorithm;many sources;optimization problem;evidence;key feature;inconsistencies;approach;problem;lack;account", "pdf_keywords": ""}, "ef9ddbc35676ce8ffc2a8067044473727839dbac": {"ta_keywords": "neural language models;softmax;softmax bottleneck;word embeddings;practice softmax;language modeling;penn treebank;matrix factorization problem;natural language;expressiveness;models;context;enough capacity;majority;art perplexities;state;issue;effective method", "pdf_keywords": "aforementioned softmax;softmax;recurrent language models;softmaxes;recurrent language model;softmax bottleneck;neural language models;rank rnn language model;language modeling;matrix factorization;matrix factorization problem;discrete latent variables;expressiveness;models;penn treebank;ruslan salakhutdinov;mixture;majority;abstract;standard formulation;iclr;state;mos;conference paper;computer science carnegie mellon university;perspective;art perplexities;work;probability distribution;issue"}, "d29f155060f96becef0247ee77dc038f96b2d983": {"ta_keywords": "speech translation system;translation processing time;translation speed;conventional speech translation systems;machine translation module;translation unit;base translation;translation;large delay;utterance;phrase table;lectures;real time;phrase;synthesis;simultaneity;accuracy;begining;content;time;news;research;end;effect;method", "pdf_keywords": ""}, "d415b724fbc35afcc8dd91738123edfa6a5db634": {"ta_keywords": "deep policy gradients;trust region policy optimization;deep policy gradient;proximal policy optimization;level optimizations;cumulative reward;algorithm augmentations;algorithmic progress;such optimizations;agent behavior;popular algorithms;rl methods;core algorithm;implementations;secondary importance;code;gain;implementation matters;trpo;auxiliary details;ppo;consequences;major impact;case study;results;roots", "pdf_keywords": "trust region policy optimization;deep policy gradient methods;deep policy gradients;deep policy gradient;deep reinforcement learning;proximal policy optimization;popular deep policy;gradient methods;cumulative reward;reward;performance gains;algorithmic progress;rl methods;popular algorithms;iclr;algorithmic properties;algorithmic behavior;agent behavior;importance;gain;agents;insights;case study on ppo;trpo;underpinnings;dimitris tsipras1;ppo;mechanisms;terms;implementation"}, "3315dee45b1edb8f8286816629de7b8c31d270d6": {"ta_keywords": "political information search;social cues;affect influence;search behavior;political judgments;simple social signals;information search strategies;social influences;voting task;social environments;information;search;neutral information environment;participants;different patterns;subjects;evaluation;items;many other people;control group;paper;fact condition;different types", "pdf_keywords": ""}, "387754dc8d4185fadd7c3c15e43956a4d085e8fe": {"ta_keywords": "nearest neighbor search;permutation search methods;true nearest neighbors;faster search;permutation methods;retrieval;proximity;permutation;distance;permutations;art benchmarks;large data;data points;data point;pivots;tree;textual domain;graph;list;tiny subset;query;image;point;original points;good proxy;extensive experimental evaluation;vp;variety;methods;state", "pdf_keywords": "highaccuracy retrieval methods;retrieval;recall;napp implementation;proximity;tunning algorithm;generic spaces;napp;competitive benchmark;baseline methods;tree;mplsh;graph;implementation;panels 4a;focus;versions;vp;4b;art implementation;current publication;state"}, "60a121c55b5144bfe3aef5b6ea8959a9f6dd12ae": {"ta_keywords": "multiple speech enhancement algorithms;speech enhancement;ensemble learning framework;noisy mixture;clean speech;frequency mask;classification;continuous masks;binary masks;various algorithms;algorithms;prediction;countless algorithms;different algorithms;regression;various machine;several approaches;context;outputs;various notions;possibility;different qualities;time;system;problem;assumption;first example;years;different flaws;strengths", "pdf_keywords": ""}, "ba56bb1eb67b188a89060058ef8ad02ce3c660ac": {"ta_keywords": "asian translation;3rd workshop;wat2016;proceedings", "pdf_keywords": ""}, "9fc33c53d1f59aa9fd7f1b642c3859900865b0e3": {"ta_keywords": "hyponym data;large collection;table;representing semi;web;dimensional representation;primitive operations;representation;many purposes;paper;small number;methods", "pdf_keywords": ""}, "d7729f2ff21f97d56d10c54adc1f1f5ffbec9e5c": {"ta_keywords": "oral leukoplakia;oral premalignant lesions;diode laser;leukoplakia;different lasers;lasers;surgical excision;different surgical techniques;erythroplakia;different surgicaltechniques;malignant transformation;treatment;scalpels;treatment modality;various studies;present study;effective outcomes;potential advantages;application;management;effective results;potential;recurrence;authors;management challenge", "pdf_keywords": ""}, "649eb9fd9a18f9601270b7fcde8d6548bfc6ec75": {"ta_keywords": "speaker speech recognition;speech separation;automatic speech recognition model;speech mixture;wsj corpus;individual attention module;mixed speech;speech;recognition benchmark;multiple label sequences;speaker;corresponding label sequences;end model;2mix dataset;streams;end framework;end;cer;sampling;model;labels;wer;system;performance;state;alignments;relative performance gains;contrast;indeterminate supervisions;scratch", "pdf_keywords": "end speech recognition model;end multispeaker speech recognition system;automatic speech recognition model;speech separation;wsj corpus;individual attention module;end model;recognition benchmark;mixed speech;speaker;speech;decoder;connectionist temporal classi\ufb01cation;encoder;decoder framework;attention;streams;2mix dataset;end;art end;model;cer;joint ctc;ctc;alignment ability;wer;state;performance;aim;sampling"}, "5884948777dfc003ba49e1513420830616281839": {"ta_keywords": "bilingual lexicon induction;unified multilingual representations;multilingual bert;monolingual representations;muse;benchmark;representations;direct comparisons;conll;such representations;relative performance;alignment;joint training;task;comparative study;simple unified framework;empirical results;bli;main paradigms;extensive experiments;space;cons;existing methods;pros;set;approaches;paper;art results;methods;limitations", "pdf_keywords": "bilingual lexicon induction;multilingual representations;uni\ufb01ed multilingual representations;monolingual representations;jaime carbonell language technologies institute;learning;joint training;benchmark;muse;comparative study;text;ziruiw;relative performance;yiming yang;such representations;simple unified framework;iclr;alignment;taskdependent;ruochen xu;jiatengx;bli;empirical results;accuracy;ruochenx;gneubig;main paradigms;extensive experiments;rcsls baseline;existing methods"}, "56bc2a1eebedab3e452a7ca3969aa1e4dd5946c3": {"ta_keywords": "influential node mining;influence maximization;node diversity;diversified im;diversification;influence spread;community detection results;average similarity;utility maximization;diversity;nodes;ranking;other natural heuristics;approximation algorithms;node;economics;reverse measure;optimization problem;perfect substitutes;im framework;factors;cobb;utilities;im;douglas;traditional im;experimental results;paper;perfect complements", "pdf_keywords": ""}, "af0adbaa0c1ea6abaed4b3d21f1dc4121c35fb30": {"ta_keywords": "current communicative agents;shot language coordination;human communication;communicative goal;language abilities;communication;conversational partners;referential game;better communication performance;different linguistic abilities;language navigation task;selfplay;unseen agents;agents;mental states;listeners;mind;speaker;lead agent;speakers;tom modeling;task;socio;ability;tom;partner;experiments;hypothesis;effect;reactions", "pdf_keywords": "shot language coordination;multilingual referential games;language navigation task;language abilities;referential game;current communicative agents;language navigation;referential games;language production;language comprehension;computational pragmatics;different linguistic abilities;better communication performance;conversational partners;unseen agents;recursive fashion;agents;selfplay;mind;actions;task;vision;lead agent;example;tom modeling;second levels;rsa models;real time;tom model;ability"}, "3c57a1aa483d8bffe1339914b80d2913f2dc8376": {"ta_keywords": "generative adversarial networks;good semisupervised learning;bad gan;gans;discriminator objective;good generator;discriminator;good semi;bad generator;preferred generator;generator;joint training;strong empirical results;definition;same time", "pdf_keywords": "categorical generative adversarial networks;gans;gan;standard gan;catgan;discriminator;generator objectives;binary discriminator;complement generator;multiple benchmark datasets2;generator;unlabeled data;feature;feature space;generator distribution;correct decision boundaries;high densities;target distribution;low densities;art results;true distribution;ssl;kl divergence;trains;idea;data points;density areas;novel formulation;information;mild assumptions"}, "866f231970f93f4a201febc2fb46aff06f501e4b": {"ta_keywords": "normalizing words;modern word forms;historical language data;historical spelling;normalization;modern language;lexicon lookup;rule entries;modernization;high german;forms;interactive way;new input;mapping;guidelines;early new;tool;set;rules;different modules;paper;case studies;work", "pdf_keywords": ""}, "4d96ec46cda5d3b223fc7d33a920ab85864ea36d": {"ta_keywords": "proteins;protein annotation;amino acid sequence;amino acid sequences;divergent protein families;copper oxygen reductase;copper oxygen reductases;neural descriptions;unique sequence features;homologous proteins;type oxygen reductases;deep learning architecture;nitrogenases;model introspection;neural networks;large datasets;find;genomic sequence;hco;neural attention mechanism;cytochrome bd;function identification;biochemical capability;model;sequence characteristics;features;important features;molecular level;primary sequence;patterns", "pdf_keywords": ""}, "6c170fe3fec5a477c938d07fa00935bb6f7b87cc": {"ta_keywords": "voice conversion;speech synthesis;individual joint speech feature vectors;individual speech features;quality speech;gaussian mixture model;rich context models;natural speech;covariance acoustic models;speech;flexible hidden markov model;original hmm;unit selection synthesis;original gmm;model adaptation;mixture;synthesis;conventional gmmbased vc;gmm;rich context;novel statistical sample;formulation;text;statistical sample;quality;vc;tts;promising flexibility;paper;flexibility", "pdf_keywords": ""}, "adac290d72c86c186837a884aae922bee4dee684": {"ta_keywords": "more reading difficulty;human reading;human readers;misspelling;misspellings;unimpaired comprehension;letter transpositions;error words;reading times;more natural errors;error rate effect;unexpected letter combinations;error rates;words;upcoming words;eye;correct words;surprisal;transpositions;error types;character;errors;effect;presence;results;traditional word;tracking study;computational model;context;paper", "pdf_keywords": "human reading;human reading times;reading experiment;reading;high error rate degrades word context;texts;text;misspellings;rare letter sequences;more reading dif\ufb01culty;tracking experiment;eye;error rate;input;character;experimental results;computational model;transpositions;experiment;surprisal;surprisal model;behavior;expectations;effect;results;higher surprisal;aim;errors;traditional word;paper"}, "23918ed366c60ae0ef85b0c80def63127f035e02": {"ta_keywords": "edge device;cloud;dnn accuracy;shredder;edge;offline learning phase;mobile gpu;noisy intermediate data;network;populated noise tensor;noise tensor;privacy;lte;world dnns;inference accuracy;text processing;speedup;accuracy;additive noise distributions;data;accurate inference;wi;image classification shows;end framework;paper;tradeoff;model;training process;inference;end", "pdf_keywords": ""}, "e7e1f5a713d20cdf31e732022731fdf0d8fb4fc5": {"ta_keywords": "supervised sentence pair classification;natural language inference;sentence tagging;anchor explanations;sentences;simple lstm architecture;classifiers;explanations;nli;level explanations;text;training data;token;predictions;shot;pairs;single piece;task;novel extension;attempts;paper;purpose;approach;lime;need;lot;work", "pdf_keywords": "neural entailment model;attention;attention thresholding approach;sentence tagging;anchor explanations;attention matrix;supervised baseline;independent sentence encoding;simple neural architecture;explanations;box multiple instance learning;level explanations;entailment relation;hypothesis explanations;nli;anchors;tokens;human judgments;shot;box methods;mil regularizers;box method;addition;mil;lime;novel extension;method;complex architectures;paper;approach"}, "37ef7941909527aaf123d7b8f90adbf4606f4917": {"ta_keywords": "gibbs sampling;speech tags;infinite hmm;nlp;machine learning algorithm;gibbs;newswire text;iterative;probabilistic model;runtime performance;instance;dynamic program;implementations;iteration duration;model;part;paper;unsupervised fashion;step;debugging;development;study;ease;parameters;relevant scores;deployment;focus", "pdf_keywords": ""}, "58e5ce12c23f815e9b394220044eaf99b28cfffe": {"ta_keywords": "crisis information;language processing;workshop;proceedings", "pdf_keywords": ""}, "cf2fcb73e2effff29ceb5a5b89bbca34d2d27c1a": {"ta_keywords": "deceptive attention masks;attention weights;attention mechanisms;attention;interpretability;accountability;predictive accuracy;explanations;gender minorities;neural architectures;training models;natural language processing;predictions;gender;fairness;models;impermissible tokens;insights;people;context;decisions;human study;model;results;features;algorithms;stakeholders;question;tool;reliability", "pdf_keywords": "deceptive attention masks;attention weights;attention;attention mechanisms;interpretability;little attention;explanations;predictive accuracy;neural architectures;natural language processing;training models;gender minorities;predictions;fairness;models;insights;gender;simple training scheme;prediction;people;context;stakeholders;gneubig;model;decisions;impermissible tokens;human study;results;tool;features"}, "79655bfc45039b4d7cfe6cc86d52a4ced492f43a": {"ta_keywords": "trec web adhoc collection;rank methods;relevance signals;web track adhoc task;specific relevance signals;trec data set;learning;usefulness;new signals;statistical methods;performance;large test data;enough queries;definitive conclusions;par;formula;hand;turn;same set;limitation", "pdf_keywords": ""}, "5c3cc301a892094d5bfca3c41a78a3a8ebd755f8": {"ta_keywords": "multiple additive regression trees;regression trees;high prediction accuracy;dropouts;ensemble model;classification tasks;employing dropouts;deep neural networks;prediction;trees;diverse tasks;regression;dart;available datasets;tool;shrinkage;few instances;specialization;large scale;later iterations;instances;tasks;negligible contribution;significant margin;mart;certain extent;work;practice;context;fundamental issue", "pdf_keywords": "deep neural networks;employing dropouts;random forest;dart;dart algorithm;classi\ufb01cation tasks;available datasets;specialization;tasks;large scale;tool;mart;regression;results;novel way;considerable extent;work;context;issue;section;signi\ufb01cant margin;problem;di\ufb00erent approach;signi\ufb01cant margins"}, "9eecfdb7c8ad9af4f3863e9f6ed857211fb710e7": {"ta_keywords": "explanation generation;natural language explanations;novel explanation system;language explanations;language argumentation interface;explanation system;salient explanations;academic advising;explanation logic;markov decision processes;markov decision process;policy presents;mdp policies;knowledge engineers;additional effort;mdp;optimal policy;trust;model builders;english;incremental upgrades;utility;actions;research;real time;applications;action;user;psychology;system", "pdf_keywords": ""}, "dfd8fc9966ca8ec5c8bdc2dfc94099285f0e07a9": {"ta_keywords": "privacy preserving text generation;same empirical privacy guarantee;empirical privacy risk;privacy;private mechanisms;real text classification datasets;nearest neighbor;nearest neighbor selection criterion;common benchmark;utility;text generation;utility tradeoff;vickrey auction;second nearest neighbors;empirical measurement framework;input words;utilitarian approach;different distance metrics;output word;second highest price;novel class;noise;highest price;tuning parameter;class;experiments;choice;input;mechanisms;traditional mechanisms", "pdf_keywords": "privacy preserving text generation;privacy;private mechanisms;nearest neighbor;natural generalization;random selection;second nearest neighbor;nearest neighbors;vickrey auction;generalizing vickrey mechanism;second nearest neighbors;text generation;utility tradeoff;selection;algorithm;common benchmark;input words;utilitarian approach;noise;vickrey mechanism;second highest price;tuning parameter;zekun xu amazon seattle;output word;feyisetan amazon;mechanisms;empirical measurement framework;different distance metrics;highest price;input"}, "e8c4a4e81084e17b0c71a6a69bdf1e4e2b6f6af1": {"ta_keywords": "speech separation;speech data;multiple sequential sources;many sequence transduction problems;single output sequence;mixture signals;speaker speech recognition;sequence models;neural sequence;single input sequence;output sequences;mixture sequence;conditional chain mapping;multiple sources;sound waves;transduction;superposition principle;sequence;efficient stop criterion;several different tasks;consistent improvements;model;mapping;primary test field;end;variable number;methods;nature;experiments;work", "pdf_keywords": "speech separation;multispeaker speech recognition;multiple output sequences;many sequence transduction problem;conditional chain model;multiple sequences;conditional chain;sequence model;mixture signals;general machine learning framework;other sequence;probabilistic chain rule;recognition;explicit modeling;standard sequence;serial mapping;multi;speci\ufb01c tasks;model;parallel mapping;consistent improvements;relevance;terms;uni\ufb01ed method;condchain;clarity;conclusions;model size;negligible increase;work"}, "59121b847fd7eb4cf92cbfccb54f1705733d8b65": {"ta_keywords": "reverberant speech;automatic speech recognition;reverberation;novel model adaptation scheme;adaptive training;acoustic model;variance compensation;gaussian variances;dereverberation preprocessing;dereverberation method;speech;dereverberation;dynamic mismatches;noise;recognition;variances;performance;dynamic components;less attention;appropriate interconnection;parametric representation;contrast;chapter;presence;order;problem", "pdf_keywords": ""}, "cec37cd54a940bec818db7216cc1086672f3fec0": {"ta_keywords": "sense inventory induction;duplicate synsets;sense inventory alignment;synsets;such synsets;crowdsourcing;lexical substitutions;inventory;broader lntersectlon;words;concepts;russian language;topical problem;beoristics;set;mistakes;experiments;approach;number;methods;problem", "pdf_keywords": ""}, "fa10752ab1768d1633001420b48be5e2518a4f80": {"ta_keywords": "inconsistency;data;experimental results", "pdf_keywords": ""}, "9fcfbc662d4095d72eb9a4e1c4f5ae8f0ffc4222": {"ta_keywords": "vivo thermal imaging studies;thermal imaging;thermal dehydration measurement;optical coherence tomography;porous lesion areas;natural lesion activity;lesion activity;water diffusion;lesion severity;teeth;enamel;secondary lesions;dehydration;water evaporation;dehydration rates;temperature change;fluid permeability;root surfaces;future studies;oct;rate;\u03bcct;increase;structure", "pdf_keywords": ""}, "5801974fcebc11b4a8085fb02e77f792454caf7c": {"ta_keywords": "social skills training;social skills trainer;social skills;social skill;social interaction;dialogue system;autistic traits;user speech;computer interaction;skill;human anxiety;virtual avatar;speech;language features;language information;feedback;application show;experimental evaluation;effect;system;features;most participants;users;process;method;minutes;relationship;additional experiments;paper;discomfort", "pdf_keywords": ""}, "20f166f7809d1af9065cd1c71ec1e38d5d92993f": {"ta_keywords": "deep reinforcement learners;deep reinforcement learning;learned reward;catastrophic states;many practical reinforcement learning problems;optimal policy visits;intrinsic fear;imminent catastrophe;periodic catastrophes;policies;new policy;supervised learning;average return;objective yields;same average return;toy problems;guards;probability;strong assumptions;states;approach;paper;theoretical analysis;weaker assumptions;second model", "pdf_keywords": ""}, "c43d9d868f5288738cd625d365f0b3a5c18d4a20": {"ta_keywords": "simultaneous interpretation corpus;professional simultaneous interpreters;interpreter experience;simultaneous interpretation data;interpreters;corpus;translation data;interpretation results;speech;english;particular talk;text;subjective qualities;nara institute;time constraints;differences;results;naist;experience;different levels;data;technology;main features;different amounts;chapter;science;others;effect", "pdf_keywords": ""}, "3be5e7310b1bec9b4431ad0f1264f536b6a39f14": {"ta_keywords": "level machine translation models;translation quality;movie subtitles;level translation;such characterlevel models;pivot language;untranslated words;translation;character alignment;phrase table filtering;noisy datasets;limited training data;pivot;sparse;character;bleu points;improvements;analysis;paper;number;experiments;case;use;impact;bitext size;choice", "pdf_keywords": "level machine translation models;translation models;translation quality;translation setups;level translation;pivot language;movie subtitles;translation;character alignment;phrase table pruning;synthetic training data;noisy datasets;linguistics;phrase table \ufb01ltering;level smt models;pivot;character;sparse;manual evaluation;bleu;preslav nakov qatar computing research institute;multiple pivots;data size;human judgments;qatar;uppsala university uppsala;philology;analysis;qatar foundation;generation"}, "6e7e095f46deb297713dcde05991faf635768d29": {"ta_keywords": "algorithmic fairness researchers;fairness research;algorithmic fairness frameworks;racial inequality;racial categories;critical race theory;race;sociological work;sociotechnical systems;way race;ethnicity;social survey research;social processes;biomedical research;conceptualization;conceptualizations;attribute;history;public health;perspectives;processes;multidimensionality;nature;work;account;current methodologies;lessons", "pdf_keywords": "algorithmic fairness researchers;fairness research;algorithmic fairness literature;algorithmic fairness methodologies;racial categories;eugenics;race;sociology;critical race theory;social inequality;sociological work;ethnicity;public health research;social survey research;biomedical research;category creation;disciplines;public health;other disciplines;classi\ufb01cation;professional topics;history;inequality;computing;studies;conceptualizations;limitations;ccs concepts;histories;long histories"}, "4d10d7c02ce01d71f11c296b09b389c6f20b354b": {"ta_keywords": "public crowdsourcing marketplaces;crowdsourcing practice;crowdsourcing;largest crowdsourcing marketplaces;efficient data labeling;efficient label collection;data labeling;real label collection tasks;label collection project;labeling process;efficient aggregation;crowd performers;incremental relabeling;aggregation;participants;pricing;dynamic pricing;attendees;yandex;world tasks;project;unique industry experience;researchers;long research;portion;key components;industrial expertise;engineers;tutorial;applicability", "pdf_keywords": ""}, "191169031c7646c02ecb1aaa9c8a6b6e05009730": {"ta_keywords": "graphene oxide;graphene film;hollow graphene spheres;graphene sheets;high dielectric loss;average dielectric loss tangent;rgo;electromagnetic absorption;average shielding effectiveness;prepared rgo;defects synergetic enhancement;ng film;ng;ni;electrostatic self;catalyzed crystallization;thickness;ghz;synergetic effect;metal;go;situ synthesis;gf;\u03bcm;order;ser;se reflection;range;se;means", "pdf_keywords": ""}, "19b6e7158ee4f13caa004a0b6c6a6e0ef965ea8f": {"ta_keywords": "robust speech recognition;robust automatic speech recognition;chime challenges;chime challenge series;chime series;recognition development;art discriminative acoustic;training data simulation;remarkable robustness;system training;language modelling techniques;speech;datasets;simulated data;statistical modelling;multicondition training;signal processing;everyday environments;data;multichannel enhancement;tasks;chapter;novel approaches;interface;systems;description;evaluation;overview;state;use", "pdf_keywords": ""}, "53f6c82035d43a19b9c8be0de651cae25bdd4bda": {"ta_keywords": "automatic speech recognition results;clean transcriptstyle text;transcripts;transcript;automatic transformation;disfluency deletion;finite state transducers;disfluencies;style language;wfst;words;style transformation;transformation;other wfst;wfsts;best system;colloquial expressions;substitutions;log;word;features;evaluation;insertion;channel model;easy combination;deletion;systems;system;linear framework;integration", "pdf_keywords": ""}, "821532ecef5bc2252823b190c35f1e4c44ddc41c": {"ta_keywords": "parallel corpora;word alignment;translation lexicons;word embeddings;word alignment task;parallel text;language models;translation outputs;language processing tools;alignment quality;alignments;parallel data;embeddings;automatic evaluation;unsupervised learning;explicit training;lms;models;other work;competitive results;objectives;paper;fine;great majority;approaches;absence;past work;wide variety;attractive alternative;applications", "pdf_keywords": "multilingual word aligners;parallel corpora;word alignment;translation lexicons;language processing tools;language pairs;parallel text;translation outputs;different language pairs;alignment quality;alignments;graham neubig language technologies institute;embeddings;automatic evaluation;lms;good performance;models;robust performance;yi dou;zi;\ufb01ne;aug;objectives;valuable tool;ofthe;addition;fine;paper;carnegie mellon university;approaches"}, "2b4edb9515a26561ea3f9ee2a63a506721c8369e": {"ta_keywords": "aspect prediction;aspect sentiments;sentiment analysis;peer reviews;aspect;scientific reviews;aspects;sentiments;machine learning;reviewers;reviews;certain aspects;active learning framework;comments;review;8k reviews;experts;training dataset;useful information;final recommendation;intriguing observation;dataset;final decision;editors;top conferences;information;iclr;disagreement;entire dataset;decision", "pdf_keywords": "aspect prediction;latent aspect sentiments;annotation framework;review sentences;sentiment analysis;aspects;aspect;peer review text;sentiment;scientific reviews;tier machine learning conferences;active learning framework;machine learning;sentiments;scientific papers;training dataset;sentence;usefulness;dataset;acl conferences;abstract;conclusion;iclr;detailed analysis;entire dataset;top conferences;8k reviews;papers;technology;animesh mukherjee"}, "f6d6c4dd0115386c234a0b027dd38f7aa9d9df2f": {"ta_keywords": "endangered languages documentation;more nlp practitioners;current nlp approaches;language documentation;documentary linguists;specific nlp tasks;nlp;language communities;challenges;revitalization;tools;understanding;impact;limitations;capabilities;needs;tutorial;ultimate goal;process;important direction;domain;attendees;order", "pdf_keywords": ""}, "31c53acd2a43dcec4342d9c42d0ffbfbef36e855": {"ta_keywords": "label shift estimation;label distribution;label shift;cifar10 image recognition datasets;classifier;label;mlls;calibration;synthetic data;coarse calibration;miscalibration;calibration method;likelihood;confusion matrix;confusion matrix invertibility condition;estimation error;conditional probabilities;estimator;information;data;class;loss;mnist;unified view;first theoretical characterization;statistical inefficiency;source;sample error;consistency;target domains", "pdf_keywords": "label shift estimation;label shift;label;mlls;various estimators;shelf predictors;interpretable error bounds;shift magnitudes;estimation error;distribution matching;data science;datasets;statistics;miscalibration;calibration;class;classi\ufb01er;calibration method;saurabh garg;\ufb01rst theoretical characterization;confusion matrices;uni\ufb01ed view;optimization objective;various target;dataset sizes;bcts calibration;figure;confusion matrix invertibility condition;consistency conditions;terms"}, "ccfaccf36b9cd7c0c05af2285ec90ecf5f51a34c": {"ta_keywords": "optimal relay locations;optimal relay location;relay channel;optimal power allocation;relay nodes;multiple relay case;relay node;total power constraint;single relay case;individual power constraints;relays;loss channel models;optimal capacity;optimal placement;destination node;node placement;optimization problem;theoretic achievable rate formulas;network;exponential path;law path;source node;destination;power;loss model;exponential;information;explicit formulas;loss;attenuation", "pdf_keywords": ""}, "d8d12c922fc571d081bae27c67fcf50cdbb17d90": {"ta_keywords": "historical text summarisation;standard text summarisation dataset;summarisation model;corresponding modern language;historians;digital humanities researchers;chinese news;parallel data;documents;language;historical forms;chinese;hundreds;techniques;art algorithms;important routine;task;years;quality gold;state", "pdf_keywords": "modern language summarisation task;standard text summarisation dataset;historical text summarisation;historical text;corresponding modern language;modern language;modern languages;chinese news;human evaluations;language;historical forms;documents;china knowledge media institute;chinese;dataset;historic;hundreds;transfer;task;beihang university;xutan peng yi zheng chenghua lin;abstract;years;distinctness;approach outperforms;quality gold;engineering;computer science;jan;value"}, "c4607387ee863d5c5e5dc9f8adfbe7930508e286": {"ta_keywords": "international machine learning society;machine learning journal;machine learning;icml;25th international conference;best paper;year best paper;imls;best application paper;23rd international conference;awards;annual conference;paper awards;best student paper;uai;conference;papers;conferences;workshops;colt;year;proceedings;discussion;field;current research;overlap day;respective workshop chairs;volume;presentation;part", "pdf_keywords": ""}, "7f4fa7c6f16f2965a104fa45071ea0c92b4366fe": {"ta_keywords": "lamina emergent joint;stiffness;origami;tenon structure;mortise", "pdf_keywords": ""}, "7634b0cf93169d2a95d4d7193f47f97a61e3b4b2": {"ta_keywords": "eliciting distinguishable behavior;diagnostic games;markov decision processes;player traits;prospect theory;distinguishable behavior;human behavior;games;machine learning systems;mutual information maximization problem;game design;latent psychological traits;behavior;players;different traits;human;task;ability;approach;ones;large margin;framework;paper", "pdf_keywords": "diagnostic game design framework;diagnostic games;markov decision processes;games;heuristics;mutual information maximization problem;prospect theory;mutual information;distinguishable behavior;game space;player traits;optimization;player space;reward;more distinctive behaviors;behavior;interaction model;general framework;task;designs;various applications;1a;framework;effectiveness;paper;speci\ufb01c ones;domain"}, "1ccf412212873ae1b020762b8b86291e1fb11f65": {"ta_keywords": "crowdsourced audio transcription;crowdsourcing;novel aggregation methods;benchmark datasets;aggregation methods;efficient data collection;principled aggregation methods;speech recognition;crowdspeech;training data;data collection;data collection pipeline;machine learning systems;better algorithms;benchmarks;data;image classification;voxdiy;specific data;evaluation;improvement;code;standard tools;advances;advanced applications;complex tasks;various insights;work;modalities;domain", "pdf_keywords": "crowdsourced audio transcriptions;audio annotations;audio transcriptions;voice assistants;datasets;speech recognition;alexa;crowdspeech;data collection pipeline;voxdiy;data collection;accessibility tools;pipeline;siri;language;scale dataset;novel domain;russian language;principled pipeline;code;domains;counterpart;applications;applicability;various areas;full replication;centers;various insights;introduction;important research problem"}, "3ba529f732d3c4a31e9ce57f1c78ddf911846bf4": {"ta_keywords": "recent weak supervision;weak supervision sources;noisy supervision sources;labeling training data;sequence tagging;labels;ws datasets;benchmark platform;datasets;ws evaluation;extensive comparisons;popular ws methods;classification;wrench;standardized evaluation;world datasets;bottleneck;ws approaches;machine;source;implementations;ws;challenge;method variants;approaches;terms;base data;extensible framework;range;custom", "pdf_keywords": "bio tagging schema;bio tagging scheme;wrench;label model;io;source initiative;performance;community;previous studies"}, "64bc7fe1c46c4d4106afba4621ff1bd4376c077a": {"ta_keywords": "electrolaryngeal speech enhancement;noise reduction;statistical excitation prediction;evaluation;hybrid approach;information science;nara institute;technology;ikoma;cho;science;takayama;shi", "pdf_keywords": ""}, "04db62a14f78f693d6bd14a4803b9b73325b36bb": {"ta_keywords": "fake news detection;external knowledge graph;knowledge graphs;single knowledge graph;news content;news items;news item;link prediction;fake news;entity prediction;textual content;subgraph classification task;subgraph;entities;knowledge;counterpart methods;relations;new concepts;social context;thousands;multiple datasets;algorithm;recent years;various types;level information;work;open research questions;approaches;much progress;significant damage", "pdf_keywords": "fake news detection;single knowledge graph;external knowledge graph;subgraph classification task;news item;textual content;subgraph;knowledge enhanced multi;fake news;knowledge;entities;classification;social context;relations;neural networks;learning;ccs concepts;information systems;computing;abstract;various types;work;recent years;ling luo;school;shanika karunasekera;university;yi han;contributions;si"}, "9bd6cdae71506eb307507e44df7abe0c285b3ca7": {"ta_keywords": "neural attentional machine translation models;statistical machine translation;neural mt reranking;asian translation;neural models;grammatical correctness;objective evaluation measures;content words;manual evaluation;lexical choice;reranking component;syntax;improvements;improvement;bleu;results;nara institute;naist;addition;output;large gain;main contributions;increase;previous work;first time;workshop;submission;technology;experiments;science", "pdf_keywords": "neural mt reranking framework;neural mt reranker;neural mt reranking;machine translation system;target sentence;general reordering;correct grammatical structure;baseline syntax;improvements;sentence;phrases;accuracy gains;languages;insertion;accuracy;unique hypotheses;errors;verb agreement;transfer;copulas;coordinate structures;examples;results;best list;conclusion;\ufb01rst subcategory;table;degradations;log;prominent gains"}, "e0a0b3438aef008fece5b8bbf76105b470f10f25": {"ta_keywords": "convertible codes;coded data;distributed storage;efficient conversion", "pdf_keywords": ""}, "1817c9f0fd8a17e31c65963dd8cee9783059495b": {"ta_keywords": "controllable text content manipulation", "pdf_keywords": ""}, "167adafac25ee108ca99c688cceded8bca710bb1": {"ta_keywords": "size constancy;size judgment;ages;constancy;age level;age;different distances;measurement techniques;experiments;size;distance;stimuli;comparison;experimental methodology;evidence;studies;data;variations;inconsistent data;shape;theory;range;such relationship;various investigators;point;function;direct confirmation;types;others;instructions", "pdf_keywords": ""}, "538466f2a69271617bf4f5b0df4e5fd854c11c35": {"ta_keywords": "group testing;complexity decoder;graph codes framework;group testing problem;graph codes;noisy test results;defective items;computational complexity;tests;robust framework;groups;judiciously group subsets;group;saffron;test;algorithm;items;high probability;order;minimum number;population;result;goal;systematic methodology;constant;presence;set", "pdf_keywords": "probabilistic group testing;group testing code design;group testing;graph codes;graph coding;sparse;computational complexity;ambient test population size;graph;robust framework;powerful density evolution techniques;saffron;density evolution;performance analysis;ing algorithm;paper;analysis;tools;defective items;order;kangwook lee;aug;powerful framework;framework;scale;dept;category;theoretic tools;theory;number"}, "7e358ffc2731a82420d84a7f0bedb155a487c39d": {"ta_keywords": "hop question composition;hop questions;new multihop qa dataset;hop datasets;unanswerable questions;hops;musique;minimal traintest leakage;composition;composition structures;datasets;reasoning steps;step;dataset;seed questions;multihop question;reasoning;context;previous step;answer;iii;process;ans;partial overlap;quality;ii;greater control;variable number", "pdf_keywords": "challenging multihop reading comprehension qa datasets;multihop qa datasets;new multihop qa dataset;hop question composition;multihop reasoning;new multihop qa;nlp community;multihop questions;new dataset construction approach;hop questions;musique;datasets;reasoning;reasoning step;ai;multihop benchmarks;multiple steps;models;new challenge;different composition structures;shortcuts;genuine multihop;composable pairs;information;elusive goal;approach;empirical analysis;evaluation;process;main contributions"}, "61cce75554a6d1bb802f26758c3b0ba97de6918d": {"ta_keywords": "graph attention networks;graph attentional networks;graph neural networks;graph context;graph locality;node classification tasks;positional embeddings;node classification;graph;nodes;node;positional encoding;positional information;gnns;similar features;structural information;enhanced gat architecture;task;labels;gat;content information;transformers;gats;model;model predictive;work;full potential;pos;limitation;art performance", "pdf_keywords": "graph attention networks;graph attentional networks;node positional embeddings;attention computation;positional embeddings;positional embedding;node classi\ufb01cation task;positional information;positional encoding;graph;supervised task;node content information;nodes;node;semantic information;gat models;structural information;gat;joint training scheme;gats;transformers;pos model;contributions;pos;paper;end;toend training;conclusion;novel framework;framework"}, "b81acc013c42796a5eea0fc20cfb04846da3a589": {"ta_keywords": "purpose linguistic annotation backend;nlp tools;natural language processing;multilingual neural networks;corpus management;language documentation process;documentary linguists;language documentation;nlp;linguists;new languages;glossing;backend apis;training material;transcription;human involvement;new project;data;technology;interfaces;use;advances;extended abstract;questions;recent advances;beginnings;intensive process;methods;work;significant portion", "pdf_keywords": "purpose linguistic annotation backend;nlp tools;language documentation process;language documentation;natural language processing;multilingual neural networks;corpus management;documentary linguists;nlp;linguist;linguists;new languages;backend overview;glossing;backend apis;transcription;new project;interface;recent advances;data;introduction;technology;extended abstract;interfaces;data upload;current lab;use;chian;dec;beginnings"}, "398a0625e8707a0b41ac58eaec51e8feb87dd7cb": {"ta_keywords": "interactive learning;embodied environments;textworld;abstract knowledge;abstract plans;agents;alfworld;rich visual environment;text;actions;action sequences;simulator;creation;abstract terms;new butler agent;kitchen;scene;alfred benchmark;prototypicality;policies;humans;concrete;washed apple;efficiency;goals;success;infrastructure;limitation;kitchen fridge;question", "pdf_keywords": "interactive text environment;textworld;textual environment;abstraction;abstract language;textual space;unseen tasks;abstract text domain;semantic priors;agents;shot generalization;alfworld;tasks;better generalization;novel environments;demonstrations;novel butler agent;abstract polices;generalization;interaction;physical world;alfred dataset;reasoning;worlds;world;corpora;training;vision;particulars;scratch"}, "4f7bbcef3d40cafad17936fdf562a121667af1e8": {"ta_keywords": "vessel tree reconstruction;complete vessel trees;vector fields;blood flow pattern;standard vessel filters;flow orientations;new geometric regularization principle;arteries;divergence;veins;capillary details;real 3d volumes;regularization constraint;unsupervised method;prior knowledge;sign ambiguity;bifurcations;general idea;convergent;important example;quality", "pdf_keywords": "vessel tree reconstruction;divergence constraints;robust curvature regularization;divergence prior;new geometric regularization principle;vessel tree;standard vessel \ufb01lters;blood \ufb02ow pattern;tree reconstruction;regularization constraint;divergence;vessel;\ufb02ow orientations;nonzero divergence;arteries;veins;vector \ufb01elds;reconstruction;prior knowledge;sign ambiguity;bifurcations;convergent;yuri boykov;marin;western ontario;general idea;important example;egor chesakov;canada;zhongwen zhang"}, "0431f60546381a9e91fb156236c3c7056f57081f": {"ta_keywords": "singing voice synthesis;pitch augmentation;reasonable singing quality;different data augmentation methods;singing;public singing databases;augmentation methods;augmentation;better qualities;deep;training strategy;neural systems;training;mix;performance;limited public available training data;subjective evaluations;svs systems;methods;several strategies;systems;svs;conventional statistical parametric;extensive experiments;difficulty;work", "pdf_keywords": "different data augmentation methods;simple data augmentation techniques;pitch augmentation;public singing datasets;data augmentation policies;singing quality;augmentation methods;public singing databases;augmentation;lyrics information;limited training data;new training strategy;training strategy;svs systems;svs;mos performance improvement;svs network;training;performance;mix;music;subjective evaluations;synthetic quality;consistent predictor module;predictor module;up method;model;several strategies;ofuton;subjective tests"}, "dbe87b171bfb789e1d22a047aeeee69105e6fd02": {"ta_keywords": "t5 sentence embeddings;sentence embeddings;scalable sentence encoders;t5 encoder;sentence bert;full t5 encoder;text transformers;text models;semantic textual similarity;contrastive learning approach;decoder models;encoder;language tasks;decoder model;t5;sequence mapping problems;text;reimers;sentence;sequence;transfer tasks;models;sts;simcse;first exploration;impressive performance;gurevych;new state;stage;art", "pdf_keywords": "new sentence representation transfer benchmark;scalable sentence encoders;t5 sentence embeddings;sentence encoders;sentence transfer tasks;contrastive learning;sentence transfer;contrastive learning method;contrastive learning approach;sentence evaluation toolkit;contrastive loss;t5 encoder;full t5 encoder;t5 sentence;encoder;tune st5;st5 models;text models;st5;decoder sentence;decoder;sentglue;text;t5;decoder model;token representations;transfer performance;benchmark;tuning \ufb01rst;sentence"}, "95788ed8affd06c0c2c6159c26ff7c123c4f2e0a": {"ta_keywords": "neural speaker diarization;end speaker diarization methods;neural diarization;speech activity;speaker;speaker issue;diarization error rate;novel speaker;speech activities;other speakers;diarization results;speakers;probabilistic chain rule;wise conditional inference method;eend;single random variable;wise chain rule;state;variable number;art end;method;end;number;paper;terms;art performance;experimental results", "pdf_keywords": "end speaker diarization methods;speaker scenarios;neural diarization method;speaker;speaker issue;diarization error rate;novel speaker;wise conditional inference method;diarization results;speakers;conventional eend method;probabilistic chain rule;variable number;method;conclusions;extension;end;state;terms;paper;\ufb01xed number;art;experimental results"}, "84908a28a03d0d7c467d9556ed36f0e416de7171": {"ta_keywords": "semantic parsing;utterances;utterance;free grammars;grammars;computer algorithm;extended context;recognition;algorithm;meaning description;novel algorithm;expert;machine;system;goal;data;article;problem;hybrid combination;approaches;key idea", "pdf_keywords": ""}, "b46be3ac246499655cc442e93c5878e7a9640ae3": {"ta_keywords": "timeline construction;temporally related story sequences;timelines;timeline;news interfaces;previous events;related events;tree edit distance measure;saga;sagas;many events;episodes;longrunning series;news;recent information;concrete representation;context;unsupervised methods;task;explicit representation;performance;hand;problem", "pdf_keywords": ""}, "8da992b611df508b1803f66ffa53bd1fb741a76c": {"ta_keywords": "challenging text generation task;reading comprehension datasets;answer hierarchies;generated qa hierarchies;question taxonomy;answer game;conditional neural language model;knowledge acquisition;questions;generating question;hierarchy;input document;input;answer pairs;student;specificity;specifics;teacher;question;labels;pipelined system;specific;strong empirical results;experiments;hintikka;process;paper;novel;squash;hakkarainen", "pdf_keywords": "challenging text generation task;novel text generation task;generated qa hierarchies;answer hierarchies;question taxonomy;reading comprehension datasets;conditional neural language model;general questions representative;hierarchy;modelgenerated hierarchy;questions;input document;generation;qa;span selection ner system;entire paragraphs;answer pairs;input;quac;tree structure;sequences;answer;labels;pipelined system;squad;paper;combination;system;modelling approaches;coqa"}, "2eea63f896deed47cc0c0000e1482ec5c860fd0b": {"ta_keywords": "controversy detection task;controversy detection;semantic information fusion graph convolutional network;sentiment information;controversial posts;comments information;social media;semantic information;news;views;social humanities sciences;widespread attention;topics;web information;influence;target post;world datasets;interpretable results;researchers;web;results;authenticity;structure relationship;mssf;important role;previous works;comprehensive experiments;computer science;gcn;reply", "pdf_keywords": ""}, "881ce19455a9923e4798e9d77d2d8623ca9d2e03": {"ta_keywords": "bayesian predictive classification;speech recognition;variational bayesian estimation;bayesian predictive distribution;data sparseness;total bayesian framework;sparse data problem;robust classification method;posterior distributions;predictive distribution;clustering;vbec;training effects;distribution;output distribution;vb;model parameters;bpc;student;others;analytical solution", "pdf_keywords": ""}, "6d9603be7e79ff33677327a0edd5bd3f7da6347b": {"ta_keywords": "\u968e\u5c64\u7684\u30d5\u30ec\u30fc\u30ba\u30d9\u30fc\u30b9\u7ffb\u8a33\u306b\u304a\u3051\u308b\u30d4\u30dc\u30c3\u30c8\u7ffb\u8a33\u624b\u6cd5\u306e\u5fdc\u7528;\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0;\u8a00\u8a9e\u7406\u89e3\u3068\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3", "pdf_keywords": ""}, "81af4e14050c410e2afee226be583088a9791ddf": {"ta_keywords": "unsupervised semantic role induction;argument embeddings;bias argument embeddings;simlex999 word similarity task;dependency relations;multiplicative representations;dependency roles;art embeddings;dependency role;context;multiplicative factors;neural model;dataset;model;qualitative results;work;state", "pdf_keywords": ""}, "ec99cf93ef22a0c0d669abe90c9509f642b2cf69": {"ta_keywords": "downsampling near semantic boundaries;adaptive sampling;good semantic segmentation;adaptive downsampling technique;semantic boundaries;efficient segmentation;segmentation;boundaries;target classes;size objects;locations;new content;better quality;accuracy;uniform;computational efficiency;auto;cost;performance analysis;processes;balance;method;critical component;rely;reliable support;problem", "pdf_keywords": "better segmentation quality;adaptive sampling;semantic boundaries;aware adaptive downsampling technique;uniform downsampling;adaptive downsampling technique;more pixels;segmentation;boundaries;ground truth;content;alternative content;new content;better quality;size objects;accuracy;target classes;neural network model;locations;uniform;costperformance analysis;fig;intuition;computational ef\ufb01ciency;balance;method;reliable support;problem"}, "48e8e8085907192d501eb2bcc582035e90431a2f": {"ta_keywords": "lingual sequence tagging;deep hierarchical recurrent neural network;sequence tagging;encode morphology;recurrent units;word levels;conditional random field layer;tags;sequence;context information;words;model;character;architecture;scratch;parameters;performance;various cases", "pdf_keywords": "lingual sequence tagging;sequence tagging;deep hierarchical recurrent neural network;tagging tasks;multiple languages;languages;recurrent units;pos tagging;crosslingual joint training;same language;spanish;english;sequence;different tasks;dutch;conditional random \ufb01elds;ner;joint training;same task;zhilin yang ruslan salakhutdinov william cohen school;model;\ufb01ve datasets;part;new model;scratch;aug;model parameters;network architecture;types;computer science carnegie mellon university"}, "5431098723db5858c4553f0259921cbbdd6492d5": {"ta_keywords": "translation initiative;different languages;translation memories;languages;particular languages;development data;localizers;virus;mt researchers;tools;resources;development;ai;testing;south asia;africa;collaborators;test;same data;east asia;tmxs;team;populations;access;spread;information;pairing;addition;south;order", "pdf_keywords": "coronavirus quarantine;coronavirus precautions;coronavirus outbreak;coronavirus cases;coronavirus news;coronavirus epidemic;novel coronavirus outbreak;coronavirus concerns;coronavirus crisis;coronavirus;coronavirus spread;coronavirus infection;coronavirus prevention;coronavirus exposure;new coronavirus;coronavirus protection;covid19 quarantine;coronavirus update;coronavirus medicines;covid outbreak;coronavirus pneumonia;coronavirus medicine;coronavirus disease;coronavirus alert;novel coronavirus infection;coronavirus patient;new coronavirus pneumonia;covid19 precautions;novel coronavirus;coronavirus incubation"}, "a72e732f2d11075aa0103b72b4f9884ddcaaaa85": {"ta_keywords": "inductive logic programming;polynomial learnability;efficient learnability;negative learnability results;logic programs;classes;restricted classes;useful techniques;practice;methods;last few years;such results;results;number;paper surveys", "pdf_keywords": ""}, "015dc5b71894dd4d05e7668d015e545ab2e162ba": {"ta_keywords": "source speech processing toolkit espnet;automatic speech recognition;espnet asr recipe;mean opinion score;other toolkits;toolkit;other latest toolkits;espnet;tts models;speech;ljspeech dataset;objective evaluation;transformer tts;tts;end text;asr;asr functions;e2e;experimental evaluation;learning;models;tacotron;kaldi;art e2e;extension;new end;fastspeech;high reproducibility;comparison;recipes", "pdf_keywords": "source speech processing toolkit espnet;speech toolkit;tts models;automatic speech recognition;espnet;espnet asr recipe;tts;end text;transformer tts;other latest toolkits;toolkit;speech;source end;e2e;2human dataware lab;tomoki toda1;new end;theart e2e;katsuki inoue4;asr;ljspeech dataset;tacotron;6google ai;ryuichi yamamoto3;extension;shinji watanabe5;asr functions;models;kaldi;integratable"}, "3122a2d7799ba585b993e432b3deb47659b3f3c1": {"ta_keywords": "form question answering;other text generation tasks;answer quality;task formulation;answers;human evaluations;paragraph;meaningful modeling progress;task;eli5 validation questions;lfqa;evaluation;form;documents;length answer;progress;many models;eli5;fundamental challenges;informative metric;form question;paper;significant train;training set;hurdles;question;dataset creation;system;validation overlap;detailed analysis", "pdf_keywords": "retrieval;retrievals;sparse attention;answer quality;eli5 lfqa dataset;human evaluation;contrastive retriever;task;performance;eli5;dataset;test folds;performance bounds;generation quality;documents;challenges;generation system;train;thorough analysis;inference time;validation;rouge;google cloud;usage;realm system;model;new system;hours;section;\ufb01nal models"}, "15d643f4c27d373aa46f26a760051e76fde81dc2": {"ta_keywords": "answer entities;question entities;question answering;end entity resolution;entity resolution;knowledge graphs;differentiable knowledge graphs;alone qa model;question text;weakly supervised dataset;er component;additional er component;e2e;models;model;training;er;end;kgqa;question;hand;boundaries;promising results;scope;runtime;work;setting", "pdf_keywords": "end entity resolution;entity resolution;question answering;entity resolution component;knowledge graphs;knowledge graph;answer entities vector y\u02c6;identi\ufb01es entities;differentiable knowledge graphs;weakly supervised dataset;intermediate annotations;inference module;end learning;machine translation;components end;end model;inference;answers;structured representation;components;end;data;models;conclusion;only questions;e2e;component;kgqa;model;entire chain"}, "5f9d8fe21efb3c2b241427869a333472ab09a22d": {"ta_keywords": "collaborative filtering;music;web", "pdf_keywords": ""}, "ea6547e877c1cc3d37229a6f488ac04e9a11de18": {"ta_keywords": "protein interfaces;best interface water predictions;interfacial water molecules;good docking performance;hotspot interface water positions;actual water positions;water positions;molecular mechanics force fields;colicin e2;immunity protein;protein;dnase domain;interactions;complexes;accurate modelling;protein portion;capri target;capri;complex;accuracy level;good models;blind predictions;predictions;recall fraction;determinant factor;contacts;optimization procedures;critical assessment;sampling;positions", "pdf_keywords": ""}, "fd1b59d22eb1fb32e0360d4fcbe58dc4ebb25af9": {"ta_keywords": "fake news detection;audio deepfakes;video deepfakes;fake content;cnn;text deepfakes;fakes;convolutional neural networks;deep neural networks;deepfakes;different deepfake categories;deep;detection;detection methods;more generation methods;dnn;few robust methods;human generation;shortcomings;generation;readers;recent trends;summary;main focus;domain;methods;research;full survey;paper;evaluation", "pdf_keywords": "audio deepfake generation;audio deepfake;audio deepfakes;video deepfakes;unconditional generative image modeling;image quality;stylegan;distribution quality metrics;2d images;recall;fid;generation;metrics;detection;full survey;precision;evaluation;art;clear need;survey;focus;version;data;results;majority;ppl;terms;methods;paper;framework"}, "86b91922923b03c66497accfa88c638299fc8d26": {"ta_keywords": "variational encoder;decoder;discrete latent variables;cmu submission;sigmorphon;msved;language;present result analysis;task;specific errors;neubig;system;zhou;paper;method", "pdf_keywords": ""}, "f35a01c1e5d5375453c39e6161526633492fb574": {"ta_keywords": "archival storage systems;data storage;data storage systems;data storage methods;simple data replication;mds queue;storage;powerful erasure codes;replication;lower storage cost;erasure codes;insightful scheduling policies;data centers;cold data;hot data;latency performance;latency;degraded reads;mds codes;improved reliability;data;throughputs;average latency;computable analytical bounds;reliability;performance;partial data;systems;reading;codes", "pdf_keywords": "mds queues;mds queue;data storage systems;data storage;insightful scheduling policies;latency performance;latency;mds codes;erasure codes;degraded reads;performance;partial data;reading;lower bounds;paper;bounds;nov;framework;kangwook lee;theory;term;lens;fig;kannan ramchandran dept;different methods;theoretic viewpoint"}, "9b71542ef5d5178041048b9a330309053bb0bcfc": {"ta_keywords": "novel speech separation;domain speech separation;speech separation;high speech quality;target speech;input mixtures;speech;masking;truth speech;classification;enhancement model;discretization;mixture;recognition;cocktail party;cocktail party problem;enhancement;models;synthesis model;regression models;prediction;regression;wsj0;snr;interference;discrete symbols;input;vctknoisy corpora;deep;discrete symbol sequence", "pdf_keywords": "speech separation model;domain speech separation;novel speech separation;speech separation;input mixtures;speech;discretization;target speech;models;enhancement model;truth speech;masking;regression models;variational autoencoder;mixture;recognition;model;regression;level loss criterion;synthesis;enhancement;cocktail party;cocktail party problem;chinese academy;classi\ufb01cation;xuankai chang2;discrete symbols;deep;sd;snr"}, "79ab3a0d6dc5d6fd3b466ea2814fdbb93a3672d0": {"ta_keywords": "textgraphs;explanation regeneration;shared task", "pdf_keywords": ""}, "da10c4bc1de7b9b7ddbb21d70ff5092a15cb866f": {"ta_keywords": "domain adaptation;protein name extraction;transfer learning;labeled target data;support vector machines;maximum entropy models;novel maximum entropy;rescaling;unsupervised version;plr;particular subproblem;comparable performance;technique;paper;general problem;current state;problem;inspiration;art", "pdf_keywords": ""}, "9db77e925015ad02efc9beeab233bedbfe04e4b7": {"ta_keywords": "other popular policy gradient;many challenging reinforcement learning;reinforcement learning;directional gaussian smoothing evolutionary strategy;smoothing evolution strategy;evolution strategy;reward function;optimal strategy;gradient estimates;several benchmark rl tasks;nonlocal search direction;rl training;dynamical control problem;competitive reward scores;black box;es approaches;es method;rl;dynamical system;adjoint methods;challenges;high accuracy;tasks;dgs;directional;objective;gaussian;great promise;ability;es", "pdf_keywords": "other popular policy gradient;blackbox optimization algorithms;directional gaussian smoothing evolutionary strategy;monte carlo type gradient estimators;gradient information;gradient estimates;nonlocal search direction;search direction;several benchmark rl tasks;reward function;faster convergence;improved asebo method;competitive reward scores;rl training;policy parameter;natural evolution;es approaches;high accuracy;es method;challenges;most current methods;dgs;baselines;scale variation;classical es;es;ability;ideas;functions;superior wall"}, "af0aa62d243c761b56a83369bc9b1f75805003cf": {"ta_keywords": "structured text networks cmu;text corpus;dependency parsing;similarity measure;syntactic relations;random walks;nodes;graph;learning;words;edges;particular task", "pdf_keywords": ""}, "f765b23f0b0d2a196bc0fe562ad24278d0c9cee4": {"ta_keywords": "adaptive gradient methods;globally adaptive learning rates;deep neural networks;adam;learning rate;stochastic optimization;neural networks;convolutional neural networks;gradient based optimization method;eve;image classification;language tasks;new algorithm;other popular methods;locally;parameter;parameters;method;paper", "pdf_keywords": ""}, "ccbc17d42f2b260079eee702fd97a75de705d8ac": {"ta_keywords": "predetermined syntactic structures;threeword phrases;monolingual setting;synthesis;multiple output vectors;synthesis phase;vocabulary;words;search;decomposition;task;vector;phases;input text;first work;neighbor search;kind", "pdf_keywords": ""}, "75b13e7131997ff6fd21325d68a2222d2c1b7157": {"ta_keywords": "speaker separation model;reverberant speech enhancement;speech separation;sequential neural beamforming;neural separation;comparative speech recognition metric;spectral separation;beamformer;invariant spatial beamforming stages;separation tasks;spatial separation;real recordings;advanced convolutional architecture;separation;noise ratio;noise ratio loss function;neural networks;neural network;better word error rate;invariant spatial component;invariant signal;covariance matrices;enhancement;amplitude component;baseline mask;libricss evaluation;spatial covariance;signal;average improvement;sequence", "pdf_keywords": ""}, "00b874f8346cedadc2a6366c4b72e60140f99556": {"ta_keywords": "semantic textual similarity;phrase word embeddings;paraphrase pairs;semeval2016 competition;paragram;attention;convolutional neural network;task;multiperspective convolutional neural network;input interaction layer;sts2015;entry;english;sparse features;sts;sts2015 data;final model", "pdf_keywords": ""}, "43c844c30765f3fa25bfabd83490ef826b9ceca1": {"ta_keywords": "adversarial misspellings;adversarial spelling mistakes;robust word recognition;adversarial training;word recognition model;bert model;downstream classifier;character attack lowers accuracy;shelf spell checkers;accuracy;words;keyboard mistakes;sentiment analysis;error reduction;defense;pipeline;front;swaps;vanilla;random adds;drops;method", "pdf_keywords": "adversarial misspellings;adversarial spelling mistakes;adversarial training;adversarial attacks;robust word recognition;accurate word recognition models;word recognition model;bert models;low word error rate;character attacks;sentiment classi\ufb01cation task;bert model;data augmentation;robustness;accuracy;random guessing;defense methods;attacks;classi\ufb01ers;word;defenses;defense mechanism;downstream classi\ufb01er;aug;downstream task;effectiveness;sentence;ddanish;front;marginal bene\ufb01ts"}, "25ae911c13da7ef9def56ee30170920ebd48a668": {"ta_keywords": "computational argumentation;web arguments;relation classification;arguments;argument pair;bidirectional lstm;argument;topics;convincingness;large datasets;topic;relation;total ordering;qualitative properties;findings;data;tasks;same stance;pair;new task;16k pairs;properties;global constraints;problem;same prompt;field", "pdf_keywords": ""}, "b48f0652605f981b5d407496aba3d9756725264f": {"ta_keywords": "net formalism;ai;ai systems;model preferences;preference;decision makers;decisions;preferences;computer science;priorities;systems;optimization criteria;libraries;properties;expressive way;datasets;constraints;decision;community;cp;quality;practical results;ability;scenarios;people;number;study;exogenous sources;many instances;impact", "pdf_keywords": ""}, "a636768c2fc6cadccd8bb4d704f651dd54dad395": {"ta_keywords": "indonesian conversational speech;indonesian speech;emotion recognition;colorful emotional utterances;conversational speech;support vector machine;svm;classifier;acoustic features;indonesian;feature selection;emotional aspect;emotion;corpus;television talk show recordings;human computer interaction;recognition;recognition performance;idesc;various topics;analysis;discussion;use;importance;parameter optimization;accuracy;paper;terms;first study", "pdf_keywords": ""}, "f664e6635d0514b0cb398a713f08bab90b4a3d81": {"ta_keywords": "sparse word graphs;statistical topic models;topic models;capturing word correlations;ap corpus;modeling word;topics;sparse;large document collections;words;documents;unsupervised fashion;lda;models;distance;bag;model;representation;new algorithm;techniques;scalable algorithm;attractive framework;work;recent advances;limitations;family;experiments;problem;assumption", "pdf_keywords": ""}, "bd1bdb3c5f28001a4cee92c0e1669512d0f06a35": {"ta_keywords": "generalized zipf;heap;heaps;simple formal derivation;simple derivation;law;russian", "pdf_keywords": "generalized zipf;unique words ex;frequent word wi;heaps;heap;text words;original zipf;asymptotic behavior;word;law;simple formal derivation;derivations;simple derivation;total number;probability;ex;abstract;russian;proof;number;respect;leonid boytsov;xi;ir;objective;november;nov"}, "a9b9404962760731d6d2fc2ecbc6da7bc2f21be7": {"ta_keywords": "voice activity detection;gaussian reduction;switching kalman filter;prior probabilities;unimportant gaussian distribution;speech;statistical model;original gmm;drichlet;distribution;optimization method;distribution shape;vad;paper;advantage;performance", "pdf_keywords": ""}, "32367e7587d5b2de0391cff9ad2d600ff8624e60": {"ta_keywords": "social skills training systems;social skills training system;social skills training;human social skills trainers;social skill training;audiovisual features;audio features;social interaction;social communication difficulties;linguistic features;computer interaction;appropriate skills;superior skills;visual features;human trainers;computers;pitch;result computer;effectiveness;experimental evaluation measures;method;people;yaw;paper;account;ratio;gap;difference;previous works;several parts", "pdf_keywords": ""}, "22f4eb19be4031e63194bbd7c355914533004918": {"ta_keywords": "urban dynamometer driving schedule;gear shift behavior;gear shifts;vehicle application;detailed power flow;loop simulation model;coaxial transmission;transmission unit;internal combustion engine;absolute co2 emission;electric motor;prototype vehicle environment;different onboard vehicle sources;passenger car;simulation model;optimal control;ecms;dht solution;longitudinal dynamics;dht;drivability penalty approach;developed model;state test bench measurements;sankey diagram;loss maps;udds;cost;ice;analysis;inputs", "pdf_keywords": ""}, "ea77b71385648f5c6ea533a0e3685f0e76302eba": {"ta_keywords": "entity recognition;resource named entity recognizers;annotator effort;real human annotation;target language;only uncertain entity spans;annotation;little annotation;effective training data;active learning;languages;model predictions;bootstrapping;ner;model;data;extensive experimentation;art models;lot;good;large amounts;study;most state;availability;recipe;solutions;problem", "pdf_keywords": "resource entity recognizers;target language;high annotation quality;resource languages;resource language;targeted annotation strategy;entity;human annotation experiments;annotations;single entity;language;annotator;different languages;ef\ufb01cient learning;train model;active learning;unlabeled dataset;active learning method;less manual effort;ner model;good preliminary model;ner systems;active learning strategy;english;full sequences;human effort;dataset;query spans;transfer;model"}, "0822f8d7e6a72a65e65f147d3a8d8fccd485da40": {"ta_keywords": "better language modeling;expensive relative position embeddings;short subsequences;shorter inputs;embeddings;absolute position embeddings;shortformer;input length;sequences;longer ones;transformers;language;maximal length;recurrence methods;transformer;tokens;efficiency improvements;queries;efficiency;model;perplexity;simple alternative;overall training time;superior results;new methods;progress;keys;models condition;conditions;methods", "pdf_keywords": "transformer language models;shorter input subsequences;longer subsequences;multiple nonoverlapping subsequences;input subsequence length;transformers;subsequence lengths;transformer;subsequences;recurrence methods;sequences;embeddings;memory ef\ufb01ciency;large evaluation;models;better perplexity;runtime;absolute position embeddings;tokens;model;maximal length;performance;attention mechanism;inference;queries;positional information;perplexity;context;new methods;word"}, "253ad629cd2d396201d71aa605bec233bff66dca": {"ta_keywords": "gaussian mixture model;speech recognition;triphone hmm states;complicated acoustic model;appropriate acoustic model topology;acoustic model;model search algorithm;variational bayesian estimation;efficient model search algorithm;clustering;decision tree;markov model states;automatic determination;vbec framework;vbec;search space;gmm;computations;efficient method;statistics;novel approach;practical level;characteristics;large number", "pdf_keywords": ""}, "fac95cc5f52f954fe89b3aa4b75895568ff6a6d4": {"ta_keywords": "normalization rules;historical wordforms;luther bible;modern wordforms;normalization;diverse language data;texts;aware rewrite rules;luther results;text;baseline;rule;exact matches;rules;sequences;characters;form;versions;results;context;certain extent;performance;different type;same period;approach;method;frequency", "pdf_keywords": ""}, "8b73e226815d57bf66fc94905ebd063e4957b449": {"ta_keywords": "privacy;reviewer identity;peer review;reviewers;adversary;pareto;efficient algorithms;pareto frontier;better papers;utility;papers;map;paper;calibration;main results;theoretical study;model;problem;tradeoff;foundational building block", "pdf_keywords": "privacy;adversary;reviewer identity;pareto;conference calibration;e\ufb03cient algorithms;calibration strategy;reviewer;optimal strategies;conference;pareto frontier;characterization;calibration;better papers;better paper;utility;paper;case errors;case error;main results;problem;instance error;section;terms;respect;error;tradeo\ufb00;foundational building block"}, "f249e3a7d4f7f964e9a4ca6e633ac31410a91dd8": {"ta_keywords": "monolingual data hallucination;resource morphological inflection;morphological inflection;inflection decoder;multiple languages;languages;step attention architecture;neural methods;typological similarity;common representation;models;accuracy;necessary resources;data;addition;higher resource settings;paucity;crucial factors;effects;long tail;state;face;low;art;success;percentage points;limits", "pdf_keywords": "monolingual data hallucination;many related languages;multiple languages;languages;step process decoder architecture bares similarities;step attention architecture;decoder;language;typological similarity;in\ufb02ection decoder;genetic similarity;morphological in\ufb02ection;common representation;contexts;models;macroaveraged accuracy;sources;better performance;crucial factors;chiang;addition;zoph;art;knight;major success factor;success;state;e\ufb00ects;anastasopoulos"}, "a309cb82c27233948f9b09f440be171a8d24ffff": {"ta_keywords": "peer selection agents;impartial peer selection;peer selection;peernomination;algorithms;individual agent;prize;novel algorithm;agents;previous algorithms;award;accuracy;explicit partitioning;higher accuracy;own chance;increased accuracy;exactness;self;subset;several metrics;literature;exiting;theoretical analysis", "pdf_keywords": "impartial peer selection;other peer selection mechanisms;peer selection outcomes;peernomination;agent rankings;reviewer graph;accuracy;underlying ground truth;novel algorithm;analytic performance bounds;higher accuracy;performance;results;classi\ufb01cation measures;exactness requirement;improved performance;milder assumptions;current best performance;terms;literature;several metrics;number;method;mallows;respect;xia;exiting;mallows model;theoretical analysis;set"}, "04a94c15fec43e7563d58be697246a0dd6c57021": {"ta_keywords": "information content providers;modern social media landscape;facebook;twitter;content;platforms;internet;tweets;myspace;internet service providers;censor;social activity;news media;telecommunications act;outraged users;youtube;information;services;interactive computer services;raw content;open web;ai;broad discretion;powerful data;telecommunications companies;liability;user experiences;users;legal standpoint;algorithms", "pdf_keywords": "modern social media landscape;modern social media giants;twitter;facebook;tweets;information content providers;content;user content;intermediaries;categorization;traditional bulletin board sites;creators;platforms;internet;text;ai;raw content;snippets;technology;photos;creation;entire articles;photographs;article;curation;online actors;tools;powerful data;technological advances;users"}, "a99de68ee8d6729eee5ca5943b152aba7e4738ee": {"ta_keywords": "neural editor;source code edit data;edit encoder;edits;neural network models;natural language;representations;models;edit;salient information;new inputs;semantics;structure;results;evaluation yields;problem", "pdf_keywords": "neural editor;represent edits;edit representation;source code edit data;natural language;edits;edit encoder;natural language sentences;edit data;generative model;representations;neural network models;semantics;learning;representation;intern;microsoft research;iclr;prototypes;task;structure;important machine;abstract;cb1;results;evaluation yields;cambridge;conference paper;marc brockschmidt;united kingdom"}, "7f20366098665cd508fe82255cc1a65e1e733a14": {"ta_keywords": "most speech enhancement techniques introduce artifacts;speech enhancement technique;automatic speech recognition;speech features;recognition performance;significant digit error rate reduction;acoustic model;feature variance;recognition;aurora2 database;such acoustic distortions;discriminative criterion;adaptation technique;reverberation;maximum likelihood estimation;further improvement;improvement;adaptation;noise;performance;severe degradation;mismatch;presence;method;conventional approach;paper;experiment", "pdf_keywords": ""}, "22d2f8030221bd0c27bfb9416eeffe4e86633780": {"ta_keywords": "efficient neural ranking;forward indexes;semantic similarity computation;hybrid indexes;query processing efficiency;semantic scores;index pruning;superior ranking performance;forward index;nearest neighbor search;dense indexes;index;retrieval;semantic similarities;query processing throughput;query processing;efficient sparse models;fast cpu;trec;fast;vector representations;dl datasets;documents;performance;simple vector;interpolation;improvements;replacement;paper;passages", "pdf_keywords": "semantic similarity scores;lexical matching scores;document retrieval;forward indexing approach;semantic similarity;semantic scores;nearest neighbor search;forward indexes;forward index;index;query processing latency;dense indexes;retrieval phase;long documents;documents;document;query;encoder models;sequential coalescing;fast;efficient end;interpolation;memory footprint;replacement;interpolation method;paper;improvements;simple vector;early stopping;cf"}, "4e0610ac4c5e055ac56b2ae0d91386a10ffbd325": {"ta_keywords": "manual knowledge;prior domain knowledge;prior knowledge;human learning;artificial intelligence;specific prior knowledge;level intelligence;intelligent agent;human acquisition;math;human students;fraction addition;education;deep features;simulation study;simstudent;addition;equation solving;agent;understanding;integration;domains;efficient algorithm;science;significant manual encoding;domain;encoding;stoichiometry;form;generality", "pdf_keywords": ""}, "8d019c77989100a51385e4b4a5fa5250445d8f1d": {"ta_keywords": "noisy middle vocabulary speech recognition task;generalized discriminative training framework;sequential discriminative training criterion;discriminative feature transformation;corpus;2nd chime challenge track;gaussian mixture models;deep neural networks;conventional system combination approach;lvcsr task;system combination;acoustic modeling;complementary systems;spontaneous japanese;conventional heuristic combination approaches;base systems;base system;new objective function;different outputs;opposite targets;method;framework;balance;performance;good performance;paper;effectiveness;experiments", "pdf_keywords": ""}, "1b97c38d0156dc8bf300b41c2ba5c0463c3a2c00": {"ta_keywords": "data augmentation;data augmentation strategies;sequence summarizing neural network;autoencoder;augmented training data;learned dnn;vector extractor;reverberation;acoustic summary;summary vector;speech;enhancement;utterance;ssnn;informative vector;mismatched training;wpe dereverberation;adaptation;such vector;workshop;novel technique;efficient technique;jsalt;selection;robustness;aim;combination;main usage;approaches;development", "pdf_keywords": ""}, "3df825e086b00dd4132c34ecbf638f9a6dc4320d": {"ta_keywords": "procedural knowledge;intelligent agent;human learning;transfer learning;synthetic student;level learning;artificial intelligence;level intelligence;agent;education;problem solving;simstudent;math;module;second language;examples;machine;science;paper;efficient approach", "pdf_keywords": ""}, "3e59b3e1e3ef65f9574a0fe30f18ba7a815ea0af": {"ta_keywords": "dialogue policy learning;boltzmann exploration;dialogue tasks;thompson sampling;dialogue systems;replay buffer spiking;efficient exploration;replay buffer;learning;exploration technique;monte carlo samples;primary reward signal;bbq networks;rewards;action spaces;neural network;backprop;task;successful episodes;successful completion;bayes;experiences;promising applications;improvement;appropriate actions;common approaches;complex sequence;problems;small number", "pdf_keywords": ""}, "790eb7e93f1d3fce470c0222fd2be83bab55a428": {"ta_keywords": "rnn language models;end speech recognition;automatic speech recognition;rnn;ahead word probabilities;end asr systems;vocabulary size;lms;asr;lm;different lms;next characters;word;competitive accuracy;benchmark;wall street journal;character;model;less computation;performance;memory usage;novel word;best wer;end;paper;wsj;significant error reduction;computational cost;task;look", "pdf_keywords": "rnn language model;end asr systems;language models;language modeling;automatic speech recognition;end asr;encoder decoder architecture;rnn;encoder decoder;asr;vocabulary size;attention;benchmark;best wer;word;hybrid ctc;lm;competitive accuracy;character;model;less computation;end;look;conclusion;paper;addition;ahead mechanism;novel strategy;process;prior work"}, "83cf7b9611fabe9da2d08722445039023f1b19e9": {"ta_keywords": "\u97f3\u5b66\u30b7\u30f3\u30dd\u30b8\u30a6\u30e02014", "pdf_keywords": ""}, "9b09ff09b88bb793b161f284ca6e66031bc5a992": {"ta_keywords": "cloud computing;1st ural workshop;parallel;young scientists;ural;pdc;proceedings;november 17th;russia;yekaterinburg", "pdf_keywords": ""}, "68f2f32e0e8fc868920971077a11042784be2616": {"ta_keywords": "ranking;sports tournaments;rating;sports teams;matchups;data mining;movie recommendations;tuning;movies;field;data mining course;list;traits;solid introductory;science;book;great introduction;attention;entities;supplemental book;last several years;many insightful asides;linear algebra;equal gusto;text;methods;enough depth;central question;myriad;intermediate text", "pdf_keywords": ""}, "a3ca4893ae941bd1601322aface4840e47339761": {"ta_keywords": "important crowdsourcing setting;peer review;agents;awards;funding;scientists;conferences;evaluations;crowd;publications;others;other strategyproof mechanisms;reviews;team;target;fundamental challenge;literature;real world domains;mechanism;detailed experiment;subset;chances;setting;parameter values;worst case;settings", "pdf_keywords": ""}, "a810d2f4a1fefd4175d8cdda9702ee1b829e5831": {"ta_keywords": "fat diet;white adipose tissue;obesity;brown adipose tissue;body weight gain;glucose homeostasis;energy expenditure;protein;body temperature;bat thermogenesis;mice;kg pha everyday;pha treatment;gene expression;molecular mechanisms;pha prevent;heat intensity;bat;prevention study results;pha;safe drugs;upregulation;key regulators;hfd;medicine;expression;results;modern advances;further study;mg", "pdf_keywords": ""}, "66081634c17b089cb47fd1b0ad7ad842c7fb3f87": {"ta_keywords": "teachable agent;tutor;fected tutor;tutors;learning;successful learning;agent technology;human student;interactive peer;cognitive fidelity;simstudent;tutee;shallow learning;tutees;tween;introduction;computational model;research field;paper;relationship;environment;effect;use;like errors;pathway;way;goal", "pdf_keywords": ""}, "d706645fbbc6edfad5fb642b1dfc3019fcabbd99": {"ta_keywords": "amazon mechanical turk;story evaluation experiments;mechanical turk;text generation papers;text generation;human judgments;amt worker judgments;text quality;amt tasks;ratings;text;reproducibility;such tasks;english teachers;amt workers;references;most researchers;grammaticality;human;likert scores;models;amt;teachers;workers;modeling choices;perils;output;strict qualification filters;vast majority;coherence", "pdf_keywords": "movie content analysis neural syntactic preordering;controlled paraphrase generation pun generation;paraphrase generation;paraphrase generation complexity;controlled text style transfer generating diverse story continuations;editing unsupervised hierarchical story in\ufb01lling neural crf model;formality style transfer plot machines;recent text generation research;controllable story generation;text generation;story generation evaluations;humor prediction datasets;sentence alignment;knowledge base completion counterfactual story reasoning;current visual storytelling models;corpus;humorous headline generation;humor generation;generative explanation framework;level targeted content transfer learning;scale language models;style transfer learning;unsupervised style transfer;multimodal relational data;end generative architecture;explainable nlp;text simpli\ufb01cation;poetry generation;joint neural network architecture;annotators"}, "ad7129af0644dbcafa9aa2f111cb76526ea444a1": {"ta_keywords": "neural fake news;careful threat modeling;disinformation;robust defenses;propaganda;vaccines;threats;exposure bias;adversary;potential threats;vulnerabilities;better detection;best current discriminators;adversaries;risks;grover;training data;news;headline;similar discriminators;modern computer security;potential mitigations;ethical issues;article;real news;models;autism;summarization;translation;view", "pdf_keywords": "neural fake news;vaccines cause autism authors;headline vaccines;article generation;vaccines cause autism;disinformation threats;machinegenerated text;childhood vaccinations;language models;disinformation;controllable text generation;autism;news;new research;threat modeling;context domain;headline;better detection;potential threats;future;models;training data;threats;best current discriminators;technology;grover;concrete initial proposal;robust defenses;grover examples;kids"}, "946e5e31b0779fc33550e8681994e7afd8d549a5": {"ta_keywords": "clinical gait analysis;motion measurement system", "pdf_keywords": ""}, "81d4357afae9680e64a645cbb36aa090c3619b19": {"ta_keywords": "diversity task;index;results;anchor text", "pdf_keywords": ""}, "a7d6b5e61024127bf4fe8f04c0182a16ff97bccf": {"ta_keywords": "probabilistic lobbying;bribery methods;bribery;probabilistic environment;lobby;voters;parameterized complexity;complexity;stochastic environment;probabilities;formal analysis;terms;forms;evaluation criteria;models;various models;actor;preferences;problems;multiple issues;issue weighting", "pdf_keywords": "bribery methods;bribery;parameterized complexity;probabilistic environment;lobby;voters;complexity;polynomial time;parameter tractable;various natural parameterizations;terms;probabilities;stochastic environment;formal analysis;forms;models;evaluation criteria;daniel binkele;actor;special case;plp;problems;np;multiple issues;abstract;preferences;time reduces;vb;issue weighting;sm"}, "419e714f22c3fa2599abebd630cae5595c70bdef": {"ta_keywords": "integraded speech recognition;speech recognition;automatic speech recognition;speech enhancement;robust speech recognition;enhanced speech;speech input;conventional e2e asr models;sslr module;sslr module extracts features;iris model;e2e model;supervised learning representation;sslr;iris;learning representation;e2e;se module;asr;module;important modules;model;evaluation results;end integration;best performance;self;se;real development;thanks;real test", "pdf_keywords": "speech enhancement model;integraded speech recognition;speech enhancement;automatic speech recognition;speech recognition;robust speech recognition;conventional e2e asr models;speech input;e2e model;e2e;iris model;supervised learning representation;iris;sslr module;asr;end integration;learning representation;sslr;yuya fujita2;model;se module;evaluation results;module;important modules;takashi maekaku2;shinji watanabe1;\ufb01netuned se module;usa 2yahoo japan corporation;end;best performance"}, "888c81cd3d1e953e2b7f8cc4ce68ca9f908c1e8d": {"ta_keywords": "differential privacy;favorite privacy frameworks;privacy;privacy loss guarantees;several recent nlp papers;nlp community;nlp;text representation learning;fundamental theoretical guarantees;apparent simplicity;dptext;short paper;implementation;dp mechanism;false claims;dp;general concept;researchers;methods;general empirical sanity check;compelling thanks;various approaches;traction", "pdf_keywords": "private text representation;several recent nlp papers;computational linguistics;text representation learning;privacy loss guarantees;dptext;reparametrization trick;dp guarantees;dp mechanism;short paper;implementation;acl;false claims;association;publication;article;inverse continuous density function;model;general empirical sanity check;heart;ivan habernal;60th annual meeting"}, "596b46dbe4fa8eee72e517ea9fd5f8ef83c9c64e": {"ta_keywords": "incremental question answering;quizbowl;quizbowl question;large factoid qa dataset;human knowledge;scholastic trivia competition;qa;intelligence;elite player;wikipedia;clues;diverse research;key contributions;gameplay dataset;players;machine;research;few clues;superiority;multiple sentences;difficulty;human;question;entity;computational approach;case;time", "pdf_keywords": "vibrant trivia community;large factoid qa dataset;incremental question answering;scholastic trivia competitions;factoid qa;natural language processing;machine learning challenges;quizbowl;like answers;computer science university;computer science;computer sciences university;wikipedia;knowledge;task;gameplay dataset;contributions;machine learning;intelligence;dataset;new research directions;umiacs;information;research;qa model;confidence scores;opponent;he department;paper;mastery"}, "650f2afca6d72d6b6e2e08849e1224f1e8b7900c": {"ta_keywords": "binary rating estimation;binary rating estimation problem;social graphs;graph side information;rating matrix;unknown ratings;optimal sample complexity;sample complexity;graph;efficient algorithm;simple correlation model;sharp threshold;entries;knowledge;quality;rich experimental evidences;number;users;limit;work;function;aid;fundamental value", "pdf_keywords": ""}, "932404745d960291925b3f27b71734dff5b23633": {"ta_keywords": "algorithms exhibit treatment disparity;class discrimination;treatment disparity;disparate learning processes;algorithms exhibit impact disparity;employment discrimination law;impact disparity;disparity;fairness;nonsensitive features;impact parity;outcomes;group membership;precedent;dlps;policy desiderata;accuracy;practical consequences;other features;parities;world datasets;notions;suboptimal trade;subgroups;experimental results;members;ml;ii;offs;iii", "pdf_keywords": ""}, "7bbd132f40c7630aeebf6379b00e307c3fff738c": {"ta_keywords": "exact replication;systematic node;node;reconstruction;optimal constructions;entire data;bandwidth;data;problem;manner", "pdf_keywords": "solomon type mds code;systematic nodes;data storage;exact regeneration;regeneration;node stores;node;repair;codes;reed;single \ufb01nite \ufb01eld symbol;entire \ufb01le;paper;construction;scheme;existence;problem;obvious means;manner;sep;setting"}, "e8c3090e66fdb05a2c169a12c52dd94bb8786fb5": {"ta_keywords": "natural language explanations;explanations;ai community;persuasive arguments;content words;stopwords;level prediction task;explanandum;neural methods;changemyview subreddit;explanation;strong predictive power;pointers;word;features;information;topic;echoing;interest;constituent parts;novel word;argument;dataset;interaction;properties;everyday life;dynamics;process", "pdf_keywords": "natural language explanations;pointer networks;word embeddings;content words;explanations;vanilla lstms;words;stopwords;neural methods;features;level prediction task;contextual properties;persuasive comment;word;echoing;explanation;strong predictive power;level classi\ufb01cation task;explanandum;noncontextual properties;nouns;novel dataset;novel word;importance;interesting patterns;rouge scores;results;generation performance;performance;computational characterization"}, "ed535e93d5b5a8b689e861e9c6083a806d1535c2": {"ta_keywords": "systematic generalization ability;proper generalization validation sets;systematic generalization;neural networks;universal transformer variants;transformers;accuracy;model configurations;models;many datasets;pcfg productivity split;relative positional embedding;embeddings;length split;performance;iid data split;performance differences;early stopping;scaling;scan;simple tricks;cutoff;devil;eos decision problem;mitigates;cogs;detail", "pdf_keywords": "universal transformer variants;universal transformers;systematic generalization ability;transformers;neural networks;systematic generalization;relative positional embedding;absolute positional embedding;models;embeddings;many datasets;accuracy;swiss ai lab idsia;eos prediction;model con\ufb01gurations;standard tasks;parameters;pcfg productivity split;performance;early stopping;scaling;simple tricks;length cutoffs;lugano;kazuki;length split;scan;mitigates;devil;abstract"}, "9abb50813e05de849dbbd89535bc7d0206f5e36a": {"ta_keywords": "semantic verb clustering;verb clustering;dirichlet process mixture models;natural language processing;verb classes;nlp;human supervision;prior knowledge;task;vmeasure metric;levin;dataset;method;model;work;solution;performance;respect;order", "pdf_keywords": ""}, "0bbfa6ab7451aea5cbb842cce97b54500bafdfc7": {"ta_keywords": "inverse decision theory;inverse reinforcement learning;uncertain decision problems;optimal decision maker;human preferences;exact preferences;uncertainty;preference;decisions;decision problem;preferences;partial observability;suboptimal humans;observability;intuition;sample complexity;sample complexities;strong assumptions;tradeoff;observational approaches;suboptimal case;unrealistic assumption;human;precision;understanding;first statistical analysis;number;idt;environment;conditions", "pdf_keywords": "inverse decision theory;human decisions;general reward learning;important preferences;preference;decisions;unknown hypothesis class;hypothesis class family;uncertainty;sample complexity;preferences;\ufb01rst statistical analysis;idt;tradeoff;precision;theorem;formal description;human;speci\ufb01c case;number;insight;distribution;hfeat;conditions;setting;own right;requirements;framework;cases;useful tool"}, "a31ab366b0a349ee5f341f1179810bc9805d32a4": {"ta_keywords": "secure msr;data file;\u21132 nodes;storage;\u21131 nodes;security;repair;eavesdropper;codes;repair traffic;msr;matrix construction;product;optimality;access;information;second disjoint set;contents;paper;point;presence", "pdf_keywords": ""}, "04d18fc81cc232b3d3dece0994c0fa8aaabaf4b7": {"ta_keywords": "japanese morphological analysis;effective domain adaptation;word segmentation;gram models;cost domain adaptation;morphological task;domain adaptation experiment;annotation;annotations;tagging;pos tags;morpheme;word boundaries;speech;general domain;pos;features;evaluation;crfs;prediction results;pointwise approach;input;part;surface information;methods;characteristic;results;method;paper;process", "pdf_keywords": ""}, "d5dcbb144a2be999610b4838d94cc3fb228f837c": {"ta_keywords": "network slicing deployment;network slicing;mobile communication network virtualization scenario;chip deployment;deployment plan;nfv backup configuration;deployment profitability;reliable backup algorithm;deployment costs;lowest deployment cost;reinforcement learning;power business;service;mathematical model;future;basis;better security benefits;prerequisite;quality;commercial use;high quality;scale;premise", "pdf_keywords": ""}, "df689bdc6c497949e9ab3b7ba19950d9fade7180": {"ta_keywords": "", "pdf_keywords": ""}, "d7fe9b46f96ae9df7fa64e1c575c7114e5ef0aaa": {"ta_keywords": "optimal tensor methods;new tensor method;tensor method;tensor methods;optimal method;uniformly convexoptimization;optimization problems;smooth convex;order method;uniformly convex functions;numerical study;method;performance;gap;practice;additional assumption;class", "pdf_keywords": "optimal tensor methods;accelerated tensor method;new tensor method;tensor methods;tensor method nesterov;optimal method;iteration complexity;optimization problems;order method;numerical study;nesterov;method;performance;svaiter;framework;practice;paper;monteiro;class;appendix"}, "4c6f7fb5c2e1bd12899c3ec2788f9ce7eb2f8a5c": {"ta_keywords": "syntactic generalization performance;syntactic structural probes;syntactic capabilities;syntactic information;syntactic knowledge;language models;speech tagging;syntactic evaluation;different syntactic phenomena;dependency parsing;paraphrase identification;syntax;models;more data;different models;knowledge;raw text data;data;downstream applications;performance;data size;better performance;roberta;study;part;environmental cost;impact;incremental sizes;experiments;higher amount", "pdf_keywords": "syntactic generalization performance;syntactic structural probes;syntactic capabilities;speech tagging;syntactic information;syntactic knowledge;syntactic evaluation;dependency parsing;different syntactic phenomena;paraphrase identi\ufb01cation;models;different models;more data;raw text data;downstream applications;performance;better performance;data;data size;part;environmental cost;roberta;impact;bene\ufb01t analysis;incremental sizes;\ufb01ndings;experiments;higher amount;different amounts"}, "b73191adcc938cfcf20ce0327cf5cd1f539f7f81": {"ta_keywords": "scientific information extraction;neural tagging model;entity recognition;unannotated articles;sequence tagging;keyphrases;scientific articles;annotated training data;task;recent advances;data selection scheme;paper;graph;domain;process;material;problem", "pdf_keywords": "scienti\ufb01c information extraction;scienti\ufb01c information extraction task;neural tagging model;neural tagging models;unlabeled data;keyphrases;label propagation;aware data selection;scienti\ufb01c articles;hierarchical lstm;task;key contributions;electrical engineering;recent advances;paper;recent results;graph;crf;abstract;sequence;material;process;ner;iii;university;ii;con\ufb01dence;cl;initialization;aug"}, "06d77cc8970b59102a0caffb5e4c5b7a3242563a": {"ta_keywords": "scaled gumbel softmax;sense;differentiable self;model", "pdf_keywords": ""}, "4715ee17ca4f52762fdf67c9a8ef8fb751c88484": {"ta_keywords": "bigger energy disaggregation framework;blind system identification;model power consumption;blind identification;corresponding arx model;arx models;electrical appliances;arx model;only output measurements;piecewise constant inputs;measured outputs;systems;constant input;unique solution;unknown times;piecewise;task;further assumptions;method;part;hand;contribution;problem", "pdf_keywords": "bigger energy disaggregation framework;model power consumption;disaggregation algorithm;blind system identi\ufb01cation;corresponding arx model;arx models;arx model;blind identi\ufb01cation;electrical appliances;individual appliances;only output measurements;models;measured outputs;piecewise constant inputs;systems;constant inputs;outputs;constant input;unknown times;unique solution;piecewise;bsi;task;novel framework;further assumptions;method;complicated problem;part;roy dong;paper"}, "cac008e541af58f738407c7f2ee86d547053188f": {"ta_keywords": "", "pdf_keywords": ""}, "1e2ef0c9a494c7949f38940ee735a88c56355202": {"ta_keywords": "dynamic sensor subset selection;active sensor selection;dynamic sensor activation;centralized tracking;sensor networks;stochastic approximation;active sensors;efficient tracking mechanisms;global optimality;tracking;algorithms;learning;cyber;physical systems;internet;iid process;squared error;complexity;infinite horizon;gibbs;energy;high performance;mean number;constraint;time;numerical results;mean;things;methods;cases", "pdf_keywords": ""}, "00c3a86551f1bc812b676025210e295021853f66": {"ta_keywords": "enjoyable answer;playful walk;history;book;answer;question;end;day", "pdf_keywords": ""}, "69d5579955a5a8859d78a70b3d1afede0f91fa09": {"ta_keywords": "energy disaggregation task;energy disaggregation;energy data;energy consumption behavior;aggregate energy data;individual appliances;device usage;power;individual device;data;output system;dynamical systems approach;consumer;whole building;nilm;device;task;novel framework;input;scale experiment;implementation;output;framework;paper;studies;results", "pdf_keywords": "energy disaggregation task;energy disaggregation;nonintrusive load monitoring;energy usage behavior data;energy data;aggregate energy data;disaggregation;individual appliances;dynamical system framework;device usage;power;infrastructure;dynamical systems approach;individual device;output system;data;whole building;novel framework;implementation;task;device;consumer;framework;nilm;implementation methods;feasible method;ds;input;output;scale experiment"}, "834d68b9befcc6c68415b460b33435a1822799fb": {"ta_keywords": "argumentation mining;argumentation model;argumentation phenomena;argumentation;normative argumentation theories;argument components;web discourse;computational linguistics;extensive annotation study;new gold standard corpus;actual web data;documents;people;challenges;user;article;variety;actual data;methods;research field;iii;unrestricted noisy user;multiple domains;gap;ii;90k tokens;several ways;registers;state;several machine", "pdf_keywords": "argumentation mining;argumentation;web discourse;computational linguistics;usergenerated web content;educational research;gurevych;people;user;habernal;methods;research \ufb01eld;german institute;features;goal;mar;ivan;technische universit\u00e4t darmstadt;model"}, "972a74968d2522908b06c5bd1e26266194c5a9ee": {"ta_keywords": "sentence decontextualization;question answering;wikipedia corpus;summarization;decontextualization;excerpts;sentences;dialogue agents;annotation procedure;new context;text;context;rich context;important subtask;sentence;richer context;tasks;abstract models;resources;key pieces;data;models;definitions;meaning;many downstream applications;local window;problem", "pdf_keywords": "sentence decontextualization;question answering;retrieval corpus;decontextualization;summarization;dialogue agents;sentences;document understanding;new context;rich context;task;sentence;models;google;1google research 2department;dataset;meaning;preprocessing component;tomkwiat;application system;abstract;model;jpalomaki;utility;systems;jennimaria palomaki1;tom kwiatkowski1;user;demonstrations;dipanjan"}, "6b387d18bae978202af501c4795f37a0c73781a6": {"ta_keywords": "hybrid proximal extragradient method;proximal extragradient method;tensor method;tensor methods;hessian evaluations;smooth convex optimization problems;hessian;svaiter method;gradient;special generalization;nesterov;convergence rate;iteration;third order inclusive;approximate solution;newton;method;derivatives;methods;auxiliary problem;step size selection condition;svaiter;complexity;upper bounds;monteiro;step;constructive solution;gap;function;problem", "pdf_keywords": ""}, "2bb1e1a5b9a16f6828fe94736cea5dab264533a6": {"ta_keywords": "semantic emulation;semantic transparency;ungrounded language models;future language models understand;abstract language models;semantic representations;other semantic relations;semantic relations;natural language;many nlp tasks;assertions;formal model;language;tokens;languages;strong notion;representations;provable limitations;ungrounded systems;equivalence;code;ungrounded form;meaning;unprecedented results;modal setting;abilities;system;results;billions;differences", "pdf_keywords": "semantic emulation;semantic transparency;ungrounded language models;semantic representations;other semantic relations;semantic relations;linguistic process;linguistic theory;natural language;language;languages;assertions;natural language text;performance chomsky;different contexts;formal model;emulation;strong notion;competence;memory;equivalence;representations;understanding;meaning;ungrounded systems;resource constraints;correct algorithmic modeling;abilities;performance;classes"}, "96b32b204a62777bef66eea595de2c47b4e9d6e9": {"ta_keywords": "other domain generalization methods;standard domain generalization data sets;robust representations;deep neural networks;training data;superficial statistics;projecting superficial statistics out;reverse gradient method;networks;samples;prior knowledge;texture;representations;patterns;glcm representation;training;sample performance;image;glcm;techniques;gestalt;target distribution;model;challenge;holdout data;distribution shift;method;better performance;first method;level co", "pdf_keywords": "textural information;training domain;synthetic datasets;new differentiable neural network building block;images;different alexnets;frequency semantic information;networks;semantic information;prediction;dg studies;architecture;image;regular da;model;sample performance;novel components;speci\ufb01c information;information;representations;da;techniques;reverse gradient method;super\ufb01cial information;fusion layer;dg scenario;glcm representation;sense;fusion;representation"}, "636611068825cb4b7bdab6ad16ef415adf4fb96c": {"ta_keywords": "many multidomain;ensemble learning effects;specific class label biases;ensemble learning algorithms;balanced class label setting;domain;algorithms;approaches;systematic analysis;clearer idea;current state;field;practice;respect;understanding;important open questions;questions;art;issues;success;result", "pdf_keywords": ""}, "6f902b8128b218563b276c1ebff46ef668dcb185": {"ta_keywords": "vehicular crowd sensing;vehicular mobile crowd sensing;crowd sensing;colluding agents;incentive mechanism;multiple vehicles;vehicles;payment mechanisms;agents;taxis;data;world data;sensors;drivers;budget;maximum amount;synthesized data;mechanism;experiments;overall goal;paradigm;gains;setting;important problem;environment;past literature", "pdf_keywords": "vehicular crowd sensing;vehicular mobile crowd sensing;mobile crowd sensing;crowd sensing;diverse urban sensing data;novel incentive mechanism;incentive mechanism;multiple vehicles;vehicles;colluding agents;arbitrary collusions;crowd;taxis;payment mechanisms;demand;community;agents;collusion;sensors;data;budget;drivers;maximum amount;insensetive mechanism;challenge;paper;mechanism;abstract;sep;overall goal"}, "7650d705b85dc399112a5b6a79e9c6f81c7c6146": {"ta_keywords": "extractive question answering;large annotated corpora;specific annotated corpora;deep learning models;base documents;diverse datasets;cloze style questions;powerful neural network;document structure;examples;large domain;task;qa;style questions;recent success;end user;model;data;further fine;system;set;effective;tunes;different domains;work;availability", "pdf_keywords": "extractive question answering;large annotated corpora;extractive qa;unlabeled corpus;deep learning models;qa;qa pairs;questions;missing spans;base documents;text;models;documents;clozes;task;answer pairs;powerful neural network model;examples;conclusion;recent success;model;style questions;abstract;end user;small set;paper;carnegie mellon university;question;system;school"}, "58834a447c749758e7f57498c6dd88a281af41a0": {"ta_keywords": "training constituency parsers;parsers;parser;dynamic oracles;dynamic oracle;novel oracle;policy gradient;strong supervision;policy gradient method;supervision;tree;training;exploration;transition system;performance gain;level metric;potential;agnostic alternative;f1;custom;addition;substantial fraction;exposure bias", "pdf_keywords": "training constituency parsers;constituency parsers;constituency parsing;parsers;parser;static oracle likelihood training;french treebank;dynamic oracles;discriminative transition;dynamic oracle;penn chinese treebank version;policy gradient;strong supervision;policy gradient method;languages;english ptb;supervision;tree;training;transition system;berkeley;exploration;jun;agnostic alternative;process;potential;cl;dan klein computer science division;model;level metric"}, "1fa32503bce4f01ab2ccb65dedd374310c488fe8": {"ta_keywords": "fair machine learning;full compliance outcomes;fair employers;partial compliance;incentive effects;fairness;fair machine;employment market;fairness desiderata;allocation outcomes;partial compliance wash;employers;regulatory frameworks;auditing metrics;local parity measures;single decision maker;global statistics;outcomes;consequent strategic behavior;extreme segregation;underlying population;auditors;universal adoption;statistics;decision subjects;aggregate;equilibrium;benefits;impact;implications", "pdf_keywords": "fair employers;full compliance outcomes;fair machine learning;regulatory frameworks;partial compliance;employment market;auditors;various employers;employers;auditing metrics;incentive effects;distributive justice;fairness;appropriate auditing frameworks;fairness desiderata;simulation tools;outcomes;equilibrium;heterogeneity;political philosophy;simulation;algorithmic tools;insights;measures;implications;simple model;statistics;global statistics;interaction effects;traditional frameworks"}, "6ea353ada2b89763f58d8068a74b2e6def526948": {"ta_keywords": "ddi corpus;annotation process;drugbank database;annotation guidelines;corpus;annotation guide;biomedical texts;pharmacological names;medline abstracts;information extraction techniques;nlp techniques;pharmacological substances;medline database;pharma;texts;classification;ddis;anno;detection;ddiextraction challenge;evaluation;results;academic research;ognition;semeval;kappa;cor;best result;agreement;f1", "pdf_keywords": "ddi corpus;annotated corpus;pharmacological text processing;information extraction techniques;corpus;ddi extraction;biomedical texts;annotation;annotation guidelines;complex drug names;biomedical informatics;metadata;drug interactions;pharmacological substances;ddis;institutional repository;drug;document;citation;recognition;similar papers;information;journal;resource;abstract;dfki gmbh;ddiextraction challenge;detection;common framework;computer science department"}, "c507ad8b7bec5d29da7cf0ee92e2bf4361a5c92f": {"ta_keywords": "deep quantization;deep networks;dnn computation;deep neural networks;quantization levels;quantization;deep reinforcement learning framework;network encodings;bits;mobilenet;neural networks;alexnet;dnns;inference tasks;bitwidth;computation resource;releq;network architecture;layer;significant accuracy loss;storage;training framework;speed;policy optimization methods;accuracy;computer vision applications;computation;automatic reinforcement learning approach;tuning;large variety", "pdf_keywords": ""}, "2899eb53cddf050e3a34f07bbc0bc0ee7907d5d0": {"ta_keywords": "speech tagging problem;annotated sentence addition;word segmentation problem;training corpus;annotated sentences;language resource additions;sentences;new words;japanese;entries addition;contexts;dictionary;entries;real occurrences;part;paper;strategies;experimental results;relative effect;first strategy", "pdf_keywords": ""}, "626f8a50a7bd24d869f25bddb6fbaa59b090268c": {"ta_keywords": "pattern recognition apparatus;pattern recognition methods;pattern recognition device;recognition performance;discriminative training session;systems;model;subsequent system;plurality;model parameters;output tendency;model differs;combination;construction", "pdf_keywords": ""}, "3681456f29398e42cc2baafb0b72d166070a3cf1": {"ta_keywords": "quadratic dynamics games;stackelberg leadership model;policy gradient;free sequential algorithms;sequential policy updates;natural gradient descent;nash equilibrium;lq games;ascent;global sublinear convergence;leader;indefinite cost structure;stabilization;algorithms;projection steps;model;algorithm;projection;free settings;way;issues;intricacies", "pdf_keywords": "quadratic dynamics games;sum linear quadratic dynamic games;global quadratic convergence rate;policy gradient;global quadratic convergence;dynamic games;sequential policy updates;free sequential algorithms;lq games;global convergence;iterative algorithms;sequential zero;\ufb01rst iterative approach;optimization;stabilization;inde\ufb01nite cost structure;cost;convergence analysis;control;lq;time gare;algorithm;interplay;player;projection steps;leader;projection;sy;key concepts;abstract"}, "a711e02f85fa52c15df0a830a8ba88df2c3928ec": {"ta_keywords": "dialog retrieval;word representations;recursive autoencoders;robust example", "pdf_keywords": ""}, "4c67c129dab9805ab248407b77a6d542c2e40d41": {"ta_keywords": "robust rank;adversarial crowdsourcing;one matrix completion;crowdsourced data;classification;original rank;rank;minimization;random graph;new algorithm;matrix;workers;algorithm;value filtering;renyi;coin david;entries;model;erd\u0151s;skene model;majority;certain probability;results;perturbations;subset;decisions;correct answer;set;problem;incorrect answer", "pdf_keywords": "crowdsourced data;matrix completion;robust rank;adversarial setting;crowdsourcing literature;rank matrix;real world datasets;workers;rank;algorithm;new algorithm;random graph;art methods;model;classi\ufb01cation;entries;computational study;method;coin david;r\u00e9nyi;skene model;certain probability;results;majority;extensive experimental results;regime;introduction;state;perturbations;subset"}, "840fabc2a7773e1bd771f152f76210b2ea5845b9": {"ta_keywords": "conditional poisson stochastic beam search;many sequence generation tasks;sequence models;beam search;efficient estimators;nlp;consistent estimators;biased estimate;stochastic process;sample;samples;conditional poisson;algorithm;diverse sets;iteration;expectations;improvements;replacement;candidates;best items;distribution;sbs;cpsbs;many applications;model;strategy;experiments;cpsbs design;useful summary;maximizing set", "pdf_keywords": "conditional poisson stochastic beam search;beam search;sequence models;stochastic process;consistent estimators;algorithm;codebase;diverse sets;sample;samples;cpsbs design;mainstay;work;new method;simple modi\ufb01cation"}, "509b42fc150a057a64c4608f64e779ef04fdff47": {"ta_keywords": "entity recognition;other nlp tasks;natural language processing models;diverse training data;temporal information;temporal drift;text data;timestamp;text;documents;better models;document;language use;changes;information;evaluation results;predictions;time;performance;task;data sets;insights;better use;improvement;hope;analysis;methods;result;potential avenues;effect", "pdf_keywords": ""}, "11c6d0851152b6bec34726be40d90bea8d8a90f0": {"ta_keywords": "annotation noise;crowdsourcing;new crowdsourcing model;annotator expertise;annotators;annotation;annotator;noise adaptation layers;common noise adaptation solution;annotator basis;individual noise;common noise;instance difficulty;instance;noise;individual confusion;instances;data;world benchmarks;source;confusions;other one;low cost;end;confusion;extensive experiments;large amounts;solution;auxiliary network;effectiveness", "pdf_keywords": "annotation noise;public crowdsourcing datasets;new crowdsourcing model;annotators;annotator expertise;annotation;annotator;noise adaptation layers;individual noise;parallel noise adaptation layers;image labeling;annotator basis;noise;datasets;music genre classi\ufb01cation;common noise;instance;instances;individual confusion;sources;confusion matrices;instance dif\ufb01culty;source;confusions;ds models;other one;skene;confusion;results;figure"}, "6c520d983923dbe1e437c01086424fdcdd8f430a": {"ta_keywords": "statistical parametric speech synthesis;synthetic speech quality;concatenative speech synthesis;synthetic speech;voice conversion;speech parameter trajectories;natural speech;ms utterance;speech;utterance;hidden markov model;generation algorithm;conventional generation algorithm;clustergen;gmm;lowdelay synthesis;gv;tts;quality;global variance;vc;ms;text;segment;feature;significant improvements;hmm;evaluation;level;modulation spectrum", "pdf_keywords": ""}, "5f46d8e18138fe572b6fae897475a2ad645a3e1a": {"ta_keywords": "external language models;recurrent neural network transducer;voice search data;target domain rnn;automatic speech recognition;domain rnn;hidden markov model;lstms;deep neural networks;rnn;target domain text data;transcript data;lm training;audio;end models;transcript;asr model;training data pairs;lms;target domain;asr;lm;classic hybrid model;dnns;data scenarios;bayes;youtube;domain;density ratio approach;end", "pdf_keywords": "recurrent neural network transducer;voice search speech data;voice search;voice search audio data;target domain rnn;available voice search text data;domain rnn;lstms;rnn;hidden markov model;end rnn;deep neural networks;lm fusion;classic hybrid asr model;external lm;shallow fusion;asr model;end models;classic hybrid model;asr;dnns;source domain;lm;target domain;youtube;tune;alternative;transition;bayes;end"}, "2ce3428ba8777c723b9b12e9f8eaeb2c87a5a793": {"ta_keywords": "textual spans;sentence level;faithful rationales;rationale;rationales;direct supervision;target task;differentiable training;trustworthiness;correct rationales;costly annotation;supervision;reinforcement learning;transparent decision;prediction;target label;task;models;pipeline approaches;such methods;high scores;process;right reasons;model;wrong reasons;performance;level;framework", "pdf_keywords": "reasoning tasks;rationales;rationale;standard bert;best rationale;target task;faithful rationales;supervision;sentence level;correct predictions;conclusion;example;models;faithful explanation;correct evidence;yin;knowledge;differentiable training;target label;target performance;model;overall performance;label;selection;process;decision mechanism;target;fever;datasets;roth"}, "cd1d915604826e5fb0ba2bbcdf8479a9b90fb289": {"ta_keywords": "optimal sequential wireless relay placement;random lattice path", "pdf_keywords": "impromptu optimal deployment;distance threshold policy;relay constraint;multihop wireless network;relay nodes;packet communication path;wireless path;random lattice path;relay;impromptu deployment;packet communication;threshold distance;optimal policy;deployment;rigorous formulation;multihop;path;commandos;numerical work;dimensional boundary;objective;control centre;\ufb01rst steps;paper;above larger motivation;performance;system parameters;terms;email;work"}, "a425a11b9b249cb768d0f54d4a32f4f1d007e279": {"ta_keywords": "pass online learning algorithms;online learning algorithms;pass online learning;traditional batch learning;online lear ners;online learning methods;batch learning methods;online learners;svm;single pass;margin balanced winnow algorithm;pass;several nlp tasks;learners;multiple passes;same training data;features;accuracy;information gain;practice;notes;voting;smaller memory footprint;advantage;data;le;order;results;performan ce;single", "pdf_keywords": ""}, "2d71fb62c71e49479c1b6ce832ee1bb88df20556": {"ta_keywords": "description logics;least common subsumer;attribute chain equalities;inductive learning;structural subsumption;subsumption;descriptions;commonalities;tractability;usefulness;computation;new operation;operation;restricted case;set;important operation;largest set;method;pair;paper;problem;close connection", "pdf_keywords": ""}, "6fa85c46ea68c754ef903edc70058ba525f1fc4d": {"ta_keywords": "like intelligent agent;representation learning;skill", "pdf_keywords": ""}, "0c89b1ec80de46222ed7efc6261c03e52a1e2c54": {"ta_keywords": "neural description model;description decoder;natural language;global contexts;other global context;urban dictionaries;wordnet;dictionaries;unknown phrases;immediate local context;context encoders;interpretation;definitions;meaning;phrase;wikipedia;expressions;definition generation;dataset;search documents;datasets;task;important clues;web;contrast;oxford;questions;model;humans;previous work", "pdf_keywords": ""}, "b2b9b0d7afd85c5d708b79a61d9a000c6c906d8c": {"ta_keywords": "graph walk based similarity measures;parsed text corpus;specific word similarity measure;graph walks;parsed text;graph walk process;graph walk method;syntactic relations;meaningful edge sequences;supervised learning;nodes;graph;paths;edges;task;words;level knowledge;new path;techniques;instance", "pdf_keywords": ""}, "3042bc348d6cc7959cd574756f720e5afad236de": {"ta_keywords": "paperboard deep drawing;paperboard;paper;shallow rectangle box;deep drawing;tray;trays;indented walls;surface quality;mechanical properties;tensile strength;round corners;process parameters;proper moisture;experimental investigations;wavy bottom;experiments;influence factors;elongation;type", "pdf_keywords": ""}, "39c5cfc0ff6660a17364cb4af1eb071d6efa463d": {"ta_keywords": "amazon mechanical turk;ordinal approach results;ordinal measurements;scoring;relative merits;empirical evidence;score;prediction;judgements;selection;measurement scheme;comparative;sample noise;tasks;minimax error rates;estimation;experiments;models;data;choice;cardinal ones;noise;luce;theoretical guidelines;smaller errors;elicit;cardinal;humans;pairwise;measurements", "pdf_keywords": "amazon mechanical turk;crowdsourcing;cardinal measurement models;empirical evidence;ordinal approach;estimation;ordinal measurements;estimators;minimax error rates;statistical decision theory;ordinal method;sample noise;models;prediction;data collection;tasks;evaluation mechanism;minimax theory;data;noise levels;results;comparative;smaller errors;few samples;experiments;overall error;cardinal ones;comparison;number;noise"}, "67b29c3fe6f110125a8892e8ed128d20b23957ea": {"ta_keywords": "entity candidate generation;disambiguation;resource languages;english knowledge base;entities;source language;resource;xel;wikipedia;limited resources;xel systems;most languages;requisite resources;resource assumptions;scarce scenarios;kb;improvements;better use;model results;accuracy;availability;limited availability;overall quality;end;zero;work;experiments;grounds;gains;effect", "pdf_keywords": "disambiguation model;resource languages;lowresource languages;disambiguation;english knowledge base;entity candidate generation;entities;source language;resource;language technologies institute carnegie mellon university;xel systems;xel;wikipedia;standard candidate generation systems;baseline xel system;resource assumptions;end xel;extensive empirical evaluation;candidate generation model;resource settings;different resource availability assumptions;neural candidate generation methods;hybrid candidate generation method;lookup;kb;limited data;improvements;availability;cl;scarce scenarios"}, "2a64da1ed300e49f2d665312146c8bb2f66920b7": {"ta_keywords": "statistical machine translation;translation accuracy;discriminative models;online optimization;minimum error rate training;direct error minimization;risk minimization;batch;optimization;smt systems;smt;maximum likelihood;losses;maximum margin;och;survey;system parameters;modern systems;recent advances;brief introduction;ney;fundamentals;research;article;appropriate methods;use;fundamental part;years;wide variety;seminal work", "pdf_keywords": ""}, "d530a007ae0493ef6a8167c25bd007104623c504": {"ta_keywords": "decompiled identifier renaming engine;decompiled identifier naming;code renaming;variable name recovery;variable names;source code;original source code;compilation process;binaries;decompiler;corpus dire;corpus;github;names;common tools;level code;structural information;novel probabilistic technique;dire;results;neural approach;models;training;time;technique", "pdf_keywords": "decompiled identi\ufb01er renaming engine;variable name recovery;code renaming;variable names;source code;corpus;original source code;parse trees;decompiler;corpus dire;binaries;names;code;structural information;common tools;novel probabilistic technique;dataset;probabilistic models;results;models;dire;oct;training;gold;functions;ii;se;graph;novel technique;time"}, "bc1bf0a21d7838ec167e77c76163afc1f5f76c3d": {"ta_keywords": "background noise removal;multiple signals;probabilistic generative model;noise;time fourier transform;covariance matrices;erps;observed signal;stft;frequency bins;frequencies;event;potentials;trial event;frequency domain;different spatial spread;time;main contribution;paper;coefficients;method;new method", "pdf_keywords": ""}, "4c9f20ce99f9b93527fd76ec04a44fcef9082005": {"ta_keywords": "interactive recommendation;fairness status;cumulative reward;reinforcement learning;interactive recommender systems;fairrec;fairness;good recommendation quality;user preferences;irs;recommendations;state representation;accuracy;term balance;system;extensive experiments;framework;time;problem", "pdf_keywords": "current fairness status;fairness;user preference state;fairrec;reward function;markov decision process;reinforcement learning;irs;finite time markov decision process;aware recommendation;preference;ups;mdp;state;diversity;accuracy;propensity;resentation component;user;ness state;balance;problem formulation;work;effectiveness;framework;paper;models;fs;conclusion;art models"}, "cb153d8469ac466606032ea457b934bc61ae86ae": {"ta_keywords": "fake news detection;fake news detectors;dual emotion features;mining dual emotion;dual emotion;emotional features;publisher emotion;fake news;emotions;news comments;real news;social emotion;features;arousal;chinese;feature set;others;people;world datasets;crowd;english;art task;relationship;paper;performance;extensive experiments;enhancement;state", "pdf_keywords": ""}, "029fa34b291c3f60b8a00cdf386e6048d45c394d": {"ta_keywords": "mixed membership clustering;spectral clustering methods;node clustering methods;competitive mixed membership alternative;effective graph;node;centric representation;edge;scalable approach;representation;data;approach;general", "pdf_keywords": ""}, "04b876e95ac3e4754c8f0c8a9355e7acc3dc70b9": {"ta_keywords": "japanese morphological analysis;language resource addition;various language resource addition cases;speech tagging;training corpus;word segmentation;language resources;annotated sentences;nlp tool providers;corpora;dictionaries;dictionary;new resources;additivity;addition;domain model;joint task;task;comparative study;notion;other domains;methods;entries;paper;part;strategies;harm;ws case;experimental results;asymmetricity", "pdf_keywords": ""}, "7393d2618c7478d937112865458862e8d5f10475": {"ta_keywords": "sequence models;prompttemplate;wellbeing domains;crossdomain reasoning;sequence;template filling;domains;commonsense;template;health;casestudy;approach;paper;enables;ability", "pdf_keywords": "cross domain reasoning challenge;reasoning;food habits;wellbeing domains;health;seq model;food;lifestyle choice;commonsense;seq;task;language models;prompts;people_with_habit;crossdomain reasoning;prompt;vegetables;sample;being domain;medical conditions;profession choice;concepts;vitamin;reason;dataset;sequence models;blood;qualifier relation;smoking;domains"}, "7137a842d496a1a5581db31ad946fa0c0827e663": {"ta_keywords": "robust nonlocalmodels;learning;data", "pdf_keywords": ""}, "f735f5f55cbc5a9d372ea1cd9b4e81d35f043a00": {"ta_keywords": "pairwise comparisons;pairwise comparison data;various parametric models;transitive models;stochastic transitivity;parametric models;standard parametric models;simple singular value thresholding algorithm;minimax rate;transitive model;tractable alternatives;minimax;thurstone models;strong parametric assumptions;flexible model;outcomes;optimal estimator;luce;computational issues;bradley;special cases;same rate;btl;terry;paper;greater flexibility;probabilities;other hand;logarithmic terms;natural form", "pdf_keywords": "stochastic transitivity;transitive model;minimax rate;transitive class;minimax;optimal estimator;classical parametric models;\ufb02exible model;pairwise comparisons;parametric models;minimum fas;models;thurstone models;tractable alternatives;estimators;algorithms;full class csst;poor \ufb01ts;various examples;outcomes;class;special cases;other hand;btl;probabilities;natural form;section;work;e\ufb03cacy"}, "380278716f4d78ad9dcc3ece9e12b235ca1d1569": {"ta_keywords": "tensorlog;tensorflow;probabilistic logic;probabilistic logical reasoning;logical queries;theano;order logic;knowledge;frameworks;examples;thousands;parameters;hundreds;network infrastructure;tens;base triples;infrastructure;differentiable functions;problems;classes;implementation;performance;close integration;experimental results", "pdf_keywords": "probabilistic deductive databases;deductive databases;deductive knowledge graphs;deductive dbs;deductive knowledge graph;tensorlog;logic programs;probabilistic databases;binary predicates;logical queries;belief propagation;neuralnetwork infrastructure;polytree;order logic;inference;prddbs;tensor\ufb02ow;sdkgs;deep learning;ptree;dkg;ai;stochastic;abstract;usual de\ufb01nitions;theano;di\ufb00erentiable functions;implementation;algorithm;classes"}, "8a880680b28dee5642ac88431b3ae1085b911f96": {"ta_keywords": "neural machine translation models;translation quality;vietnamese translation task;translations;language pairs;naive regularization methods;resource languages;best regularizer;regularizer;iwslt15 english;neural models;sentence length;input sentences;bleu score;ter score;punctuation;limited data;example;word frequencies;resource scenarios;relative differences;little inductive bias;data;disadvantage;large amounts;average increase", "pdf_keywords": ""}, "4f7b108830de2e7964b6e1a89bf1c2da60140a34": {"ta_keywords": "latent representation learning;deep latent variable modeling;representation learning;variational autoencoder;effective representation learning framework;powerful language model;intractable marginal data likelihood;posterior collapse;typical surrogate objective;surrogate objective;text;likelihood;vae;vaes;data distribution modeling;effective results;reconstruction;results;paper;elbo;heuristics;effective fix;evidence;simple fix;art methods;combination;practice;previous state;goals;isolation", "pdf_keywords": "variational autoencoders;vae learning;latent variable models;autoencoder objective;inference network;representation learning;language modeling;vae training;neural networks;latent space;typical surrogate objective;vaes;text reconstruction;data distribution;elbo objective;simple heuristic techniques;observed data;free bits;kl term;useful information;welling;introduction;kingma;method;paper;quality;results;former technique;local optima;goals"}, "14119210e5f9e0d962e329c833557dfb5524c4bd": {"ta_keywords": "porous sio2 nfs scaffold combination;flammable organic liquid electrolytes;solid polymer electrolyte;oxygen batteries;state lithium;3d sio2 nfs framework;efficient inorganic filler;nanofibers;lithium;batteries;ionic conductivity;cathode;intimate cathode;ices;high discharge capacity;nfs;sslobs;lobs;cycling capacity;dendrite growth;interfacial resistance;reaction sites;tight connection;performance liberation;safety;framework;long lifetime;structure;great promise;issues", "pdf_keywords": ""}, "de8ded0d66f3227d99751a89fdd5f4b438d6e8ee": {"ta_keywords": "robust speech analysis;source separation;recognition;application", "pdf_keywords": ""}, "e74d7523d7d96ab65f05f059284f9d0a994bb074": {"ta_keywords": "ntt ted talk treebank;syntactic parsing;treebank;sentence segmentation;speech translation;machine translation;fundamental natural language processing technology;lecture speech;language modeling;syntax;speech;ted talks;iwslt translation campaign;resources;naist;applications;other applications;current target;interaction;investigation;number;work;paucity", "pdf_keywords": ""}, "3efee0095cb578659dfaaf0d87a616f133ecf85c": {"ta_keywords": "data augmentation approaches;johns hopkins university speech recognition system;multiple microphone arrays;acoustic modeling efforts;dinner party speech;end speech dereverberation;neural network architectures;vector extraction;house implementations;word error rate;available tools;improved baseline;absolute improvement;refined techniques;tools;previous baseline;paper;comparisons;development set", "pdf_keywords": ""}, "9896a68e999298410bf16ffd08e8e67a54ad6a91": {"ta_keywords": "natural language processing software;existent natural language processing software;natural language processing tools;data processing tools;gearman framework;cloud computing environment;middleware;specific middleware;software;large document collection;minimal deployment;licensing;existent infrastructure;efficient use;consolidation;support;usage costs;paper studies;organizational issues;such advantages;isolation;important step;way;problem;rational choice", "pdf_keywords": ""}, "52c040c4b1786166325a0d930af94a529e2b5023": {"ta_keywords": "speaker adaptation;dnn adaptation technique;sequence summarizing neural network;dnn system;acoustic summary;vector extractor;neural network;summary vector;utterance;single loss function;ssnn;sequence;input;fmllr;networks;additional improvement;fbank;such vector;main network;performance;paper", "pdf_keywords": ""}, "da564ff902a5490088f60c9fb100531fc9f97288": {"ta_keywords": "probabilistic logic;probabilistic language;information extraction;personalized pagerank;entity resolution task;large database;propositional inference;queries;joint inference task;retrieval;order logic;inference;propositional representation;information integration;many information;classification;grounding;classification task;query;facts;programming;groundings;database size;order;small graph;speedup;management tasks;cost;approach;key problem", "pdf_keywords": "stochastic logic programs;personalized pagerank process;personalized pagerank;personalized pagerank vector;correct approximate inference scheme;e\ufb03cient inference;inference;correct approximate grounding scheme;short derivations;annotated edges;order language;linearized version;case approximation error;rapid learning;gradient computation;proof space;computation;slp;ppr;variant;extension;feature;proof;conclusions;information;bias;language;iteration method;query;graph"}, "27724bd19946d6a824d06cdca3cdfe5d40f71003": {"ta_keywords": "edit completions;abstract syntax tree;editcompletion task;past edits;syntactic models;neural crfs;contextual code changes;edits;learned model;edit operation;edited code;completion;lstms;sequential models;code snippet;edit;thorough evaluation;modeling approaches;program;snippet;multiple strong models;model;representation;novel approach;higher accuracy;task;ast;source;transformers;structural model", "pdf_keywords": ""}, "0cee58946a13a5c2845647b4af8b9d2bf52a8b6b": {"ta_keywords": "domain named entity recognition;entity recognition;external knowledge bases;manual annotations;distant labels;language models;distant supervision;language model;bert;ner models;ner tasks;bond;noisy distant labels;ner;recall;training approach;prediction performance;new computational framework;assisted open;domain;stage training algorithm;model performance;roberta;precision;self;challenge;second stage;first stage;large amounts;problem", "pdf_keywords": "supervised ner methods;language models;language model;incomplete annotation;distant labels;distant label;recall;training approach;ner tasks;labels;prediction performance;contextual information;benchmark datasets;ner models;stage training algorithm;bert;missing words;bond;model performance;datasets;new computational framework;mlm;challenge;task;model;precision;roberta model;student framework;data;teacher"}, "8274799029bfac4402685e1efd995a8aeb9e7426": {"ta_keywords": "sequence autoencoder;abstractive sentence compression;latent word sequences;pretrained language model;neural sequence;sequence models;reconstructed sentences;latent sequences;encoder;several natural language processing tasks;decoder pairs;large parallel corpora;sentences;sequence;last sequences;categorical distributions;middle sequence;discrete latent variables;human;sentence;input;words;prior;model;reinforcement learning;continuous relaxations;gradient;length;optimization;important information", "pdf_keywords": "unsupervised abstractive sentence compression;abstractive sentence compression;sequence autoencoder;reconstructed sentences;neural sequence;sequence models;autoencoder;encoder;decoder pairs;several natural language processing tasks;large parallel corpora;last sequences;sequence;abstract;middle sequence;sentence;differentiable sequence;seq3;parallel data;speci\ufb01c loss functions;gradient optimization;contrast;additional task;words;model;input;discrete latent variables;optimization;end;gradient"}, "927efd299cffcfca3716efefcc904331b70c153e": {"ta_keywords": "interpretable graph question answering dataset;interpretable reasoning graph;bilingual qa;reasoning graph metric;qa tasks;reasoning graph;existing qa datasets;deep learning models;answer quality;new qa model;art qa models;qa;answers;noahqa;numerical reasoning;questions;datasets;scores;mathematical expressions;art qa research;diverse question;compound mathematical expressions;appropriate evaluation metric;aspects;evidences;exact match scores;above shortcomings;humans;human performance;simple calculations", "pdf_keywords": "interpretable reasoning graph;truth reasoning graphs;bilingual qa;reasoning graph metric;reasoning graph;new qa datasets;semantic similarity;existing qa datasets;new qa model;art qa models;chinese test;noahqa;questions;numerical reasoning;scores;automatic evaluation method;math23k;exact match scores;dropqa;english;compound mathematical expressions;conclusion;ground;graph;gts model;above shortcomings;humans;dagsim;complex numerical questions;human performance"}, "6a116b897569fe4d6ea9ad4c3ba9a18825b96f49": {"ta_keywords": "knowledge base completion;probabilistic logical rules;logical rules;differentiable learning;reasoning tasks;neural controller system;learning problem;primitive differentiable operations;logical reasoning;differentiable model;models;order rules;perceptual tasks;many tasks;discrete optimization problem;end systems;structure;level;sets;theory;end;term goal;alternative approach;paper;work", "pdf_keywords": "neural logic programming;knowledge base reasoning tasks;logic programming outperforms;tensorlog;memory attention vectors;neural lp;neural lp model;logical rules;neural controller system;natural language;learning models;structure learning;primitive differentiable operations;word representations;queries;order rules;differentiable model;attention mechanism;differentiable framework;structure;memory;operator;operations;parameters;framework;several types;parameter;order;new approach;differentiable system"}, "3c0e8f7337491ca4f714de14021eb23ca43d1d5e": {"ta_keywords": "robust speech recognition;speech enhancement;automatic speech recognition;acoustic model adaptation;reverberant environments;telephone speech;reverberant rooms;field microphones;noisy audio;asr;neural network methods;training data;aspire;noisy conditions;robustness;evaluation data;performance degradation;challenge;data;systems;techniques;paper;approach;work", "pdf_keywords": ""}, "6c78bac2dd71efb89951d9bab72c8129bbc07f67": {"ta_keywords": "topic models;topic distributions;latent variable mixed membership models;regularization framework;regularization;document perplexity;regularization technique;language modeling;sentiment;membership models;indicative features;words;product reviews;latent;star counts;polysemy;reviews;membership behavior;content;sparsity;priors;models;paper;modification;documents;pseudo;preferences;many domains;observed variables;characteristics", "pdf_keywords": ""}, "ce45aa1c64da82bfd02db0e147efa268da6980e4": {"ta_keywords": "ofdm system;bit loading algorithms;sub carriers;classic bit loading algorithms;greedy algorithm;bits;algorithms;numbers;simulation;methods;performance;article", "pdf_keywords": ""}, "d32fb57467d64bb82dce60e904ddc5c18b3f0f91": {"ta_keywords": "similar spatial parking demand;curbside parking demand;curbside parking;gaussian mixture model;park;urban areas;pricing policies;congestion;transportation;spatial autocorrelation;seattle;temporal consistency;pricing schemes;spatio;temporal analysis;data;repeatability;city;seattle department;zones;metric;incentives;drivers;information;recent years;attention;understanding;performance;case;rapid expansion", "pdf_keywords": "similar spatial parking demand;parking demand;observed occupancy patterns;curbside parking;similar spatial demand;gaussian mixture model;spatial demand;spatial autocorrelation;transportation;temporal consistency;temporal characteristics;spatio;demand;repeatability;metric;industrial areas;data;zones;faces;gmm;belltown;seattle department;consistency;model;map;groups;time;data sources;section ii;fig"}, "ab5c6703fceb3dce6558be309cc65a4a8615c774": {"ta_keywords": "approximate neighborhood graph;distance symmetrization;neighborhood graphs;fast retrieval;search algorithm;index;graph;distance;straightforward metrization;space mapping;symmetrization;complex;performance;construction;substantial performance degradation;turn", "pdf_keywords": "distance symmetrization;approximate neighborhood graph;neighborhood graphs;proximity graphs;neighborhood graph;retrieval algorithm;nn search;retrieval method;metricspace mapping;search algorithm;distance metrization;approximate neighborhood;retrieval method sw;metric space;symmetrization;quasisymmetrization;re\ufb01ne symmetrization;graph;index;dimensional mapping;full symmetrization;cases;performance;construction;substantial performance degradation;full \ufb01lter;force;modi\ufb01ed;coercion;turn"}, "d6741241efb9ffd933df974b43d7109c72238371": {"ta_keywords": "musical events;several tracks;track instrumentation;musical material;different tracks;interactive demo;track;generative system;level inpainting;transformer architecture;note density;transformer;generation time;single sequence;control;bar;single time;time;sequence;level;various representations;mmm;contrast;user;high degree;previous work", "pdf_keywords": "polyphonic music generation;track instrumentation;musical material;generative system;track;interactive demo;transcription;transformer architecture;output;level inpainting;generation;generation time;novel representation;note density;dimensional sequences;temporal dependencies;control;various representations;novel approach;variety;mmm;future work;bar;level;application;exciting avenue;\ufb01ne;goal;methods;high degree"}, "d41216f2f809e9fe26a684392f0ded4778f79e74": {"ta_keywords": "tracking speech recognizer;monolithic multilingual asr system;language speech corpus;automatic speech recognition;language speech;new languages;end language;asr systems;independent neural network architecture;dynamic tracking;pronunciation dictionaries;utterance;asr;language;linguistic information;code;switching;end;mixed;training procedure;switches;model;burden;paper;flexibility;opportunity;advantage;need", "pdf_keywords": ""}, "66cbda3e730285cb572c4792edcef209af32c564": {"ta_keywords": "question answering;information retrieval;knowledge distillation;retriever models;many natural language processing systems;distilling knowledge;retriever model;retriever;neural networks;reader;continuous representations;documents;query;supervised data;annotated pairs;support documents;downstream tasks;features;important component;task;such methods;challenge;competitive results;open domain question;paper;traditional methods;pairs;technique;hand", "pdf_keywords": "question answering;information retrieval;information retrieval module;retriever models;many natural language processing systems;retriever systems;reader model;retriever model;distilling knowledge;knowledge distillation;annotations;retriever module corresponds;sequence reader;retriever;queries;reader module corresponds;documents;annotated pairs;reader;edouard grave1 1facebook ai research;support documents;supervised data;student model;task;teacher model;query;downstream tasks;such methods;important component;attention scores"}, "7b96f6165ce5f686e46868c53b111b8e43b93de3": {"ta_keywords": "acl anthology;older papers;older literature;recent papers;outgoing citations;natural language processing;recent work;papers;acl venues;other researchers;years;field;age;unprecedented growth;tendency;analysis;opportunity;growth;rate;work;period;surge;stock;expense", "pdf_keywords": ""}, "863b2b38b33ffc4e5462adbc7aaf84aeb93adda8": {"ta_keywords": "annotation projection;parallel corpora;multiple source languages;single source language;annotation;indoeuropean languages;dependency projection;integer linear programming;multiple sources;languages;multiple tasks;speech;ilp;task;algorithm;joint part;hundreds;subset;previous work;time;contrast", "pdf_keywords": "computational linguistics;parallel corpora;dependency annotations;syntactic dependencies;multiple source languages;annotations;annotation;source languages;resource languages;languages;word alignments;tags;pos tags;pos labels;commodity\ufb02ow formalization;bibles;integer linear programming;intermediate target graph;ilp;novel ilp;algorithm;trees;multiple tasks;association;word;proceedings;contributions;hundreds;contribution;berlin"}, "d16d24dd5135f148556df1b2304b3747eee19e00": {"ta_keywords": "reply lines;text email messages;mail classifiers;email corpora;email message;extract signature;email threading;signature blocks;text;email;automatic content;lines;anonymization;speech systems;sequence;line;features;sequential representation;analysis;machine;set;methods;many potential applications;method", "pdf_keywords": ""}, "7f54429be66319dc19a42c0c9fceda3ac33fc92d": {"ta_keywords": "cognitive tutors;cognitive tutor;tutoring;intelligent authoring tool;simulated student;ai programming;cognitive task analysis;human student;programming;cognitive model;educators;tasks;demonstration;essential tasks;authors;author;subject domain;tool;computer;algebra equation;primary target users;instance;production rules;successful form;correct production rules;hand", "pdf_keywords": ""}, "c97500763de8a0871f1b83b1f968fcf4a8b31aee": {"ta_keywords": "stance tasks;automatic stance recognition;natural speech;stance;audio corpus;weak stances;strong stances;corpus;unscripted conversations;corpora;corpus collection;speaking rate;subjectivity;acoustic signals;collaborative tasks;ataros project;disfluencies;participants;involvement;tasks;low involvement;preliminary assessment;styles;other high involvement;support;initial task validation;ataros technical report;dyads;taking;portion", "pdf_keywords": ""}, "2ded680be56e03c8c17a04065deaac8ea6d4fa12": {"ta_keywords": "novel hla;new hla;donors;anhui province;china;typing;characterization", "pdf_keywords": ""}, "753d10503a3cf340e41552109087ffd15ec96446": {"ta_keywords": "local entrepreneurial network;experimental economics study;detailed structure", "pdf_keywords": ""}, "998bd8862ab4193e672bb16fe1aae4d446f7536e": {"ta_keywords": "image synthesis;image translation;contrastive learning;unpaired image;learned feature space;single image;mutual information;dataset;image;training;corresponding patches;input;domain;content;negatives;other elements;output;corresponding patch;elements;similar point;patch;other patches;several critical design choices;addition;straightforward method;framework;method", "pdf_keywords": "unpaired image translation problems;image translation;contrastive loss;image synthesis;contrastive learning;unpaired image;contrastive learning e\ufb00ective;unsupervised learning;input images;separate encoders;mlp projection network;sided translation;mlp networks;encoder genc;images;mutual information;content preservation;training time;quality;input;ablation study;output;external patches;outperforms;features;model;weight sharing;several critical design choices;variants;\ufb01nd"}, "d1206ccabd1980848f14472d6548251c2fab7963": {"ta_keywords": "transfer learning;transferable source tasks;nlp tasks;predicting transferability;task embeddings;source task;scale language models;transferability;downstream tasks;target task;task complexity;task data;nlp;target data size;transfers;source data size;task;domain similarity;speech;drop qa dataset;source;results;factors;performance;recent advances;experiments;part;effectiveness;role", "pdf_keywords": "nlp tasks;task embeddings;transfer learning;task transferability;data source tasks;question answering;ofspeech tagging transfers;target tasks;identi\ufb01es source tasks;new tasks;sequence labeling;target task;task data;tasks;target training data;task library;task complexity;transferability;vector representations;similarity;effective transfer;drop qa dataset;text classi\ufb01cation;data;broad classes;models;source;qa;codebase;bene\ufb01ts"}, "e9d26b9f5e6b619bbb759a67560cb949a9f034ba": {"ta_keywords": "ascent learning dynamics;strict local minmax equilibria;strict local minmax equilibrium;time gradient descent;asymptotic saddle avoidance result;unconstrained continuous action;nonconvex optimization problem;gradient descent;theoretic equilibria;sum games;gradient;nonconvex;natural game;stability characterization;ascent update;stable points;games;\u0142ojasiewicz;timescale separation;learning;pursuit;sure convergence guarantee;stationarity;classes;p\u0142;polyak;convergence;notions;player;class", "pdf_keywords": ""}, "6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91": {"ta_keywords": "multimodal machine learning;multimodal machine;specific multimodal applications;such multimodal signals;late fusion categorization;modality;fusion;artificial intelligence;multiple such modalities;common taxonomy;taxonomy;broader challenges;new taxonomy;future research;translation;survey;recent advances;representation;world;progress;alignment;something;researchers;field;paper surveys;order;directions;way;state;research problem", "pdf_keywords": "multimodal machine learning;multimodal emotion recognition;multimodal fusion;multimedia event detection;fusion;vision models;unique challenges;medical image analysis;technical challenges;recent developments;language;\ufb01ve core;chaitanya ahuja;translation;importance;representation;\ufb02avors;avsr;data;main applications;computational researchers;broad range;texture;experience;applications;aug;survey;objects;research \ufb01eld;world"}, "480d545ac4a4ffff5b1bc291c2de613192e35d91": {"ta_keywords": "dynamic neural network toolkit;tensorflow;dynamic declaration strategy;computation graph construction;symbolic computation graph;dynamic declaration;computation graph;programming language;different network structures;complicated network architectures;neural network models;network structure;static declaration strategy;toolkits;dynet;toolkit;symbolic representation;procedural code;network outputs;implementation;computation;training example;python;cntk;theano;models;construction;engine;examples;derivatives", "pdf_keywords": "dynamic neural network toolkit;dynamic neural networks;recursive neural networks;alternative programming model;structured network architectures;static declaration toolkits;programming model;execution programming model;network architecture;several popular toolkits;standard model architectures;neural networks;toolkit;programmers;program;natural language processing;serious software engineering risks;uni\ufb01ed declaration;execution;uni\ufb01es declaration;declaration;tree;autodi\ufb00 libraries;dynet;language;alternative paradigm;sequences;creation;concept;execution e\ufb03ciency"}, "aeccb1d53e08adcfe271d1e4b08c0a2cdc3c42b4": {"ta_keywords": "open information extraction;external knowledge bases;level tuple extractions;corpus;relation phrases;individual sentences;sentences;level extractions;world corpora;remine;entity;global structure constraints;systems mine relation tuples;entity arguments;sentence;distant supervision;local context;global structural signal;novel open ie system;local context signal;predicate string;relation;supervision;ie;objective;facts;unified framework;other open ie systems;joint optimization problem;robustness", "pdf_keywords": ""}, "824cd8db8a68732db04f4d8b7139eb4475e59ff2": {"ta_keywords": "natural language generation;nlg research;nlg;centric corpora;gem;human evaluation standards;evaluation;evaluation strategies;benchmark;new models;models;metrics;tasks;current models;challenge;progress;datasets;limitations;opportunities;environment;target;limitation;regular updates;ecosystem;wide set;disconnect", "pdf_keywords": "nlg challenges;entire nlg community;automatic evaluation;evaluation;gem;gem datasets;benchmark;task;leaderboard;model outputs;workshop;generation;progress;acl;description;metrics;shortcomings;depth evaluation;selection;announcement;hill climbing;opportunities;research;data;construction;paper;linzen;support;wide range;fallacy"}, "508e9bb13fcb1fa0c4dbac47288e8a3c2487bfc2": {"ta_keywords": "generalization;proof tree;automata;formal framework;algorithm;new algorithm;implementation;learning;constants;number;tree;examples;outputs;systems;operation;explanation;variables;several alternative frameworks;approach;paper;shape;desiderata;illustration;cohen;literature", "pdf_keywords": ""}, "7a733a8d8f8649cc07e3ea9091f454ae117573af": {"ta_keywords": "attentionmesh;biomedical text;information retrieval;annotations;word level;medical subject headings;attention mechanism;deep learning;human evaluations;index mesh terms;textual evidence;nlm;curators;expert;end model;mesh;high level;article pair;article;national library;medicine;accuracy;relevant words;model;novel end;art mif performance;interpretability;final model;bioasq chanllenge;contest", "pdf_keywords": ""}, "abb9b27440719ca44db5947a537fde07f0547973": {"ta_keywords": "distributed storage setting;mds code;storage;nodes;node;explicit codes;repair;file;explicit code;first explicit code;system parameters;system;data;reduction;uncoded form;paper;fragment;area;feasible values;set;recent work;knowledge;case;way", "pdf_keywords": ""}, "808a9c9dece4c21be50f41e6caf50101f2b24b47": {"ta_keywords": "preference models;human preferences;qualitative preference statements;human experiments;experimental psychologists;preferences;ai researchers;utility functions;experiment;testing data;bias;decision makers;statistical hurdles;choices;models;choice;data;many mathematical frameworks;logic formalisms;particular mathematical model;specific data;prior data;causality;design;model;methods;considered setting;other subjects;constraint optimization;environments", "pdf_keywords": ""}, "104f75283ae9027eb478e7984bd26b680277ce6f": {"ta_keywords": "robust instruction representations;language navigation;room benchmark;language pretraining;robust navigation;stochastic sampling;long sequential action;expert actions;room;training;stochastic;agent;unseen instructions;action;actions;challenge;vision;environments;test;techniques;own mistakes;scheme;vln;path length metric;success rate;new state;schemes;previous best result;core;art", "pdf_keywords": "navigation agent;stochastic action;long sequential action;toroom benchmark;expert actions;stochastic;training;language models;inference time;r2r benchmark test set;agent;forcing;test;teacher;second challenge;actions;techniques;student;press;robust generalization;room;underexplored techniques;own mistakes;vln;complex approaches;spl;success rate;previous best result;current state;new state"}, "f83ef3250ba1166d7c1c7585da7dd78e0641fae7": {"ta_keywords": "cooperative music generation;symbolic music generation;generative adversarial networks;music;rock music;coherent music;musegan;tracks;gans;additional tracks;accompaniment;composer model;piano;drums;specific track;guitar;ai;bass;models;strings;jamming model;bars;dataset;art;network;temporal model;human;rolls;time;hybrid model", "pdf_keywords": "generating music;symbolic music generation;novel generative model;generative adversarial networks;coherent music;accompaniment;rhythmic structure;gans;generator;musegan;adversarial learning;audio samples;networks;hsuan yang1;temporal structure;models;videos;multitrack interdependency;dataset;national tsing hua university;code;essence;images;discriminator;computer science;hsinchu;taiwan 2department;bars;abstract;richard40148"}, "199f383e9acd62649121ccde1e06631ce62c89e9": {"ta_keywords": "secret sharing;sneak algorithm;several cryptographic protocols;secure multiparty;communication complexity;general network;byzantine agreement;dealer;kpropagating;networks;efficient generalization;low communication cost;dealer condition;network;algorithm;general networks;communicationcomplexity;direct communication links;computation;key management;threshold;shamir;large class;participants;paper;bounds;worst case;art solution;wide class;problem", "pdf_keywords": ""}, "645bc7a5347a299a1e8aa965867bd097f6f4bddd": {"ta_keywords": "agent answers;agent task;recursive mental model;answer generation;progress agents;reinforcement;agent models;agent;navigation steps;navigation actions;reward signal;mind;questions;instruction;answers;novel environments;goal;turn models;better generalization;paper;rmm;candidate;theory", "pdf_keywords": "recursive mental model agent;recursive mental model;dialogue navigation;shortest path planner;navigation;robots;reinforcement learning;guide model;humans questions;trajectory;language;mind;next \ufb01ve steps;guide;component models;navigation error;lemon;questioner;novel environments;better generalization;feedback;target;model failure;rmm;abstract;answers;failures;homero roman roman1 yonatan;jesse thomason3 asli celikyilmaz1 jianfeng;figure"}, "d00a403028eb0786915dab7a76692e5eeadf60be": {"ta_keywords": "transductive transfer learning;unsupervised transductive transfer learning;transfer learning;protein name extraction;transfer;supervised version;target domain;training;related task;data;information;task;models;research;previous work;methods;approaches;challenging case;comparative study;important new area;current state;problem;performance;art", "pdf_keywords": ""}, "7abcc79e10ff651ef59dea84d347fa64c51e11b2": {"ta_keywords": "organic heterostructures;axial ohss;unilateral axial ohss;sequential crystal nucleation rate;intermolecular interactions;different cocrystals;hierarchical charge;assembly strategy;low lattice mismatching rate;shape;sequential self;types;engineering;account;ohss;more kinds;effective approach;avenue;present work", "pdf_keywords": ""}, "31b3e84f0a66e27c53c7fe403a0c6cd2319ed797": {"ta_keywords": "tensorlog;neuralnetwork infrastructure;tensorflow;probabilistic logic;logical queries;probabilistic logical reasoning;probabilistic database;learning infrastructure;theano;order logic;knowledge;deep;frameworks;examples;thousands;hundreds;parameters;tens;base triples;infrastructure;problems;classes;differentiable functions;implementation;performance;close integration;experimental results", "pdf_keywords": ""}, "805e49c7282b847faee048a63c1f43ceb08f5257": {"ta_keywords": "voting systems;voting rules;elections;election data;different voting rules;voting data;coalition size;small coalitions;votes;vote deficit;condorcet efficiency;high consensus;place candidates;condorcet;statistical models;borda rule;restricted preference profiles;peakedness;empirical study;manipulations;large datasets;large samples;theories;manipulation;rules;paradox;testing;occurrence;lack;instances", "pdf_keywords": ""}, "641af3bc3cc17993dc72098725d2eb9c0d98049d": {"ta_keywords": "density tree estimates;density clustering;tda;confidence sets;statistical perspective;data sample;data analyst;overview;key techniques;theoretical properties;results;project;such techniques;tools;deep dive;set", "pdf_keywords": ""}, "84f2cfbc142ad3165ea3bcacd189a3d1110660e0": {"ta_keywords": "relative word error rate;wsj eval92 test set;relative wer reduction;wsj;array results;attention e2e asr;field asr robustness;array framework;formula;best wer;wer;multiple microphone arrays;e2e;heterogeneous encoders;automatic speech recognition;asr;separate encoders;methods;parallel;reduction;res framework;conventional fusion strategies;diverse information;experiments;wall street journal;parallel streams;same acoustics;complementary information;research directions;mem", "pdf_keywords": "encoder ctc;parallel encoders;wordlevel prediction fusion;encoders;stream attention;heterogeneous encoders;rnn;acoustic features;cnn;decoder;wav alignment;convolutional layers;input features;attention;level fusion;frame concatenation;res framework;same acoustics;rnnbased;temporal resolutions;separate ctc networks work;same speech;res architecure;several conventional fusion strategies;substantial wer reduction;mem;different architectures;rover;architecture;architectures"}, "ceefd51b4b391668e313afe8edb3588197002e37": {"ta_keywords": "speech synthesis;speech parameter trajectory;speech parameter sequence;smoothing;parameter generation algorithm;natural speech;modulation spectrum;postfilter;global variance;quality degradation;new feature;feature;ms;features;gv;hmm;effects;example;effect;pattern;order;effectiveness;main cause;paper", "pdf_keywords": ""}, "2ec99c834bd67ac64ec04b426e5f9fd04f639024": {"ta_keywords": "crowdsourced audio transcriptions;crowdsourcing;audio transcriptions;datasets;quality datasets;crowdspeech;efficient data collection;aggregation methods;data collection pipeline;data collection;machine learning systems;better algorithms;scale dataset;voxdiy;data;benchmarks;image classification;language;russian language;general challenge;principled pipeline;novel domain;counterpart;specific data;evaluation;code;improvement;advances;standard tools;domain", "pdf_keywords": ""}, "4375cccdfaf2ce3d013e4129d39f7801ef8a468e": {"ta_keywords": "translation results;asian translation;automatic evaluation server;tasks;mixed domain subtasks;6th workshop;wat2019;research paper submissions;results;paper;teams", "pdf_keywords": ""}, "50a1dd504037463578f6ba8ee40afe4143f3d6fa": {"ta_keywords": "vector uniformly;norm;uniform measure;sphere;expectation;upper bound;upper bounds;euclidean unit;concentration;vector;problem;phenomenon", "pdf_keywords": "order convex optimization;bandit;optimal algorithm;machine learning research;point feedback;journal;zero"}, "fac2368c2ec81ef82fd168d49a0def2f8d1ec7d8": {"ta_keywords": "entity recognition;information extraction tasks;entity mentions;coreference links;relation extraction;contextualized embeddings;event extraction;scoring text spans;entities;bert;adjacent sentences;tasks;span representations;context;dynamic span graph updates model;sentence;relationships;instance;domains;enumerating;datasets;capabilities;model;state;range;framework;refining;experiments;art results;variety", "pdf_keywords": "event extraction;information extraction tasks;entity recognition;relation extraction;bert embeddings;contextual language models;contextualized span representations;text span graph;entity;contextualization methods;candidate text;context;bert building;multitask framework;tasks;spans;task;relation;ie tasks;additional structure;sep;speci\ufb01c message updates;graph propagations;graph propagation;arti\ufb01cial intelligence;results;capabilities;consideration;abstract;domain"}, "25ee819bc444b02db43fcbeced982c975edee033": {"ta_keywords": "crowdsourced labeling;binary task labels;task specialization model;worker clustering;task types;tasks;worker skill estimation;task;worker;labeling;inference algorithm;majority voting;type;recovery accuracy;unmatched types;types;particular type;queries;information;reliable answer;performance;finite set;minimum number", "pdf_keywords": "binary task labels;worker clustering;task types;recovery accuracy;worker skill estimation;semide\ufb01nite programming;weighted majority voting;inference algorithm;task;new clustering method;majority voting;worker;workers;algorithms;clustering result;art inference algorithms;type specialization model;queries;sdp;answers;dawid;skene model;knowledge;\ufb01rst algorithm;estimators;second algorithm;performance;information;good performance;diverse parameter regimes"}, "6b13c4ac18f621155a550238a037a670bdce8969": {"ta_keywords": "\u7b2c15\u56de\u97f3\u58f0\u8a00\u8a9e\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "06d0af396fb08caa6a665dd476380aa16b6199b2": {"ta_keywords": "computer question answering;human;workshop;proceedings", "pdf_keywords": ""}, "3e33c988969b4c9f1d9af8c1c0f7644a30d0311f": {"ta_keywords": "speech translation system;reliability speech translation;medical corpus;translation experiments;corpus;language barriers;medical domain;medical situations;system;design;problems;paper;overall design;collection;first steps", "pdf_keywords": ""}, "6fb3d5a48be16fe1a4cff5e83093b77fbcd1013b": {"ta_keywords": "privacy tradeoff;smart grid operations;consumer privacy;privacy;privacy metric;private parameter;direct load control programs;adversary;strong adversary model;smart meters;electrical grid;better load control;utility;load control example;consumers;monitoring;tradeoff;loads;data;algorithm;simulation results;many advantages;performance;frequency;paper;ability;results;modernization;installation", "pdf_keywords": ""}, "032e660447156a045ad6cf50272bca46246f4645": {"ta_keywords": "personalized neural machine translation;machine translation;output softmax;translation;extreme adaptation;native language;efficient adaptation technique;person;gender;variations;particular user;bias;social status;models;factored approximation;own flavor;content;mt system;mt;size;parameter;fits;system;number;paper;geographical origin;factors;significant effect", "pdf_keywords": "domain adaptation;softmax bias;domain adaptation problem;personal linguistic variations;softmax layer;few prototypical bias vectors;speaker annotated ted talks;language pairs;bias;additional bias vector;speakerspeci\ufb01c variations;translation;new dataset;domains;task;domain;model parameters;little data;better scores;millions;factored model;user;model;baseline;person;different users;parameters;real world application;mixture;small proportion"}, "2aad7765250f7d9e312c9382f929ea5239b0fd73": {"ta_keywords": "cell biology;biology;cells;biological;computer scientist;complexity;guide;other ways", "pdf_keywords": ""}, "a1d578646cf42f2f69ee996742af484d03cc9121": {"ta_keywords": "multilingual nlp tasks;multilingual language models;machine translation;multilingual version;unified text;parallel data;nmt5;larger models;mt5;model capacity increases;t5;performance;text format;objectives;art results;wide variety;gains;straightforward way;state", "pdf_keywords": "standard neural machine translation objective;translation language modeling;multilingual language models;language id models;machine translation;language pairs;text objectives;parallel data;languages;several text;nmt5;various text;mc4;performance;1subject;objectives;model;representations;tlm;precision;conneau;lample;\ufb01nd;paper;impact;straightforward way"}, "0ba3e29dac0857100935b6eb22bce9cee4afcf17": {"ta_keywords": "statistical information retrieval;local name constants;name constants;global domains;normalization routines;local names;normalization;similarity;plausible global domain;personal names;most databases;exact matching;heterogeneous databases;natural language text;entities;names;appropriate global domain;detailed knowledge;whirl;inferences;query;benchmark problem;accuracy;world;real world;space model;purpose;course numbers;logic;many cases", "pdf_keywords": ""}, "cec6de30eea5b4a5a414cf99830fbdb5c56a481c": {"ta_keywords": "parallel vod content distribution;vod system;bandwidth constraints;packet level simulation;storage capacity constraints;various network;heterogeneous nodes;node failures;central server;storage;markov approximation technique;network failure;heterogeneous environments;larger system;remarkable robustness;massively scaled;network connections;user churn;general architecture;large catalog;algorithm;user device;demand;reliability;static optimization problem;dual framework;load;implementation;thousands;system scale", "pdf_keywords": ""}, "987658ba918710bbce5de8d92eb44bd127cf72c5": {"ta_keywords": "phoneme mappings;allophone graphs;phonemic transcriptions;allophone mappings;universal speech recognition systems;universal speech recognition;differentiable allophone graphs;speech annotations;specific phoneme;phonological units;universal phone level;rich pronunciation variations;new languages;state transducers;linguists;languages;spoken sound;learnable weights;language;phone;lexicons;annotations;level supervision;systems;surface levels;general framework;work", "pdf_keywords": "phonemic transcriptions;phoneme mappings;interpretable probabilistic phone;speci\ufb01c phonemes;phonemes;phone realizations;phoneme rules;speech recognition model;differentiable allophone graphs;allophone discovery;multilingual model;learnable weights;underlying language;languages;unseen languages;state transducers;phones;universal phone;phone;allograph model;language;pronunciation variation;linguistic applications;level supervision;mappings;training;graph;layer;end manner;prior works"}, "c0a32c68b992b44f1812492c95ac91fb62a6df37": {"ta_keywords": "policy gradient reinforcement learning;competitive gradient;generic local nash equilibria;certain online convex optimization;nash equilibria;competitive agents;gradient flows;bandits;learning algorithms;gradient;learning;games;smale games;other competitive environments;unstable critical points;dynamics;algorithms;critical points;competitive settings;markets;periodic orbits;single agent case;morse;like flows;strict saddles;guarantees;wide breadth;formal mathematical sense;schemes;behaviors", "pdf_keywords": ""}, "01138945dc9de691cd559d09a46597cca7659efb": {"ta_keywords": "peer review;ethical norms;bias;data science;various biases;human evaluations;disciplinary perspectives;data;dishonest behavior;fairness;technology;data management systems;research question;subjectivity;research papers;performance measures;certain social impacts;policies;social impacts;law;society;protocols;confer harms;genetics;concerns;powerful tools;management decision;questions;management;deep", "pdf_keywords": ""}, "ca7cd3a90d2953b2f8e45686afa3e79eb3a39add": {"ta_keywords": "edit completions;editcompletion task;abstract syntax tree;lightweight neural model;past edits;syntactic models;neural crfs;completion;edit operation;edits;learned model;edited code;code snippet;lstms;thorough evaluation;sequential models;edit;snippet;program;modeling approaches;multiple strong models;model;representation;task;higher accuracy;ast;rest;novel approach;transformers;source", "pdf_keywords": "edit completions;editcompletion task;past edits;syntactic models;abstract syntax tree;learned model;completion;contextual code changes;edit operation;edits;sequential models;edited code;edit;code snippet;model;program;snippet;higher accuracy;shaked brody;technion;structural model;ast;relative gain;israel uri alon;source;israel eran yahav;israel;target;goal;state"}, "d7bebb71635cb818d2f5e0ca0a70434283deb4b6": {"ta_keywords": "imitation learning;imitationlearned policy results;imitation;higher human prediction accuracy;humanlike policies;chess;human behavior;regularized search;play learning;expert humans;human actions;like gameplay;search;search techniques;human;stronger performance;kl;examples;kl divergence;self;task;strong;strength;problems", "pdf_keywords": "imitation learning;imitationlearned policy results;novel regret minimization algorithm;monte carlo tree search;\ufb01rst regret minimization algorithm;higher human prediction accuracy;imitation;human imitation;human prediction accuracy;search policy;chess;games;search;anchor policy;art prediction accuracy;policy;press diplomacy;il policy;prior state;mcts;il model;cost term;kl divergence;stronger performance;standard mcts;value function;algorithm;human;art results;state"}, "4d7a50f6cfd8f27ebd4d5201fad6c5ef42c33733": {"ta_keywords": "hospital mortality predictions;mortality prediction;hospital mortality;clinical notes;intensive care units;bert model;electronic health records;icu patients;patient health;continuous vital signals;embeddings;various medical devices;icus;auc score;ehr;summaries;patient;doctors;data;information;model;series data;entire text part;paper;opinions;sources;new standard;time;state;art", "pdf_keywords": ""}, "1cf2e9e198feef3893da2800a7949f6880ddc084": {"ta_keywords": "nlp evaluation;various nlp tasks;nlp research;explainable leaderboard;nlp;leaderboards;evaluation tool;standard leaderboard;functionality;common errors;holistic accuracy numbers;tool;performance;api;particular errors;models;systems;weaknesses;online platform;github;implementation;single system;various systems;multiple systems;rapid development;explainaboard;diagnose strengths;researchers;users;new conceptualization", "pdf_keywords": "nlp evaluation;natural language processing;nlp;leaderboard development;standard leaderboard;empirical methods;emnlp;functionality;implementation;explainaboard;new conceptualization;roadmap;weaknesses;implications;ijcnlp;researchers;diagnose strengths;conference;9th international joint conference;new paradigm;paper;system demonstrations;addition;single system;proceedings;brussels;china;belgium;online;hong kong"}, "5665d864d0f1bce6672d6d2bf9f8d8646093cb37": {"ta_keywords": "furious fact check challenge;semantic parsing;simple numerical claims;numerical claims;knowledge bases;fact;temporal expressions;verification;challenge;training data;quarter;multiple tables;test instances;population;system demonstration;identification;system;paper;germany;extensible framework;previous work;order", "pdf_keywords": ""}, "e050cd9cec5eed73bd56cb2c9726ea85e985384b": {"ta_keywords": "incremental sentence compression;current sentence compression techniques attempt;sentence compression;lstm recurrent networks;lstm;dependency tree representations;term memory;syntactic structure;full parse;rnn;shortened form;human references;sentence;compression;neural networks;compression rates;art tree transduction models;better accuracy;real time;performance;possibilities;end;time step;word;paper;experimental results;approaches;method;state;decision", "pdf_keywords": ""}, "63567f348231abed171c02f99d4c49c2892a2ade": {"ta_keywords": "differential privacy;loose privacy guarantees;privacy;biases;deep learning;sensitive information;data imbalance;small imbalances;fairness;imbalance;disparate impacts;private;accuracy;data;models;utility;fair;contributors;industries;model;decisions;performance;crowd;impact;availability;different fields;different levels;compute;day;deployment", "pdf_keywords": "private deep learning;differential privacy;stricter privacy guarantees;privacy;privacy protections;fairness metrics;demographic parity;biases;security;neural networks;fairness;datasets;accuracy;model accuracy;models;data;imbalance;disparate impact;model;classes;ccs concepts;equality;disparate impacts;metrics;protocols;social aspects;respect;different levels;decisions;situations"}, "d558c6b953e0267781ed5da90a35c122ba360f10": {"ta_keywords": "complex word identification;best monolingual models;multiple languages;annotation;phrases;language;cwi;simple learning models;latest cwi shared task;neural networks;words;dependent features;inconsistencies;sentence;features;task;strong baselines;identifying;results;data;target audience;art performance;future development;state;area;settings", "pdf_keywords": "complex word identi\ufb01cation;monolingual systems;best monolingual system;multiple languages;phrases;words;cwi;annotations;simple learning models;latest cwi shared task;french;task;features;identifying;sentence;target audience;strong baselines;most models;technology;andreas vlachos2;shef\ufb01eld 2department;better guidelines;abstract;computer science;manchego1;1department;pierre finnimore1;paper;analysis;addition"}, "d33d6c16d7c34dd387841efca74b457b7e60933a": {"ta_keywords": "recursive logic programs;inductive logic programming;determinate programs;linear recursive ij;learning;examples;algorithm;program;example;standard benchmark problems;programs;queries;pac;simulation;valiant;force2;model;twoclause;types;sets;depth;proof;class;new technique;restricted class;foil;variant;current systems;crucial problem;ability", "pdf_keywords": ""}, "68ca176c7566067ae4b3311957cc4a134bfbc819": {"ta_keywords": "neural cognitive architecture;deep learning;learning;architecture;human cognition;supervision;future ones;self;controllable manner;world applications;world;time;end;system;past problems;multiple distinct perception;experience;problems;action modalities;thesis;nca;multiple problems;multiple noisy sources;utcs;number;multiple case studies;gap;aforementioned properties", "pdf_keywords": ""}, "163c6b06d948d0869eb8173b537c441c9a786977": {"ta_keywords": "markov decision process congestion games;mdp congestion games;congestion game;classic congestion games;congestion;game equilibrium;selfish agents;simulated seattle ride;markov decision process;markov decision processes;incentives;reward function;tolls;population mass constraints;social planner;mdp;maximum social output;constraint satisfaction;downtown seattle;payoff;auxiliary objectives;strategy;share model;minimum driver density;distinct objectives;continuous population;more population;such methods;extension", "pdf_keywords": "markov decision process congestion games;mdp congestion games;classical congestion game equilibrium;congestion game;classic congestion games;classic nonatomic routing games;congestion;markov decision process;markov decision processes;constraint satisfaction;reward function;mdp;tolling;population mass constraints;incentives;tolls;optimization model;mdpcg;social planner;strategy;auxiliary objectives;payoff;sel\ufb01sh agents;continuous population;more population;introduction;relationship;class;lillian ratliff2;yue yu1"}, "2b63812db40152b12925ce4a848b929fa591b858": {"ta_keywords": "neural machine translation;sequence models;neural sequence;human language;sequential data;natural language processing;basics;neural networks;tutorial;programming;implementation exercise;techniques;reader;content;various methods;math;tasks;readers;enough mathematical detail;number;handling;practice;sort;toolbox;powerful tool;suggestion;intuition;particular experience;anyone;powerful set", "pdf_keywords": "machine translation;machine translation system;machine translation practitioner;universal translation device;language input;source language;output language;human language;online translation web sites;target language;language;conversion;languages;native language;statistical techniques;tutorial;technology;content;sequence;task;goal;words;structure;sci;target;source;plethora;section;broad variety"}, "8b608ad2ec6d0300b6a0bb8f616d4a2b01150693": {"ta_keywords": "topic tracking model;automatic meeting analyzer;topic word extraction;topic changes;topic models;language model adaptation;topics;speech recognition;speech recognition performance;language features;corpus;language environment;spontaneous japanese;appropriate topic information;current text information;changes;analysis;improvement;speakers;online manner;paper;effectiveness;styles;method;real environment", "pdf_keywords": ""}, "0a4b8b161931799d5c6bc3ecf07c53bae0e9e502": {"ta_keywords": "high school newspaper articles;language models;diverse text data;training corpora;corpus;newspapers;quality filtering;various texts;selecting web text;language;language ideology;web dumps;wikipedia;new dataset;news;quality fil011 ter;books;larger schools;resources;high quality;anchors;better transparency;edu013;urban zip codes;more care;modeling;justification;stu009 dents;inclusion;exclusion", "pdf_keywords": "popular internet content;high school newspapers;education statistics;large web data sources;demographic data;data sources;faire data collection;training corpora;content;high quality text;many language models;text data selection;data homogeneity;wikipedia;empirical evidence;language ideology;newswire;new dataset;quality \ufb01lter;larger schools;books;laissez;high quality;authors;reference;counties;\ufb01lter;united states;zip codes;summary"}, "7a737872a6693ba3f0c99651191b93dad0dadcee": {"ta_keywords": "third dihard speech diarization challenge;neural diarization;diarization error rates;subsystems;ensemble results;jhu system;system combination;hybrid subsystem;system;track;hitachi;dover;lap;detailed description;paper;end", "pdf_keywords": "diarization performance;utterance normalization;diarization results;multiple diarization results;batch normalization layer;ln compression;log10 compression;neural network;vbx clustering;extractor;extractors;res2net;tdnn;iterative inference;dihard ii challenge;layers;doverlap;xvectors;eend;eendasp;vad post;delay;bn;un;highlights;systems;b1;system;results;ii"}, "4d44f2c3f269ea6cbc840b99c3f8119a13829509": {"ta_keywords": "joint phrase alignment;statistical machine translation;preprint;extraction", "pdf_keywords": ""}, "94c0a8be74d69787a1f3f6e91dcb480a2fd0dd56": {"ta_keywords": "natural language reasoning;reasoning knowledge;poet empowers language models;language models;program executors;giant language models;reasoning;logical reasoning;drop benchmark;benchmarks;poet;model performance;numerical reasoning;programs;execution results;art performance;future research;drop;t5;representative example;bart;data;light;new gate;f1 metric;approach;studies;paradigm;analysis;new state", "pdf_keywords": "natural language reasoning;reasoning knowledge;reasoning capability;several reasoning skills;reasoning ability;poet empowers language models;language models;broader natural language scenarios;program executors;reasoning;logical reasoning;poet;numerical reasoning;programs;models;datasets;benchmarks;model performance;data;execution results;conclusion;approach;summary;numerical;contribution;studies;quantitative experiments;experimental results"}, "de41f897ea6ca5447cfae81e9505f94ccf50e6a5": {"ta_keywords": "jsmi;77th annual meeting", "pdf_keywords": ""}, "0a4dd1e51616b422aa2d437610dbfbdd3733a114": {"ta_keywords": "dialog modeling;dialog systems;dialog agent;dialog management;dialog system;dialog examples;human conversation examples;human conversation example;human conversation;conversational mapping;semantic similarity retrieval;systemoutput dialog pairs;statistical machine translation;movie scripts;datadriven approach;cosine similarity retrieval;twitter;agent;available human;ebdm;human;various data;tf;ebdm techniques;example;input;database design;movies;user;approaches", "pdf_keywords": ""}, "d5ec188a5a39e504788c1fe33457eeb816a99f31": {"ta_keywords": "constituency grammar induction;visual semantic role labels;dependency grammars;dependency induction;unsupervised grammar induction model;dependency parsing;grammar induction;structure grammars;syntax models;dependency structure;word concreteness;multimodal information;structural vision;visual perception;pure text;dependency;concreteness;text;structure;constituency;direct attachment score;strong indicator;phrasal;art models;signal;extension;model;heuristic;lens;improved performance", "pdf_keywords": "dependency parsing;unsupervised grammar induction model;phraselevel vision;structure grammars;grammar induction;word concreteness;dependency induction;pruning grammars;phrase levels;smaller grammar;visual semantic role labels;concreteness priors;grammatical structure;concreteness;concreteness interacts;function words;level concreteness;structural vision;constituency;dependency;language;words;structure;understanding subcategories;word;various levels;content;pcfg;task;models"}, "d878828c2345b665ab9651f20fb0e60e1ffe9de5": {"ta_keywords": "spectrometer;standard nuclear magnetic resonance;heterostructure interfaces;nuclear spins;nmr;gaas;split frequency value;al;strain;strains;epoxy resin;sample;lattice;observation;sensitivity;first time;interface;technique;custom;contraction", "pdf_keywords": ""}, "84e566e326b64b105cabf0c47dff336c4f632a1c": {"ta_keywords": "sunpy;solar physics;python package;asish panda6;sudarshan konge6;sanjeev dubey6;swapnil sharma6;ankit kumar6;david stansby14;shashank srikanth43;sarthak jain6;matt earnshaw6;igor babuschkin6;shresth verma27;deepankar sharma6;himanshu6;dominik sta\u0144czak26;russell hewett15;ankit baruah6;jordan ballew6;yash jain19;yash sharma6;agneet chatterjee24;harsh mathur44;larry manley6;sally dacie30;rajasekhar reddy mekala6;jai ram rideout31;matt bates6;matthew mendero6", "pdf_keywords": ""}, "18268bdfc8a6e0a51f373bc4acf65c8b9a7bd6a0": {"ta_keywords": "neural machine translation models;binarized prediction;error correction", "pdf_keywords": ""}, "9e77f94e5a12cb33b8b464dc834fd81da1a609e2": {"ta_keywords": "delay dynamical system;asymptotic stability;general lyapunov;new stability results;delay;improved delay;dynamical system;krasovskii;inline;new relaxed conditions;novel relaxed condition;information capacity;conditions;dds;formula;dptf;lkf;tex;type;strategy;addition;relevant information;problem;product;definition;method;paper", "pdf_keywords": ""}, "24219135d563b1cb24523bf522366c91a55d7604": {"ta_keywords": "best achievable f1 score;f1 metric;optimal thresholding;optimal threshold;uninformative binary classifier;thresholds;f1;performance;instances;properties;paper;relationship", "pdf_keywords": ""}, "274b4ad4840b0a8a70c5bac3fe4b4861ce5fbb95": {"ta_keywords": "shot relation classification dataset;relation classification;shot learning methods;shot learning models;relations;supervised few;relation;distant supervision methods;fewrel;different reasoning skills;sentences;dataset;wikipedia;crowdworkers;humans;task;sentence;range;art;recent state;thorough evaluation;methods;art evaluation;empirical results;state;scale", "pdf_keywords": "shot relation classi\ufb01cation dataset;fewshot learning;supervised few;shot learning models;shot learning methods;meta learner;relation classi\ufb01cation;relations;dataset;network meta;different reasoning skills;sentences;base learner;fewrel;intelligent technology;arti\ufb01cial intelligence;task;wikipedia;training process;new benchmark;traditional classi\ufb01cation model;meta;thorough evaluation;network;ing algorithm;humans;crowdworkers;empirical results;cst;baselines"}, "78e838bcd2268260ddce6be6db4907df6f29f04f": {"ta_keywords": "anime corpus;expressive speech;expressive text;text balloons;emotion recognition;anime films;acoustic speech;text systems;text;automatic speech recognition systems;speech;acoustic features;static text;emotions;verbal message;comic books;unified text;comics;emotional state;communication;speaker condition;information;data;generation;shape;background noise;considerable interest;research;system;today", "pdf_keywords": ""}, "66f7d22d6373af5032074b25828331958b07e7f9": {"ta_keywords": "differential privacy;better privacy;private training;personal data;deep neural networks;aptos dataset;dnns;dp training;interpretability;medical imaging;medical imaging applications;utility trade;importance;use;diagnosis;case study;effects;tasks;increase;extensive study;large body;work", "pdf_keywords": "privacy budget;privacy;interpretability;interpretability method;various privacy regimes;datasets;dnns;aptos dataset;interpretablity;dp training;explanation quality;models;class activation maps;global dp;dp;aptos;utility;different dp variants;model;cam;medical setups;cats;\ufb01rst benchmark;apt;dogs;different levels;results;space;grad;medical imaging applications"}, "26a238217321008cd1daaa649683d461e16e7574": {"ta_keywords": "historical text normalization;policy gradient training;accurate normalizations;policy gradient fine;neural sequence;sequence models;scratch reinforcement learning;unseen words;small datasets;level log;significant improvements;exact matches;direct optimization;models;standard approach;phrase;tuning;likelihood;board", "pdf_keywords": ""}, "eec490a41bdc716fccf98f4a7996c1d31334985a": {"ta_keywords": "symbolic music generation;music generation system;datasets;dataset;dataset analysis;dataset management;dataset management system;data preprocessing;muspy;data;open source python library;statistical analysis;model evaluation;use tools;results;future research;guide;essential components;autoregressive model;likelihood;map;process;domain overlap;others;potential;paper;order", "pdf_keywords": "music generation systems;music generation system;symbolic music generation;lstm;recurrent neural network;dataset;long shortterm memory;dataset management;machine learning model;heterogeneous datasets;rnn;dataset management system;recurrent unit;autoregressive models;autoregressive model;data;new toolkit;model evaluation;data preprocessing;muspy;essential tools;new python library;use tools;gru;generalizability;transformer network;essential components;network;process;likelihood"}, "dc26c3775d233a5fa9516d21fee12aa5b46f8a25": {"ta_keywords": "scientific term extractor;information extraction;knowledge graph;limited annotated resources;unannotated papers;annotated data;scientific recommendation;scientific literature;natural language processing;wikipedia;scientific papers;scientific terms;scientific recommendations;search engines;method recommendation;researcher;relevant papers;large collection;key ideas;relational signals;terms;structural external resources;new technologies;advances;data;minimal use;methods;domains;large amount;large variety", "pdf_keywords": "scienti\ufb01c information extraction;scienti\ufb01c knowledge graph;information extraction;semisupervised approaches;scienti\ufb01c term extractor;knowledge graph;unsupervised approaches;scienti\ufb01c recommendation;knowledge graph construction;unannotated papers;scienti\ufb01c recommendations;unannotated data;annotated data;scienti\ufb01c papers;scienti\ufb01c literature;wikipedia;scienti\ufb01c terms;dependency relations;method recommendation;relational signals;intrinsic relation signals;terms;research community;auxiliary relations;structural external resources;large collection;more papers;data;text;thesis"}, "ef2e2f3a847667000b591c8708b543eaf259113b": {"ta_keywords": "speaker adaptation;speech recognition;bidirectional lstm;lstms;lstm mask estimation;acoustic modeling;hybrid acoustic model;lstm;acoustic model configurations;microphone array processing;language modeling;previous chime challenge;language model;beamforming strategy;rnnlm;channel track;art asr systems;mask estimation;robust features;back end;previous system;triple threat;several complementary systems;main subsystems;previous state;blstm;system combination;systems;module;dnn", "pdf_keywords": ""}, "b176a46ec214b9f75df751dcd2c894f0a7a72a9a": {"ta_keywords": "argumentation mining;argument component identification;debate portals;diverse annotated corpora;web discourse;arguments;word embeddings representation;nlp;unlabeled data;machine learning;clustering;domain;user;attention;field;novel features;extent;current approaches;lack;approach;performance", "pdf_keywords": ""}, "83145b7a391b792e24d8d38f74ed6b6ae7a149dc": {"ta_keywords": "neural machine translation;level machine translation systems;translation quality;aware word dropout;translation time;lexical cohesion;anaphoric pronoun resolution;extra context;context;context usage;sentences;contrastive datasets;aware models;much document;models;bleu;simple training method;metric;performance;necessity;usage;metrics;comet;present model;paper;many current methods;feasibility;recent work;method;experiments", "pdf_keywords": "aware word dropout;longer context;source context;level machine translation systems;target context;different context sizes;context;much document;aware models;cxmi;broader settings;source;conditioning;metric;models;simple training method;paper;usage;toolbox;impact;results;rigorous empirical analysis;\ufb01nd;effect;particular varieties"}, "45eea76ac46b402f3a209de57e469275419fdc9e": {"ta_keywords": "unknown word detection;gaze;eye;speech tag;personalization;non;part", "pdf_keywords": ""}, "94a11c9425bf5f4f9b8ed1b07ea1d15a81b96e9f": {"ta_keywords": "crowdsourcing applications;crowdsourcing;online crowdsourcing;term crowdsourcing;mechanical turk;crowd participation;outside programmers;software development industry;software industry;collaborative software frameworks;collaboration process;participants;human knowledge;development;intrinsic incentives;people;creativity;company;applications;platforms;inexpensive manner;task;lower opportunity costs;acquisition;labor;journalist jeff howe;large group;open call;amazon;other topics", "pdf_keywords": ""}, "222ae836430ad0c922b47a9345c17212f9584097": {"ta_keywords": "conventional orthognathic surgery;gingival recontouring;gummy smile;excessive gingival display;upper lip;lip;surgery;successful treatment;major esthetic hurdle;laser;modified laser;scalpel;invasive alternative;young female;better alternative;egd;lrs;hypermobility;present case;population;today", "pdf_keywords": ""}, "723770d9ac418e923db5e087ae18c04702f5986e": {"ta_keywords": "new rule learner;other rule learners;rulesets;boosting;ensemble;effective learner;rules;adaboost;rule;generalization;slipper;builder;confidence;relative simplicity;appropriate constraints;use;spite", "pdf_keywords": ""}, "b9ede62d1d586e1a3b1ef7ec046f09e4e35639bf": {"ta_keywords": "effective retrieval pipelines;nn retrieval algorithm;retrieval pipelines;nn search;retrieval;search;subtle term associations;similarity function;vocabulary mismatch;candidate records;approximate algorithm;term;exact brute;candidates;new possibilities;accuracy;small loss;magnitude;orders;beaten path;approach;issue;expense;account", "pdf_keywords": "nearest neighbor search;text search;nn search;similarity function;nn search algorithm;unlimited term aliases;document terms;index;bm25 scores;text collection;classic data structure;bm25;ibm model;term;scores;contrast;function;log;\ufb01rst successful attempt;combination;ef\ufb01cient;locations;system;generic framework;end"}, "6dafc41e9bbd3aa476a0a1c15ca2c459eaef6b98": {"ta_keywords": "morphological inflection models;generic neural seq2seq models;morphological inflection;languages;unseen lemmas;sigmorphon;sophisticated models;lemma overlap artificially inflates models;models;inflection;generalization capacity;test splits;split;lemma;results;average accuracy;performance;harder train;average drop;scores;drop;task;systems;points;effective means;experiments;little data;percentage points;task show;effect", "pdf_keywords": "new split examines models;morphological in\ufb02ection models;morphology;morphological in\ufb02ection;generalization abilities;models;generalization capacity;sophisticated modeling;tasks;systems;performance;related splits;model;lemma overlap arti\ufb01cially in\ufb02ates models;task data;new splitting method;sigmorphon;future research;important task;test splits;challenging evaluation;abstract;instance;split data;in\ufb02ection;usage;harder train;recent years;lot;world use"}, "21066ab388b386f3d3552a4a4c25322e0ca69632": {"ta_keywords": "supervised relation extraction;hypernymy extraction;word embeddings;hypernym prediction;hypernyms;projection learning;negative training examples;explicit negative examples;regularization;positive examples;extraction;negative sampling;model;new approach;performance;paper;impact;fu et al;art approach;state", "pdf_keywords": "hypernymy extraction;distributional word vectors;hypernymy relations;hypernymy prediction task;explicit negative training instances;synonyms;russian languages;projection learning;relations;extraction;negative sampling;projection operation;context;projection;english;enforces asymmetry;other types;information;study;model;novel approach;paper;art model;conclusion;approach;signi\ufb01cant improvements;experiments;new model;contribution;state"}, "900ce63d71dce47059434cdf2d5e1d77bc716e8d": {"ta_keywords": "sdns;big data;clouds;mutual opportunities", "pdf_keywords": ""}, "8ae392fc9acbada67a4288a6affc2a77f83befcd": {"ta_keywords": "variational autoencoder;neural machine translation;automatic speech recognition;machine translation problem;language model;tts models;autoregressive transformer;vae model;nmt model;end text;vae;speech;subword units;feature extraction;text;discrete symbol sequence;input text;model;vq;hyperparameters;tts;transformer;asr;discrete symbols;sequence;nmt;new end;mapping;beam search;mapping function", "pdf_keywords": "variational autoencoder;neural machine translation;autoregressive transformer;speech articulation;machine translation problem;language model;subword unit;jsut corpus;vqvae;small downsampling factor;acoustic features;vae;parallel wavegan;tts framework;speech;vq;nmt model;end model;tts;nonautoregressive vector;shallow fusion;end text;model;conventional transformer;asr \ufb01elds;reconstruction condition;text;new end;nmt;novel e2e"}, "317d95f99ef62237f6c7d7834d1d19027166b392": {"ta_keywords": "e2e nlg challenge;end language generation;structured prediction;imitation;structured prediction approaches;encoder;decoder model;3rd best naturalness clusters;decoder;large search space;human evaluation;naturalness;trueskill scores;sequences;words;2nd best quality;model;quality;variations;5th best cluster;systems;sheffield;system;university", "pdf_keywords": ""}, "db190db2567c334b772fd653dca10f300074e421": {"ta_keywords": "end speech synthesis;speech data;speech recordings;automatic speech recognition;corresponding transcriptions;pretrained models;asr models;end tts;such raw text data;phonemes;end text;target speaker;speech;asr;text output;text data;text;tts;intermediate linguistic features;models;unpaired dozen minutes;training;end;such accessible data;art end;remarkable performance;state;other hand;systems;use", "pdf_keywords": ""}, "02cbb0db288af2c83b48a023f245812bd22a2408": {"ta_keywords": "text generation metrics;information extraction;text models;reference texts;texts;wikibio;text;human judgments;references;human evaluation study;information;evaluation;recall;reference;tables;parent;datasets;large scale;wiseman et al;metrics;table;grams;comparable correlation;poor correlation;bleu;precision;rouge", "pdf_keywords": "natural language descriptions;sequence models;structured data;reference texts;neural models;webnlg data;references;human judgments;sequence;texts;tables;reference;text;metrics;recall;neural network;data;similar systems;task;different hyperparameters;parent;poor correlation;precision;reiter;introduction;interest;template;dale;grams;bleu"}, "20937a0f03bcb845afbedda901a6d4e93a2b5c34": {"ta_keywords": "terrorism analysis;export networks", "pdf_keywords": ""}, "b8e2e764ac82f81a5bc645c818d0d5ad7806e806": {"ta_keywords": "speech separation;chime;recognition challenge;analysis;outcomes", "pdf_keywords": ""}, "7c976b0b54ace7d13b87e8feefe6f29c0599d78d": {"ta_keywords": "semantic word network;semantic relations;lexical relations;other relation extraction methods;distributional semantics;available dictionary resources;russian language;di erent datasets;hierarchical contexts;individual words;crowdsourcing;relations;lexical senses;unsupervised method;watlink;datasets;subsumptions;negative human judgements;recall;crowd;new resource;swn;network;score;wisdom;method;f1;methods;paper;lrwc", "pdf_keywords": ""}, "a83bbc7bf70b1beedbfe0140d24d556e2dc5acc8": {"ta_keywords": "adversarial robustness;smooth kernels;gradients", "pdf_keywords": ""}, "2aaf2ee779cd4ff0f26bb73958ea9fb0faa61907": {"ta_keywords": "subcellular location image finder;subcellular location patterns;text features;fluorescence microscope images;intensity histogram features;binary classification problem;images;unlabeled dataset;text;edge features;online journal articles;training set;protein;journal articles;image;accuracy;words;information;bag;performance;slip;system;set;problem;addition", "pdf_keywords": ""}, "08f199ebfd27a5f9ada79edd07ac41e46c7278d5": {"ta_keywords": "autism;socialization scores;human communication;movie data;socialization;communication;ipad application;factor analysis;development;significant relationship;real world;quotient;paper;experiment", "pdf_keywords": ""}, "34d5d2f75934caff89311ef20d18a275da5abb47": {"ta_keywords": "explanation based learning;multiple examples;learning;number", "pdf_keywords": ""}, "fbf2a6a887ea92311cf207d522c535daf867a6ba": {"ta_keywords": "speech synthesis;text embeddings;more natural prosody;end text;language understanding tasks;natural language processing;speech;embeddings;text;enhanced text;synthesis model;tts;tts systems;semantics;representations;pronunciation;word;end;self;pre;information;phrase;importance;recent work", "pdf_keywords": ""}, "da06caf4f340ebc81395f092f9dc3a3101827506": {"ta_keywords": "el speech enhancement method;several el speech enhancement methods;intelligible el speech;el speech;statistical voice conversion;proficient laryngectomees;laryngectomee;single laryngectomee;other laryngectomees;electrolarynx control;statistical excitation prediction;speech;excitation sounds;electrolarynx;el;electrolaryngeal;face conversation;listenability;statistical prediction;mechanical excitation;excitation;excitation parameters;direct control method;multiple speakers;effectiveness;evaluation;method;device;proficiency;f0 patterns", "pdf_keywords": ""}, "acc2ad56a9c68c799747e08d978f9803997c1527": {"ta_keywords": "inorganic materials synthesis planning;inorganic synthesis insights;perovskite materials;inorganic materials;syntheses;language models;entity recognition model;synthesis planning;neural networks;word embeddings;precursors;conditional variational autoencoder;natural language text;scientific literature;only training data;materials design;new data sources;literature;discovery;data;potential;interest;key step;decade;strides;pace;method;technique", "pdf_keywords": "synthesis predictions;unsupervised conditional variational autoencoder;materials synthesis planning;perovskite materials;language models;synthesis insights;perovskite compounds;synthesizability screening;materials science text;synthesis;materials science;syntheses;synthesis planning;sensitive embeddings;materials science community;materials;thermodynamic knowledge;precursors;representations;model;fasttext word;only training data;several key resources;cvae;context;potential;elmo;scienti\ufb01c literature;properties;variety"}, "2aea6cc6c42101b2615753c2933a33e57dd665f2": {"ta_keywords": "knowledge base graph;large scale knowledge base;knowledge base;many more inference tasks;clause learning;soft inference procedure;path ranking algorithm;inference;different target relations;inference method;new learning method;imperfect knowledge;learning;random walks;new beliefs;rank;incomplete coverage;earlier horn;weights;different paths;cohen;precision;new system;graph;nell;version;combination;system;lao;problem", "pdf_keywords": ""}, "1134ec4cdfc1c2161d157b0f4e03dec85d8c4c8a": {"ta_keywords": "deep convolutional networks;road connectivity;roads;connectivity;ground truth road;canals;false positive roads;irrigation canals;network;road;aerial images;loss function;loss;background regions;prediction;standard road benchmarks;art maps;unwarranted disconnections;disconnections;such unwanted connections;image;gaps;gap;like structures;output;novel;main idea;opposite sides;new data set;state", "pdf_keywords": "binary segmentation convnets;convolutional neural net;drainage canal networks;reconstructed networks;deep convolutional networks;road network delineation;drainage canals;irrigation canals;road connectivity;connectivity;roads;network;proper connectivity;differentiable loss function;loss function;aerial images;road;graph;standard road benchmarks;standard skeletonization algorithm;enforcing region separation;like structures;art maps;structures;leonardo citraro;output;purpose;differentiable manner;doruk oner;pascal fua"}, "b9b83860bc0d79b3b629b3035c4b7b7f9f71b5af": {"ta_keywords": "wireless sensor networks;wireless relay networks;deployment algorithms;deployment algorithm;propagation;forest trail;nodes;impromptu deployment;trail;relays;deployment;forest;sensor;algorithms;sink node;quality measurements;locations;experimental experiences;raw measurement data;statistical model;priori unknown point;useful insights;proper theoretical formulation;experiences;application example;results;necessity;paper;parameters;person", "pdf_keywords": "wireless relay networks;deployment algorithms;wireless sensor networks;deployment algorithm;forest trail;propagation;impromptu deployment;forest;deployment;heuristic;algorithms;limited exploration;line algorithms;bharat dwivedi;heuexplorelim;extension;experimentation;bangalore;proper theoretical formulation;indian institute;prior work;cost;statistical model;parameters;useful insights;anurag kumar;campus;raw measurement data;necessity;additional measurements"}, "386bfd0e411dee4f512a8737c55dd84846981182": {"ta_keywords": "tables;table;prediction tasks;tabular representation;table substructures;tabular data;language models;rows;simple pretraining objective;embeddings;tabbie;cells;bert;learning;text;joint pretraining;tasks;columns;corrupt cell detection;self;model;objective functions;questions;suite;compute;work;approaches;state;art", "pdf_keywords": "tabular information embedding;table extraction;models tables;tabular data;tables;different tabular substructures;tabbie con\ufb01rms;pretrained representations;tabbie;corrupt cell classi\ufb01cation;prediction tasks;corrupted cells;corrupt cell detection;simple pretraining objective;language models;rows;cells;tabert;representations;columns;embeddings;complex semantic properties;numeric cells;decomposition pipelines;substructures;several core tasks;task;objective functions;text;bert"}, "466865aaeb8902f6f8ed93ceeb5fbf9fc8b593b1": {"ta_keywords": "online speech enhancement;speech enhancement;reverberant speech enhancement task;deep learning;better enhancement performance;stft;inverse stft;deep neural network;better enhancement;online enhancement;frequency resolution;stftdomain;extra features;stftdomain system;istft;second dnn;dnn;tasnet;deep;addition;regular input window size;target speech;shorter output window;inherent latency;algorithmic latency;conventional dual window size approach;larger window;comparable performance;less computation;frame", "pdf_keywords": "domain neural speech enhancement;online speech enhancement;speech enhancement;microphone array processing;better enhancement performance;inverse stft;frequency resolution;better enhancement;stft;online enhancement;deep learning;complex spectral mapping;deep neural network;low algorithmic latency;stftdomain system;target speech;extra features;dnn;dnns;algorithmic latency;second dnn;term fourier transform;addition;add algorithm;deep;frame;frameonline beamforming;comparable performance;less computation;singleor"}, "4759aaacd71fbb2b5ca253aa13ccceac0bc7fe8a": {"ta_keywords": "computational argumentation;web argument convincingness;rich svm learners;arguments;argument pairs;natural language;convincing arguments;argument;argument pair;explanations;bidirectional lstm;26k explanations;corpus;convincingness;certain controversial topic;challenging task;neural networks;feature;full label distribution;classes;convolution;task;new crowd;empirical manner;qualitative properties;attention mechanism;flaws;types;several strict quality measures;tasks", "pdf_keywords": ""}, "2cf21fc85af45512bf34d710f325872dca8a5331": {"ta_keywords": "region traffic prediction;openstreetmap;graphical traffic condition data;traffic data;traffic conditions;personal travel planning;urban planning;popular mapping service;prediction model;shanghai;baidu map;osm;source map provider;transportation dispatching;area;china;model;source;various parts;approach;paper;novel system;system", "pdf_keywords": ""}, "fb0a68981dae15f31cbcf5442509a3b8279b264c": {"ta_keywords": "mfcc enhancement;noise feature space;mfcc vectors;noise features;stereo data;vts enhancement method;linear discriminant analysis;feature mapping;noise estimates;frame basis;noise model;joint space;frame;vector;dimensionality;dynamic parameters;practical computational cost;algorithm;computational cost;time;novelty;method;paper;acceptable level", "pdf_keywords": ""}, "4d41c2fa74dd018e39ddb3cbbfead1b42615612c": {"ta_keywords": "unseen deep architectures;deep learning;training networks;imagenet;neural architectures;parameter prediction;neural networks;hypernetwork;other networks;diverse computational graphs;parameters;features;pipelines;performant parameters;model;strong representation;graph;machine;single forward pass;scale dataset;task;efficient paradigm;advances;cpu;past knowledge;results;design;analysis;fraction", "pdf_keywords": "neural network architectures;imagenet;neural architectures;neural networks;parameter prediction;single hypernetwork;diverse feedforward;ghn model;model;diverse computational graphs;pass;standardized benchmark;strong representation;performant parameters;distribution architectures;novel task;progress;task;scale dataset;distribution;several baselines;contributions"}, "709f0a4229e40339b595072ae9fbd3a1ae1fd93e": {"ta_keywords": "dynamic neural network toolkits;dynamic computation graphs;minibatch computations;tensorflow;single instance computations;batches;batching algorithm;manual batches;pytorch;toolkits;performance algorithms;theano;instance;operations;computations;architectures;comparable speedups;cntk;aggregations;fly operation;hardware;tasks;dynet;models;developers;developer;fly;chainer;require;variety", "pdf_keywords": "minibatch computations;single instance computations;batching algorithm;batches;dynet toolkit;autobatch;manual batches;operations;same operations;dynet;gpus;arithmetic operations;aggregations;sequential evaluation;modern cpus;comparable speedups;algorithm;tasks;implementation;architectures;frameworks;singleinstance;command line \ufb02ag;developers;capability;variety;strategies;introduction;ef\ufb01cient;paper"}, "d745ba895cf8dcba5670fb01feea931fc72f9c77": {"ta_keywords": "deep reinforcement learning;complex downstream tasks;sample complexity;drl agents;simpler environments;useful representations;layers;policy;useful representation;environment;representation;environment states;experiments;drl;related game;transfer;performance;same game;new insight;experiment;source;paper;requirements;benefits;requirement;set;scratch;distinction;majority;fraction", "pdf_keywords": ""}, "af6c6e66fe0a9ba19c304665e01db1c5a5fba1e4": {"ta_keywords": "constrained upper confidence reinforcement learning;upper confidence reinforcement learning;constrained markov decision processes;stochastic decision problems;auxiliary cost constraints;cost functions;reward function;constraints;decision maker;transition kernel;exploration;policy;known dynamics;environments;setting;priori;applications;settings;class;paper;number", "pdf_keywords": ""}, "3389b6b8ee5a1ef0395df9f383e771650087b828": {"ta_keywords": "classical information retrieval systems;classical information retrieval;information retrieval system;domain expert;language models;search engine;corpus;utterances;experts;domain expert advice;information;documents;prose;references;users;answers;information need;systems;true understanding;ideas;dilettantes;paper;hallucinating;world;contrast;promise", "pdf_keywords": "information retrieval;domain expert response quality;question answering;information retrieval framework;classical information retrieval;human expert quality answers;language models;nlp models;text corpus model;document retrieval;retrieval;modern ir;ir;classical ir;summarization;traditional ir systems;modern ir systems;nlp;new tasks;tuning tasks;domain expert advice;rank;indexing;information needs;consolidated model approach;lms;ambitious research direction;modeling approach;aspects;model"}, "f432d10677897cf72f9594ba7bd4c9199b270fb3": {"ta_keywords": "classification performance measures;several performance measures;classification results;classification literature;symmetric balanced accuracy;accuracy;measures;matthews correlation coefficient;measure;systematic analysis;desirable properties;systematic approach;important tool;properties;list;many others;situations;others;family;practitioners;question;new family", "pdf_keywords": "good classi\ufb01cation measures;several performance measures;performance measures;classi\ufb01cation results;classi\ufb01cation literature;threshold measures;probability measures;measures;accuracy;classi\ufb01cation;symmetric balanced accuracy;average precision;class;measure;multiclass scenario;roc curve;matthews correlation coef\ufb01cient;soft labels;liudmila prokhorenkova yandex research;labeling;labels;probabilities;several types;desirable properties;anton zhiyanov yandex research;countless applications;martijn g\u00f6sgens eindhoven university;relative order;informed decision;particular application"}, "da9ec5053c8ad8854bdd2ddc3f9c3d82a4114d71": {"ta_keywords": "endangered language texts;purpose ocr tools;scanned books;transcriptions;recognition error rate;natural language processing models;languages;benchmark dataset;correction method;systematic analysis;data;scarce setting;training", "pdf_keywords": "ocr postcorrection method;purpose ocr tools;language text;purpose ocr system;\ufb01rst pass ocr;transcriptions;recognition error rate;scanned books;languages;natural language processing;benchmark dataset;nlp;\ufb01rst pass transcription;english;nepali;resources;models;data;performance;ainu;training;scarce setting;systematic analysis;lack;bottom;image;methods;world;main contributions;systems"}, "f66c82ca087b435463ef4fa0de49825c4eb55885": {"ta_keywords": "semantic parsing;semantic annotation;novel parser;free parser;atis corpus;data formalization;general probabilistic context;better probability estimation;context;simple tree;data;evaluation;system;method;article;novel method;main issues;different domain;practical applications", "pdf_keywords": ""}, "b37d073109cfcf913cf53aded3872e6158e828a0": {"ta_keywords": "visual objects;visual environment;visual counterparts;visual features;benchmark room;object detections;language navigation;art vln models;vision;room dataset;expert models;unseen new environments;natural language;models;vln;vln task;routes;grounds;art models;route;door;route structure;performance;available modalities;prediction time;grounding procedure;different modalities;access;geometric structure;set", "pdf_keywords": "visual attention;textual attention;visual context;visual representation;resnet cnn features;visual agent;ground language;lstm inputs;object features;attention mechanism;textual features;image features;object detections;vln task;object detection system;route progress predictor;grounding;prediction time;symbolic output;way mixture;mixture;expert models;level object;instruction words;grounding procedure;experts approach;generalizable way;performance;art models;sm model"}, "e2ef0dc26a669ed764e2d70257b162298b8b608e": {"ta_keywords": "aided multiantenna dfrc secrecy channel;multiple eavesdroppers;secrecy rate;eavesdropper;radar channels;eavesdropping;function radarcommunications;multicast irs;radar target;common signaling methods;optm3sec;dfrc setup;dfrc systems;physical layer design approach;dfrc;messages;surfaces;energy signal;numerical experiments;feasibility;additional challenges;ed;algorithm;legitimate users;systems;susceptibility;use", "pdf_keywords": "aided multiantenna dfrc secrecy channel;multicast irs;multiple ed multicast multi;multiple ed multicast;multiple eavesdroppers;function radarcommunications;dfrc interception problem;eavesdropping;eavesdropper;optm3sec;common signaling methods;radar target;dfrc;dfrc systems;optimization;nonconvex problem;messages;new delhi;additional challenges;energy signal;paper;states ccdc army research laboratory;matrices;ed;nj;new jersey;md;siddharth sankar;adelphi;india"}, "243880fde63abfc287bd1356c2e1dbf68a1a0aac": {"ta_keywords": "indigenous language transliteration;indigenous language technologies;indigenous languages;speech recognition;language learning;speech synthesis;machine translation;speaker diarization;optical character recognition;text;text prediction;speech;image technologies;canada;spell;approximate search;future horizons;computer;assessment;challenges;checking;past achievements;article;successes", "pdf_keywords": "indigenous language technologies;indigenous language transliteration;indigenous languages;indigenous1 languages;speech data;distinct language families;language learning;languages;speech recognition;dialects;machine translation;canada policy;speech synthesis;optical character recognition;speaker diarization;alberta;text;text prediction;speech;certain technologies;technologies;montreal road ottawa;patrick littell national research council;little text;canada;feasibility;image technologies;christopher cox carleton university;spell;applications"}, "9364eff879a9dcb34fe3dfdd0843e69c14dd333b": {"ta_keywords": "interpretability;models;user studies;optimization loop;humans;several data sets;algorithm;sparsity;operations;approach;proxies;number;work", "pdf_keywords": "predictive neural networks;high likelihood models;neural networks;prediction;models;interpretability;optimization loop;optimization;pipeline;model;best model;optimization procedure;user study;different input gradient patterns;\ufb01nd models;diverse set;inference;diverse collection;user studies;humans;human;level overview;several data sets;candidate;discussion;approximate map solution;algorithm;computation;collection;approach"}, "64c575bb8b3e11097605028de5c289b0b2d839a4": {"ta_keywords": "speech synthesis;synthetic speech;voice conversion;synthesized target speech;phonetic correction method;prosodic correction method;nonnative speech;speaker individuality;unnatural prosody;phonetic characteristics;foreign language speech;natural speech;dependent acoustic characteristics;model adaptation;spectrum replacement;speaker;pronunciation;speech;target speaker;target languages;unvoiced consonants;mother tongue;linguistic systems;naturalness;partial correction;degradation;new approach;hmm;differences;use", "pdf_keywords": ""}, "5af9ab65d186e4e1e0b1cef1962ca15336f37931": {"ta_keywords": "dependent semantic parsing;semantic parser;corpus;new corpus;available corpus;imitation learning framework;corpora;interactive tourist information system;utterances;annotation;imitation;context;mrl;alignment information;database;task;algorithm dagger;training;most approaches;paper;small number", "pdf_keywords": ""}, "4f8e1a4247ce06a15760fc2692c6849601d41b6f": {"ta_keywords": "textual entailment task;multiple textual entailment datasets;textual entailment;entailment models;natural language processing;external knowledge sources;knowledge graphs;contextual subgraphs;graph convolutional networks;textual content;external knowledge;semantic information;convolutional networks;personalized pagerank;background knowledge;subgraphs;knowledge;text;information;task;kgs;graph;fundamental task;prediction accuracy;models;use;noisy kgs;few approaches;model;addition", "pdf_keywords": "textual entailment task;textual entailment;contextual subgraphs;entailment models;knowledge graph;graph convolutional networks;semantic information;natural language processing;external knowledge;relevant subgraphs;subgraph \ufb01ltering;subgraphs;convolutional networks;knowledge;ibm watson ai lab;personalized pagerank;text;information;graph;kg;fundamental task;kgs;abstract;conclusion;systematic approach;multiple datasets;challenges;paper;neighbor;kes approach"}, "9cf75483deee77b3c0ee4f996d808437ab4a7435": {"ta_keywords": "myofibrillar protein;thermal gelation;chicken breast;oxidation;process;effect", "pdf_keywords": ""}, "0ce184bd55a4736ec64e5d82a85421298e0373ea": {"ta_keywords": "conventional recurrent neural networks;rnn;speech applications;multilingual asr;asr benchmarks;tts benchmarks;transformer;tts tasks;asr;open source;significant performance benefits;available datasets;various training tips;kaldi;reproducible recipes;comparative study;exciting outcomes;task;st;style;comparison;surprising superiority;intensive studies;community;total;experiments", "pdf_keywords": "comparative study on transformer vs rnn;multilingual asr;end speech applications;speech applications;conventional recurrent neural networks;speech translation;automatic speech recognition;toend speech processing;rnn;multilingual end;corpus;various corpora;end asr;multilingual;asr;corpora;transformer;speech;sequence models;tts benchmarks;hidden markov model;nanxin chen3;shigeki karita1;takaaki hori7;tts;kaldi;1ntt communication science laboratories;alphabetical order;shinji watanabe3;text"}, "448e15e267b20bee1644034e18630da2e68cf36e": {"ta_keywords": "seismic response analysis;deep loose sand;ale method;subway station", "pdf_keywords": ""}, "4c94dc1b2391d78c9cfdd69955d20b56d7a16982": {"ta_keywords": "linear mds codes;erasure codes;code redundancy;storage systems;code conversion;code dimension;storage cost;convertible codes;optimal linear mds;linear mds;fault tolerance;node failures;failure rates;redundancy;access cost;valid parameters;conversion;nodes;lower bounds;parameters;small subset;access;data;such tuning;explicit construction;length;paper;scale;number;change", "pdf_keywords": "linear mds codes;convertible codes;optimal linear mds;code construction;linear mds;lower bounds;valid parameters;access cost;conversions;conversion;explicit construction;extended version;parameter regimes;ieee isit;access;generalizations;freedom;design;general regime;split;combination;paper;regimes;analysis;challenge;section iv;degrees;route;jun;same title"}, "c55d5805a6eb8b1482f21581fe893484eaf9ffb5": {"ta_keywords": "voice timbre control method;voice timbre control;singing voice conversion;novel voice timbre control technique;voice timbre;singing voices;voice conversion;singing voice;prosodic features;gaussian mixture models;acoustic features;perceived age;singer;spectral features;segmental features;regression;listener;age;actual age;effect;gmm;song;individuality;notable characteristics;subjective evaluations;key words;larger effect;modified mr;perceptions;svc", "pdf_keywords": ""}, "4275d4c4bd10742b321467f175f16198ed7d17d7": {"ta_keywords": "domain music generation;cooperative music creation;midi bars;generative adversarial networks;music;rock music;noisy midi files;coherent music;piano track;gans;musegan;additional tracks;composer model;accompaniment;ai;generation result;models;jamming model;pop;art;subjective evaluation;bars;addition;temporal model;network architecture;time;human;return;underlying model assumption;domain", "pdf_keywords": ""}, "802ddaf5bd731b91e64d8cee43f7fb614b42c1df": {"ta_keywords": "fair online allocation;electric vehicle charging;perishable goods;artificial intelligence;data;proceedings;paper;28th international joint conference;application;diaz", "pdf_keywords": ""}, "75f90cbbf3c27a8b27567d6a9c8c4538743c8fff": {"ta_keywords": "text generation tasks;text generation;extensible toolkit;machine translation;source toolkit;natural language;texar;modularized;dialog;content manipulation;prototyping;arbitrary model architectures;modules;summarization;model architecture;reusable modules;diverse tasks;library;inference;versatile;modularity;learning processes;algorithmic paradigms;design goals;inputs;high concept level;versatility;experimentation;extensibility;functionalities", "pdf_keywords": ""}, "7e386158f474a395618c5e065ac55844b507007c": {"ta_keywords": "speech processing tasks;general speech processing;lightweight prediction heads;universal performance benchmark;benchmark toolkit;ssl representations;representation learning;leaderboard;speech;superb tasks;minimal adaptation;task;performance;various tasks;minimal architecture changes;accessibility;sota;model;challenge;competitive generalizability;unlabeled data;wide range;large volumes;data;top;framework;simple framework;gap;results;superb", "pdf_keywords": "universal performance benchmark;general speech processing;lightweight prediction heads;benchmark toolkit2;speech;representation learning;leaderboard1;ssl representations;superb tasks;task;competitive generalizability;models;various tasks;model;generalizability;accessibility;challenge;framework;simple framework;top;results;superb;community;aspects;ef\ufb01cacy;research;experiment results;problem"}, "9976ed0d88a4156ecdd3ebe39714c5fb4a5a0246": {"ta_keywords": "japanese large vocabulary speech recognition;large vocabulary speech recognition systems;large vocabulary speech recognition;kaldi speech recognition toolkit;covariance matrix adaptation evolution strategy;art speech recognition system;corpus;evolution strategy;training script;tune dnn;supercomputer;tsubame;cma;automation;csj;wer constant;numerous parameters;system building;similar system;systems;human experts;smaller model size;lower wer;hmm;configuration;es;laborious effort;available recipe;approach;experiments", "pdf_keywords": ""}, "814421bb20ba1fba88928fc168db1b7175cca6ac": {"ta_keywords": "electrolarynx;direct f0 control;time excitation prediction;implementation", "pdf_keywords": ""}, "e8bd03ff376ab3c863f72f931c91e90eeb9b2be9": {"ta_keywords": "south asian intellectual property knowledge network", "pdf_keywords": ""}, "36c95e3ef362742a5c1844257e8b79d3251a781e": {"ta_keywords": "robotic language understanding;new benchmark shapenet annotated;language grounding models;3d objects;objects;robot;novel reasoning task;simple natural language requests;referring expressions;discriminative information;vision;language;3d nature;robot platform;models;view estimation;snare;several clip;human performance;image;example;accuracy;candidate mice;model;flat images;wireless mouse;manipulation;key role;recent advances;properties", "pdf_keywords": "new benchmark shapenet annotated;robotic language understanding;language grounding models;referring expressions;object referents;language grounding;language models;3d objects;objects;natural language expressions;candidate referent objects;novel reasoning task;vision;view estimation;language;object rotation;current view estimation;several clip;views;3d nature;models;robot platform;accuracy;clip model;random chance performance;image;human performance;model;snare;key role"}, "807e421679d4a9d629d2fad1f60f28787dca60e7": {"ta_keywords": "training question answering models;generative domain;novel domain adaptation;generative model;adaptive nets;novel training framework;questions;reinforcement learning;unlabeled text;human;model;substantial improvement;data distribution;experiments;framework;discrepancy", "pdf_keywords": "novel domain adaptation;generative domain;domain adaptation techniques;generative models;generative model;adaptive nets;discriminative model;modelgenerated data distribution;novel neural framework;adversarial way;reinforcement learning;reinforcement learning algorithms;unlabeled text;reinforcement learning algorithm;data distribution;loss;tune;gdans;combination;\ufb01ne;discrepancy"}, "d06493373421c86ba33dbb8834ccb725105a665f": {"ta_keywords": "lexical distinctions;lexical selection;vocabulary items;different possible translations;new language;language;distinctions;languages;spanish;rules;ambiguous word;greek;pared;readable format;wall;fine;key challenge;quality;muro;machine;method;work;setup", "pdf_keywords": "lexical selection;lexical distinctions;lexical distinction;lexical choices;lexical choice;vocabulary items;readable concise descriptions;parallel corpus;different lexical manifestations;l1 word;understandable descriptions;present l2 learners;concise descriptions;semantic features;semantic subdivision;parallel sentences;distinctions;easier interpretation;words;l2;learning \ufb01ne;l1;new language;target language;rules;prediction model;ii;sep;key challenge;\ufb01ne"}, "ece62ada00cef99d9fc7a60e7d4b773f6d87c8f9": {"ta_keywords": "tasks machine translation;low resource human language technologies;ariel;text;situation frames;lorehlt18;entity discovery;cmu submissions;speech;sf text;lorehlt;cmu systems;edl;evaluations;linking;mt;detection;paper", "pdf_keywords": "multilingual corpus;bilingual lexicons;multilingual word vectors;monolingual english text;monolingual sinhala text;incident language training data;bilingual dictionaries;machine translation training data;ni speech annotation systems;english data;low resource human language technologies;machine translation;human language technology;monolingual kinyarwanda text;language models;english systems;computational linguistics;related languages;incident language;neural machine translation;speech data;word vectors;annotation;natural language processing;english;situation frame detection;text;keyword model outputs;speech;entity discovery"}, "73635c9dc0ffb61c2eac79234108c6eee1362c1b": {"ta_keywords": "smoothed reward feedback;correlated markovian environments;reward;rewards;markov chain;iterations;learning algorithm;discount;algorithms;epochs;time;epoch;arm;dynamic environment;observations;times;time intervals;access;past;state;priori information;work;end;formulation;average;number;problems;function;types;fashion", "pdf_keywords": "markovian rewards;bandit problems;bandit algorithms;correlated markovian environments;bandits;smoothed reward feedback;reward feedback;markov chain;learning policy;future rewards;reward;rewards;online learning;discount;iterations;principled approach;dynamic environment;agent;algorithms;past actions;state;dependence;priori information;decision;environments;interaction;tanner fiez department;ii;arm;wa"}, "18289b2b04fc8a7a86f474236e55a3b1070a98ad": {"ta_keywords": "\u6587\u732e\u6284\u9332 \u6d44\u6c34\u51e6\u7406\u306b\u304a\u3051\u308b\u819c\u30d5\u30a1\u30a6\u30ea\u30f3\u30b0\u30b3\u30f3\u30c8\u30ed\u30fc\u30eb\u306e\u305f\u3081\u306e\u51dd\u96c6\u53ca\u3073\u9178\u5316\u51e6\u7406;\u6d78\u6f2c\u819c\u69fd\u3078\u306e\u4f4e\u6fc3\u5ea6\u30aa\u30be\u30f3\u6ce8\u5165\u306e\u9069\u7528", "pdf_keywords": ""}, "db500c4e746897e5d5adafbf222b959c512445ad": {"ta_keywords": "adversarial attacks;new data poisoning attack;nlp model predictions;concealed data poisoning;adversary;trigger phrase;model predictions;extra human annotation;customizing triggers;poison examples;prediction accuracy;training data;defenses;predictions;james bond;input;sentiment model;attack;training set;model;time inputs;positive;instance;test;changes;cost;work", "pdf_keywords": "new data poisoning attack;data poisoning attack;dangerous new vulnerabilities;adversary inserts;novel vulnerabilities;nlp models;overlap poison examples;poison examples;poison generation process;adversary;trigger phrase;new vulnerability;model predictions;models;hot coffee;training data points;examples;ensemble;overlap examples;inputs;iced coffee;input;data;machine;scratch;defender locate;mt models;experiments;gradient;overlap"}, "00936aa7c8f64fc919dd4dcee6192ccc83e0d26e": {"ta_keywords": "occlusal reflectance images;proximal reflectance;occlusal reflectance;multispectral occlusal transillumination;multispectral imaging devices;reflectance device;proximal transillumination images;multispectral proximal transillumination;swir imaging;reflectance;interproximal lesions;radiography;proximal transillumination;tooth;lesions;teeth;transillumination;lesion severity;swir occlusal;proximal surfaces;lesion dimensions;swir;wavelength;diagnostic performance;microct;occlusal;lingual surfaces;device;accurate measurements;study", "pdf_keywords": ""}, "58b0800ef48da2678e15e5e8bc1d786e24190742": {"ta_keywords": "field speech processing;speech enhancement;automatic speech recognition;deep learning;more microphones;end signal enhancement;audio;amazon echo;recognition;signal processing communities;acoustics;extraction;chime;separation;reverb projects;speech;asr;field;more speakers;far;active field;machine;major breakthroughs;recent scientific advancements;end;distance;special issue;long time;progress;commercial products", "pdf_keywords": ""}, "901fbb51d6fb9078e572c83a446b408da4de9b2b": {"ta_keywords": "uncontextualized word embeddings;frame induction", "pdf_keywords": ""}, "d0a58b6da9f7788534aa9963a78c24a87038e4fc": {"ta_keywords": "computational social choice;empirical risk minimization;desirable values;novel paper;community;novelty;paper;papers;aggregate mapping;natural axiomatic properties;extensive experiments;reviewers;only choice;handful;framework;whole", "pdf_keywords": ""}, "490c31b460316b7f68e9b8f5ff0d26aef2f7f45f": {"ta_keywords": "markov decision process congestion games;mdp congestion game equilibria;selfish optimization;congestion effects;common mdp;decision maker;action costs;decision makers;sensitivity analysis;uncertainty;sensitivity;implicit function type analysis;cost;state;states;perturbations", "pdf_keywords": "mdp congestion game equilibria;mdp congestion game;mdp congestion game framework;optimal user equilibrium;style game equilibria;wardrop equilibria;stochastic braess paradox;paradox sensitivity;deterministic dynamics;stochastic dynamics;network design;stochasticity;individual decision maker;braess paradox;sensitivity analysis;uncertainty;action costs;potential game;sensitivity work;traf\ufb01c assignment literature;sensitivity;variational inequality;hypergraph structure;simulations;implicit function type analysis;system;level perspective;introduction;perturbations;analysis"}, "2e0b1484740047d6d6fb6bd2c9d8816b54b33811": {"ta_keywords": "review process;reviewers;ordinal rankings;neural information processing systems;thorough quality assessment;subsequent conferences;conference;submissions;peer;annual conference;machine learning;attendees;improvement;nips;tier;design;data;insights;paper;soundness;experiment;massive scale;previous year;efficacy;terms;growth;rapid growth;goal;several aspects;novel means", "pdf_keywords": "neural information processing systems;review process;review data;reviewers;good reviewer assignment;reviewer scores;common reviewers;nips;review procedure;machine learning;volunteer reviewers;review scores;reviews;junior reviewers;intelligent systems;tools;papers;software systems;automated manner;useful insights;paper;statistical tests;analysis;biases;topics;max planck institute;computer science;comparable biases;accepted papers;future conferences"}, "2444be7584d1f5a7e2aa9f65078de09154f14ea1": {"ta_keywords": "dark knowledge;knowledge distillation;teacher outputs;teachers;permuted predictions;teacher max;teacher;machine learning model;knowledge;students;compressing models;distillation objectives;datasets;language modeling tasks;densenets;confidence;student;again networks;bans;cwtm;kd;computer vision;additional experiments;art performance;experiments;various capacities;dkpp;role;validation error;methods", "pdf_keywords": "knowledge distillation;teacher model converges;again neural networks;model compression;arti\ufb01cial neural networks;compressing models;training technique;knowledge;machine learning model;teacher;teachers;students;student;ml;teaching selves;new student;capacity model;michael tschannen;dual goals;minsky;anima anandkumar;such transfer;kd;formidable performance;simple re;jun;bene\ufb01ts;new perspective;results;output distribution"}, "f17ee5b9d3120960eddd2bdb9af2f4f689cebb3a": {"ta_keywords": "automatic relation extraction;relation extraction;qa entity mention pairs;relation mentions;massive text corpora;trec qa dataset;semantic evidence;text features;indirect supervision;same relation types;qa dataset;such supervision;similar representations;indirect source;answer pairs;supervision;qa loss;qa;public re datasets;novel margin;interest;dimensional spaces;types;great importance;f1 score;novel framework;paper;question;similar question;ds", "pdf_keywords": "relation extraction;qa entity mention pairs;richer semantic knowledge;relation mentions;better feature embeddings;knowledge bases;clearer semantic knowledge;test relation mentions;model mentionfeature;semantic evidence;text features;same relation types;relation type;similar representations;marginbased rank loss;training data;shared features;qa datasets;noisy training data;answer pairs;qa dataset;qa pair;indirect source;feature;such supervision;qa loss;information;novel margin;sources;qa"}, "90af87c1e4fba127d6db8f5e1f9e1ef3472507e8": {"ta_keywords": "\u5408\u6210;\u97f3\u58f0\u4e00\u822c;\u97fb\u5f8b;\u751f\u6210", "pdf_keywords": ""}, "39365d95992c8294ba32d85c69d337040ddb8e54": {"ta_keywords": "neural machine translation;dependency parse trees;arbitrary tree structure;tree structures;various target tree structures;syntactic information;tree;standard seq2seq models;balanced binary trees;translations;nmt model;decoder;nmt systems;side syntax;nmt;linguistic knowledge;constituency;best improvements;model;bleu points;recent advances;specific types;target;target side;quality;bleu;topology;paper;experiments;other methods", "pdf_keywords": "neural machine translation;translation process;tree structures;arbitrary tree structure;tree;various target tree structures;syntactic information;novel tree;nmt model;translations;nmt;nmt systems;decoder;target side tree topology;side tree topology;translation;trdec;2google brain;mountain view;pengcheng yin1;xinyi wang1;topology;graham neubig1;carnegie mellon university;quality;abstract;target;recent advances;paper;target side"}, "162515d87256f13888d9d7ba95275ac4b6c35396": {"ta_keywords": "adversarial misspellings;adversarial spelling mistakes;robust word recognition danish;adversarial training;word recognition model;bert model;shelf spell checkers;character attack lowers accuracy;downstream classifier;accuracy;words;keyboard mistakes;sentiment analysis;error reduction;defense;pipeline;front;swaps;vanilla;random adds;drops;method", "pdf_keywords": ""}, "615358de8e9a7cf318c172afafc2a303eab93d98": {"ta_keywords": "fashion coordinates recommender system;fashion models;clothing coordinates;fashion item;fashion item region;fashion magazines;fashion style;fashion magazine;recommender system;body photographs;photographs;probabilistic topic model;real photographs;visual features;recommendations;photograph;coordinates;information;useful references;services;method;paper;bottom;task;number;effectiveness", "pdf_keywords": ""}, "58c04126a5196deb57ae31d6174cd4aae154f138": {"ta_keywords": "example annotation costs;annotation budget;standard active learners;active learning;real annotation;active learners;annotation;labels;partial labels;label;hard examples;learner;partial feedback;many classes;example;class;dataset;papers;rounds;binary feedback;baselines;form;alpf;pairs;strategy;conventional wisdom;binary question;ii;realistic setting;mismatch", "pdf_keywords": "example annotation costs;active learning;real annotation;active learners;annotation;traditional active learning;partial feedback;partial labels;partial feedback framework;traditional active learners;labels;label;alpf learners;scale classi\ufb01cation benchmarks;hard examples;many classes;learner;examples;binary feedback;iclr;fewer binary questions;abstract;data;experiments;effective scheme;conference paper;papers;conclusion;more ef\ufb01cient;form"}, "bdfb9f1c79ad726049a3563c741311391e18532a": {"ta_keywords": "speech style manipulation;speech recognition system;entrainment", "pdf_keywords": ""}, "eadf5023c90a6af8a0f8e8605bd8050cc13c23a3": {"ta_keywords": "kinect microphone arrays;robust automatic speech recognition;microphone capture;binaural microphone pairs;chime challenge series;speech enhancement;natural conversational speech;array track;conversational language modeling;speech material;asr;speech;end asr;signal processing;track;language processing;machine learning;challenge;data;task;array synchronization;baseline systems;dinner party scenario;systems;interface;data collection procedure;robustness;technology;detailed description;aspects", "pdf_keywords": "5th chime challenge;chime challenge series;conversational asr;speech processing;speech separation;robust automatic speech recognition;chime;distant multimicrophone;binaural microphone pairs;natural conversational speech;speech enhancement;conversational speech;kinect microphone arrays;speech material;recognition challenge;multiple microphone arrays;asr;end asr;speech;language processing;machine learning;dataset;signal processing;challenge;task;data;language;real home environments;loria;cnrs"}, "11465566a1f5ec7d4176bb7ab8edd26a154a1b60": {"ta_keywords": "privacy contracts;privacy;privacy breach;electric utilities;smart meters;electric utility;utility;consumption data;consumers;contracts;consumer;social welfare;costs;data;optimization problem;operations;valuation;mathematical model;users;operation;different valuations;world;same time benefits;population;paper;mechanisms;problem;probability;goal;unprecedented levels", "pdf_keywords": "privacy contracts;privacy;privacy breach;electric utilities;future smart meter collection practices;new service contracts;electric utility;service contract;contracts;utility;utility company;consumers;incentive;costs;consumer;optimization problem;social welfare;mathematical model;mathematical framework;operation;users;different valuations;fundamental tradeoff;problem;population;probability;model;paper;line;research"}, "ba00cbd314dc52b299a8b0c34f1887bcd43cdc12": {"ta_keywords": "synonymy dictionaries;word sense induction;lexical resources;synonyms;word embeddings;wiktionary;synsets;ambiguous words;automatic induction;weighted graph;watset;terms;gold standard datasets;english;new graph;available resources;graph;score;simplicity;excellent results;art methods;competitive state;paper;scale;approach", "pdf_keywords": "synonymy dictionaries;word embeddings;lexical resources;synonyms;english datasets;wordnet;synsets;gold standard datasets;russian;yarn dataset;automatic induction;language;terms;english;informatics;markov clustering;new graph;comparative analysis;mathematics;\ufb01ve;resource;natural sciences;abstract;russia;art graph;results;cw;graph;eco clustering;clique percolation method"}, "48220433a2fb07761b26b2d6aa59b615289a3d4c": {"ta_keywords": "fooling graph neural networks;adversarial example;graph neural networks;specific attacker node;node attack;various gnn types;malicious users;social networks;gnn;gnns;node;attacker;graph;single arbitrary node;gcn;attack;target node;gat;world datasets;label;variety;gin;product recommendations;domains;broad applicability;behavior;single;paper;scenario;fertile ground", "pdf_keywords": "single attacker node;multiple attacker nodes;attacker node;speci\ufb01c attacker node;single independent attacker;adversary;attacker;single arbitrary node;single node;attack;node;single edge;target node;graph topology;graph;free approach;gnn;label;own representation;feasibility;box gradient;example;limited scenario;troublesome scenario;choice;approaches;approach;account;paper;box"}, "25c50ef5a902586a06099ceb29e7f34e2172020a": {"ta_keywords": "wireless networks;neural networks;guidelines;techniques;applications", "pdf_keywords": ""}, "e79bd5d5ad084009233c8524b02ac887029c5fe2": {"ta_keywords": "variable oil damper;design optimization method;base;structure", "pdf_keywords": ""}, "f1b52bf723d7f5c4b68c8551c4d168ed1224f016": {"ta_keywords": "sinocyclocheilus wenshanensis;abstract sinocyclocheilus wenshanensis;complete mitochondrial genome;cyprinid fish species;cyprinidae fishes;sinocyclocheilus fishes;phylogenetic analysis;cyprinidae;mitogenome;cypriniformes;southwestern china;gene arrangement pattern;ribosomal rna genes;transfer rna genes;genes;base pairs;generation;bp;entire length;characterization;method;protein;control region;study", "pdf_keywords": ""}, "c14fb834ac6ede13f94f71cfaf5649b55e70a2c2": {"ta_keywords": "data market;data aggregators;multiple data purchasers;quality data;single data aggregator;data sources;data;aggregator;same data;moral hazard;economy;undesirable outcomes;competitive settings;equilibria;sellers;research;nash;mechanisms;analysis;quality;need;effort;components;gn;good;literature;sufficient conditions;own right;recent years;important role", "pdf_keywords": "data market;other data aggregators;data buyers;data aggregator;single data aggregator;multiple data purchasers;second data aggregator;data sources;data source;data;high quality data;generalized nash equilibria;market;social inef\ufb01ency;undesirable outcomes;moral hazard;ef\ufb01cient outcomes;competitive settings;sellers;gn equilibria;nonrivalrous nature;research;suf\ufb01cient conditions;analysis;mechanisms;same mechanisms;coupling;need;solutions;components"}, "7c085d7f50a76cf1a09a114986206256e0ee1931": {"ta_keywords": "\u70b9\u4e88\u6e2c\u3068\u7cfb\u5217\u4e88\u6e2c\u306e2\u6bb5\u968e\u5316\u306b\u3088\u308b\u54c1\u8a5e\u63a8\u5b9a\u306e\u7cbe\u5ea6\u5411\u4e0a", "pdf_keywords": ""}, "293ed3367027c99a81ead6ff3f31be7de43bce9c": {"ta_keywords": "strategyproof peer selection;randomization;partitioning;apportionment", "pdf_keywords": "strategyproof peer selection;new allocation mechanism;randomization;fraction allocation;new strategyproof mechanism;partition mechanism;continuous resource;partitioning;selections;peer reviews;conference paper;unsw sydney;modern science;ideas;apr;desirable properties;mechanism;apportionment;sydney;data61 csiro;evaluations;hebrew university;literature;israel;integer one;abstract;solutions;fundamental aspect;australia;jerusalem"}, "adeed0816a2cab763e3bee769957ff1849985759": {"ta_keywords": "modern spellings;normalization;variant word forms;string distance measures;historical texts;distance measures;pos tagging;spelling;norma tool;lemmatization;further processing;several approaches;different types;methods;data;paper;focus;variance;high degree", "pdf_keywords": ""}, "bd8334c1246adbd47f80eea60249c30a74925d7a": {"ta_keywords": "asynchronous stochastic approximation based learning algorithms;asynchronous stochastic approximation;wireless networks;wireless relay networks;unmanned aerial vehicles;fast deployment;deployment agent;optimal policies;deployment progresses;optimal policy;wireless link quality measurements;best relay placement location;possible deployment approaches;algorithms;free algorithms;average cost optimality equation;deployment;uavs;emergency situations;agent;average cost mdp;robots;human agents;forward approach;emergency;few successive steps;line placement decisions;fast speed;explore;convergence", "pdf_keywords": "asynchronous stochastic approximation based learning algorithms;asynchronous stochastic approximation;wireless networks;wireless relay networks;unmanned aerial vehicles;optimal policies;corresponding optimal policies;optimal policy;fast deployment;wireless link quality measurements;deployment progresses;average cost optimality equation;average cost minimization problem;algorithms;deployment;free algorithms;uavs;emergency situations;robots;agent;human agents;emergency;line placement decisions;asymptotic convergence;convergence;fast speed;line;model;avishek ghosh;need"}, "7e0eb21f4903c2fe860d1c4f213879e99d7cd23c": {"ta_keywords": "electrolaryngeal speech enhancement;voice conversion method;proficient laryngectomees;laryngectomees;noise reduction method;electrolarynx;statistical source excitation generation;intelligible el speech;electrolaryngeal;el speech;excitation parameters;speech;mechanical excitation;spectral compensation;excitation;listenability;spectral parameters;el;device;hybrid method;hybrid approach;degradation;naturalness;issues", "pdf_keywords": ""}, "1d56a0b8fb560a79ca28b44bfd6f1e645a36549a": {"ta_keywords": "thermal control device;automatic resistance measurement function;thermocouple;temperature collection;heating belt;room temperature;automatic measurement;heating plate;resistance value;machine interface;system design;measurement speed;output voltage signals;system;software;application;robustness;research;main contents;friendliness", "pdf_keywords": ""}, "ead3182dd47bdd8da98476cca1cfe0373dfc2edc": {"ta_keywords": "gaussian mixture model;speech recognition;triphone hmm states;complicated acoustic model;appropriate acoustic model topology;acoustic model;model search algorithm;variational bayesian estimation;efficient model search algorithm;clustering;decision tree;markov model states;automatic determination;vbec framework;vbec;search space;gmm;computations;efficient method;statistics;novel approach;practical level;characteristics;large number", "pdf_keywords": ""}, "b593be8ff3c09c6994657678fcde0c5adf43328e": {"ta_keywords": "unsupervised syntactic parsing;full parse tree annotation;english wsj penn treebank;structural annotation;improved latent tree induction;latent tree induction;span constraints;distant supervision;lexicon;exact text matches;wikipedia;entities;text;constituency;minimal effort;researchers;counterparts;years;form;f1;modern systems;methods;work;experiments;approach;practical use;technique", "pdf_keywords": "english wsj penn treebank;supervised constituency;structured svm loss;ground truth entities;span constraints;english newswire data;diora;biomedical text;svm;distant supervision;entities;synthetic data;partial structure;constraints;recursion depth;constituency;gazetteer;\ufb01nd;\ufb02exible optimization framework;strong results;f1;gap;martins;klein;kitaev;ps;domain;new method;performance;experiments"}, "07a5536c0570804f816fdb5a0a5ae890630e61bd": {"ta_keywords": "electrolaryngeal speech enhancement;el speech enhancement;speech enhancement method;statistical voice conversion method;statistical voice conversion;noise reduction;noise reduction method;el speech;acoustic parameters;laryngectomees;statistical excitation generation;natural voices;electrolarynx;noise;excitation parameters;el;excitation;spectral parameters;conversion;spectral;intelligibility;device;external device;degradation;naturalness;hybrid approach;vc;errors;latter approach;paper", "pdf_keywords": ""}, "d14afc470cd90521147130e153c0d3e1324cd104": {"ta_keywords": "neural machine translation system;neural nlp;language representations;languages;typological databases;typology prediction;neural models;language;phonetic inventory features;semantics;parallel texts;phylogenetic neighbors;english;syntax;nmt system;information;central mystery;subject matter;baseline;experiments;existence;method;access", "pdf_keywords": "multilingual neural language models;language vector;linguistic typology;neural machine translation;human languages;phonetic inventory features;typology prediction;typological features;languages;parallel corpora;language;linguistic concepts;entire language;feature vectors;neural networks;neural network;features;sentences;representations;latent state;encoder;holistic analysis;single vector;nmt;other classes;systems;several methods;classes;classi\ufb01cation;relationships"}, "6aac35ec3bfaf7e835ac633414419c9623838007": {"ta_keywords": "dimensional speech features;timit phoneme sequence recognition task;auditory features;cochleogram features;spectrogram feature combination;spectrogram features;deep neural network;convolutional neural network;hybrid neural network;relative phoneme error rate;dimensional cochleogram;cochleogram;cochleograms;gammatone filters;cnn;single features;best accuracy;mel filter banks;dnn;nn;markov model;log;significant advantages;hmm;performance;level combination;reduction;various possibilities;system;use", "pdf_keywords": ""}, "9895531c6dc3854f082de1a1ec651a9e179bbd07": {"ta_keywords": "connectionist temporal classification loss function;tonal languages;tonal prediction;tonal transcription;phonemes;transcription;pitch information;tones;phonemic context;linguistic workflow;phonemic facts;neural network architecture;training data;recognition performance;yongning na;language documentation setting;acoustic signal;minutes;linguistic consideration;typographical errors;technology;importance;eastern chatino;use;changes;findings;promise;efficiency;framework;method", "pdf_keywords": ""}, "8d1fd086a76d30343d2224b61cb7ddab2125d0b2": {"ta_keywords": "machine learning;solution paths;program;novel representation;examples;certain unusual optimizations;performance;previous search problems;sll;typical inputs;common approach;theory;framework;paper;behavior;formal framework;sort;positive results;analysis;much research;problem;experimental evidence;mechanisms;mechanism;order;series;set;many respects", "pdf_keywords": ""}, "3256198d819f23f82640490b9160e85139627d6c": {"ta_keywords": "signal reconstruction;signal reconstruction problem;wavelet transform domain;edge intensity;image processing;norm optimization problem;threshold operation;iterative algorithm;salient feature;solution;linear simultaneous equation;representation;information;application;amount", "pdf_keywords": ""}, "f9a86c2df17f408105c2d3e9429410cdc376c6f0": {"ta_keywords": "distributional semantics;distributional lexical semantics;semantic space models;semantic spaces;rich lexical semantic resources;nlp;computational linguistics;lexical acquisition tasks;distributional methods;scalable distributional methods;latent topic models;machine learning;paper submissions;representation;models;kernel methods;tensor analysis;natural engineering;journal;papers;ideas;workshop;gems;field;interdisciplinary view;art;independent communities;association;people;research", "pdf_keywords": ""}, "66713fbcb8d5e48a9eb6425bd7fdbb53751e60b1": {"ta_keywords": "novel vectorized scheme;new vectorized scheme;better compression;compression;fastest schemes;vectorization;compression ratio;bits;decompression;desktop processors;integers;arrays;relational database systems;search engines;data;pfor;billions;int;many important applications;costs;form;second;substantial effort;approaches;same time;times", "pdf_keywords": "compression techniques;better compression;bit integer sequences;binary packing scheme;compression ratio;novel vectorized scheme;competitive compression ratios;new vectorized scheme;scheme simd;desktop processors;simd;speeds;speed;fastpfor;best available schemes;algorithms;new schemes;bp128;scheme;pfor;art scheme;state;metrics;times;results;table;approaches;conclusion;literature"}, "3a2446c47000c3d0681b2cdf6d8b87a11ff630e2": {"ta_keywords": "exterior wall insulation board installation engineers;building exterior wall insulation board;exterior wall insulation boards;insulation board;artificial installation;dimensional software solidworks;installation device;construction workers;poor installation quality;installation;engineering;better surface quality;virtual assembly;dimensional modeling;labor intensity;improved safety;design;high risk factor;device;analysis;high application value;third;work;study;research;results;stability", "pdf_keywords": ""}, "5ce3148ed36a1ea034da2c05b8cde9efbaf43e6a": {"ta_keywords": "field speech recognition;deep beamforming;ami meeting transcription task;deep learning framework;minimum variance distortionless response bf;bf network;noise scm;bf weights;spatial covariance features;scm features;generalized cross correlation;speech;conventional asr pipeline;sum bf;features;advanced bf methods;phase information;bf;spatial covariance matrices;input signals;networks;individual frequency bands;word error rate;network;scm;phase;gcc;delay;use;paper", "pdf_keywords": ""}, "981dbdf6f87f13f3f3047a925c519fc39a35202b": {"ta_keywords": "neural probabilistic language model;word embeddings;language modeling;level language model benchmarks;short input contexts;neural architectures;next word;word;term dependencies;baseline transformer;forward network;lower perplexity;model;hardware;feed;modern hardware;window;recent progress;optimization improvements;nplm;paper;bengio et al;many limitations;advances;result;analysis", "pdf_keywords": "neural probabilistic language model;level language modeling datasets;language modeling;wordlevel language modeling datasets;attention layer;neural architecture;classic language model;neural architecture design;attention;transformer lm;layer normalization;transformer;concatenation layer;local concatenation layer;perplexity;\ufb01rst selfattention layer;consistent perplexity;word;hardware;baseline transformer;nplm;self;simple variants;\ufb01rst layer;depth;validation perplexity;optimization;table;\ufb01rst self;variants"}, "d92e0443768ec3715205cb232ef1a1917372b0af": {"ta_keywords": "end speech processing toolkit;automatic speech processing;downstream natural language processing;various speech processing tasks;spoken language understanding;speech translation;different spoken language understanding;nlu models;various slu benchmarks;few open source toolkits;espnet;benchmarks;speech;toolkit;nlp;different asr;asr output;asr;slu;quick development;text;tts;tasks;implementations;models;reproducible results;source standard;end;parameters;current state", "pdf_keywords": "source speech processing toolkit espnet;various speech processing tasks;various slu benchmarks;nlu models;slu toolkit;popular espnet toolkit;benchmarks;various benchmarks;slu systems;slu;different asr;source toolkit;espnet;toolkit;new e2e;source e2e;implementations;model evaluation;models;data preparation;training;standardized recipes;fast research;architectures;easy access;objective;state;art performance;access;development"}, "04e3a3ee41c1ee977e023052435bbb5f4c680f66": {"ta_keywords": "new retail stores;freshippo stores;location choice;nanjing city;community;development;optimization;case study", "pdf_keywords": ""}, "eba4c6b0b860a34461ffb8544111c89a3ef0d8b7": {"ta_keywords": "noisy pairwise comparisons;ranking problem;strong stochastic transitivity;recommender systems;crowdsourcing;algorithms;previous known algorithms;algorithm;possible algorithm;competitive ratios;competitive ratio;web search;linear time algorithm;social choice;comparison;competitive analysis;pair;general noise model;sst;many samples;noise;contrast;instance;times;problem;applications;model;set;setting", "pdf_keywords": "ranking problem;pairwise comparisons;strong stochastic transitivity;competitive ratios;previous known algorithms;algorithm;possible algorithm;competitive ratio;recommender systems;crowdsourcing;linear time algorithm;competitive analysis;web search;comparison;social choice;general noise model;pair;sst;many samples;noise;contrast;algor;instance;may;times;applications;ithms;problem;model;set"}, "9d628e420922cc23a8944de1511ca5d3309f5d58": {"ta_keywords": "noteworthy utterances;soap notes;summary sentences;annotations;transcripts;full soap note;notes;soap sentence;patient visit records;summary sentence;extraction;abstractive subtasks;full conversation;complete pipelines;oracle experiments;improvements;generative capabilities;unique dataset;machine;end approach;approaches;approach;cluster;end;rouge point gain;subsection;paper;first study;performing method;ii", "pdf_keywords": ""}, "40ba59c9945e7c19d06dadfa8f496da5810ee30d": {"ta_keywords": "faster beam search;speech recognition;beam search;right beam search algorithm;original beam search algorithm;multiple speech utterances;multiple utterances;encoder decoder network;encoder decoder;vectorization;speech;batch;rnnlm;shallow fusion;parallelism technique;attention;speedup;search process;line recognition use;multiple hypotheses;gpu;processing unit;traverse;loop program;inference step;ctc;hypotheses;external modules;scores;addition", "pdf_keywords": "speech vectorization method;librispeech corpus;utterances;decoder networks;recognition time;multiple utterances;csj corpus;original beam search algorithm;vectorization;utterance;online decoding1;process parallelism;cpu core;speedup;single core cpu;ctc pre\ufb01x score;batch;encoder network;gpu;ctc;speed;execution;hidden vector;attention;algorithm;minutes;computation;original program;hypothesis traversal;operations"}, "ccd33442fef058c7c0eafc57d2c6e6a4cde10a3b": {"ta_keywords": "spherical graph convolutional network;protein model quality assessment;protein model quality assessment problem;molecular graphs;structure prediction;spherical convolutions;proteins;graph structure;spherical convolution method;3d models;equivariant spherical filters;particular rotations;3d objects;graph nodes;model assessment;body transformations;rotation;local coordinate systems;benchmarks;amino acid;gcn;local coordinate system;angular information;casp;quality;art methods;input data;critical assessment;framework;methods", "pdf_keywords": "spherical graph convolutional network;molecular graphs;molecular graph;protein model quality assessment task;convolutional network;protein model quality assessment problem;voronoi 3d tessellation;4d geometric descriptors;deep convolutional networks;spherical convolution method;proteins;3d models;spherical architectures;volumetric data;3d structure;classical gcn approach;classical gcn architecture;precomputed descriptors;graph;spherical harmonics;gcn baseline;gcn;vorocnn;model assessment;convolution operation;network;proq3;local coordinate frames;atom;sbrod"}, "5dd34d2781ca702d0e3cd1224517ff60d6c3e2ee": {"ta_keywords": "informal romanization;character mappings;latin character sets;character substitution choices;character pairs;visual similarity;languages;visual priors;informal digital communication;text;common keyboards;unsupervised fashion;decipherment;supervised skyline;idiosyncratic process;channel wfst cascade model;inductive bias;humans;performance;users;results;model;variety;same main principles", "pdf_keywords": "informal romanization;language model;romanized russian;languages;natural language processing systems;russian;russian social network website;arabic;state transducer;egyptian arabic;curriculum learning;parallel text;unsupervised models;unsupervised model;human annotations;text;neologisms;channel wfst cascade model;unsupervised fashion;online communication;original scripts;new dataset;test time predictions;confusion matrix;original orthography;cascade model;wfst;channel model;data;stepwise em algorithm"}, "054ba27fe5cc6085d20ea2707de886db6865dbed": {"ta_keywords": "pagerank measure;relational retrieval;novel learnable proximity measure;entity recognition;popular entity experts;popular proximity measure;retrieval;edge label sequence;rankings;entities;particular entities;graph representation;supervised learning;edge label;random walks;path experts;graph;proximity;random walk;edges;rwr measures;query;scientific tasks;independent experts;experts;weighted combination;path;ner;rwr;paper", "pdf_keywords": ""}, "7621bfe36cc649a5876cea587366201e158a8b38": {"ta_keywords": "semantic role labeling;domain adaptation;resource corpus;biological domain;richer annotations;target labels;source labels;processbank;resource domain;crf;biological processes;srl systems;biological process;srl;mapping;event relationship;scale datasets;neural network architecture;systems;event;final crf layer;sequence;challenging aspects;current state;approaches;f1 gain;possible insights;paper;performances;other approach", "pdf_keywords": ""}, "c1a4c5380d90dc77064de6003cfb9611ad218600": {"ta_keywords": "neural dialogue response generation;controlled neural dialogue generation;dialogue generator;conditional adversarial learning;dialogue history;adversarial discriminator;adversarial approach;sentiment label;conditional variational;sentiment labels;seq2seq model;seq2seq;sentiment;sequence;generator;response;standard sequence;fluency;reasonable responses;training;model;quality;feasibility;high;method;paradigm;framework;flexibility;work", "pdf_keywords": "sentimentcontrolled dialogue generation;neural dialogue response generation;controlled neural dialogue generation;dialogue generator;dialogue responses;conditional adversarial learning;conditional generative adversarial network;adversarial discriminator;dialogue history;adversarial approach;generative adversarial networks;gans;sentiment label;sentiment labels;sentiment;human evaluation;response;generator;yiming yang;conditional variational;language technologies institute carnegie mellon university;reasonable responses;training;xiangk;powerful model;bohan li;sequence;model;bohanl1;feasibility"}, "9d06638df32f8feefb95ef5a4769adbb1ae6297d": {"ta_keywords": "effective rule learner;new rule learner;other rule learners;rulesets;boosting;ensemble;rules;adaboost;rule;generalization;slipper;confidence;builder;appropriate constraints;use", "pdf_keywords": ""}, "4c78943e11195fb72a3c878a03b248bc317180e0": {"ta_keywords": "description logics;simple description logic;learnable sublanguage;learnability;polynomial learnability;terminological logics;syntactic restrictions;predicate calculus;enable tractable learning;order logics;expressive power;order logic;type languages;examples;few formal results;concepts;vocabulary;positive examples;different syntax;order representations;kl;subsets;subset;size;different set;results;paper;amount;experimental research", "pdf_keywords": ""}, "f0baf134f0a2ee6e99f6f2287791109cf93305e7": {"ta_keywords": "location proteomics;text matching;ocr;optical character recognition;subcellular localization;caption understanding;captions;fluorescence microscope images;text;protein;subcellular patterns;text mining;search engines;images;literature;figures;figure;localization;data;comprehensive toolset;online journals;assertions;information;present special challenges;such efforts;techniques;form;current system", "pdf_keywords": ""}, "db253b17043b6a86e02173b6aa597664b0c7f256": {"ta_keywords": "visual character;many writing systems compositionality;embeddings;characters;rare characters;compositionality;text classification task;character;visual characteristics;convolutional neural network;rare words;words;languages;better processing;korean;sparsity;image;japanese;such model;chinese;level models;effect;parts;instances;paper;previous work;meaning;sum;level;problems", "pdf_keywords": "visual embeddings;embeddings;visual model;recurrent neural networks;characters;cnn;unicode representation;representation;convolutional neural networks;cnns;compositionality;character;lookup baseline model;language;languages;wikipedia dataset;features;image;different languages;semantic information;end model;component parts;rendering;appearance;shape;short titles;end;humans;meaning;future work"}, "f516c98c3d2dde5b31931715fbc48bbbc0580e27": {"ta_keywords": "email patterns;email messages;team leadership roles;team members;group leader;large email collection;work groups;leadership roles;leaders;work group dynamics;leadership positions;several workgroups;entire workgroup;email;textual patterns;information patterns;message headers;sender;message thread position;semantic information;trac;shelf learning algorithms;patterns;language usage;task;intent;performance;message;collection;other aspects", "pdf_keywords": ""}, "553b74de8cb7ebca42a686e2a3a2d6aae170946e": {"ta_keywords": "speech enhancement;clean speech signals;quality audio;diffusion probabilistic model;raw audio;better enhancement results;diffuse model;clean signals;gaussian noise;probabilistic models;diffwave;noisy signals;diffuse;diffusion;probabilistic model;fast sampling;natural images;conventional full step inference process;reverse processes;reverse process;full sam;low computational cost;model;supportive reverse process;generation model;pling schedule;erty;outstanding capability;few steps;fundamental architecture", "pdf_keywords": "speech enhancement;clean speech signals;audio generative models;highquality audio waveform generation model;diffusion probabilistic model;diffwave;raw audio;clean signals;better enhancement results;diffuse model;noisy signals;diffuse;gaussian noise;probabilistic models;diffusion;probabilistic model;standardized voice bank corpus se task;fast sampling;reverse processes;reverse process;low computational cost;natural images;model;conventional full step inference process;supportive reverse process;yen;academia sinica;full sampling schedule;taipei;shinji"}, "616cc6826066184a8c77c3f2562e4e891ce42911": {"ta_keywords": "deep reinforcement learning;reinforcement learning;intrinsic fear;atari games seaquest;reward;dqns;learning objective;toy environments;catastrophe;catastrophes;catastrophic mistakes;agent;dangerous states;sisyphean curse;policies;supervised learning;asteroids;wild;steps;freeway;guards;probability;paper;approach;score;problems;second model;new method;short number", "pdf_keywords": "safe reinforcement learning;reinforcement learning;intrinsic fear model;learned reward;supervised fear model;intrinsic fear;reward function;catastrophic states;adventure seeker;safety;guards drl agents;learning;catastrophe states;robustness;safety research;modern drl algorithms;catastrophe;domestic robot;periodic catastrophes;prior knowledge;algorithms;brittleness;ability;barber;kr steps;simple pathological problem;objective;little foreknowledge;approach;paper"}, "7e82015c386726f4b8f6f686b6e6bb7d1e7564bb": {"ta_keywords": "controversial posts;reply relationship modeling;public sentiment;social media;topics;semantic information;posts;content;comments;graph structure;unrelated features;topic;views;structural information;events;tpc;information;post;dtpc;gcn;influence;cases;fundamental task;significant generalizability;models;results;limitations;analysis;model;methods", "pdf_keywords": "controversy detection;comment graph convolutional network;controversial posts;graph convolutional network;public sentiment;semantic;social media;graph structure;posts;content;topics;views;topicpost;comments;intelligent information processing;topic;structural information;china 2university;events;unrelated features;tpc;paper;information;beijing;novel method tpcgcn;junbo guo1;conclusion;fundamental task;china;dtpc"}, "b8cabd2f7fbf816d667701c5d756b5fcb982e6fe": {"ta_keywords": "strict local minmax equilibria;stochastic gradient feedback;gradient descent;finite timescale separation;ascent provably converges;learning rate;finite timescale separation parameter;timescale separation;sum games;ascent;significant impact timescale separation;corresponding convergence rates;training performance;players;player;edge cases;explicit construction;celeba;update;role;work;results", "pdf_keywords": "strict local minmax equilibria;gradient penalty;learning dynamics;gradient descent;wasserstein cost function;generative adversarial network formulation;stochastic gradient feedback;ascent provably converges;learning rate;generative adversarial networks;sum games;regularization;local stability;finite timescale separation;ascent;corresponding convergence rates;critical points;rates \u03b31;discriminator;\u03b31;\u03b32;convergence rate;player;quadratic discriminator;discrete time;dynamics;continuous time;covariance matrix;explicit construction;introduction"}, "c5a323f8744838093ee36bee3739dea599ce62f0": {"ta_keywords": "\u4e00\u822c\u30bb\u30c3\u30b7\u30e7\u30f3", "pdf_keywords": ""}, "e82eff0f3e3d150617f9a721f83046940a963c03": {"ta_keywords": "learning system;basic learning system;nonincremental learning system;learnability;perceptron learning algorithm;previous learning system;concept learners;loop induction algorithm;suitable loop induction algorithm;loop induction;abstraction functions;particular abstraction function;algorithms;hypothesis space;generalization;algorithm;approximate hypotheses;incremental version;trees;abstract space;examples;method;control rules;several examples;model;techniques;standard explanation;pac;explanation;representation", "pdf_keywords": ""}, "c8171eaa3a3aac78c3b37351412101bc06e5f359": {"ta_keywords": "monolingual annotators;comparable corpora;machine translation;translations;comparable training data;acceptable translations;target languages;captions;resource languages;languages;hindi;dictionary extraction;human evaluations;dataset;english;source;such images;pivot;images;pairs;downstream tasks;quality;set;potential;approach;method", "pdf_keywords": "parallel corpus creation;training machine translation systems;parallel corpora;machine translation;acceptable translation pairs;bilingual speakers;specific language pair;source language;target languages;dictionary extraction;hindi;english;dataset;complex culture;practical ml;downstream tasks;evaluation techniques;data;developing countries workshop;source;concise;ways;cost;utility;specific activity;traditional process;universal concept;work;such situations;images"}, "51c33a79e05425b6335c8676a166a0f4e178c0a2": {"ta_keywords": "novel text classification approach;line test items;skewed data sets;assessment;overall test performance;specific knowledge gaps;students;skill;teachers;performance;information;level;methodological concerns;hierarchical nature;paper;scheme;service;problem;goal", "pdf_keywords": ""}, "2c1cb736df7bf526fc3facecd078980e007abceb": {"ta_keywords": "yeast calmodulin;vertebrate calmodulin;chicken gizzard myosin light chain kinase;saccharomyces cerevisiae;calmodulin;porcine brain phosphodiesterase;yeast;maximum activation;ca2;higher concentration;same maximum activity;maximum activity;similar affinity;baker;mol;times;other hand;number", "pdf_keywords": ""}, "62d1a3137b01a69443bebf4d92c1990ec512a6a1": {"ta_keywords": "training data extraction attack;extraction attack;large language models;verbatim text sequences;private datasets;language models;training data;language model;adversary;scrapes;individual training examples;attack;public internet;hundreds;document;above sequences;model;paper;parameter;such settings;success;factors", "pdf_keywords": "private machine learning models;verbatim text sequences;many natural language processing tasks;neural network language model;natural language processing pipelines;verbatim sequences;language models;language modeling;private stochastic;gradient descent;training data;language model;public internet;box query access;words;sgd;query access;scrapes;sequence;email address;name;individual person;physical address;model;phone number;training;hundreds;algorithm;attack;probability"}, "bc4cb14af1023123b3122a5f0b6f3bb76334ffb4": {"ta_keywords": "kev lowenergy beam transport;conversion ion source;pop ion source;los alamos neutron scattering center;ion source;proton storage ring;beam emittance;ma design beam current;beam;los alamos national laboratory;lawrence berkeley national laboratory;kev;operational surface;psr;lansce;lanl;lbnl;operation;lebt;pop;status;improved version;results;factor;column;initial tests;proof;application;principle;modeling studies", "pdf_keywords": ""}, "073798fde720d5f08dccfbb0c1917a064828c399": {"ta_keywords": "cytomegalovirus subverts macrophage identity", "pdf_keywords": ""}, "81f5ef41dfa72679cb7cb38999a41a1c534c3871": {"ta_keywords": "casual relationships;book review;memory", "pdf_keywords": ""}, "8d69f466bdf56ce6663c2f809514577e79dd3bed": {"ta_keywords": "wearable device comprises;smart tools;gesture recognition;camera;projector;interface;devices;hardware restrictions;technologies;image processing;own gesture;color marker detection;lab;internet;speech recognition;idea;system;security;environment;things;sixth sense;responsiveness;paper;place;techniques;user", "pdf_keywords": "sixth sense technology;iot;gesture recognition;smart tools;wearable device comprises;gesture;camera;own gesture;information technology;interface;color marker detection;image processing;projector;sixth sense;technologies;devices;speech recognition;machine learning;management gwalior;internet;indian institute;implementation;shubhankar mohan;lab;idea;environment;prachie gupta;things;security;techniques"}, "79c6713c41b4fedf9c7454b7e2bb48d0aeb1ae0f": {"ta_keywords": "spectral designs;sample designs;high quality space;optimal space;several benchmark optimization functions;designs;arbitrary dimensions;design performance;surrogate modeling;image reconstruction;spectral analysis;space;optimization framework;spatial domain;detailed performance comparison;dimensions;inertial confinement fusion;spectral domain;objective measure;simulation code;novel technique;metric;efficient estimator;uniformity;randomness;icf;theoretical insights;different applications;properties;new approach", "pdf_keywords": "inertial con\ufb01nement fusion;surrogate modeling;several benchmark optimization functions;surrogate model design;surrogate models;image reconstruction;simulation code;simulator;detailed performance comparison;national ignition facility;icf;cube;dimensions;r2;rigorous empirical studies;nif;mse;goldsteinprice;superiority;aae;rosenbrock;statistic;function;di\ufb00erent applications;subsection;chichinadze;problem"}, "2821db8962fce43265215a9c4b8d66af02e16ae7": {"ta_keywords": "optimal static scheduler;optimal dynamic scheduler;optimal dynamic scheduling policies;optimal scheduling policy;actual optimal scheduling policy;scheduling;optimal average job latency;redundant requests;lower average job latency;latency;cancellation delay;data storage systems;cancellation;overhead;small cancellation;jobs;job;computing;twoserver case;useful insights;common assumption;importance;models;observation;literature;system;known fact;number;stark contrast;results", "pdf_keywords": ""}, "94245856c88e3e08777c876fc038ed1adf8f3285": {"ta_keywords": "classic description logic;experimental results", "pdf_keywords": ""}, "9ef4f6a070c750b746fe98ef34083d6a08c9ba42": {"ta_keywords": "pricing mechanisms;pricing;nash equilibrium;convex feasibility problem;quadratic game;feedback control strategy;selfish agents;nash followers;cost function;feedback control;time infinite horizon;control actions;cost;total cost;uncoupled leader;time finite horizon settings;other players;control inputs;leader;follower;quadratic dependence;nominal cost;followers;player;game;explicit dependence;methods;use;means;several extensions", "pdf_keywords": ""}, "ff86133b3b49974f06fc881548c6f3c7a8ceffee": {"ta_keywords": "statistical singing voice conversion;singing voice timbre;singing voice;voice timbre control method;arbitrary target singer;voice timbre;arbitrary source singer;perceived age;singers;singer;age control;prosody;statistical approach;age;song;listener;technique;individuality;perceptions;experimental results;notable characteristics;varieties;physical constraints;limitation;adverse effect;use;previous work", "pdf_keywords": ""}, "43d82bc8203c09edc7eb6b2bedcf4ab500690852": {"ta_keywords": "large multilingual language models;lingual adjustment;various nlp tasks;nlp tasks;contextual word representations;english models;different languages;english data;unrelated words;languages;related words;embeddings;shot transfer;xnli task;nli;similar words;vietnamese;hindi;ner;adjustment;mbert;differences histograms;better understanding;specific task;qa performance;relative distances;contrast;tuning;study;effectiveness", "pdf_keywords": "word embeddings;nlp tasks;small parallel corpus;english models;different languages;unrelated words;languages;cosine similarities;nli;shot transfer;mbert;vietnamese;adjustment;ner;original mbert;hindi;prior work;qa performance;study;histograms;effectiveness;conclusion;qa;points;case;experiments;point;help;following"}, "b57da3ccf214e8dad49116c8db9590c2c89629f5": {"ta_keywords": "entity recognition;african languages;nlp research;african continent;languages;ner tasks;extensive empirical evaluation;datasets;quality dataset;ner;researchers;masakhaner;characteristics;different stakeholders;challenges;practitioners;step;art methods;settings", "pdf_keywords": "language annotators;african languages;ken african languages;nlp research;ner datasets;nlp practitioners;online news corpora;language speakers;ner task;entities;african continent;ner;african university;dataset curators;models;strong baselines;datasets;nigeria;evaluation experts;representation;best models;huggingface model hub7;evaluation;ibadan;technology 28 instadeep;27namibia university;abstract;challenges;lule\u00e5 university;abuja"}, "05c8f15dbdd7c6661b9176638262bbc1e11de85f": {"ta_keywords": "interpretable sense embeddings;word sense embeddings;sense embeddings;interpretable embeddings;sense groups;gumbel softmax function;multiple sense;differentiable discrete sense selection;interpretability comparison;interpretability;downstream evaluations tasks;sense;downstream evaluations;unsupervised model;specific vectors;context;single word;worlds;many previous approaches;performance;method;methods", "pdf_keywords": "sense embeddings;interpretable sense representations;evaluations uncover sense representations;interpretable senses;duplicate senses;modern contextual representations;sense induction;appropriate senses;new coherence evaluation;representation learning;sense;muse;word;most words;gumbel attention;average cosine similarities;distinctness;models;nearest neighbors;human;measures;model agreement;meaning;discrepancy;sec;users;minimal model;connections"}, "58737fba500075136ee0f33f7801a5ac7f82ab68": {"ta_keywords": "lucene;bm25;scoring variants;document length;source search library;variants;researchers;variant;scale reproducibility study;significant effectiveness differences;newswire collections;original formulation;experiments;many tweaks;approximation;implementation;question;practitioners", "pdf_keywords": ""}, "14919b6a453a71f2a007d5fa57241887a982575f": {"ta_keywords": "coreclassic;representation;usual complexity assumptions;independent hardness;theorem;core classic;open problem;frazier;proof;error;direction;question;pitt", "pdf_keywords": ""}, "fb089347919e8dada9335b4bac01f16eea758c56": {"ta_keywords": "ethical questions;common ethical theories;ethics;ethical issues;computer games;artificial intelligence;computer science;technologies;remote contact;students;machine;machine stops;strong emotional associations;professional careers;questions;tools;story;other media;level view;structure;key front", "pdf_keywords": ""}, "e2c05b3abf77900ec82ffa8a95aa774308d2780f": {"ta_keywords": "level language detection;level language detection technique;multiple languages;specific languages;languages;twitter;code;text;switching;novel unsupervised word;text input;training data;sentence;novel generalized word;world scenarios;word;large number;priori information;models", "pdf_keywords": ""}, "719916251f7e36d2e7a40e70f89f20ab97a8bc29": {"ta_keywords": "single channel speech enhancement;various speech enhancement applications;speech enhancement;spectral mask estimation;multichannel enhancement techniques;speech signal;speech recognition;blstm mask;soft mask;mask;teacher learning;soft mask target;multichannel input;beamformer;channel input;masks;teacher;blstm;student network;neural networks;term memory;student;original loss;paper;great success;paradigm", "pdf_keywords": "speech enhancement;various speech enhancement applications;multichannel speech enhancement;single channel speech enhancement;different speech enhancement metrics;quality speech masks;multichannel speech enhancement properties;speech mask target;conventional blstm masking;spectral mask estimation;speech quality;blstm mask;speech processing;speech distortion ratio;mask estimation;channel enhancement;original noisy speech;multichannel enhancement techniques;noise mask target;multichannel enhancement;mask;speech;teacher learning;blstm;teacher training;acoustic model;studentteacher technique;blstms;teacher network;new training paradigm"}, "0909fee90833e20913adb553bf6667c9a3b854b0": {"ta_keywords": "learning system;wrapper management system;learning systems;learner;text asm;wrapper;database;program;learning rate;level representations;earlier wrapper;representations;dimensional geometric views;page;tabular data;examples;website;such different representations;visual appearance;tasks;active use;new domains;dom;whizbang labs;level;broader coverage;system;strength;experiments;part", "pdf_keywords": ""}, "4a45ace1f8c6a30ba00201b30acd93844b9797eb": {"ta_keywords": "center histidine;chloromethyl ketone;trypsin;heptanone;specific reagent;tosyl;n\u03b1;evidence;active;use", "pdf_keywords": ""}, "dd3ba828dbbb17cf478f6840a37954f6ebc81770": {"ta_keywords": "attention lstms;dependent spoken language understanding;human hotel reservation task;term memory;lstm;hotel reservation task;sensitive spoken language understanding;lstms;attention;speaker intentions;utterance;dialog;rnns;roledependent context;conversation;neural networks;role;roles;agent;dialog turns;speaker;context;level context;different role;right context;intentions;bidirectional;slu;label accuracies;sensitive model", "pdf_keywords": ""}, "81e57827bebb04305cc9e6c85e96c83951244ec2": {"ta_keywords": "knowledge graph;new knowledge graph;link prediction;link prediction task;tensor decomposition;drug combinations;adverse effects;graph convolutions;polypharmacy side effects;precision recall curves;possible adverse effects;polypharmacy side;decagon model;effect data;vectors;model;effects;roc;machine;formulates;multiple works;terms;techniques;area;approach;work;experimental evaluation;technique", "pdf_keywords": "related knowledge graph;knowledge graph;new knowledge graph;tensor factorisation;vector representations;tensor decomposition;link prediction task;polypharmacy side;decagon model;recall curves;precision recall curves;vectors;drugs;side;roc;model;effects;terms;precision;area;experimental evaluation;technique;work;approach"}, "e98621050e52e9d8c60829d8d861e81ac86a8617": {"ta_keywords": "model space speaker adaptation;map estimation;feature", "pdf_keywords": ""}, "e2b097bce656db9215505659357263c43190194b": {"ta_keywords": "optimal reviewer splitting;random reviewer split;additional reviewers;phase paper reviewing;conference experiment design;phase paper review process;reviewers;conference experiment design settings;random choice;optimal assignment;many scientific conferences;random strategy;additional review;initial reviews;conference;real conference data;papers;phases;assignment;program chairs;oracle;interpretable conditions;several datasets;actionable insights;theoretical bounds;phase;explanations;conditions;certain natural conditions;set", "pdf_keywords": "stage paper assignment problem;optimal assignment;conference experiment design;random reviewer split;conference experiment design settings;random choice;phase paper assignment;random strategy;conference;assignment;real conference data;modern conferences;reviewers;program chairs;phases;oracle;interpretable conditions;phase;section;conditions;several datasets;theoretical bounds;actionable insights;explanations;applications;certain natural conditions;practical importance;phenomenon;issue;suboptimality"}, "c0c1950fb0a129b71a218ffa8b9fbc6d088cba2d": {"ta_keywords": "computer science;higher education;innovative approaches;1st international workshop;proceedings;chelyabinsk;russia;may 26th", "pdf_keywords": ""}, "27f9b91bd7c70a99f578c8a5cb52d37e4123da47": {"ta_keywords": "tensor regression layers;tensor contraction layers;order activation tensors;order activation tensor;output tensor;tensor;imagenet;tensor contraction;activation vectors;convolutional layers map;networks;layers;multilinear structure;multilinear mapping;accurate nets;layer;resnet architectures;connected layers;regression weights;activations;uk biobank dataset;structured data;dimensionality;topological structure;rank constraints;comparable architectures;outputs;mri;fewer parameters;input", "pdf_keywords": "tensor regression layers;tensor contraction layers;tensor regression;tensor structure;tensor contraction;order activation tensor;output tensor;popular imagenet dataset;neural networks;trainable architecture;uk biobank dataset;layers;trainable components;multilinear structure;activations;comparable architectures;multilinear mapping;network;dimensionality;signi\ufb01cant performance improvements;input;outputs;end;similar performance;tasks;art architectures;substantial space savings;paper;tcls;trls"}, "b09d49c3eacd93782a32ad16ab52f98a21ecc206": {"ta_keywords": "", "pdf_keywords": ""}, "1bf49ef0b33bf8fcc3ebdd16326db419f3af65d8": {"ta_keywords": "soft nearest neighbor loss;outlier data;entanglement;predicted class;independent similarity structures;representations;hidden layers;class manifolds;representation space;training distribution;generalization;neighbors;class;discrimination;different classes;uncertainty;close pairs;data;final layer;estimates;same class;pairs;points;normal number", "pdf_keywords": "representation entanglement;hidden representations;soft nearest neighbor loss;entanglement;nearest neighbors;representation space;class similarity structure;representation spaces;training objective;training data;gans;nearest neighbor search;hidden layers;discriminator;training objectives;dknn;semantics;classi\ufb01er;regularizer;perplexity;model;input domain;distance;original loss;bonus;uncertainty;notion;test input;papernot;paper"}, "3a4f39dbb5e06a5fc55622315797da7a97cc76f6": {"ta_keywords": "recurrent neural networks;global contextual information;level quality estimation;target word;local context information;global context;wmt2018;translation;source sentence;neural network approach;sentence;dimensional convolution layer;feed;words;word;tracks;machine;forward;output;third part;qe;task;part;cmu entry;strong results;predictions;stack;second part;model;paper", "pdf_keywords": "context encoding quality estimation;bidirectional rnns;word embeddings;better sequence prediction;wmt18 word;global contextual information;neural architecture;source words;convolution modules;target word;better encoding;context;more robust predictions;words;salient local feature maps;of\ufb01cial benchmark;word;level qe task;dimensional convolution;temporal dependencies;features;level qe;part;neural network approach;data;target;local patterns;face;additions;ceqe"}, "b9a701c90f3d3df27366f5b29a97f798eb940ac7": {"ta_keywords": "range language models;level language understanding capabilities;chapterbreak;long segment;challenge dataset;narrative;chapter boundary;chapterbreak show;next chapter;range context;lrlms;level model;discourse;same narrative;lrlm;long;negative segments;segment;end;meaningful evaluation;beginning;task;ground;set;numerous architectures;truth;experiments", "pdf_keywords": "range language models;global narrative understanding;narrative shifts;chapterbreak;chapter transitions;level language understanding capabilities;complex chapter transitions;discourselevel understanding;next chapter;chapter boundary;narrative;form narratives;long input sequences;long segment;challenge dataset;discourse;long;lrlms;same narrative;lrlm;shifts;view;suf\ufb01x identi\ufb01cation dataset;dataset;documents;beginning;events;meaningful evaluation;pointof;archive"}, "2559417f8a3d6ab922cfa824b43f9f0c642a1dae": {"ta_keywords": "entity recognition systems;entity recognition;entity extraction;external dictionaries;external dictionary;sequential word classification;entity name;dictionaries;other useful entity;entities;useful similarity measures;performance ner methods;entire candidate names;performance similarity functions;ner;similarity;art ner systems;ner problem;information;data integration methods;level features;words;direct use;natural formulation;systems;formalism;performance;addition;state;natural way", "pdf_keywords": ""}, "3ad3ba8d7fc793a19dfe6a87e32453449195c074": {"ta_keywords": "text autoencoders;autoencoders;end speech recognition;automatic speech recognition;encoder decoder;encoders;librispeech corpus;large speech;end asr;decoders;asr performance;corpus;training datasets;asr;speech;art asr;tts models;tts training;word error rate;character error rate;text;datasets;tts;features;model;reductions;large unpaired subset;state;subset;experimental result", "pdf_keywords": ""}, "765bdcf27ebc1eb03a14f1e47aefa4dda1e03073": {"ta_keywords": "break neural machine translation;neural machine translation;noisy texts;end translation systems;invariant word representations;robust training;model robustness;convolutional neural network;vocabulary issues;morphology;models;natural noise;representations;model;noise;art models;character;nmt;structure;humans;trouble;state;approaches;multiple kinds", "pdf_keywords": "robust training;invariant word representations;adversarial examples;invariant word representation;noisy texts;model robustness;cnn;robustness;similar increased robustness;convolutional neural network;representations;ensemble training;natural human errors;machine translation scenario;nmt models;models;language;phonological phenomena;noise;character omissions;character;model;training;natural sources;training time;errors;common sources;structure;different kinds;rich characteristics"}, "1263e36598dd95cc4becf0e18398f832bb5cf337": {"ta_keywords": "adversarial language network;low resource languages;language vector injection;languages;corpora;encoder;attention;lstms;morphological inflection;sparsemax loss;decoder approach;training;base units;transformers;performance;ancillary techniques;hallucination;several applications;good social impact;system;varied components;contribution;primary goals;analysis;paper;approach", "pdf_keywords": ""}, "978582ad754eab481856d62bdc7b0ee5bcf21811": {"ta_keywords": "federated unsupervised clustering;iterative federated clustering algorithm;supervised datasets;cluster information;unlabeled datasets;generative models;cluster;different clusters;training models;uifca;individual datapoints;fedavg algorithm;synthetic data;multiple models;heterogeneous setting;ifca framework;data;clients;ifca;statistical heterogeneity;model;same client;general setting;environment;solution;method;setting;work;issue;effectiveness", "pdf_keywords": ""}, "675098c4611b13920d163a9a9b972da7751460cb": {"ta_keywords": "spoken dialog systems;novel recurrent neural network;spoken language;latent topic models;entire dialog;rnn;language understanding;proposed rnn;unsupervised training methods;neural network;scale corpora;slu networks;tasks;sequences;slu;goal estimation;word;training;essential components;relative error reduction;commands;intention identi\ufb01cation;term characteristics;performance;different time scales;baseline system;architecture;use;low resource conditions;user", "pdf_keywords": ""}, "dd64013273eb4398821bf2fc8f024735466e5a1d": {"ta_keywords": "procedural knowledge;simulated student;intelligent agents;human learning;level intelligence;prior knowledge engineering effort;knowledge;artificial intelligence;education;prior domain knowledge;simstudent;agent;students;previous cognitive science research;novices;plausible simulation;math;experts;understanding;fundamental goals;fundamental goal;example solutions;manual encoding;algorithm;science;humans;essential goal;abilities;different representations;integration", "pdf_keywords": ""}, "1abbe9b6bf3f134ce86e618bba83bf5c94f60f03": {"ta_keywords": "parametric prediction;prediction algorithms;parametric agents;prediction;incentivization procedure;agents;agent;potential voters;algorithm;training data;potential customers;overall prediction error;joint design problem;parameter;known distribution;mechanism design perspective;future demand;principal desires;challenge;election;product;form;people;effort;quality;assumption;winner;instance;paper;control", "pdf_keywords": "optimal joint incentive mechanism;prediction elicitation;elicit heterogeneous agents;parametric agents;private information;prediction;agents;parametric prediction;prediction algorithm;utility;several valuable engineering insights;heterogeneous rational agents;information engineering;di\ufb00erent capabilities;mechanism;mechanisms;prediction error;jianwei huang;cost;best interest;electrical engineering;computer sciences;yuan luo;terms;chinese university;opinions;truthful reports;analysis;hong kong;jean walrand"}, "a2ea2261bd56ae2505750d7571b501d9836175f0": {"ta_keywords": "discriminative training framework;discriminative training;discriminative training methods;automatic speech recognition;complementary models;complementary systems;training data;complementary system;complementary system outputs;mutual information criterion;system combination methods;complementary hypotheses;mutual information;base system ones;multiple systems;base systems;single system;correct labels;labels;parameter update algorithm;objective function;majority voting scheme;lattice;addition;method;methods;requirements;hypotheses;degree;other hand", "pdf_keywords": ""}, "39456ca31a530d85ec182b2676dc94266dada597": {"ta_keywords": "compositional distributional semantics;standard semantic similarity tasks;word vectors;syntactic constructions;tensors;order tensors;mapping words;lowrank approximations;transitive verbs;adjectives;sentences;phrases;longer expressions;rank representations;rank approximations;meanings;representations;machine learning models;rank matrices;matrices;orders;vectors;full matrices;meaning;models;full models;standard gradient;parameters;thesis;magnitude", "pdf_keywords": ""}, "bc8e67d532693818eb33aa8e401260fe2b774a18": {"ta_keywords": "wrapper induction system;complex documents;tabular data;web;application", "pdf_keywords": ""}, "29dc4b10e60ed1e2b84598cc6f2622c786841fdf": {"ta_keywords": "temporal logic specifications;linear temporal logic;motion planning specifications;temporal logic;control barrier functions;mobile robots;complex task specifications;barrier functions;barrier function;quadratic programs;robotic system;specification;control method;reachability;prioritization;safety;control;infeasibility scenarios;controller;feasibility;automatic framework;framework;composition;system;convenient tool;methods;aim;fragment;sequence;article", "pdf_keywords": "temporal logic speci\ufb01cations;linear temporal logic;control barrier functions;mobile robotic systems;control architecture;motion planning speci\ufb01cations;mobile robots;robotic system;barrier functions;barrier function;dynamical systems;controller;control;physical systems;transportation systems;autonomy;scalable tools;framework;speci\ufb01cation;veri\ufb01cation;challenges;applications;area;ieee;mar;research;paper;samuel coogan;fragment;large class"}, "3f0f6c19c6f5d4e4d5066984c5f3e922a2c2ff85": {"ta_keywords": "learned language abstraction;reinforcement learning;reward shaping;sparse rewards;level tasks;sparsereward tasks;ai collaboration;competitive language;reward sparsity;synthetic language;reward;agents;instruction complexities;language instructions;instruction;exploration;level instructions;complex grid world environments;suite;key elements;environments;many episodes;shaping methods;relevance classifier;ella;policies;instructions;environment;several environments;termination classifier", "pdf_keywords": "learned language abstraction;level language task;reward sparsity;intermediate rewards;abstraction;reward;level behaviors;level task;coffee example;exploration;tasks;babyai platform;language;level primitives;coffee machine;language instructions;complex babyai;level instructions;task;instruction complexities;agent;sparse;ella;environments;level constituents;shaping;cup;strict hierarchical decomposition;primitives;suite"}, "81ea04f822a1d5317e5846783900ac424a8f7528": {"ta_keywords": "autism spectrum disorders;linguistic cues;acoustic features;automatic classifiers;prosody;japanese children;voice quality;word categories;pauses;automatic identification;children;characteristic differences;narrative;typical development;significant differences;features;differences;terms;respect;integration;regards;new turns;previous works", "pdf_keywords": ""}, "98fdc7e1e167eb465cdb1c8ee0800db750101155": {"ta_keywords": "statistical voice conversion;speaker spectral variation;spectral conversion metric;many speech samples;observed prosodic changes;spectral conversion;prosodic parameter differences;utterances;utterance;spectral parameter variation;spectral distance;spectral variation;spectral parameters;same speaker;single speaker;evaluation;experimental evaluations;variation;training criteria;prediction;distance;improvement;results;same sentence;vc;measures;method;investigation;paper", "pdf_keywords": ""}, "ae25ca24eb6c2772ef88e2d0315fc428feb8553e": {"ta_keywords": "unsupervised information extraction system;unsupervised information extraction approach;knowledge base;websets;extract sets;categories;new categories;structured information;html tables;entities;certain categories;candidate category names;hearst patterns;meaningful sets;clustering algorithm;web;extended abstract;set;application;form;coverage;method;experiments", "pdf_keywords": ""}, "689ab475e8a0f552bf6e39a2f774d9d20e50b9cb": {"ta_keywords": "embedded systems design project final project report power;snns;cse", "pdf_keywords": ""}, "38a73e6f48d057cb58264f5148f8b05522d0d030": {"ta_keywords": "semantic parsing corpus;dependent semantic parsing;semantic parsing;machineinterpretable meaning representation;natural language;new corpus;annotation;context;corpora;nl;guidelines;task;mr;progress;narrow domains;paper;new set", "pdf_keywords": ""}, "045f90129a8d7148eec4a58770bc4166b51330ca": {"ta_keywords": "parking demand;similar spatial demand;parking;gaussian mixture model;data driven spatio;park;congestion;temporal modeling;pricing policies;spatial autocorrelation;transportation;pricing schemes;demand;data;zones;repeatability;incentives;seattle department;drivers;time;performance;information;attention;understanding;method;work;technique;significant amount;support", "pdf_keywords": ""}, "fd0aa185be4e1f1fe3975779aec179348ec19ea8": {"ta_keywords": "blind computer science conferences;blind conferences;reviewers self;reviewers;visibility;higher visibility;research papers;review process;submissions;surveys;papers;arxiv;debates;icml;paper;ec;report;authors;tier;pros;third;correlation;cons;preprints;dilemma;a\ufb03liations", "pdf_keywords": "blind computer science conferences;blind reviewing;peer review;reviewers;reviewers self;submissions;blind conferences;surveys;tier publication venues;posting preprints online;review process;publication;study quantifying pros;computer science;papers;manuscripts;international conference;study;academic disciplines;debates;machine learning;acm conference;research questions;arxiv;internet;authors;paper;technology;report;search"}, "f837bf72e5b864e1c162e924fed59b778e946e23": {"ta_keywords": "visual guessing games;aware latent embeddings;imagination module;guesser accuracy;imagination;conceptual representations;encoders;objects;guesser;category;attributes;scene;shot scenario;inference time;context;models;questions;target object;object properties;guesswhat;category labels;gold category labels;training;players;art competitors;compguesswhat;regularized auto;effective strategy;module;oracle", "pdf_keywords": "imagination embeddings;aware latent embeddings;conceptual representations;new imagination models;imagination;encoders;object visual properties;category;aware latent;scene;context;category labels;guesser accuracy;object;models;attributes;training;art performance;image crop;art;inference time;model;regularized auto;module;compguesswhat;improvements;use;extensive error analysis;conclusions;state"}, "df4e3aa275b8f81e22a5332ab550805083094dae": {"ta_keywords": "efficient neural machine translation;neural generation;document generation;natural language processing;translation;nmt;text;third workshop;summaries;document;nmt systems;language;structured data;emnlp;tasks;empirical methods;results;annual conference;dgt;findings;participants;assistance;concert;systems", "pdf_keywords": "neural machine translation;translation task;neural generation;textual accuracy;new document generation;translation;nlg;natural language processing;content accuracy;text;summaries;language;tasks;generation;nmt;level generation;document;nmt systems;structured data;findings;results;single testbed;rg;emnlp;third workshop;dgt;empirical methods;nara institute;f1;ef\ufb01cient"}, "e5efd7e2087e58c5a8860398dfcf143aa9dc865e": {"ta_keywords": "weakly supervised sound event detection;event detection task;sound categories;event detection;event classification methods;event localization;supervised label inference;accurate event boundaries;dcase challenge;audio;deep neural network;events;event classes;event;joint acoustic;boundary detection;recognition;training data;acoustic properties;class inference;supervised methodologies;segmentation;unlabeled data;scale weakly;unsupervised methods;additional challenges;accuracy;data;large amounts;advantage", "pdf_keywords": "sound event detection;acoustic event classi\ufb01cation;sound events;complex acoustic scenes;event detection;supervised label inference;deep neural network;event classes;segmentation;semisupervised methods;boundary detection;event;new events;unlabeled data;generative framework;scene;crbm networks;tracking;perceptual attributes;recognition method;section;rbm;statistics;analysis;interplay;sounds;knowledge;machine;conclusion;bottom"}, "0ae93646ad058853eb6424c1dc0ec1559414e5af": {"ta_keywords": "rumour verification models;automatic rumour verification;natural language processing models;rumour unfolds;model predictions;predictive uncertainty;data uncertainty;human fact;uncertainty;estimates;checker;model;model performance;difficult instances;method", "pdf_keywords": "automatic rumour veri\ufb01cation;rumour veri\ufb01cation models;natural language processing models;predictive uncertainty;data uncertainty;model uncertainty;epistemic uncertainty;unsupervised approach;uncertainty estimates;model predictions;uncertainty;human fact;rumour unfolds;supervised method;aleatoric uncertainty estimates;instance rejection;dif\ufb01cult instances;knowledge;estimates;example;instance removal;data;heterogeneous datasets;model;model performance;rumours;world consequences;types;class labels;checker"}, "0c12e4c611b32997f8be5811021ead80395a7e5c": {"ta_keywords": "neural conversation models;speaker;role", "pdf_keywords": ""}, "9af2264799bdc3490e4650e2f5d126762caf420f": {"ta_keywords": "end speech recognition;connectionist temporal classification;attention model;long input sequences;encoder;attention;output sequences;joint ctc;decoder framework;ctc;speech;text;end;length input;end approach;fast convergence;initial training stage;data;target character;alignments;mapping;performance;novel method;history;conditional independence assumptions;poor results;robustness;interest;alignment issue;paper", "pdf_keywords": "end speech recognition;end speech recognition method;attention encoder;attention models;attention model;attention;encoder;auxiliary ctc;decoder baselines;decoder;character error rate;joint ctc;novel end;ctc;end;fast convergence;relative improvements;cer;performance;model;alignment issue;speed;wsj;objective function;above misalignment issues;novel method;advantages;system;conclusions;robustness"}, "9d555ed29496850c4ef8a3facd7dce734c86aae7": {"ta_keywords": "comment completion tool;programmer comments;codecompletion tools;comment typing;statistical language models;language models;programming languages;natural language documents;open source projects;topic models;source files;standard code editors;comments;prediction;code;comment;completion capability;project;models;performance;recent work;background data;task;grams;work;amounts;setting", "pdf_keywords": ""}, "7d9863258ef44ca8a6b87b68be738f7a83ac849a": {"ta_keywords": "end speech recognition;end asr architecture;multichannel speech signal;speech enhancement;automatic speech recognition;such challenging noisy asr tasks;neural beamformer;asr architecture;neural beamforming;end asr objective;asr components;multichannel end;such asr components;asr;single neural network;existing end;end framework;multichannel;end system;array signal processing;end frameworks;sum beamformer;end systems;unified architecture;language models;conventional end;strong background noise;inputs;end;end baseline", "pdf_keywords": ""}, "c6c18ad62f39060e2547a0b683525e83312d0700": {"ta_keywords": "peer review paper assignment;inspired bidding scheme;paper reviews;bidding scheme;incentives;bidding phase;reviewers;favorite papers;reviewer;bid distribution;large academic conferences;paper;demand;private costs;budgets;real conferences;budget;market;assignment;price;extensive simulations;information;analysis;data;goal;best response", "pdf_keywords": "peer review paper assignment;simple alternative bidding mechanism;inspired bidding scheme;paper reviews;bidding process;bidding scheme;bidding requirement;incentives;bids;bidding phases;reviewers;bidders;incentive;reviewer;favorite papers;papers;paper;demand;budgets;private costs;budget;large academic conferences;assignment;market;conferences;price;primary contribution;overall price;pma;analysis"}, "be4d47a61fee83d332ca2f3fe097f19f63863d6c": {"ta_keywords": "node clustering;node clustering performances;social network analysis;modeling networks;undirected graphs;graphs;graph analysis;bioinformatics;network characteristics;art algorithms;spectral families;empirical study;best model;research;paper;family;many applications;active area;state;course;experiments;important operation;significant role", "pdf_keywords": ""}, "554eade16fb6040bbd21a72bacf903245d7458f1": {"ta_keywords": "ai;ai system;human capabilities;machine intelligence;ai research community;human decision making;cognitive theories;causal reasoning;evaluation metrics;similar capabilities;insights;adaptability;causal components;common sense;generalizability;inspiration;vision;new methodologies;better understanding;research direction;premise;level description;several research questions;frameworks;instance;causes;paper;spirit", "pdf_keywords": "ai;human intelligence;human reasoning;other ai systems;ai researchers;human capabilities;cognitive theories;ai research community;machine intelligence;individual agents;kahneman;theories;speci\ufb01c skills;decision making;capabilities;theory;causal source;fundamental research questions;better understanding;self;inspiration;uni\ufb01ed theory;vision;several research questions;new methodologies;signi\ufb01cant advances;special focus;action;general approach;approach"}, "b8f5f3c8816ab389c2f366fd8a45603550ea9667": {"ta_keywords": "automatic biomedical text;biomedical text;text mining;constructing reliable genetic association database;integrative artificial intelligent reader;deep reinforcement learning;genetic association database;biomedical science research;scientific literature;articles;text;pubmed;authentic articles;like mining;current primary task;mining;automatic human;genes;researcher;latest knowledge;directional lstm;knowledge;reliable curation;challenge;results;answers;umls;complex traits;human;human behaviors", "pdf_keywords": ""}, "5e327c2285ddf2a76d08e5c00d16c7358bc5412c": {"ta_keywords": "peer assessment;peer grading;conference peer review;dishonest evaluations;strategyproofness;evaluators;strategic behavior;assignment;competition;submissions;organizations;homeworks;individuals;expertise;employees;own submission;scientific papers;proposal review;own work;paper;variety;individual;compromise;terms;constraint;form;partitioning;work;world applications;different subsets", "pdf_keywords": "strategyproo\ufb01ng peer assessment;peer assessment;peer grading;conference peer review;strategyproof assignment;optimal algorithms;empirical evaluation;assignment;heuristic algorithm;strategyproofness;evaluators;strategic behavior;proposal review;quality guarantees;organizations;steven jecmen carnegie mellon university;homeworks;employees;methods;scienti\ufb01c papers;time algorithms;variety;expertise;price;order;partitioning;terms;compromise;dataset;fundamental problem"}, "f878a7c756b90c0ed612838492fbbc02ecaaab70": {"ta_keywords": "learning agent;automatic tutors;cognitive skills;human students;interleaved problem orders;interleaved problem order;effective learning;next problem type;interleaved problem order yields;problem order;problem orders;student;simulation study;computational model;examination;problem order question;agent;different math;skill benefits;interleaved order;simstudent;examples;problems;fraction addition;addition;error detection;problem;machine;order;effective performance", "pdf_keywords": ""}, "1ee276db29ba9127e81d9a7d9cb08f5138339412": {"ta_keywords": "scale distributed matrix multiplication;matrix multiplication scheme;parallel computing;redundant computing;dimensional product codes;optimal compute time;computing;matrix;scale computation;optimal computation;straggler;computation;stragglers;combat stragglers;encoding;crippling bottleneck;proofing massive;communication costs;machine learning tasks;system performance;massive scale;limitation;challenge;scheme;critical challenge;order;judicious introduction;theory;attractive paradigm;procedures", "pdf_keywords": ""}, "34cb1f081c1d1d6b3dc16a9278940a9ee85fb2e0": {"ta_keywords": "simultaneous interpreter performance;interpreter performance;machine translation output;interpreter confidence;quality estimation;translation;interpretation strategy;language pairs;prediction accuracy;qe pipeline;evaluation measures;interpretation interfaces;meteor evaluation metric;simultaneous interpretation;pedagogical tools;spoken word;qe;task;computer;adequacy;novel features;message;number;experiments;methodology;potential applications;time;methods;settings", "pdf_keywords": "machine translation output;simultaneous interpreter performance;interpreter performance;machine translation;interpreter output;interpreters;interpretation strategy;qe pipeline;language pairs;evaluation measures;simultaneous interpretation;quality estimation;qe;meteor evaluation metric;outputs;source sentence;prediction;attentional burdens;conclusion;quality;task;dif\ufb01cult task;mt;si;assistance;novel features;effective application;work;cai systems;experiments"}, "839cbcf5c13d5875e952e40ec2da14b19eee2202": {"ta_keywords": "unconditional optimization problems;smooth convex optimization problems;accelerated directional search;accelerated descent method;conditional optimization problems;accelerated gradient;full gradient;free methods;gradient;free method;prox;norm;nesterov;random direction;advance;numerical solution;structure;convergence;such problems;further work;distance;rate;method;non;approach;estimates;solution;starting point;difficulties;problem", "pdf_keywords": "stochastic nonsmooth convex optimization problems;point methods"}, "ebcb425ed1a51e8f1a6eca422882abd454fe04f2": {"ta_keywords": "assist esl learners;english vocabulary;rich lexical information;second language learners;target words;collocations;link grammar;word definitions;grammar patterns;encyclopedic information;terms;evaluation;information;addition;method;system;set;good performance", "pdf_keywords": "vocabulary learning system;vocabulary learning;esl learners;target vocabulary;vocabulary list;vocabulary;voa learning english1;learners;second language;language skills;linggle booster;encyclopedic information;rewarding learning experiences;engaging content;computer science national tsing hua university;link grammar;content;corpora;ting tsai2;l2;kai;web pages;wen tuan2;deep knowledge;applications national tsing hua university;chingyu;2institute;engaging system;ching;ming chiao tsai1"}, "4bff8862ba7956fdc2288e8399fb187b9595982b": {"ta_keywords": "biocreative ii gene mention recognition;gene mention task;gene name mentions;genome biology;substrings;biocreative ii workshop;s2;brief descriptions;article s2 smith et al;sentences;results;lowest scoring submissions;submissions;digital academic repository;best result;overview;uva;task participants;statistical analysis;teams;systems;suppl;september;article;use;electronic version;volume;methods;dare", "pdf_keywords": ""}, "d8aeb318f68f4635b34c72aa1a0369fadcd79450": {"ta_keywords": "cbs topic model;derive user topic distribution;topic model;model associates topicspecific sentiments;user communities;twitter datasets;topics;probabilistic graphical model;emotional topics;user community;mining user;cbs model;sentiments;community;networks;content;cbs;representative behaviors;behaviors;art models;paper;experiments;addition;rest;other state", "pdf_keywords": ""}, "8442f9fd620ea34e1de3128b9388bddd1263f29b": {"ta_keywords": "conic optimization;integral projected gradient method;conic constraints;minimization;dual optimality conditions;convex quadratic function;dual infeasibility;gradient method;infeasibility;order method;proportional;expipg;iterates;set;proof", "pdf_keywords": "conic optimization;integral projected gradient method;conic constraints;di\ufb00erentiable convex objective function;minimization;constraint violation;gradient method;order method;computational engineering;aeronautics;dual gap;iterations;astronautics;washington;dec;austin;math;oc;oden institute;abstract;texas;wa;rate;seattle;tx;ufuk topcu;university;pipg;yue yu;number"}, "ee24fb876e6f1b345d492101c499bc5dd6b8196b": {"ta_keywords": "probabilistic eeg signal enhancement method;eeg signal enhancement;blind eeg signal separation method;observed eeg signals;eeg signals;electroencephalogram;channel wiener filter;target eeg component;eeg;brain machine interfaces;brain activities;probabilistic generative model;spatial correlation matrices;spatial correlation;erps;prior information;potentials;various artifacts;analysis;features;event;performance;previous work;example;interest;several attempts;paper", "pdf_keywords": ""}, "ce0fce520c639af010c71cc6adf57cdeb2790322": {"ta_keywords": "probabilistic black box optimization techniques;black box optimization;automatic speech recognition;speech recognition performance;vocabulary speech recognition experiments;bayesian optimization;covariance mean adaptation evolution strategy;neural networks;asr system;word accuracy;gaussian process;input;gaussians;asr;cma;parameters;systems;performance;experts;output;function;hmms;neurons;layers;multiple techniques;state;states;numbers;es;many types", "pdf_keywords": ""}, "516a0faeab9ec3a68bc6e7ec13a2df235a27ab52": {"ta_keywords": "cnn model;other traditional deep network models;unstructured clinical data;convolutional neural network model;clinical data;complex medical meaningful features;unstructured clinical notes;electronic health records;semantic features;intensive care units;clinical notes;strong baseline models;automatic diagnostic system;unstructured textual input;primary discharge diagnosis;diagnosis decision making;decision tool;frequent disease classes;clinical setting;patients;textual admission information;model;available dataset;f1 score;clinicians;f1 score values;prediction power;fewer layers;decision support;beth israel deaconess medical center", "pdf_keywords": "unstructured clinical data;clinical data;diagnosis prediction;unstructured clinical notes;electronic health records;convolutional neural network model;intensive care units;automatic diagnostic system;convolutional neural networks;complex medical meaningful features;convolutional neural network;textual admission information;clinical notes;medical diagnosis;semantic features;cnn model;primary discharge diagnosis;other traditional deep network models;unstructured textual input;diagnosis decision making;patients;admission notes;admission information;pittsburgh medical center;clinicians;frequent disease classes;decision tool;text classi\ufb01cation;available dataset consistsing;psychiatry"}, "d3793ae5b3b31f72605978b749e41811e6dcacd4": {"ta_keywords": "inverse reinforcement learning;contextual bandit orchestrator;contextual bandit;reinforcement learning;environment reward;constrained policy;reward;agents;agent;constraints;implicit constraints;actions;such constraints;policies;demonstrations;orchestrator;constraint;unspecified constraints;pac;algorithms;observed behavior;behavior;environment;task;novel approach;best actions;societies;ethical principles;laws;novel ways", "pdf_keywords": "inverse reinforcement learning;reinforcement learning;contextual bandit;environment reward;behavioral constraints;reward;agent;other agents;demonstrations;actions;policies;policy;constraints;unspeci\ufb01ed constraints;environment;such constraints;constraint;rl;pac;direct interaction;algorithms;task;irl;world;orchestrator;novel approach;humans;complex ways;functions;approach"}, "405c0d9b7cf5482d2e1197167f690e7b7801b9bd": {"ta_keywords": "hop question answering;question generation;training data;qa system;hotpotqa dataset;heterogeneous data sources;unsupervised framework;learning performance;questions;qg;data source;mqa;multiple information;data;hybridqa;human;answer pairs;first selecting;relevant information;demand;possibility", "pdf_keywords": "fewshot learning setting;training data;like questions;shot learning settings;qa system;heterogeneous data sources;unsupervised framework;qg;multiple information;data source;input source;data;steps;generation;answer pairs;human;mqa;different information;multihop question;model;relevant information;general framework;demand;experiments;question;set;model \ufb01rst;possibility;basic operators"}, "7bf2620188c0a66e1d0e779083cf61960a2f3e2f": {"ta_keywords": "synthesis system;synthesis quality;combinational logic;timing constraints;synthesis;multilevel logic;design time;logic;optimization;automation;chip;functional correctness;technology;circuitry;circuit;socrates;significant improvements;area;paper;terms;user;savings;account", "pdf_keywords": ""}, "d04c91bbb043666ebd6dae51995ee5bbc4291ddf": {"ta_keywords": "double man", "pdf_keywords": ""}, "b209f2acbf0fbc62a3fd19ad6c13abbd46547736": {"ta_keywords": "microsoft speaker diarization system;voxceleb speaker recognition challenge;continuous speech separation;diarization output voting error reduction;speaker;voxsrc;diarization track;system fusion;extractor;res2net;conformer;leakage filtering;components;system design;dover;wild;method;issues;paper;details", "pdf_keywords": "microsoft speaker diarization system;voxceleb speaker recognition challenge;continuous speech separation;diarization output voting error reduction;voxsrc challenge;speaker overlap problem;diarization error rate;speaker;diarization system;diarization track;voxsrc;extractor;best system;system fusion;youtube;microsoft;conformer network;res2net;systems;conformer;components;evaluation set;challenge;eess;leakage \ufb01ltering;yu wu;jinyu li;css system;modi\ufb01ed dover;gang liu"}, "9e3e6ddf958c2005f7041cc9dd5fe050a0dbd02e": {"ta_keywords": "multiscale wavelet transform;wavelet transform;signal correspondence method;wavelet transform domain;multiple resolution analysis;signal correspondence process;transform signal corresponds;similar signals;signals;crossing points;correspondence;original signal;crossing point;plausible correspondence;scales;eye observation;image;lines;cost function;algorithm;order derivative;weight coefficient;edge;quality;viewpoint;accuracy;method;mwt;points;derivative property", "pdf_keywords": ""}, "4ec1d3407a5136c525b53f703c803571200902a4": {"ta_keywords": "\u4e00\u822c", "pdf_keywords": ""}, "f2818da69bb72526fff9d601677db38f24a62ecc": {"ta_keywords": "user satisfaction prediction;satisfaction prediction methods;dialogue modeling;dialog example databases;user satisfaction;user satisfaction score;response utterances;dialog;dialogue quality;response selection methods;multiple response candidates;user adaptive;best system response;user feedback;response pairs;system response;system responses;user query;system response pairs;user preference;ebdm framework;prediction;ebdm;example database;evaluation;conventional ebdm;query;user;systems;example", "pdf_keywords": ""}, "febb305a854d02b138250a8a19af956ffa0ada4f": {"ta_keywords": "linear quadratic games;unique global nash equilibrium;policy gradient;nash equilibrium;classic reinforcement learning setting;reinforcement learning problems;nash equilibria;gradient dynamics;gradient algorithms;action spaces;such games;games;ricatti equations;continuous action;state space;gradient;play;local convergence;policy;guarantees;only critical point;popular approaches;convergence;guarantee;conditions;sufficient conditions;existence;sum;state;counterexample", "pdf_keywords": ""}, "f21a9d70319ca99227300349d7bcab5dee5869cd": {"ta_keywords": "real incomplete multilingual corpora;incomplete multilingual corpus;incomplete multilingual corpora;incomplete corpora;many multilingual corpora;source translations;higher translation accuracies;translations;subtitles;source nmt;most english talks;nmt experts;nmt;languages;missing data;nmt systems;relevant languages;ted talks;tokens;ted;bleu;example;mixture;training time;small portion;study;special symbol;test time;practice;approaches", "pdf_keywords": "incomplete multilingual corpus;incomplete multilingual corpora;actual incomplete multilingual corpora show;multisource nmt;nmt experts;source nmt;source translations;available translations;target languages;input sentences;french;sentences;null;training;study;source;results;data;task;performance;mixture;special symbol;simple modi\ufb01cation;simple implementation;comparison;test time;approaches;experimental results;use;conclusion"}, "b168fc72fa39e9669567bd099bab179549a15e14": {"ta_keywords": "a\u03b22gp1 iga;a\u03b22gpi iga;a\u03b22gpi;thrombosis;antibodies;thrombotic risk;iga acl;acl iga;igm acl;aps;iga;conventional igg;sle patients;diagnosis;clinical value;clinical contexts;house elisa;sle;last international guidelines;patients;significant association;routine detection;conclusion;target domains;determination;contribution;evaluation;retrospective analysis;study;identification", "pdf_keywords": ""}, "de43afd166a79c24b3a7dd16c5695059d9f0aa71": {"ta_keywords": "cognitive development;infancy;cognitive learning;physical analogy;physical analogies;concepts;child;children;transitivity;abstract concept;adulthood;age;train system;piaget;theory;abstract ones;years;better insight;timescale;general overview;many arguments;group", "pdf_keywords": ""}, "ab94fae3d49cd7016a47020469dc257d8090f5bb": {"ta_keywords": "challenging speech separation;speaker separation;deep clustering;deep learning architecture;better regularization;deeper architecture;signal fidelity;end signal approximation objective;new signal approximation objective;enhancement layer;sdr improvement;embeddings;overall improvement;baseline system performance;sdr;end training;signal estimates;baseline;distortion ratio;baseline system;enhancement stages;word error rate;performance;unprecedented performance;larger temporal context;model;end;signal;basis;wer", "pdf_keywords": "challenging speech separation;speaker separation;speech recognition error rates;deep clustering framework;automatic speech recognition;signal reconstruction quality;signal quality metrics;end signal approximation objective;better regularization;deeper architecture;sdr improvement;signal estimates;enhancement layer;baseline system performance;end training;overall improvement;sdr;baseline system;baseline;enhancement stages;signi\ufb01cant improvements;distortion ratio;signal;performance;larger temporal context;model;end;signal \ufb01delity;conclusion;results"}, "6c477a65f0922d405c3665e31581eaa0f269116e": {"ta_keywords": "wordnet;word representations;relational semantics;knowledge base completion;analogy tests;relational objective;distributional objective;multipliers;raw text;alternating direction method;admm;objectives;improvements;preliminary results;hypothesis;end;cases;show", "pdf_keywords": "distributional semantics objective;distributional semantics;neural language model;wordnet;distributional objective;joint objective optimization;relational objective;joint objective;relational objectives;nlm;vector representations;words;above objectives;alternating direction method;multipliers;algorithms;admm formulation;admm;timization;raw text;several tasks;collobert et al;end;introduction;present preliminary results"}, "10085f7fb0871329d34529cc54df0a8f75756fce": {"ta_keywords": "automatic speech recognition;automatic transcription system;asr accuracy;asr system;verbatim transcripts;language models;style training texts;meeting minutes;asr;japanese national congress;sst;minutes;reference texts;training;labels;models;style transformation;performance;documents;lsv;systems;framework;approaches;estimation method;update;efforts", "pdf_keywords": ""}, "248824ec5d9b4ddf0c36cdc51b6b57af6e881328": {"ta_keywords": "good transfer languages;transfer languages;different nlp tasks;optimal transfer languages;representative nlp tasks;resource transfer language;natural language processing;nlp;resource languages;resource task language;selection;ranking problem;aforementioned features;features;hoc baselines;cross;single features;prediction;task;accuracy;invaluable tool;performance;models;future ad;paper;model;insights;use;method;isolation", "pdf_keywords": "different nlp tasks;nlp tasks;representative nlp tasks;better transfer languages;speech tagging;good transfer languages;machine translation;natural language processing;dependency parsing;promising transfer languages;nlp;entity linking;task language;attentional graph;tagging;resource languages;single language;language;languages;entity;training data;task;dependency;speech;hoc baselines;dataset features;features;deep biaf\ufb01ne;part;models"}, "70170035ef870df1c064cc52804178a52f6a69ef": {"ta_keywords": "incremental learning;question answering;text", "pdf_keywords": ""}, "75c4aefc55bf0b345587740cad0a4e994f29962a": {"ta_keywords": "polyphonic sound event detection;sound event activity;sound activity detection;sound events;sound event;sequence detection;hidden markov model;frame detection method;term memory;dependent temporal structures;temporal structure modeling technique;neural network;rnn;event;frame methods;sequence;segments;thresholding;segment;blstm;dcase;frame;task;binary mask post;challenge;evaluation;network;new hybrid approach;score;noisy conditions", "pdf_keywords": ""}, "cc19de8d0782917098029ed20261cbe0b0c62bf5": {"ta_keywords": "bias;societal biases;biases;peer reviews;review text;blind reviewing policy;review ratings;subgroup membership indicators;systematic disparities;hiding policy change;compelling evidence;reputed machine;employment rates;wages;recommendation letters;evidence;identification strategy;population subgroups;different subgroups;text;observations;ground truth;members;identity;visibility;time periods;work;conference;access;novel framework", "pdf_keywords": "peer reviews;blind reviewing policy;blind reviewing;review text;review ratings;bias;biases;subgroup membership indicators;reputed machine;nonparametric estimation;hiding policy change;learning representations;evidence;ground truth;international conference;text;secondary data;visibility;observations;conference;inference procedure;iclr;dataset;identi\ufb01cation strategy;identity;access;novel framework;work;time periods;framework"}, "8484fdb56e4690927dc0191ede11c2d24bc5e2ef": {"ta_keywords": "modern text generation models;text generation model;text generation;generation tasks;neural text;distributional evaluation metrics;learnt distribution;information divergences;human text;divergence frontiers;text;human judgments;extensive empirical study;space;distribution;comparison measure;human;mauve;model size;gap;fewer restrictions;known properties", "pdf_keywords": "text generation model;text generation;human text;language model;distributional evaluation metrics;discrimination accuracy;learnt distribution;text;lower discrimination accuracy;discriminators;text length;generation;bert;human;binary classi\ufb01er;test accuracy;machine;mauve;installable python package;divergence;comparison measure;distribution;source;results;fewer restrictions;divergence frontiers;strong correlation;variety;basics;model size"}, "aff5d7f43823e06bb68220db41de3bc82e2f3990": {"ta_keywords": "tier cellular networks;tier poisson network model;small cell networks;stochastic poisson process;frequent handoff;average downlink data rate;handoff outage periods;tier network structure;throughput maximization;average throughput;frequent data outage;poisson line process;high mobility;independent poisson process;mobile users;handoff;mobile;stochastic geometry;average data rates;data rate;micro base stations;static users;larger cells;same base station;different transmit powers;constant speed;static;mean total number;typical static;mus", "pdf_keywords": ""}, "45cdf5e239a1f0057c350f6654ccd348fb4e2332": {"ta_keywords": "uncertain linear preferences;stable matching;sided stable matching setting;linear preferences;weak preference order;lottery model;compact indifference model;matching;preference profiles;uncertainty;stability probability;lottery;joint probability model;preferences;highest probability;probability distribution;models;computational complexity;agents;communication;agent;weak order;limited information;linear order", "pdf_keywords": "stable matchings;stable matching;stable marriage problem;matching;weak preference order;independent uncertainty models;preference lists;independent uncertainty model;lottery model;linear preferences;preference pro\ufb01les;uncertainty;joint probability model;stability probability;lottery;highest probability;dominance relation;models;polynomial time;compact indi\ufb00erence model;useful characterization;computational complexity;probability distribution;agents;weak order;notion;agent;goal;speci\ufb01ed;linear order"}, "4731f89169604cd0d8b5352380baa1b4728bca0b": {"ta_keywords": "machine translation error analysis;machine translation;discriminative language models;focused mt error analysis;correct translations;error analysis;effective error analysis;erroneous word strings;error trends;word strings;lms;correct sentences;mt;tool;detailed analysis;systems;overall efficiency;previous work;use;paper;frequency;new method", "pdf_keywords": ""}, "601408d6617bf72894c9f41ae54cf9c17905903a": {"ta_keywords": "string machine translation system;other machine translation;accurate translation;hierarchical phrase;t2s systems;accurate tree;t2s;previous reports t2s systems;tree;translation;performance gap;alignment;search;systems;string;accuracy;phrase;construction;results;mt;much promise;peripheral elements;elements;promise;reason;methods;paper;number", "pdf_keywords": ""}, "3dc20be709818630e2249ab28b35b0666b4b544d": {"ta_keywords": "paralinguistic information;english bilingual corpora;conventional speech;utterance;speech;languages;input speech;translation;emphasis;s2s;information;sentence;focus;content;various types;systems;analysis;type;limitation;paper;step", "pdf_keywords": ""}, "ead6323f137c2f99ef0ffcfa34fa6eb1c6eca3c6": {"ta_keywords": "unsegmented multispeaker speech recognition scenario;6th chime speech separation;multispeaker speech recognition;speech recognition modules;speaker diarization;5th chime challenges;unsegmented recordings;speech enhancement;recognition challenge;new challenge;recognition;first challenge activity;track;everyday home environments;reproducible open source baselines;baseline description;community;paper;complete set;problem;success", "pdf_keywords": "unsegmented multispeaker speech recognition scenario;multispeaker speech recognition;speech recognition modules;6th chime speech separation;challenge tracks;speaker diarization;unsegmented recordings;5th chime challenges;speech enhancement;8linguistic data consortium;recognition challenge;\ufb01rst challenge activity;track;5christoph boeddeker;reproducible open source baselines;1shinji watanabe;7naoyuki kanda;1sanjeev khudanpur;6yusuke fujita;7takuya yoshioka;baseline description;ben yair;1vimal manohar;1xuankai chang;1aswin shanmugam subramanian;3university;2michael mandel;6hitachi;trmal;2the city university"}, "af5c4b80fbf847f69a202ba5a780a3dd18c1a027": {"ta_keywords": "commonsense inference;natural language inference;commonsense reasoning;aggressive adversarial filtering;adversarial filtering;stylistic classifiers;human biases;potential counterfactuals;art language models;inference problems;annotation artifacts;situations;challenges;datasets;ensemble;high accuracy;new dataset;partial description;diverse set;car;engine;empirical results;task;humans;hood;af;data;multiple choice questions;situation;swag", "pdf_keywords": "aggressive adversarial \ufb01ltering;nli models;adversarial filtering;commonsense inference;art nli models;human biases;theart language models;potential counterfactuals;stylistic classi\ufb01ers;annotation artifacts;ensemble;dataset;datasets;new dataset;diverse set;challenges;situations;new challenge;swag;af;humans;current state;data;results;state;ofthe;rich spectrum;multiple choice questions;novel procedure"}, "d15eb5744474cec2d0634651bb30000b3873a309": {"ta_keywords": "time expression normalization;automatic rule generation;time expressions;normalization rules;normalization;grammars;sota normalization methods;annotated data;corpora;social media texts;artime;rules;recognition;possible operation sequences;temporal value;operations;data;sequence;experts;significant progress;performance;recent years;common surface forms;paper;expert interventions;novel method;research", "pdf_keywords": "time expression normalization;tweets benchmark;time expression recognition systems;automatic rule generation;normalization rules;normalization;time expressions;rule methods;annotated data;sota methods;artime;recognition;novel software technology;wtding;candidate rules;temporal value;jinmao li;possible operation sequences;end results;operations;basic operations;expert;data;operation sequence;competitive results;jh_chen;abstract;sequence;expert interventions;jianhao chen"}, "3b563c16e9a918631d63a20027dad735b625625a": {"ta_keywords": "text generation tasks;text generation;source toolkit;neural machine translation;toolkits;toolkit;texar;extensible toolbox;modularized;arbitrary model architectures;reusable modules;diverse tasks;versatile;library;components;various algorithmic paradigms;extensibility;specific applications;broad set;system design;common patterns;functionalities;methodologies", "pdf_keywords": "purpose text generation toolkit;text generation tasks;text generation applications;text generation;machine translation;purpose toolkit;extensible toolkit;natural language;source toolkits;source toolkit;texar;dialog;summarization;tensorflow;pytorch;modularized;content manipulation;models;arbitrary model architectures;diverse tasks;machine learning;library;algorithmic paradigms;reusable modules;versatile;abstract;inputs;modularity;paper;bowen tan"}, "a8372f7cb2e482a455b06c3e47f65aec5c7a924b": {"ta_keywords": "future em pump design;annular linear induction pump;pump efficiency;low pump efficiency;bismuth target circuit;pilot molten lead;mw accelerator;bismuth;beam power;liquid alloy;circulation loop;low efficiency;circulation;commercial cfd code;nevada;em body force;numerical study;lbe;ads;las vegas;femlab;operational parameters;alip;experimental measurements;system parameters;unlv;system;algorithms;university;insight", "pdf_keywords": ""}, "0c07cc7ba1b862556f5cfee0d5d849866d21a693": {"ta_keywords": "oblivious update process;oblivious updates;stale node access;storage networks;update algorithm;entire stale data;nodes access;storage code;stale node;mds code construction;nodes;node;linear encoding;communication;communication requirements;capacity;data symbols;contents;data;side information;fundamental limits;knowledge;set;amount;weak conditions;value;results;terms;settings;setting", "pdf_keywords": "oblivious update process;storage networks;storage nodes;oblivious updates;stale node needs;oblivious update;storage code;storage systems;replication;stale node;update algorithm;mds code construction;linear encoding;message symbols;single message symbol;communication;code;data;of\ufb02ine;paper;amount;fundamental limits;abstract;california;preetum nakkiran;special case;eecs;berkeley;section iii;\ufb01nite \ufb01eld"}, "9650dbe79d34498113371770dcdb48f1bd7c9711": {"ta_keywords": "topic map;information retrieval;term extraction;term similarity;heatmaps;phrase similarity;visual exploration;natural language processing techniques;maps;research topics;research papers;map;paper titles;base map;heatmap overlays;papers;particular conference;words;titles;word;journal;phrases;conference;computer science;cities;specific journal;dblp database;practical approach;profile;example", "pdf_keywords": "topic map;functional visualization system;interactive visualization system;information retrieval;bibliographic data;functional visualization system mocs;term extraction;natural language processing;several possible explorative visualization uses;natural language processing techniques;term similarity;map representations;maps;geographic map metaphor;large relational data set;base maps;arbitrary basemaps;research papers;spatialization;computer science;heatmap overlays;database;journals;dblp bibliography server;conferences;modi\ufb01cations;papers;conference;novel aspects;particular journal"}, "889c3b4394826639d483c039467cd9a05e68e73c": {"ta_keywords": "human composers;ancestral sampling;partial musical scores;music;composition;better samples;sample quality;machine learning models;motifs;gibbs;gibbs procedure;chronological process;convolutional neural network;likelihood;beginning;conditional distributions;nonlinear fashion;process;human evaluation;cheap approximate;piece;analogue;yao et al;log;task;order;choices;single pass;use;contrary", "pdf_keywords": "musical counterpoint;musical scores;deep convolutional model;coconet;generative model;piano rolls;music;partial scores;convolutional approach;gibbs sampling;composition;ancestral sampling;better samples;machine learning models;markov chain monte carlo method;machine;by convolution;beginning;model;adam roberts google brain;gibbs procedure;orderless nade;single pass;chronological process;piece;joint probability distribution;task;human evaluation;conditional distributions;techniques"}, "68af273e04906e0450a5d01d5606c8313da01453": {"ta_keywords": "optimal sensor subset selection;sensor subset selection;sensor selection problem;gibbs sampling;optimal sensing;large sensor network;large scale sensor networks necessitates;practical sensor networks;stochastic approximation;sensors;possible sensors;data estimation;estimation;fusion center;subset;algorithms;estimation error;gibbs;joint statistics;new algorithm;underlying statistics;respective optimal solutions;constrained version;iterative;true underlying distribution;set;binatorial;energy;efficient use;conjunction", "pdf_keywords": "optimal sensing;large sensor network;ef\ufb01cient data estimation;large scale sensor networks necessitates;stochastic approximation;data estimation;sensor selection problem;active sensing;estimation;active sensors;estimation error;expectation maximization;possible sensors;unconstrained optimization;gibbs;energy ef\ufb01cient use;algorithms;novel algorithm;new algorithm;algorithm;fusion center;constrained version;convergence speed;above unconstrained problem;arpan chattopadhyay;convergence;context;subset;mean number;urbashi mitra"}, "04f8f739924a19c01d196a48783b914554ac0fe5": {"ta_keywords": "composite convex optimization;convex optimization;domain newton methods;continuous hessian;conditional gradient method;convex functions;order algorithms;lower approximation;order generalization;functional residual;algorithms;order models;affine;lipschitz;region scheme;convergence;contracting;global rate;objective;iteration counter;order;trust;smooth component;problem domain;variant;approach;paper;assumption;interpretation", "pdf_keywords": "composite convex optimization;convex optimization;contractingdomain newton method;domain newton methods;domain newton method;empirical risk minimization problem;order optimization algorithm;conditional gradient method;newton method;order algorithms;algorithms;order models;order generalization;algorithm;stochastic extension;contracting;present computational results;method;region scheme;nikita;trust;louvain;model;catholic university;variant;neuve;la;approach;paper;section"}, "86ae1161026f23f9df691a867fd7453cee56fd28": {"ta_keywords": "semantic change;lexical cognate models;lexical phylogenetic inference;language change;phylogenies;lexicon;word embeddings;change;evolutionary approach;variation;recent approaches;meaning classes;meaning;nyungan;time;illustrations;pama;importance;issues", "pdf_keywords": "semantic change;semantic shifts;lexical stability;lexical replacement;semantic stability;language change;language splits;meaning change;cognate evolution;lexicon;phylogenies;phylogeny;evolutionary approaches;categories;change;meaning;variation;recent approaches;such models;theoretical models;modeling;abstract;data;explicit ways;ct;new haven;conclusion;paper;case studies;key"}, "5b8eaaf660b9e2d6a19886991350fffa1320b372": {"ta_keywords": "entities;local classifiers;sentences;ilp inference;relations;inference;several different approaches;ilp;training;others;integer linear programming;study;evaluates;different strategies;ibt;experiments;particular problem", "pdf_keywords": ""}, "781e0e81834119c135091c8bdfcd1966c10b09ab": {"ta_keywords": "integer compression schemes;text retrieval conference;text collections;simd instruction;simd galloping algorithm;common processors;decompression speed;conjunctive queries;modern cpus;simd instructions;posting lists;simd;integers;subsequent processing;speed;trec;multiple data;pairs;logs;intersection;clueweb09;gov2;techniques;fact;instructions;effort", "pdf_keywords": "bit simd vectors;simd instructions;bit scan reverse;conjunctive queries;trec text collections;query track;assembly instruction bsr;modern cpus;logs;compression trade;trec;log2;various speed;speed;gov2;integer;clueweb09;purpose;variations;techniques;state;common one;boytsov;offs;lemire;art approach"}, "65f632cbac465633a13b1e3f8c8c410c2f3aec3d": {"ta_keywords": "stackelberg game;simple competitive robotics environment;total policy gradient;emergent behaviors;competitive games;agents;novel game;interactive manipulation tasks;stackelberg maddpg;robust control;robotics community;game environment;hierarchical interaction structure;player marl problem;game;better policy;information advantage;information asymmetry;advantage;player;low quality equilibrium;leader;maddpg;maddpg updates;follower;local best response;marl;theoretic marl algorithm;environment;turn", "pdf_keywords": ""}, "76862a851bd2c17dcf6bfc2cecbf4af186730123": {"ta_keywords": "grayscale document images;grayscale document image;nontext objects;otsu thresholding method;halftone images;maxtree structure;maxtree;line drawings;image;graphs;connected operators;paper;structure;objects;tables;unconventional method;later stage;non;solution;simplification;use", "pdf_keywords": ""}, "1a20d6c6891f3a0462515ff9560bc37e66eb422a": {"ta_keywords": "fruct conference;itmo university;conferences;conference;petersburg state university;ict;ismw;social media;petersburg;international school;universities;web search;regional leaders;artificial intelligence;cooperation;strong scientific schools;natural language;beautiful city;events;information extraction;globe;ainl;saint;long history;first time;strong traditions;ground", "pdf_keywords": ""}, "68258e0541132027ef86f872b92406de1c6edab3": {"ta_keywords": "millimeter wave d2d communication;explore relays;transmission;dynamic obstacles;presence", "pdf_keywords": ""}, "b1d309073623d46548e55269fb73485a3b7f11a8": {"ta_keywords": "pretrained language model embryology;totipotent language model;more pretrain steps;language model;linguistic knowledge;different learning speeds;developmental process;speech;embryology;knowledge;world knowledge;downstream tasks;birth;comprehensive knowledge;model;tokens;albert;different parts;performance;findings;pos;results;parameters;set;proceeds", "pdf_keywords": "pretrained language model embryology;language models;language model;totipotent1 language model;more pretrain steps;learning speeds;different learning speeds;linguistic knowledge;developmental process;embryology;speech;world knowledge evolve;good downstream task performances;downstream tasks;knowledge;models;world knowledge;birth;behaviors;model;comprehensive knowledge;development;cheng;information;han chiang national taiwan university;lms;performance;different parts;feng huang;yi lee"}, "0110abf15bf0ee1bdf28061ad05f85b1c9f6e1c3": {"ta_keywords": "structured information sources;knowledge integration;overall similarity score;similarity measures;knowledge integration problem;similarity;databases;answer substutitions;datalog;common object identiiers;relations;documents;predicate;information;ordinary text;query;text;abstract;web;extension;type;list;new type;whirl;passages;paper;keys;end user;veneer;observation", "pdf_keywords": ""}, "a3da7028a1b721e392c421c2f15096abb1a71afb": {"ta_keywords": "atherosclerotic plaque vulnerability;intravascular optical coherence tomography;percutaneous coronary intervention;greater lipid index;higher macrophage index;elevated hba1c;underwent elective percutaneous coronary intervention;hba1c levels;density lipoprotein cholesterol;hemoglobin a1c;lipid profiles;macrophage index;culprit vessels;total cholesterol;minimal fibrous cap thickness;lipid;oct assessment;hba1c;thinner minimal fct;macrophage;oct examination;elective pci;pci;elevation;minimal fct;multivariable linear regression analyses;fct;assessment;conclusion;calcium", "pdf_keywords": ""}, "3ed07f6643856b9ac4687b3bc667767f3ab4b563": {"ta_keywords": "voice quality control method;voice quality control;better voice quality control;converted voice quality;multiple voice quality expression words;voice quality expression words;gaussian mixture model;quality expression words;perceptual score assignment;acoustic features;perceptual scores;gmm;selection;performance;accuracy;regression;mr;correspondence;report;method;independency;experimental results", "pdf_keywords": ""}, "ecde7c041e9ac48bccef7a8d078a3f80239b0479": {"ta_keywords": "video objects dataset;object detection;context frames;videos;frames;consecutive frames;target frames;video;youtube;temporal context;recurrent neural network;target frame;strongest image;convolutional neural network;strong supervision;regularization;accuracy;smoothness penalty;static images;supervision;consistency;improvement;input sequences;promising new frontier;predictions;baselines;pseudo;domain;new framework;recent breakthroughs", "pdf_keywords": "context frames;video frames;neighboring video frames;videos;video domain;object detection;uni\ufb01ed object recognition;temporal context;consecutive frames;frames;recurrent neural network;available video frames;rnn;youtube objects;target frames;neighboring frames;video;contextual information;novel recurrent;target frame;image domain;weaksupervision;regularization;convolutional neural network;neural network;strong supervision;pseudo;dataset;accuracy;predictions"}, "085072963b33367b842369b9ce81394d32ac8843": {"ta_keywords": "channel speech separation;channel speech separation systems;noisy speech;separation models;noisy oracle sources;field speech;noisy single;synthetic mixtures;speech;noise;ground truth;noisy conditions;mixtures;training;large gap;network;initial systems;performance;need;domain data;small step;condition task;use;more challenging conditions;desire", "pdf_keywords": "training speech separation systems;channel speech separation;channel speech separation systems;noisy oracle speech sources;noisy speech paradigm;better separation systems;noisy speech signals;speech processing;noisy oracle sources;discount noise separation errors;separation systems;domain training;noisy data;training models;noise;clean sources;sdr;training objective;human language technology center;noisy conditions;training;relative inseparability;sisdr;gap;large gap;inseparability;data paradigms;signal;chinese academy;si"}, "76fe5f80dd25078eefa522e59a7763bc5d5da826": {"ta_keywords": "adaptive spelling error correction models;learner english", "pdf_keywords": ""}, "9165d5e99b2106825dd00b9f5daf60e454434399": {"ta_keywords": "simultaneous interpretation corpus;simultaneous interpretation data;professional simultaneous interpreters;simultaneous interpretation systems;simultaneous interpretation;translation data;interpretations styles;interpretations;interpreter;better interpretations;corpus;transcriptions;english;lectures;differences;data;different amounts;collection;main features;experience;time;news;paper", "pdf_keywords": ""}, "23d299b35366c18e397faeb2c8687c20f8e17688": {"ta_keywords": "malicious deception attack;deception attack;adversarial image detection;image classifier;image classification;external attacker;deep neural network;attacker model;detection;classifier;such attacks;dnn;cyber;images;image;vulnerability;human eye;pixel values;change;physical systems;paper;several studies", "pdf_keywords": ""}, "72302d8c5cdcf59b6df96290ffc874d3613fe6b1": {"ta_keywords": "cancer pathology classification comparing sets;high dimensions version;committee;april", "pdf_keywords": ""}, "12e9d005c77f76e344361f79c4b008034ae547eb": {"ta_keywords": "charagram embeddings;textual sequences;gram count vector;dimensional embedding;compositional models;several similarity tasks;charagram;sentences;convolutional neural networks;level recurrent;character;sentence;words;grams;complex architectures;word;art performance;single nonlinear transformation;simple approach;new state", "pdf_keywords": "charagram embeddings;text representation;textual sequences;natural language processing;natural language understanding systems;nlp community;convolutional neural networks;charagram;compositional models;sentences;several similarity;character;level recurrent;simplest architecture;words;complex architectures;models;fundamental component;grams;code;introduction;il;high performance;abstract;empirical methods;new state;art performance;conference;jul;proceedings"}, "f053137323a88eb932d590bcdfc959ee805e2520": {"ta_keywords": "dependency parsing;parse tree;parsers;stackptr parser benefits;pointer networks;dependency tree top;subtree structures;internal stack;stackptr;stack;other transition;whole sentence;sentence;classical transition;leaf;novel architecture;depth;first fashion;time complexity;first search;root;steps;algorithm;top;step;child;information;model;right restriction;word", "pdf_keywords": "dependency parsing;stackptr parser;pointer networks;parsers;dependency tree top;stackpointer networks;internal stack;stackptr;novel neural network architecture;stack;model \ufb01rst reads;subtrees;sentences;whole sentence;carnegie mellon university;novel architecture;leaf;information;eduard hovy carnegie mellon university;nanyun peng university;jingzhou liu;root;gneubig;paper;graham neubig;abstract;procedure;tsinghua university;steps;may"}, "a4b1afd75bd2da0b21df58cd4ae1649fefabd8dd": {"ta_keywords": "parametric agent utility functions;fitness game;mobile fitness game;learned utility functions;utility maximizers;simulated game;equilibrium strategy;utility functions;utility function parameters;privacy;individual agent;other desirable objectives;reward;linear program;physical fitness;agents;game;equilibrium;play results;players;feasible set;data;parameters;theoretic framework;relative importance;calories;chicken;user places;method;dare", "pdf_keywords": ""}, "cbf9a2560eac548e7b3d5eb7074c40b7bb861909": {"ta_keywords": "neural speaker diarization;speaker diarization;end speaker diarization;speech activity;conditional multitask;overlap detection;diarization error rate;conventional eend systems;subtasks;subtask;eend;probabilistic chain rule;end;paper;method;terms;experimental results", "pdf_keywords": "speaker diarization;speech activity;multitask learning;conditional multitask;diarization error rate;multitask mechanism;overlap detection;conventional eend systems;probabilistic model;subtasks;subtask;multiple tasks;eend;probabilistic chain rule;input data;learning strategy;models;model;od;performance;sc;framework;paper;method;terms;experimental results"}, "e9dfccd86b6116f7601d44590985de2df434a094": {"ta_keywords": "tutor learning;tutoring strategy;tutoring;tutor;tutors;teachable agent;lessons;successful learning;adaptive help;learning;students;skills;simstudent;explanations;feedback;gamelike environment;cognitive anatomy;responses;examples;studies;hints;technology;linear equations;problem selection;connections;hypotheses;process data;instance;problems;performance", "pdf_keywords": ""}, "c933fed82e7b5cbf7230f0f970b69590b40f86a1": {"ta_keywords": "decentralized sgd methods;decentralized sgd;universal convergence rates;unified convergence analysis;linear convergence rates;local sgd;coorperative sgd;averaging;unified theory;complexity results;weak assumptions;models;various communities;prior work;many special cases;instance;iid;rates;different intuitions;proofs;local updates;large variety;several aspects;data;paper;host;different applications;important scenarios;topology;problems", "pdf_keywords": "decentralized sgd;sgd methods;adaptive network topology;local sgd updates;universal convergence rates;stochastic optimization methods;local sgd;data locality;pairwise gossip updates;linear convergence rates;convergence rate;coorperative sgd;iteration cost;linear speedup;local updates;prior work;graph topology;complexity results;algorithmic framework;weak assumptions;local steps;models;instance;data heterogeneity;averaging;iid;uni\ufb01ed theory;rates;topology;proofs"}, "91d98b0a175237b48122e7560010e87a968fb6e0": {"ta_keywords": "speech enhancement problems;mask prediction networks;robust speech recognition;speech separation;nonnegative matrix factorization;deep computational architectures;deep recurrent neural networks;deep neural networks;recognition;speech;noise;separation;background signals;learning;level enhancement;challenging environments;performance;conventional statistical techniques;techniques;environments;superior results;initial signal;problem;considerable interest;use;variants", "pdf_keywords": ""}, "cf8f2ca0c2d618104bc8724a6effc509088f16c4": {"ta_keywords": "ending language learner;learner;knowledge base;most current machine learning systems;knowledge;lessons;machine learning;new relational predicates;ontology;neverending;new beliefs;web;data model;features;beliefs;type;single data set;many years;paradigm;never;people;diverse experiences;millions;biscuits;day;many different types;humans;case study;nell;properties", "pdf_keywords": ""}, "cc7858e74a79edceb5a42c30fc5c2dc5117f365b": {"ta_keywords": "deep reinforcement learning;generative adversarial tree search;learned model;monte carlo tree search;deep generative models;atari environments;deep rl algorithm;planning;dqn;bias;rl environments;tree;model;environment model;better sample complexity;potential;better policies;rl;leaves;gats;free methods;variance trade;estimate;mcts;sample;alluring prospect;approaches;many recent advances;unsupervised data;faster converges", "pdf_keywords": "arcade learning environment;latest arcade learning environment;atari environments;generative adversarial tree search;atari games;learned model;monte carlo tree search;deep generative models;deep rl algorithms;deep rl algorithm;new openai;rl environments;gym;depth;model;like interface;ale;environment model;environment;gdm;mcts;rp;gats;different modes;work;sample ef\ufb01cient;robust method;study;domain change;design"}, "82cb0c428f5edb1db6e733dc4b1b20023a2ce15f": {"ta_keywords": "voting systems;voting rules;different voting rules;voting data;election data;elections;alternative vote;ordered preference data;netflix prize dataset;restricted preference profiles;condorcet efficiency;high consensus;condorcet;statistical models;empirical evaluation;rules;available data;plurality;testing;paradox;large samples;approval;probability;occurrence;instances;lack;support;rav;borda;repeated", "pdf_keywords": ""}, "f0bbc7b84c166e2258b6ba4f9d9835ecac04e842": {"ta_keywords": "spontaneous speech recognition;bayesian acoustic modeling;speech fluctuation modeling;speech recognition;variational bayesian estimation;speech data;speaker variances;accurate acoustic model construction;various speech fluctuation factors;practical bayesian framework;bayesian approach;clustering;variations;maximum likelihood approach;vbec;appropriate model selection;complicated integrals;scale task;paper;advantages", "pdf_keywords": ""}, "19b6537012412bee0a36e3e271f84b95868fe859": {"ta_keywords": "ad hominem arguments;ad hominem argument;ad hominem;arguers;fallacious arguments;ideal debate;explainable neural network architectures;linguistic insights;scale annotation studies;controversy;fallacy;various neural architectures;reasonableness;opponent;typology;hypotheses;research;paper;triggers;rules;potential causes;solid empirical investigation;gap;main requirements", "pdf_keywords": "ad hominem arguments;ad hominem;ad hominem properties;direct ad hominem;genuine dialogical argumentation;rhetorical triggers;dialogical exchange;discourse complexity;discussions;attentive;\ufb01rst nlp work;gold spans;typology;occurrence;self;\ufb01ner granularity;neural network;causes;representation;research gap;mace;accuracy;prediction;quantative properties;theories;data;purpose;levels;models;paper"}, "36a5e0e0a8ce67e4cd9077d86e3b4d50fdcff15f": {"ta_keywords": "efficient dual functional electrocatalysts;nickel foam;ni3se2;overall water splitting;facile route", "pdf_keywords": ""}, "d3e13d2514edaf74b863bfbe45a739c32a7689e1": {"ta_keywords": "neural code generation model;code generation tasks;program source code;predicted code;sentence similarity scoring method;code examples;gram action subtree;subtree retrieval;code;complex code;natural language;programming;input sentences;tree structure;sentences;recode;models;complex structures;actions;method;probability;methods;performance;lack;approach;ability;common approach", "pdf_keywords": "neural code generation models;neural code generation model;neural code generation;code generation tasks;code generation problem;code examples;action subtree retrieval method;program source code;subtree retrieval;purpose code;semantic parsing;natural language;code;neural mt method;retrieval;retrieval methods;neural model;subtask;tree structures;ast;tree structure;descriptions;language technologies institute;generation;nl;models;abstract;recode;method;test time"}, "ba3322280992d0425bc9e2b4c59de24857e5f4e7": {"ta_keywords": "performative risk minimization;performative prediction;risk minimization;strategic classification;classifier;performative risk;decisiondependent distributions;multiple local minimizers;learner;gradient flows;algorithms;performative alignment;term behavior;processes;algorithm;trajectories;data distribution;example;incentive;decisions;mapping;data source;data;particular label;situations;loop behavior;observed data;convergence;methods;notion", "pdf_keywords": "gradient descent \ufb02ow;performative risk minimization;prm gradient \ufb02ow;risk minimization;gradient descent method;risk minimizers;gradient \ufb02ows;gradient \ufb02ow;stochastic approximation;lyapunov function;perturbation;performative alignment;trajectories;various equilibria;time \ufb02ows;rgd \ufb02ow;convergence;state behavior;\ufb02ow;attraction;equation;connections;geometric condition;notion;paper;identi\ufb01ed regions;results"}, "3c6670ecdfccd4633755c4b19d774453bfb77de3": {"ta_keywords": "fairness;deceased donors;organs;patients;decisions;algorithms;blood types;waiting list;responsibility;first challenges;australia;awareness;different types;regions;lives;particular context;review;number;mechanism;age;account;need;come", "pdf_keywords": ""}, "d79b613a67cf79740e1c08037f7d054585a12284": {"ta_keywords": "nar decoders;nar decoder;encoder;end speech translation;translation quality;connectionist temporal classification;cmlm decoder;language model;unified nar e2e;nar models;baseline nar model;auxiliary shallow ar decoder;language directions;nar;efficient end;ctc;e2e;parallel ar rescoring;benchmark datasets;models;cmlm;large improvements;training methods;model;st framework;multiple tokens;orthros;speed;parallel;basis", "pdf_keywords": "nar decoders;nar decoder;speech encoder;encoder;uni\ufb01ed nar framework;translation quality;auxiliary shallow ar decoder;language model;baseline nar model;uni\ufb01ed nar e2e;conformer encoder;language directions;parallel ar rescoring;connectionist temporal classi\ufb01cation;ctc;ar model;benchmark datasets;speed;orthros;e2e;cmlm;model;parallel;cpu;large improvements;st framework;st task;fig;top;small overhead"}, "fd9e38e240b4372c49b9205d6f909d070ff3804c": {"ta_keywords": "unlabeled background knowledge;more general similarity;improved text classification;statistical similarity measures;textual data;background knowledge;information retrieval community;inductive classification;reasoning tasks;relational databases;intelligent use;many diverse forms;whirl;strings;tasks;information;training set;diverse set;examples;data;appropriate sets;new tools;extension;heterogeneous forms;internet;use;paper;error rates;number;size", "pdf_keywords": ""}, "cd96cae0f8eabc7bb327c6f30151741bfdd62ee0": {"ta_keywords": "new conference coordination officer;new information officer;sigai;new leadership team;new officers;officers;anuj karpatne;board louise dennis;ai matters;many changes;alan tsang;changes;amy;global pandemic;amy mcgovern;michael;unexpected challenges;first year;michael rovatsos;excellent service;election;activities;years;year;hang ma;particular note;hang;course", "pdf_keywords": ""}, "dec6bb3c7bb671c86296a2a089e0e38aa3f69279": {"ta_keywords": "nat models;existing nat models;best translation quality;nat model;nat;knowledge distillation;autoregressive models;distilled data;autoregressive model;training data;generation speed;better performance;performance;substantial improvements;accuracy;complexity;capacity;data sets;systems;output data;output tokens;sequence;several approaches;large gains;strong correlation;variations;findings;success;technique;reason", "pdf_keywords": ""}, "6bfeb25ea4bb41ab0840bb1be09f9b2de7eea8e4": {"ta_keywords": "guinea pig cytomegalovirus;gpcmv genome;gp33 gene;guinea pig cmv;mutant gpcmv;gpcmv;infected cells;viral growth;cytokine secretion;pathogenesis;cellular signaling;gp33;viruses;viral loads;inflammation;receptor;transient inflammation;maternal organs;receptor homolog;r33;pregnant animals;gpcr;alveolar hemorrhage;placentas;lungs;redet;spleens;step recombination system;vivo;livers", "pdf_keywords": ""}, "609010cb866a19dd996281d00818c3fc7363ec94": {"ta_keywords": "lingual named entity recognition;named entity recognition;bilingual dictionary;language pair;ner knowledge;different languages;many languages;ner;language;neural methods;unsupervised way;new sota;models;parallel data;features;tasks;sota;need;paper;results;good margin;state;effectiveness;approach;art;experiments", "pdf_keywords": "lingual named entity recognition;named entity recognition;bilingual dictionary;ner knowledge;language pair;target language;base ner model;ner;\ufb01ve language pairs;source language;many languages;languages;language;zeroresource;training data;\ufb01ve di\ufb00erent languages;neural methods;unsupervised way;parallel data;feature augmentation;models;target model;tasks;features;data;word;model;new sota;singapore;adversarial learning"}, "a1c4ce9de92338646c6ee93c7c2e5ee366784b1a": {"ta_keywords": "neural semantic parsing approaches;semantic parsing;semantic parsing datasets;different meaning representations;meaning representations;missing logical forms;new unified benchmark;execution engines;logical forms;unimer;unified benchmark;grammar rules;representations;missing execution engines;representation;benchmark;program alias;performance;different performance;gaps;complete enumeration;implementation;lot;impact;thorough experimental study;recent work;researchers", "pdf_keywords": ""}, "facefd2fc4b718c6a0d8096b4eb02866028a04c2": {"ta_keywords": "truth answer span;span answers;question answering;conversational qa;retrieval convqa;span answer;retrieval;freeform answers;long answers;conversations;weak supervision approach;single span;answers;text;span;supervision signal;strict spans;qa;passages;quac;information;large collection;known answer;convqa;weak supervisor;less satisfactory results;passage;coqa datasets;evidence;role", "pdf_keywords": "question answering;span answers;diverse paraphraser;conversational qa;retrieval;weak supervision approach;freeform answers;answers;training data;conversations;weak answer;span;retrieval setting;novel training method;qa;large collection;quac;coqa datasets;known answer;weak supervisor;datasets;convqa;passage;role;less satisfactory results;coqa;evidence;experiments;people;lack"}, "75d33c125eba966b50d4dccd359a2f6aa4e0e2e7": {"ta_keywords": "contextual bandits;lipschitz risk estimates;lipschitz risk functionals;policy risk assessment;finite sample guarantees;lipschitz risks;prospective policies;cdf estimators;risk;plugin estimates;target policy;first uniform concentration inequalities;cdf;many distorted risks;cpt risks;cvar;objectives;broad class;experiments;ii;conditional value;rate;framework;data;variance;others;entire class;collection;opra;error", "pdf_keywords": "lipschitz risk functionals;many risk functionals;cumulative prospect weighting;risk;lipschitz risks;\ufb01nite sample guarantees;rewards;cdf;plugin estimates;target policy;cpt risks;many distorted risks;objectives;cvar;conditional value;variance;practical interest;sup norm;lipschitz;broad class;sup norm di\ufb00erences;class;respect;novel class;absolute di\ufb00erences;others;framework;ii;opra;collection"}, "cb0de2de79533d4faada3d745f43702eb89d1a60": {"ta_keywords": "reusable documentation templates;documenting datasets;standard documentation practices;documentation;nlp datasets;natural language generation;documentation guidelines;use templates;natural language processing;reusable templates;nlp;gem data;gem benchmark data;guides;huggingface data card;model cards;datasets;tools;huggingface;models;detailed descriptions;general purpose card;generation;skills;developers;case study;researchers;field;standardization;backgrounds", "pdf_keywords": "documentation templates;documenting datasets;nlg models;documentation;nlp datasets;reusable documentation templates;documentation strategy;natural language processing;documentation guidelines;natural language generation;language datasets;standard documentation practices;documentation stakeholders;gem workshop;term model card;use templates;gem data;nlp;gem benchmark data;huggingface data card;gem benchmark;guides;reusable templates;model cards;models;term data card;huggingface;datasets;resources;hugging face"}, "13b6c8cce3b4557ad7a3188f2d54636e755e8145": {"ta_keywords": "multichannel gaussian mixture model;multichannel source separation;multichannel mixtures;domain multichannel audio;source separation;deep unfolding;deep mcgmm;simultaneous speakers;novel deep network;deep networks;generative model;mcgmm;original mcgmm model;model;computational network;frequency;architecture;improved performance;respect;advantages;approaches;experiments", "pdf_keywords": ""}, "77c63e8f102465e3fc4a46e0b07c32fa8d2f8a54": {"ta_keywords": "unsupervised grammar induction;unsupervised ccg parsers;grammar induction;syntactic structure;tag sequences;ccgbank;linguistic strengths;dependencies;raw word;progress;errors;new research directions;depth analysis;limitations;paper;light;amount", "pdf_keywords": ""}, "c065f9997794b13565dd49a6e475fc5e8c9d54ce": {"ta_keywords": "lamina emergent torsional joints;compliant joints;tensile stiffness;similar bending stiffness;lamina emergent torsional;laminated material structure;flexibility;high flexibility;let joint;kinetostatic model;joints;flexible h18 aluminum foil;joint;equivalent spring;material structure;design method;triple;design;let;extension;accuracy;paper;performance analysis;dl;high accuracy;order;layer;equations;results;key aspects", "pdf_keywords": ""}, "112eb8a8273ab725d47789efb87237edbc4f02db": {"ta_keywords": "description logics;simple description logic;learnability;learnability results;syntactic restrictions;predicate calculus;first order language;order logics;propositional conjunctions;order logic;conjunctions;primitive classes;descriptions;expressive power;conjunction;concepts;infinite attribute spaces;monomials;alphabets;different syntax;haussler;valiant model;valiant;roles;different set;subsets;piror work;form;boundaries;blum", "pdf_keywords": ""}, "e6accbbb366387faf817126dc7b0260c450bd2e6": {"ta_keywords": "noisy test results;optimal sample complexity;group testing;approximate recovery;sparse;graph codes;tests;algorithm;analysis tools;robust framework;defective items;graph;groups;unknown offsets;saffron;paper;example;inline;variations;items;order;formula;design;problem;theory;presence;positive integer", "pdf_keywords": ""}, "ca7a67aa29c67b006017f651601091145644f243": {"ta_keywords": "speaker localization;speech localization;speech detection;speech detection techniques;reverberation;utterances;localization errors;speakers;classifier;rooms;simple spherical wave assumption;other rooms;accuracy;domestic environments;real environments;minimum cost criterion;method;conventional methods;development;template;challenge;test;discrepancy;paper;baseline;problem;strategy", "pdf_keywords": ""}, "a61aebbfe029c4b8eafae4042e6242cdca8f54b7": {"ta_keywords": "relational qa dataset;wikipedia hyperlinks;target answer entity;extractive qa;latent relations;qa datasets;dense passage retriever;wikidata triplets;domain qa model;webquestions;entities;relations;qa;qa model;tail relations;questions;qa techique;natural questions;domain questions;exact match accuracy;propoed rgpt;generalization performance;rgpt;triviaqa;question;types;absolute improvement;wide range;dpr", "pdf_keywords": "relational qa dataset;annotated qa dataset;target answer entity;extractive qa;wikipedia hyperlinks;dense passage retriever;domain qa model;qa systems;latent relations;qa model;qa;webquestions;wikidata triplets;latent relation;questions;art qa frameworks;qa techique;relations;tail relations;natural questions;propoed rgpt;exact match accuracy;rgpt;results;triviaqa;good initialization;requirement;question;large human;wide range"}, "2d1f442578feb7034aa2b68bbf95f608f2342256": {"ta_keywords": "bandit arm selection;group fairness;fairness;equal group probability;sequential decision maker;groups;group;various groups;arm;payout;regret;potential arm;cmab;particular group;arms;probability;context;algorithm;arbitrary number;proportional parity;bounds;novel algorithm;time step;definitions;work;setting;notions;size;finite set;fact", "pdf_keywords": "group fairness;bandits;reward;biased feedback;fairness;groups;resources;implicit societal bias;machine learning;equal group parity;algorithms;proportional parity;world datasets;synthetic data;maryland college park;computer science;algorithm;intervention settings;cmab;work;setting;active topics;novel notions;abstract;university;tulane university new orleans;novel formulation;nicholas mattei;usa;feb"}, "147ba336fcba32fadca470e14a858ce069375475": {"ta_keywords": "speech synthesis;contour generation;rich context models;f0;hmm", "pdf_keywords": ""}, "00c8d88abef116d8d3d673a28ff4098115cf8da3": {"ta_keywords": "automatic cooperative persuasive dialogue system;cooperative persuasive dialogue system;cooperative persuasive dialogue policies;cooperative persuasive dialogue;dialogue management module;dialogue manager;natural language generation;nlg modules;natural language understanding;nlg;reinforcement learning;computational linguistics;text;reward;user satisfaction;oz framework;international conference;nlu;policy;human;users;wizard;previous evaluation;proceedings;framing;specific action;paper;oz setting;user;coling", "pdf_keywords": ""}, "04a7d9f0388ded93c1ec16e36a6df3cd44cb95b0": {"ta_keywords": "multilingual entity linking;single entity retrieval model;large new multilingual dataset;entities;entity;auxiliary entity;dual encoder;languages;specific mentions resolve;language;improved feature representation;agnostic knowledge base;negative mining;task;key insights;http url;model;training enhancements;frequency;end;prior work;new setting;setting;new formulation;analysis", "pdf_keywords": "multilingual entity linking;multilingual entity;large new multilingual dataset1;single entity retrieval model;entity linking;multilingual el task;low resource languages;entities;entity;rare entities;auxiliary entity;languages;language;matching dataset;dual encoder;daniel gillick google research;agnostic knowledge base;negative mining;speci\ufb01c mentions;world challenges;improved feature representation;task;diverse set;key insights;scope;abstract;end;model;training enhancements;nov"}, "9768d7ba9d09ac3bf3d52ec674bde1a6e615daad": {"ta_keywords": "minimax risk;adaptive estimators;pairwise comparison probabilities;strong stochastic transitivity;oracle estimator;pairwise comparisons;adaptivity index;estimation;future comparisons;estimator;pairwise comparison data;intrinsic difficulty;case risk;bernoulli probabilities;large parameter space;models;specific difficulty;sst;sst model;extent;underlying problem;probabilities;instance;performance;order;measure;flexible class;methods;parameter space;condition", "pdf_keywords": "adaptive estimators;strong stochastic transitivity;adaptivity index;pairwise comparisons;achievable adaptivity;least squares;logarithmic adaptivity index;pairwise comparison probabilities;estimation;sst matrices;e\ufb03cient estimator;bern;hardness;step estimator;randomize;sst;\ufb02exible framework;bernoulli probabilities;logarithmic factors;mar;count;crl;step;gap;indi\ufb00erence sets;form"}, "b7ffc8f44f7dafd7f51e4e7500842ec406b8e239": {"ta_keywords": "reading comprehension;comprehension tasks;gating;comprehension;paragraphs;level tasks;level representations;gating mechanism;scalar weighting;book test dataset;words;concatenation;level;character;children;questions;word;performance;interaction;idea;experiments;properties;previous work;art results;new state;approach", "pdf_keywords": "reading comprehension tasks;comprehension tasks;character gating;character gating mechanism;comprehension;general neural network architecture;gating approach;queries;gating mechanism;level representations;paragraph;representations;words;query;document;documents;level;tasks;word;character;\ufb01ne;variety;improved performance;interaction;approaches;properties;work;settings"}, "90357a6dc817e2f7cec477a51156675fbf545cf1": {"ta_keywords": "multimodal neural script knowledge models;multimodal reasoning;visual commonsense reasoning;multimodal script knowledge;video corpus;auxiliary supervised data;videos;youtube videos;visual world;recognition;transcribed speech;inferences;images;video;training;cognition level;future;art models;events;diversity;questions;static images;corresponding words;diverse objectives;self;label;boxes;mix;level;time", "pdf_keywords": "powerful multimodal representations;multimodal reasoning capacity;video corpus;multimodal script knowledge;collecting videos;stack multimodal;youtube videos;videos;literal captions;intermediate visual representations;youtube;corpus;transcribed speech;transcripts;video frames;individual video frames;associated transcripts;recognition;representations;model representations;level representations;training;single frames;data;self;frame;diversity;cognition level;label;static images"}, "ba3f39606cfd4150ea80fec1b2e1137933c6d143": {"ta_keywords": "automated pcr setup;forensic casework samples;pcr setup;normalization wizard;robotic methods", "pdf_keywords": ""}, "8ae4a584539a8f30d654e2678dde64a8334461b7": {"ta_keywords": "personalized product reviews;classify reviews;level recurrent neural network;generative concatenative nets;reviews;rnn;review;recommender system;rating;sentiment;text;generative model;product category;gcn;large vocabularies;evaluation;character;product;users;remarkable accuracy;misspellings;author;user;terms;slang;unseen items;negation;machinery;purpose;basic task", "pdf_keywords": "generative model likelihood scores;generative concatenative nets;classify reviews;generative concatenative network;personalized product reviews;review generation;characterlevel recurrent neural network;recommender system;lstm rnn;recommender systems;traditional supervised learning tasks;character level rnn;rnn;text;strings;scoring mechanism;high accuracy;labels;distinct individual tastes;items;unseen items;evaluation;gcn;large vocabularies;knowledge;users;apr;misspellings;diverse set;purpose"}, "b01ecfd2322437fcc9c7ce6605d6f5a50f67ec50": {"ta_keywords": "successor model;alternative al strategies;retrospective evaluations;models;training;training dataset;model;specific models;al;current approaches;inconsistent performance gains;dataset;acquisition;findings;tasks;practice;studies;benefits;use;opportunity;practical obstacles;question;paper;promise;particular domains", "pdf_keywords": "standard nlp tasks;training dataset;sequence tagging;acquisition model;predictive performance;acquisition functions;training;text classi\ufb01cation;models;speci\ufb01c models;acquisition function combinations;dataset;successor model;acquisition;model;classi\ufb01cation;train;distinct successor model;tables;standard al methods;performance;al;current approaches;table;results;tasks;bene\ufb01ts;ner;\ufb01nd;conclusions"}, "2177bf060aaf2c0c2b551d3e805779cb35c19bb1": {"ta_keywords": "new red phosphor ceramic k2sif6", "pdf_keywords": ""}, "2068825cabd94c951a0282ed731a8b8f2da1721c": {"ta_keywords": "semantic parsing;available unlabeled nl utterances;formal meaning representations;natural language;variational auto;latent variable models;supervised models;nl;encoding model;tree;tree structures;parallel data;structvae;data;bottleneck;task;corresponding mrs;limited amounts;mrs;limited availability;time", "pdf_keywords": "semisupervised semantic parsing;semantic parser functions;semantic parsing;latent meaning representations;formal meaning representations;surface nl utterances;available unlabeled nl utterances;observed nl utterance;natural language;generative story;python code generation;encoding model;latent variable models;original observed utterance;treestructured latent mrs;principled deep generative approach;variational auto;structvae;graham neubig language technologies institute carnegie mellon university;latent variables;tree;semisupervised sequence;vae;tree structures;encoding;standard vae architecture;inference model;nl;models;latent mr"}, "8ca58f3f6e59a6d243f3da6c196e9f730e6e9993": {"ta_keywords": "end neural diarization handling overlapping speech;neural speaker diarization;speaker;end diarization;speakers;speech;online end;buffer method;conventional clustering;eend;original eend;variable numbers;flexible numbers;online scenarios;extension;model;number;end;methods;problems;limitations;significant improvement;paper;ii;advance", "pdf_keywords": "online streaming speaker diarization method;online diarization problem;wise diarization methods;speaker;speakers;online system;of\ufb02ine eend method;extended stb;online method;stb;buffer;speech;chunks;comparable performance;eend;dihard ii datasets;of\ufb02ine method;second latency;callhome;comparable results;method outperforms;\ufb02exible numbers;different number;flex;eda;bw;paper;method;better results;solution"}, "ca6d5c7829a76d10069fa3aa6776c35cc044b7ba": {"ta_keywords": "course selection tool;courses selection;basic course planning;human advisors;career paths;software tools;undergraduates;lessons;students;rote requirement checking;large state university;tool;detailed questions;surveys;preferences;terms;session;course;person;nothing", "pdf_keywords": ""}, "6e3f8187f8fef3e11578a73f32da07d33dbf8235": {"ta_keywords": "semantic parsing;text generation;semantic triples;tree ontology annotation;text annotations;semantic dependencies;text datasets;declarative sentence conversion;structured data;spoken dialogue systems;dataset construction framework;domain generalization;tables;webnlg;unification;data record;data;new challenges;systematic evaluation;dart;darts;table title;table headers;answer pair;heterogeneous sources;structures;nontrivial structures;new state;open domain;end", "pdf_keywords": "semantic parsing;novel tree ontology annotation;tree ontology annotation;semantic triples;tree ontologies;domain corpus;semantic frame;semantic dependencies;semantic triple input;wikipedia tables;declarative sentence conversion;\ufb02at table schema;ontology structure;structured data record;text models;diverse predicates;text generation;meaning representation tasks;dataset construction framework;tables;dialogue;table;tree;domain speci\ufb01c;webnlg;table headers;domain nature;new challenges;art data;table title"}, "bdbf635476477eec5be5a292b494e20b8902cc35": {"ta_keywords": "machine translation;synthetic noise;clean data;robustness;text;vanilla mt system;noise;other noise;mt systems;slang;dialect;mt;accuracy;typos;social media;manner;loss;disastrous impact;paper;methods;idiolect;realm", "pdf_keywords": "noisy text;noisy data;social media text;synthetic noise induction model;machine translation;natural noise;social media sources;improved resilience;robustness;adaptation;social media;noise;back translation;text;resilience;target noise;mtnt;translation;vanilla mt systems;dataset;arti\ufb01cial noise;clean data;data;vanilla mt system;mt systems;internet;english;prior work;primary methods;methods"}, "b3979990dc2080138021cb3d767c7ec6d3e96194": {"ta_keywords": "literary relationships;dynamic fictional relationships;fictional relationship;global relationship descriptors;novels;novel;accurate relationship trajectories;digital humanities scholarship;plot summaries;unsupervised learning;relationship;characters;descriptors;raw text;neural network;former friends;dataset;best friends;families;model;key challenge;trajectory;labels;previous work;enemies;task;time;set", "pdf_keywords": ""}, "e12c52fb542f76b3f0d29178842428d6a4edfe1e": {"ta_keywords": "biased users;external decision;other agents;potential biases;fairness;learning;accuracy;decision;rejection;maker;makers;models;experiments;systems;process;concept;interaction;model;algorithm;system;work;stage framework;effect;simple version;entire system", "pdf_keywords": "external decision;adaptive rejection learning;rejection learning;fairness case;fairness;potential biases;learning;other agents;pipeline;decision;rejection;process;makers;maker;dm;accuracy;concept;oracle;algorithm;model;interaction;equivalence;system;stage framework;work;method;framework;simple version;whole;e\ufb00ect"}, "4ce47dd7a8674f8ffd53f1883bc57e62460a83f0": {"ta_keywords": "differential nash equilibria;nash equilibria;smart grid;energy ecosystem;utility learning;design incentives;vulnerability tradeoff;nash;systems theory;scale cyber;incentive design algorithm;policy;games;efficiency;physical systems;agents;planner;demand;new sensing;myopic update rule;regulations;small modeling errors;socioeconomic factors;cps decision;characterization;qualitative insights;measurement noise;discussion;futureresearch directions;makers", "pdf_keywords": ""}, "fa9b043ae8da3cc60c975762ae9066d2fb010f41": {"ta_keywords": "graph clustering;unsupervised nlp tasks;natural language processing;several efficient graph;graph;nlp;algorithms;representations;implicit structure;useful knowledge;tasks;implementations;data;effective approach;tutorial;evaluation methodology;applications;variety;weaknesses;strengths", "pdf_keywords": ""}, "52540497682c4209b8e20125c8255358b22d0fa7": {"ta_keywords": "cognitive tutors;simulated student;efficient skill acquisition;problem representations;skill knowledge;representation knowledge;prior knowledge engineering effort;human learning;future learning;intelligent agents;prior domain knowledge;prior knowledge;harder problems;novice;agent;extended agent;specific prior knowledge;simstudent;extended simstudent;students;representation;multiple difficulty levels;math;complexity;problem difficulty;feature predicates;original simstudent;problems increases;effort;deep features", "pdf_keywords": ""}, "2ed6f376e9e7eee6d833ad7b6aba63d7ad40c0f8": {"ta_keywords": "thermal hydraulic design;cool blanket;cfetr;research", "pdf_keywords": ""}, "bd0db679d595399b91c5acca1db33a2803697d53": {"ta_keywords": "online political information search;political information;social cues;information search;online information;online content;informed counterparts;voters;judgments;politics;web;internet;likes;evaluation;previous readers;news;heuristic;users;effect;comments;patterns;americans;paper;processing;subjects;form;number;greater numbers;software;apparent tallies", "pdf_keywords": ""}, "79f47ebf896b848e7c981c8aa6862ca1a7e5e7e5": {"ta_keywords": "adaptive geodesic kernels;kernel clustering limitations;kernel clustering;adaptive kernels;data density inhomogeneity;density equalization;kernels;density mode isolation;bias;real data experiments;density law;continuous generalization;data analysis applications;theoretical findings;theoretical understanding;diverse disciplines;gini criterion;broad spectrum;general class;common class;breiman;conditions;principal solution;principled solutions;solution", "pdf_keywords": ""}, "0222a48657d554b2a5a3d7ec3bb0b6833b8970a1": {"ta_keywords": "induced thrombocytopenia;heparin treatments;thrombocytopenia;heparin;lateral flow immunoassay;rapid assay;arterial thrombosis;serum;rapid nanoparticle;assay;diagnosis;lfia stic expert;plasma samples;hit;prospective evaluation;test results;pretest probability;patients;plasma;conclusion;npv;large prospective cohort;score;results;study;high risk;aim;negative result;result;emergency conditions", "pdf_keywords": ""}, "8c5ba1c914eab16b705da03352fe69d5bcfc72ea": {"ta_keywords": "abstractive summarization models;abstractive text summarization;document summarization models;novel abstractive summaries;abstractive summaries;summarization framework;summarization;training corpora;long source document;sentences;summary;cnn;source documents;content;explicit dependencies;source document;limited abstractiveness;document;interpretable sentence;layout bias;source;standard baselines;level structure induction;dm dataset;grams;end;several key challenges;style;latent;information", "pdf_keywords": ""}, "7fc0097f6a51282dc1e9020d7c28e12cecaef519": {"ta_keywords": "xstream", "pdf_keywords": ""}, "3cfb319689f06bf04c2e28399361f414ca32c4b3": {"ta_keywords": "transfer learning;colossal clean crawled corpus;question answering;unified text;natural language processing;text classification;nlp;text transformer;rich task;transfer;text;summarization;downstream task;text format;unified framework;dataset;many benchmarks;data;models;language problem;paper;code;insights;future work;model;art results;techniques;exploration;scale;powerful technique", "pdf_keywords": "transfer learning;nlp problems;natural language processing;nlp;question answering;text tasks;transfer;learning;downstream task;text transformer;rich task;text framework;language problems;uni\ufb01ed text;tasks;text;machine learning research;training;document;model;takeaways;uni\ufb01ed framework;abstract;data;english;machine;single model;paper;google;noam"}, "d19e097f388ca12ff111989b2bac7d3cc3cf15ca": {"ta_keywords": "text similarity graph;similar textual content;different disinformation narratives;user coordination network graph;coordinated messaging;capitol riots;coordinated user clusters;totext graph;user parleys;networks;narratives;influential groups;text;parler;elections;users;analysis;user;support;general methodology;method;january;study", "pdf_keywords": "user coordination graph;social media data;social media usage;coordinated messaging;user coordination network graph;coordinated user clusters;unusual online activity;user parleys;text similarity graph;similar textual content;di\ufb00erent disinformation narratives;capitol riots;textual content;main user groups;january 6th riots;totext graph;networks;users;parler;text;user;parleys;moniker;activity;elections;patriot;in\ufb02uential accounts amon;in\ufb02uential groups;support;account types"}, "2c9158e20f58df04a6c5cd54dd3ee7d8df656421": {"ta_keywords": "new retrieval toolkit flexneuart;other retrieval systems;nlp community nmslib;sparse representations;lucene;flexible toolkit;dense representations;nmslib;training data;flexneuart;library;ir;new distances;weights;candidate generation;agnostic algorithms;structure;distance;qa applications;objective;integration capabilities;annoy;signals;mixing;faiss", "pdf_keywords": "nn search library nmslib;new retrieval toolkit flexneuart;similarity search methods;flexible retrieval;new search methods;nmslib;\ufb02exible toolkit;distance functions;nlp community;extendible library;library;flexneuart;toolkit;principled support;ir;eric nyberg carnegie mellon university;code;objective;naidan;evaluation;boytsov;abstract;qa applications;integration capabilities;leonid boytsov;ef\ufb01cient;nov;candidate generation;signals;pittsburgh"}, "d864944df8e765d597484ace12dbc3ac99e950a9": {"ta_keywords": "proximal policy optimization;modern policy gradient algorithms;surrogate reward function;surrogate reward;robust statistics;dimensional robust estimator;gradient clipping;gradients;estimation;behavioral policy;policy diverges;agent;actor network;outlier;tailedness;heuristics;policy;loss;gmom;ppo;successful learning;tricks;likelihood ratios;detailed empirical study;main sources;substitute;advantages;techniques;nature;paper", "pdf_keywords": "ppo gradients;ppo heuristics;surrogate reward function;ppo objective;gradient clipping;policy gradient steps;objective clipping;advantage estimates;standard ppo implementations;offpolicy training;standard ppo;gradient distribution;heuristics;dimensional robust estimator;gradients;ppo;gmom;policy training;tailedness;heavytailedness;rigorous empirical study;value loss;tricks;detailed empirical study;primary contributors;consequences;substitute;actor;\ufb01rst contribution;role"}, "e6239cc789da289929d49ffed2c0a562213d4703": {"ta_keywords": "fillet welding;titanium alloy ring;welding position;cylindrical shell;welding;underwater carrier equipment;residual stresses;deformation uniformity;deformation;residual stress;cylinder body;finite element software;ring;constraint tooling;main pressure structure;abstract ring;frame;structure;distortions;safety;gravity;performance;results;analysis;paper;significant impact;great threat;little effect;influence", "pdf_keywords": ""}, "60e339d25d43c026cf96395aa8accf34eae744a5": {"ta_keywords": "crowdsourced pairwise comparisons;evaluation dataset;pairwise comparison tasks;crowdsourcing platform;crowdsourcing;imagenet;scale machine learning models;recommender system evaluation;datasets;open datasets;challenging artificial intelligence tasks;information retrieval;dataset;comprehensive evaluation;subjective human perception;objective responses;model evaluation;pairwise;imdb;pairs;scale dataset;images;squad;ms coco;wiki;peoples;several baseline methods;suitability;options;one", "pdf_keywords": "crowdsourced pairwise comparisons;evaluation dataset;dataset;evaluation pairwise comparisons;computer vision systems imdb;crowdsourcing;benchmark;imagenet;crowdsourcing platform;age information;open datasets;pairwise comparisons;photos;images;genders;peoplenum;imageclarity;peopleage;scale dataset;largest available open dataset;ages;people;dmitry ustalov yandex;imdb;pairs;comprehensive evaluation;nikita pavlichenko yandex;pairwise;wiki;scale machine learning models"}, "4ef77ef9b8ca8c8a96f1e62fa86a988feb582bd1": {"ta_keywords": "domain adaptation;language model adaptation;neural language models;domain set;machine learning theory;sets;training setup;concepts;distance;model;offs;distributions;size;benefit;trade;work", "pdf_keywords": "domain adaptation;language model adaptation;domain adaptation techniques;importance sampling;neural language models;contrastive data selection;intelligent data selection;adaptation techniques;machine learning theory;data selection;selection methods;in\ufb02uence function selection;language;domain data;model training;similarity;david grangier google;concepts;statistical estimation technique;different \ufb01nal task;offs;common techniques;common framework;abstract;palo alto;popular setting;subtle differences;in\ufb02uence functions;analysis;cl"}, "09ec8d8e2251e079abb0e109979f33ee120211fa": {"ta_keywords": "hybrid proximal extragradient method;proximal extragradient method;tensor method;tensor methods;hessian evaluations;smooth convex optimization problems;hessian;svaiter method;gradient;nesterov;convergence rate;third order inclusive;iteration;approximate solution;special generalization;newton;method;methods;auxiliary problem;complexity;derivatives;svaiter;step size selection condition;upper bounds;monteiro;constructive solution;order;step;gap;problem", "pdf_keywords": ""}, "a8a863e85a95919773868204d672f1260e0058ce": {"ta_keywords": "universal neural machine translation;neural machine translation;contextual parameter generator;target language embeddings;contextual parameter generation;domain adaptation;monolingual data;shot translation;parameter generator;encoder;nmt;single universal model;multiple languages;decoder;language;specific parameterization;standard nmt system;parameters;model architecture;models;neural network;input;weights;training;simple modification;cpg;changes;new component;source;system", "pdf_keywords": "universal neural machine translation;neural machine translation;new contextual parameter generator;translation model;contextual parameter generation;language speci\ufb01c parameterization;language encoder;language embeddings;domain adaptation;learned language embeddings;monolingual data;shot translation;language pairs;translation;single universal model;multiple languages;languages;context;parameters;models;decoder systems;nmt;training;datasets;cpg;nmt systems;modular framework;theart performance;simple modi\ufb01cation;aug"}, "d82592f3a110308366dfc7c42565d437b5bf59af": {"ta_keywords": "social skills training;social skills trainer;social skills;social skill;autistic traits;social interaction;dialogue system;user speech;computer interaction;appropriate skills;skill;human anxiety;speech;virtual avatar;language features;language information;application show participants;feedback;features;effect;system;users;relationship;process;minutes;method;experiments;discomfort;paper;additional experiments", "pdf_keywords": ""}, "5dab371fecc43904c0b785a50136d20cee43a99a": {"ta_keywords": "translation tasks;machine translation corpora;machine translation system;end speech translation;speech translation;attention;transcribed speech;attention stages;corpus;other available speech recognition;source speech;source text alignments;parallel texts;attention mechanisms;trainable models;speech;trainable recognition;second modeling source;cascade;models;such models;text alignment;efficient end;direct model;model;error propagation issues;robust;end;data;end fashion", "pdf_keywords": "direct attentional models;translation tasks;machine translation system;speech translation;attention;transcribed speech;attention stages;auxiliary training data;source text alignments;source speech;attention mechanisms;parallel texts;corpus;trainable models;speech;second modeling source;models;text alignment;twostage models;such models;stage models;model;baselines;error propagation issues;performance;previous formulation;end;basic variant;abstract;remedy"}, "461188735d46dc1062f5d1d382d940a24c355fad": {"ta_keywords": "entity pairs;level relation classifier;large corpus;locatednear relation;such relationship;commonsense knowledge;benchmark datasets;physical objects;sentence;future research;scores;real life;kind;evaluation;paper", "pdf_keywords": ""}, "f6be5d90199d1644b85e6b41a7a7f42fb29dbc9a": {"ta_keywords": "spatial abilities;spatial ability;ospt training;ospt ability;appropriate ospt assessment tool;general skills;general intellectual skill;specific skill;ospt;geometric objects;4th graders;detailed everyday objects;abstract geometrical target objects;ospt performance;learning;young children;novel tasks;such curriculum;training program;spatial issue;ability;most school curricula;mathematic achievements;children;explicit instruction;everyday information processing;short training;object types;mathematic scores;view", "pdf_keywords": ""}, "a278c07c8bd2921e59dd862cd91a0540dd340030": {"ta_keywords": "regularization;regularization procedure;neural networks;propensity score;treatment effect;treatment effects;bias;estimation adjustment;downstream estimator;estimation;dragonnet;models;treatment;final estimate;observational data;statistical literature;adaptations;training;effect;outcome;insights;unit;optimal asymptotic properties;order;use;question;sufficiency;quality;box;design", "pdf_keywords": "treatment effect;estimation adjustment;neural networks;treatment effects;estimation;downstream estimator;models;dragonnet;propensity score;\ufb01nal estimate;observational data;adaptations;statistical literature;effect;statistics;insights;stat;training;ml;claudia;1department;victor veitch2;use;abstract;new architecture;computer science;question;design;order;natural choice"}, "9c5c794094fbf5da8c48df5c3242615dc0b1d245": {"ta_keywords": "disentanglement learning;unsupervised learning;learned representations;disentanglement;unsupervised learning algorithms;inductive biases;representations;downstream tasks;models;supervision;reproducible experimental setup;data;prominent methods;world data;losses;few explanatory factors;evaluation metrics;sample complexity;variation;several data sets;future work;experimental study;different data sets;results;key idea;role;concrete benefits;properties;scale;different methods", "pdf_keywords": "unsupervised disentanglement learning;disentanglement learning;disentangled representations;unsupervised learning;disentanglement methods;learned representations;disentanglement;unsupervised learning algorithms;disentanglement metrics;inductive biases;representations;downstream tasks;representation;supervision;data;sample complexity;few explanatory factors;reproducible experimental setup;models;variation;empirical study;gunnar r\u00e4tsch;data sets;world data;posterior;role;current approaches;several data sets;dimensions;concrete bene\ufb01ts"}, "2a2d03a1534b365c5b048c824c0886e16ccf7dfa": {"ta_keywords": "binary relation prediction;large knowledge base;semantic inference rules;knowledge base;large web text corpus;relational knowledge;binary relations;relational information;syntactic patterns;parsed text;random walk model;background knowledge;freebase;other relations;graph representation;text;web;extraction;path;significant accuracy improvements;text show;methods;experiments;previous studies;scale implementation;potential", "pdf_keywords": ""}, "535c58ec8020782d41ed3ca72cf94aff7fd65120": {"ta_keywords": "acoustic models;automatic speech recognition research;speech recognition;future prospects;recent progress", "pdf_keywords": ""}, "4c93bcc05d6b41cb3df451d703f34bab9c9e9201": {"ta_keywords": "private text generation mechanisms;differential privacy;private text mechanisms;quantifiable privacy guarantees;privacy;privacy amplification step;user trust;better machine learning;noisy vectors;user data;text queries;text;vectorial representations;guarantees;models;ml;noise;lac;utility;word;generalized form;such mechanisms;applicability;high level;projection;high dimension;proposals;challenges;additional suite;framework", "pdf_keywords": "privacy;noisy vectors;di erent methods;di erent techniques;privacy framework;privacy ampli cation step;data sensitivity;nearest neighbor;message perturbations;text;noise;distance;vectorial representations;curator;d\u03c7;euclidean space;word;projection;truncation;users;high dimension;density;proposals;local region;variety;additional suite;approaches;high level;such mechanisms;potential ways"}, "96abcdded2985bd44b9514e28f5b8da4fa1e4371": {"ta_keywords": "model interpretability;interpretability;machine learning;mythos;concept", "pdf_keywords": ""}, "18e8646001fc53465fdc8f8eb01523e24c134493": {"ta_keywords": "cardinal scores;rankings;ranking;ratings;ordinal data;scores;rating;miscalibrations;miscalibration;linear biases;possible estimators;estimators;estimation errors;popular approach;simplistic models;assumptions;only useful information;widespread folklore belief;novel fundamental insights;terms;rates;approaches;eternal debate;absence;people;paper;issue;practice;work;approach", "pdf_keywords": ""}, "f78e5aaf34cc1e4874490e9155c640b73c630021": {"ta_keywords": "sum games;opponent behavior;conjectural learning;opponents;learning;gradient conjectures;strategy;games;agents;dynamic behavior;equilibrium concept;gradient;players;surrogate cost;last joint action;outcomes;belief;general framework;rules;contrast;recent years;suitability;number;work;framework", "pdf_keywords": ""}, "f132f6534ec326a1ba61870b701015cd3d1560a2": {"ta_keywords": "domain adaptation;tuning domain;popular contrastive data selection method;domain classifiers;machine translation;data training;data selection;fine tuning;selection;language modeling;training phases;tuning;much data;neural networks;complementarity;performance gains;little data;limited progress;data;practical recommendations;long lasting progress;complementary effect;session;experiments;benefit;ii;trade;iii;work", "pdf_keywords": "domain adaptation;contrastive data selection;neural machine translation;neural language modeling;\ufb01ne tuning dataset;machine translation;data training;data selection;contrastive scoring;data selection techniques;common data selection method;fine tuning;common selection methods;data selection mechanism;selection;language modeling;domain adaption;discriminative model classi\ufb01er;training phases;limited improvements;complementarity;neural networks;domain classi\ufb01ers;david grangier google brain;language pairs;more data;\ufb01ne tuning;best data;data;simple variants"}, "835587dbe94b70adeb0b16384e10bb6e0e29de84": {"ta_keywords": "stable matching;uncertain pairwise preferences", "pdf_keywords": ""}, "97bcea32979ed602fd404448a4e4cedad4171d79": {"ta_keywords": "individual nonverbal behaviors;nonverbal behaviors;nonverbal behavior label;nonverbal behavior;dialogue corpus;personality;personality traits;big five personality scores;virtual agents;eye gaze;spoken sentences;virtual agent;posture;spoken language;input language representation;dyad interactions;transcripts;participants;models;arms;whole body;head;key technical challenge;process;broad range;work", "pdf_keywords": ""}, "89c148d3d4edcb7b13c35da36b97ffb881c38058": {"ta_keywords": "several el speech enhancement methods;enhanced el speech;statistical excitation prediction;microphone;statistical excitation feature prediction;normal speech;original el speech;electrolarynx;laryngectomees;loudspeaker;speech;face conversation;electrolaryngeal;excitation;el;real time;listeners;excitation parameters;direct f0 control;telecommunication;device;evaluation;face;methods;naturalness;framework;simulation;paper;issue", "pdf_keywords": ""}, "b8dcc2ae3346e41a421232169c2ca07957c654c4": {"ta_keywords": "evolutionary game theory;dynamic agents;chaotic coevolution;archetypal game;static games;recurrent orbits;evolutionary learning;static game;evolve;games;agents;poincar\u00e9 recurrent;sum competition;online learning;competitive settings;possible initializations;replicator;conservation laws;time analogue;theoretic flavor;populations;initial conditions;behavior;theoretic setting;artificial divide;regularities;current population mixture;multiplicative weights;network;time", "pdf_keywords": ""}, "135ace829b6ad2ec9db040d8e5fd137034e83665": {"ta_keywords": "exact learning;conventional crfs;segmentation;inference algorithms;segments;labels;transitions;segment;subsequences;input sequence;features;properties;individual elements xi;time;spite;version;additional power;small constant factor", "pdf_keywords": ""}, "635932ee917d71e01f07211c0359abf3e0e65e47": {"ta_keywords": "automatic speech recognition;connectionist temporal classification;right decoding;output token sequence;asr tasks;future output context;autoregressive generation;asr;predict;token generation;nat model;insertion;ctc;models;nat;attention;many e2e models;model;e2e;end;modeling;type;nmt;mask;addition;joint training;length;heuristics;variants;additional component", "pdf_keywords": "autoregressive transformer;strong autoregressive transformer;insertion transformer;connectionist temporal classi\ufb01cation;asr tasks;insertionbased model;similar decoding condition;beam search;models;nat;joint modeling;nmt;ctc;insertion;joint training;l2r;bbt;public benchmarks;better performance;type;csj;addition;indigo;competitive performance;tedlium2;formulation;new formulation;paper;aishell;experiments"}, "b30195763eb103e2e5564228119f3810ab423b2e": {"ta_keywords": "text classification;current text classification methods;sentiment classification;label names;classification;classification models;unlabeled data;label name;language model self;training data;categories;benchmark datasets;training approach;words;class;documents;examples;topic;human;humans;model;small set;paper;real applications;most cases;good number;potential", "pdf_keywords": "current text classi\ufb01cation methods;text classi\ufb01cation;label names;category vocabulary;label name replacement;lotclass model;label name;language model self;unlabeled corpus;label;training data;indicative words;categories;category prediction;class;words;level classi\ufb01cation;text;category understanding;category;word;training approach;generalization;documents;training;neural lms;name;\ufb01cation;jiawei han1;model"}, "002c256d30d6be4b23d365a8de8ae0e67e4c9641": {"ta_keywords": "powerful language models;language modelling;recurrent architectures;parameter models;models;neural networks;training compute;memorization;model parameters;transformers;large performance improvements;attention;training data;inference time;parameters;unsupervised task;lm;training;tasks;text;data;additional computations;factors;years;form;number;wide array;past;benefits;shot formulation", "pdf_keywords": "large text database;language models;general knowledge extraction;scale memory;retrieval;explicit memory;database size;unprecedented scale;databases;models;explicit neighbour copying;trillions;model size;language;quences;tokens;data;magnitude;enhanced transformers;computations;performance;training;new avenues;order;e\ufb03cient means;conclusion;fig;method;work;complementary path"}, "933396f5b9111f6acdd76710ee6ab4d24e8673dd": {"ta_keywords": "speech data;automatic speech recognition;large unpaired speech;encoder;autoencoding;encoder network;text datasets;conventional language model integration;larger character error rate reduction;text sequences;text data;feature extraction;speech;wall street journal dataset;text;asr;extraction;intermediate representations;intermediate representation;different domains;less human effort;end;dissimilarity;experimental results", "pdf_keywords": ""}, "4c49e9b57c8fc58b0df29a27ecca8cc2e376f02b": {"ta_keywords": "collaborative filtering;web lists;search engines;autonomous web spider;cf spider;pages;lists;spiders;cf algorithms;spider;particular pages;particular sites;commercial web;entities;useful data;cf;heuristics;knowledge;data;interest;real users;domain;cohen;format;plausible hand", "pdf_keywords": ""}, "7d5f83cb234a5640487bd258ace06d9dc967d222": {"ta_keywords": "statistical relational learning;statistical relational learning model;joint information extraction;scalable statistical relational learning approach;information extraction;knowledge base;world wikipedia datasets;reasoning tasks;joint learning;inference;reasoning task;order logics;learning;reasoning;latent context invention;text;ie;tasks;kb;results;key issue;art baselines;multiple domains;errors;steps;approach;sl;quality;state;paper", "pdf_keywords": ""}, "f1c7419b87cbf853e691e500643f71720b68fb86": {"ta_keywords": "online stacked graphical learning;collective classification methods;collective classification;graphical learning;online learning scheme;large graphs;online learning;social networks;relational data;learning;graphical models;datasets;dataset;iterative inference;class labels;learning procedures;relational database;hyperlinked webpages;memory;minimal memory;data;iterative optimization;instances;domains;memory cost;training time;reliable results;less time;sample problems;paper", "pdf_keywords": ""}, "9b3fd2525a2d1abc44145308e013f117d3d7bdee": {"ta_keywords": "el speech enhancement technique;several el speech enhancement methods;enhanced el speech;statistical voice conversion;el speech;statistical excitation prediction;microphone;statistical excitation feature prediction;original el speech;laryngectomee;electrolarynx;loudspeaker;excitation signals;face conversation;excitation parameters;real time;statistical prediction;direct f0 control;articulation;intelligibility;significant improvements;effectiveness;f0 patterns;evaluation;f0 values;method;face;methods;naturalness;experimental results", "pdf_keywords": ""}, "1afa3ab80abda57920b8d456a6513e6f01cc82e7": {"ta_keywords": "survival text regression;event prediction tasks;survival regression;event prediction;event forecasting;classification tasks;regression tasks;conversation;conversations;nlp;classification models;event;regression techniques;such predictions;reliability engineering;time;context;platform;length;point;healthcare;applications;family;recent work;application;user;formulation;fact;paper", "pdf_keywords": ""}, "5cfdb162ffa4dce18f7c576d352bd459b6a11292": {"ta_keywords": "personalized coupons;discount coupons;party coupon provider;future purchases;purchase behavior;promotions;shopping;consumer spending;purchases;dining purchases;promotion;transactions;spending;consumers;temporal dynamics;sales account;predicts;weekends;urgency;time;next event;transaction records;right timing;category;category information;commission;dollars;duration;data;different categories", "pdf_keywords": ""}, "1ddcc9671dd6486e34cefadfe71bbbc1bc55035a": {"ta_keywords": "neural machine translation;source word embeddings;word embeddings;standard word embeddings;small corpus;subword information;ted subtitles;character level models;subword;available linguistic resources;rich language;word similarity task;arabic;nmt model;resource nmt system;nmt;naacl hlt;word;nlp proceedings;en mt;second workshop;resource settings;ar;impressive results;parallel data;large amounts;way;success;initialization;settings", "pdf_keywords": ""}, "33d2ebe41477811296abc4077bf9ce09b927ef98": {"ta_keywords": "voice conversion;voice conversion framework;voice conversion studies;speaker gmm;gaussian mixture model;speaker model;few parallel utterances;parallel corpus;utterances;joint density gmm methods;target speakers;noisy channel model;speakers;probabilistic densities;joint density model;training data;same linguistic content;nonparallel data;gmm;joint vectors;transform function;target;source;addition;sufficient quality;amount;novel framework;paper;effects;plenty", "pdf_keywords": ""}, "c0e8846eb5ce574a6dca3f3a600e82b184339254": {"ta_keywords": "language;utterances;underlying reward function;desirable actions;rewards;actions;new contexts;context;jetblue;jetblue \ufb02ight;information;speakers;classic instruction;preferences;general preference;maps;model;\ufb02ight;user", "pdf_keywords": "reward estimates;natural language utterances;reward functions;infers rewards;natural language;inverse reinforcement learning;language;utterances;rewards;mapping language;optimal actions;naturalistic interactions;actions;flightpref;task;\ufb01rst maps language;game;descriptions;new interactive \ufb02ight;instruction;information;interactions;underlying preferences;humans;people;environments;relative accuracy improvements;models;unseen environments;instruction following"}, "a3cc75975a5998d5a7dd494e70a479ba0a550013": {"ta_keywords": "tutoring;cognitive tutor;expert model;intelligent tutoring system;authoring processes;demonstration;synthetic student;demonstrations;simstudent problems;more demonstration;feedback;decision making;simstudent;performance;particular step;steps;fewer incorrect ones;author;results;more time;latter approach;hints;quality;correct steps;problems;contrast;following", "pdf_keywords": ""}, "04f4e55e14150b7c48b0287ba77c7443df76ed45": {"ta_keywords": "physical commonsense reasoning;physical commonsense;physical commonsense questions;question answering;natural language understanding systems;natural language;corresponding benchmark dataset physical interaction;knowledge;ai systems;questions;more physical domains;models;text;bert;challenge;more abstract domains;encyclopedia entries;task;bias;news articles;future research;progress;paper;question;piqa;kind;significant opportunities;analysis;dimensions;today", "pdf_keywords": "physical commonsense knowledge;physical commonsense reasoning;physical commonsense understanding;corresponding benchmark dataset physical interaction;question answering;language models;natural language;robots;language representations;knowledge;nlp community;dataset;new dataset;true aicompleteness;models;benchmark;future research;task;progress;piqa;major challenge;insight;construction;world;paper;road;goal;analysis;signi\ufb01cant opportunities;dimensions"}, "5e0f2f82b4a28d59f1aa8b8ffe497790de1cdf9d": {"ta_keywords": "deep reinforcement learning;reward function;catastrophic states;catastrophe state;reward;intrinsic fear;learning objective;catastrophes;catastrophe;dqns;catastrophic mistakes;agents;agent;supervised learning;policies;shaping;dangerous states;new policy;wild;toy problems;steps;guards;function approximation;probability;experiences;unacceptable performance;paper;approach;score;problems", "pdf_keywords": ""}, "7a9f4a8a99f9a38e9213da890f9eab6150ae928e": {"ta_keywords": "novel learnable proximity measure;personalized pagerank;similarity measures;edge label sequence;random walks;edge label;random walk;weight;prior work;reset", "pdf_keywords": ""}, "ebaae38a09c5a4909049e16af759c71db9cc87dc": {"ta_keywords": "natural language processing tasks;natural language inference;neural models;words;model prediction;many words;model confidence;mitigation;regular examples;input;inputs;robustness;simple training technique;answer;weaknesses;question;performance;discovery;problem;world applications;wrong reason;extreme;analysis", "pdf_keywords": ""}, "b17fa6625681d99370122145ba9911f701dd92cb": {"ta_keywords": "typical context modeling methods;semantic parsing;semantic parser;context modeling methods;context;frequent contextual phenomena;complex contextual phenomena;grammar;exploratory study;datasets;considerable attention;representative models;limited scenarios;world;significant improvements;state;potential research directions;previous works;light;best model;top;methods;art performances;analysis", "pdf_keywords": "typical context modeling methods;context modeling methods;semantic parser;contextual clues;better pronouns inference;frequent contextual phenomena;grammar;representative models;datasets;common sense;explicit manner;signi\ufb01cant improvements;sota;best model;state;top;potential research directions;performances;future work;light;\ufb01ne;analysis;art performances;art;potential directions"}, "bf4da952df7a6ef9c0b2be8b4b4b69ad63848b8f": {"ta_keywords": "traffic speed prediction;little historical traffic data;transfer learning framework;traffic speed;intelligent transportation systems;historical data;various effective spatiotemporal features;classic regression models;downstream applications;target areas;source areas;competitive performance;historical time;series data;areas;novel model;baseline methods;wide range;approaches;machine;large amount;experimental results", "pdf_keywords": ""}, "879cd78b0d4413aef614bc6b6cce075e8e6ad4be": {"ta_keywords": "streaming codes;stream;erasure channel;erasure channels;convolutional codes;live video trace;channel;source packets;arbitrary erasures;code constructions;code;erasures;code construction;delay;bursts;size arrivals;transmission;delay constraint;capacity;class;simple construction;size;new trade;higher rate;recent works;rate;several representative parameter settings;number;models;variability", "pdf_keywords": ""}, "bd318e959236b0d33a7567b6d3afc8d5e92b8ea3": {"ta_keywords": "ai agents;ai;more ai agents;ethical properties;ethical boundaries;ai systems work;ai technique;goal specifications;decision support systems;modular approach;subjective preferences;concrete examples;examplebased approach;freedom;notion;compositional approach;symbolic rule;decision making;contextual approach;isolation;scenarios;things;best path;essential ingredients;goal;data;approach;challenge;reason;unexpected situations", "pdf_keywords": "ethically bounded ai;ai;ai research;more ai agents;ai systems work;ethical properties;ai technique;ibm research;societal challenges;notion;abstract;isolation;concrete examples;society;compositional approach;ibm research yorktown heights;social sciences;internet;modular approach;scenarios;outstanding challenges;decision support systems;decision making;humans;things;world;paper;contextual approach;unexpected situations;pervasive use"}, "4a93f7654f795871ed99dece2e1805e4950fd194": {"ta_keywords": "spatial utterances;spatial language;utterances;generative probabilistic framework;human english speakers;semantic relations;comprehension data;spatial configurations;landmarks;tabletop scene;sentences;symbolic representations;referent;objects;physical locations;space;referents;probabilistic model;human performance;inference problem;sentence;proficiency;model;production;meaning;level;system", "pdf_keywords": ""}, "9e172f35b2b0ebcff090f01d40e61fa5aecefa68": {"ta_keywords": "various adversarial loss functions;adversarial losses;adversarial loss;adversarial training objectives;discriminative adversarial network setting;discriminative models;regularization approaches;regularization terms;divergence;deeper understanding;training;model distributions;component functions;different component functions;empirical results;data;like measure;framework;reference;future research;effects;theory;recent work;sufficient conditions;paper;extensive set", "pdf_keywords": ""}, "ebe04f06580abab035408c4c2e65245b3950934e": {"ta_keywords": "variable oil damper;earthquake input levels;base isolated structure;design method", "pdf_keywords": ""}, "dd36aca034312a266d6f10b37414d3342c3b9c79": {"ta_keywords": "knowledge base queries;faithful embeddings;supplementary material", "pdf_keywords": ""}, "17351cfeac949c266f4d1ff86c515250b931bdc2": {"ta_keywords": "inductive logic programming;markov logic networks;scalable probabilistic logic;probabilistic logic;structure learning;efficient structure learning;logic programs;large knowledge base;parameter learning;interpretive learning methods;structures;novel structure;mlns;graphs;multiple datasets;proppr;order theories;competitive baselines;order;ilp;foil;framework;tractable fashion;method;approach;paper;results;recent success;experiments;various settings", "pdf_keywords": ""}, "394e17f5ee5e8a734b2714795b7da3cd704716da": {"ta_keywords": "peer grading;ordinal evaluations;peer evaluation;ordinal approach;other students;moocs;students;cardinal scores;evaluation;lectures;student;conventional classrooms;conventional cardinal approaches;evaluators;download study material;precision;number;feedback;answers;critical aspect;videos;robustness;information;experts;expertise;evidence;ease;means;anyone;set", "pdf_keywords": ""}, "57e4074c588c0e27e4c0bc89f12512ccdb900d79": {"ta_keywords": "unsupervised text style transfer;unsupervised style transfer tasks;other recent unsupervised style transfer;unsupervised machine translation techniques;deep generative model;machine translation techniques;style transfer tasks;recurrent language model;sentiment transfer;parallel corpus;adversarial loss;author imitation;related language translation;parallel latent sequence;unsupervised fashion;backtranslation;decoder;formality transfer;variational objective;encoder;transduction distribution;probabilistic formulation;word decipherment;probabilistic approach models;probabilistic view;sequence;prior;sequences;model;data", "pdf_keywords": "standard unsupervised machine translation task;unsupervised text style transfer tasks;unsupervised text style transfer;unsupervised style transfer tasks;text sequence transduction systems;sentiment transfer;deep generative model;related language translation;parallel corpus;formality transfer;author imitation;text sequence;natural unsupervised objective falls;amortized variational inference;deep neural systems;word decipherment;iclr;probabilistic approach models;probabilistic formulation;graham neubig carnegie mellon university;welling;uni\ufb01ed approach;principled probabilistic technique;domains;natural objective;current state;taylor berg;probabilistic principles;conference paper;suite"}, "8a99e1eb3285f127eed7169441679d47be7f1633": {"ta_keywords": "text generation tasks;text generation;free grammar;splicing together nearest neighbors;neighbor text;generation;text;shortest such derivation;target pairs;oracle derivation;generations;particular weighted context;segments;neighbor;data;neighbors;source;training;policy;right;standard techniques;recent work;conditions", "pdf_keywords": "text generation tasks;text generation;splicing together nearest neighbors;free grammar;sourcetarget pairs;generalized insert function;oracle sequence;strong baselines;generationby;neighbor text;shortest sequence;particular weighted context;training generation;generation;insert actions;automatic metrics;text;such manipulations;wikibio datasets;spans;microsoft research;training example;oracle one;segments;actions;arbitrary positions;human evaluation;neighbor;comparable quality;interpretability"}, "3c40fc36217a56aafb0abc735ff7d132b17e83a0": {"ta_keywords": "automatic melody harmonization;harmonic accompaniment;bar melody sequence;chord sequence;deep learning method;triad chords;deep learning;genetic algorithm;template matching;hidden markov model;objective evaluation;model;canonical approaches;performance;task;different metrics;comparative study;result;participants;subjective study;paper", "pdf_keywords": "automatic melody harmonization;total \ufb01ve melody harmonization models;melody harmonization;keywords symbolic music generation;deep recurrent neural network;deep learning;hooktheory pianoroll triad dataset;music;rnn;hidden markov model;functional harmony;hidden markov;template matching;models;genetic algorithm;model;new dataset;canonical approaches;template;canonical methods;performance;variants;contributions;task;lead sheet samples;approaches;number;giraldo;paper;set"}, "77efa3102456c9f921b05b95eefe845d2ce6bc4b": {"ta_keywords": "minimum relative entropy discrimination;discriminative training method;conventional discriminative training methods;regularization techniques;speech recognition;convex optimization;acoustic models;optimization method;plane algorithm;constraints;approximation method;bayesian interpretations;realization method;mred;solver;ad;order;principle", "pdf_keywords": ""}, "803a0d2677a7d6b20c3964533595775fa5c7c750": {"ta_keywords": "pairwise comparison models;world pairwise comparison data;ranked preference data;pairwise comparisons;total ranking dataset;pairwise comparison data;rankings;demographic divisions;relative performance;ratings;sample testing;sample complexity;european football teams;test;testing algorithms;sample test;world datasets;lower bounds;results;significant difference;samples;data;sushi preferences;gender;thurstone;modeling assumptions;assumptions;sst;mst;people", "pdf_keywords": "ranked preference data;comparison models;ranking data;rankings;total rankings;comparison data;comparisons;preference data;sample tests;sample testing;statistics2;aarti singh1 machine learning department1;pairwise;results;thurstone;lower bounds;stat;mst;sst;world data sets;modeling assumptions;assumptions;ml;range;computer science department3;btl;charvi rastogi1;number;wst;extensive simulations"}, "c859416a8e5682bee3c35df29bc02e02a22de072": {"ta_keywords": "automatic speech recognition tools;automatic transcriptions;automatic transcription;speaker speech transcription tool;language documentation;language documentation workflow;persephone toolkit;linguist;linguists;source toolkit;language;yongning na;tools;automatic recognition;speech;persephone;na data;practical usefulness;data collection;technology;development;southwest china;low error rate;requirements;practical recommendations;friendly interfaces;type;resource setting;early stages;canvas", "pdf_keywords": ""}, "90705ece92a71efcf256cd047da53cbc1d4e5295": {"ta_keywords": "gear mesh impact theory;gear meshing impact;gear meshing frequency component;gear vibration data;meshing frequency;meshing impacts;transient dynamics analysis;fast kurtogram;gear;frequency band;test rig experiment;heavy load;impacts;structure resonance;signal;load;analysis results;filtering;fk;method;relationship;causes;system;results;point;paper", "pdf_keywords": ""}, "30fa01df767339a6c8bd37c32160992fcb19ed18": {"ta_keywords": "empirical games;empirical game;approximate nash equilibria;bounding regret;scale games;new optimization goal;sample complexity results;saucb;extensive experiments;quantitative guarantee;deviation;variants;better performance;prior work;computation;theoretic analysis;techniques;several baselines;models;set;quality;number;ne;lack;output;problem", "pdf_keywords": ""}, "196be0bdec3b7bcb3ee35cd126fb2730a9d742d6": {"ta_keywords": "simstudent;tutor effect;educational software infrastructure;students;computer agent;line learning environment;interactive event;others;peers;phenomenon", "pdf_keywords": ""}, "46619f0547b1a9c2e7649d0e5c931e9aa857a938": {"ta_keywords": "covid;tracking project", "pdf_keywords": ""}, "8963602d4b9c3b1054a5ed6fb2a2088dec774824": {"ta_keywords": "personal information management tools;information management;machine learning;personal information;email messages;difficult searches;management;machine;computer technology;items;workstation documents;task;performance;calendar entries;context;track;techniques;awareness;type;part;experimental evidence;others;whole;ways;cost error;certain types;directions;visible current uses", "pdf_keywords": ""}, "daedf33077099f7c808e9f4022469e15bf224ad7": {"ta_keywords": "transcriptome expression profiling;kidney transplants;chronic injury;biopsy;prospective study;risk", "pdf_keywords": ""}, "59d487d6ef839c82ae128550e35fa44058b03d37": {"ta_keywords": "implementation;model;paper;data", "pdf_keywords": ""}, "60ce57713261b41fe2e3d222f1d4530c4fc69241": {"ta_keywords": "probabilistic serial rule;probabilistic serial;polynomial time;computational complexity;expected utility;lexicographic best response;assignment problem;ps rule;agents;agent;time algorithm;rules;rule;np;best response;better response;case;ps;study;other hand", "pdf_keywords": "multiple agents;optimal manipulation;computational complexity;sequential allocation;ordinal preferences;expected utility;other agents;agents;agent;lexicographic best response;ps rule;utilities;time algorithm;preferences;complex task;houses;complete knowledge;nphard;best response;dl;better response;eu;case;ps;other hand;study"}, "74d8a998269bcdd087a21840b0e28d86c256c121": {"ta_keywords": "more general preference models;preference models;pac learning;utility models;learnability;active learning algorithms;learning bounds;naive algorithms;intertemporal choice;learner;models;choice;guarantees;pac;membership queries;large class;exponential improvement;data;vc dimension;structural criterion;time;stream;higher level;exponential;questions;form;setting;time periods;full power;situation", "pdf_keywords": "quasihyperbolic discounting;more general preference models;time dependent choice;preference models;utility models;preference model;intertemporal choice;preference relations;weighting decisions;learnability;learning bounds;choice;models;naive algorithms;time delays;guarantees;model;exponential improvement;time;preliminaries;agent;structural criterion;criteria;cal;large class;quirements;vc dimension;signi\ufb01cant freedom;pac;stream"}, "c994372b3c33bbc1ad6b504c5efb5afd515a5009": {"ta_keywords": "target speech extraction;speaker identity loss;speech recognition;auxiliary loss function;target speaker;mixture consistency loss;speech;correct speaker characteristics;speaker characteristics;such weak supervision;weak supervision;libricss dataset;word error rate;real recordings;original mixture;recognition;adaptation;only supervision;loss;loss yields;additional improvements;parts;several segments;sources;data;system;\ufb01rst", "pdf_keywords": ""}, "09d88e0bb8863fd402030aeb625c52c0492c4fef": {"ta_keywords": "robust automatic speech recognition;reverb challenge development;deep recurrent;proposed asr system;encoders;asr;model adaptation;feature transformations;word error rates;machine interaction;challenge baseline;early fusion scheme;dae;environments;hands;real data;joint efforts;significant improvement;end;complementary performance gains;paper;results", "pdf_keywords": ""}, "320278b24a3c53a44f95e8ef5465bebe56f24225": {"ta_keywords": "pause prediction;joint dependency parsing;dependency parsing;pauses;prosodic information;speech;disfluency detection;dependency tree;dependency structure;correct dependency tree;syntactic structure;text;shift;prediction;latent variables the;latent variable;sentence;tasks;joint model;data;baselines;black text;correct action sequence;model;actions;section;basic technology;work;paper;effective use", "pdf_keywords": ""}, "568462ab0a0a59a2575b70db2cd9022572526f3f": {"ta_keywords": "learning dynamics;implicit learning dynamics;stackelberg games;stackelberg game;simultaneous gradient descent;continuous games;novel gradient;stackelberg equilibria;sum games;generative adversarial networks;simultaneous play games;games;nash equilibrium solution concept;hierarchical decision;stochastic updates;deterministic updates;machine learning problems;local convergence rate;equilibria characterization;dynamics;implicit function;rotational behavior;only critical points;natural structure;sum;empirical study;convergence analysis;structure;contemporary work;exhibit benefits", "pdf_keywords": ""}, "92622a58377a4671b2ba59e8e59b19b0ab5119bb": {"ta_keywords": "knowledge graph identification;knowledge graph construction;knowledge graphs;ontology graph;ontology;ontological constraints;entities;partitioning;powerful extraction engines;hash;noisy extractions;extractions;relations;such graphs;billions;attributes;model performance;relationships;millions;superior results;kgi;model;powerful representation;results;uncertain inputs;approaches;magnitude speedups;order;techniques;numerous challenges", "pdf_keywords": ""}, "2ab481028dda04197283c03115bb5f46f5998cc3": {"ta_keywords": "russian thesauri;linked open data", "pdf_keywords": ""}, "582089a00a6c9fb534f16d1dbbafc50cc4e3912a": {"ta_keywords": "schema aware semantic reasoning;natural language query interfaces;schema aware semantic reasoning framework;interpreting natural language queries;specialized query language;ontology reasoner;bi queries;ontology;schema details;natural language interpretation;natural language question;system athena;solvable tasks;bi;enterprise settings;information;data storage;benchmarks;better results;framework;users;need;average accuracy improvement;paper;sequence;top;state;end;art;experiment", "pdf_keywords": ""}, "1adadbfa95e43a70fcd17e6ce947a0652b86bfc3": {"ta_keywords": "colossal clean crawled corpus;documenting large webtext corpora;larger text corpora;other benchmark nlp datasets;many nlp tasks;large language models;machine translation systems;blocklist filtering;common crawl;unexpected sources;dataset;researchers;content;text;first documentation;filters;remarkable progress;patents;data;military websites;evaluation examples;minority individuals;case study;machine;single snapshot;impact;significant amount;c4;work;us", "pdf_keywords": "colossal clean crawled corpus;webtext corpora;other benchmark nlp datasets;negative sentiment;positive sentiment;ethnicity;arab;bias;eastern black arab african;common crawl;representational harms;disparate cooccurrences;words;demographic identities;machine translation systems;paragraphs;american latino middle;american african;source;word;content;web;dataset;positivity;li et al;text;evaluation examples;geographic origins;commoncrawl;\ufb01lters"}, "90129b0733ac48ead26b7c86e8b4df917568e208": {"ta_keywords": "heterogeneous databases;textual similarity;common domains;queries;integration", "pdf_keywords": ""}, "02d98ca8f4ecd1a2b885d6867f4c1407ae8d1007": {"ta_keywords": "active queries;human annotators;weak supervision;active learning;manual annotations;parsers;different active learning heuristics;such queries;extra supervision;full supervision;wikisql show;weak learning signal;examples;learner;query;wikitablequestions;input;cold start;effectiveness;performance;accuracy;large space;difficulties;spurious mrs;model;different datasets;baseline;experiments;gap;method", "pdf_keywords": "semantic parsers;semantic parsing;semantic parser;semantic parser maps;natural language commands;semantic parsing maps;human annotators;active supervision;parsers;human annotator;weak supervision;extra supervision;annotator;nl utterances;manual annotations;natural language;active queries;active learning;executable meaning representations;nl;utterance;search;parallel corpora;general purpose programming languages;learning;training;executable meaning representation;query selection heuristic;learner;nls"}, "601398838250a4e69c69cc339d65f5c51e727ad1": {"ta_keywords": "role question generation;question generation;possible semantic roles;contextualized questions;semantic role;independent question prototype;questions;predicate mention;predicate;context;role;passage;text;task;answers;inherent step;stage model;conditioning;approaches;situation;approach;set;end", "pdf_keywords": "\ufb02uent natural language questions;information extraction tasks;semantic relations;natural language text;natural language question;semantic role;questions;annotated data;syntactic structure;predicates;broadcoverage ontology;srl questions;qa;predicate;ontology;information;relations;automatic generation;arguments;context;text;introduction;passage;essential communicative ability;traditional srl;representations;speci\ufb01c;\ufb02exible format;bene\ufb01ts;roles"}, "c783bc02f5f901e4604eb3b0d504a036369afd91": {"ta_keywords": "sr2tio4;srlaalo4;srtio3;perovskite layer;laalo3;line intensity;energy;comparative study", "pdf_keywords": ""}, "a3452276ada37727d0008dad8ca7c27bbbee6984": {"ta_keywords": "rumor classification;rumor detection methods;rumor detection method;hierarchical graph attention network;twitter datasets;conversation structures;conversation structure;fake claims;rumors;conversation thread;posts;user responses;irrelevant posts;target claim;claim;entire social contexts;responsive posts;undirected interaction graph;user opinions;representation;extensive experiments;negative impact;valuable clues;strict relation;interaction;state;early stages;art methods;superior capacity;study", "pdf_keywords": "rumor detection;early rumor detection;hierarchical graph attention network;hierarchical graph attention networks;rumor classi\ufb01cation;tweet contents;lic twitter datasets;twitter;realworld twitter;social media;rumors;informative posts;attention;entire conversation context;embeddings;posts;debunking;undirected interaction graphs;inference;node information;target claim;undirected interaction graph;aware attention;latent space;interaction graph;claim;graph;mingfei cheng1;entire social contexts;gat"}, "19be8dd52d949fed1a3e5aca7630669da2575d73": {"ta_keywords": "uncertain linear preferences;stable matching;sided stable matching setting;linear preferences;weak preference order;lottery model;matching;compact indifference model;uncertainty;preference profiles;stability probability;lottery;joint probability model;highest probability;preferences;probability distribution;models;computational complexity;agents;communication;agent;weak order;limited information;linear order", "pdf_keywords": ""}, "35ee53492c7f32dbb3b4ed7ba4d1395218b13ee9": {"ta_keywords": "everyday algorithm auditing;such auditing behaviors;organic auditing behaviors;formal auditing approaches;auditing;problematic machine behaviors;everyday users;algorithmic systems;everyday interactions;harmful behaviors;detection;tools;algorithms;day interactions;everyday use;day;awareness;users;systems;process;future platforms;major blindspots;work;world cases;concept;critical issues;paper;context;design;cases", "pdf_keywords": "everyday algorithm auditing;everyday algorithm audits;such auditing behaviors;everyday audits;auditing;problematic machine behaviors;everyday users;algorithmic guidance;expert guidance;algorithmic systems;potential design interventions;community guidance;day interactions;algorithms;organizational guidance;detection;tools;incentivization;day;awareness raising;testing;process;initiation;users;future platforms;concept;lifetime;future research;design;knowledge"}, "1f38ba33063f118f574cf57ff9f1a0e7de2857ff": {"ta_keywords": "russian semantic similarity evaluation;semantic similarity;russian nouns;russian language;gram models;rich morphology;russian;russe;free word order;language;languages;di erent sources;dialogue;sophisticated supervised models;english;di erent;comparative studies;contest;task;such measures;evidence;conjunction;lot;conference;gap;submissions;features;overview;analysis;paper", "pdf_keywords": "russian semantic similarity;semantic similarity measures2;gram models;russian language;raw text corpus;novel benchmark datasets;gram model;novel test datasets;russian;unsupervised skip;russe;benchmarks;english;best submissions;results;source tool;task;best results;submissions;orthographic features;analysis;evaluation methodology;first workshop;end;key contribution;complex methods;successful approaches;teams"}, "857036a25401c19e484cc32d974c90cd9a46cd66": {"ta_keywords": "local nash equilibria;local optimality;iterative steepest descent algorithm;optimal control theory;nonlinear programming;local convergence;numerical approximation;continuous games;games;computational techniques;dimensional differentiable manifold;algorithm;generalizations;computation;order conditions;dimensional hilbert space;characterization;results;sufficient condition;analogy", "pdf_keywords": ""}, "d473ff103565d8c76e0cbfa33bdd4b0db1cbb23f": {"ta_keywords": "bid auction games;complex bayesian games;mixed equilibrium computation methods;finite strategy;strategy generator;agent strategies;loop regret minimization;natural evolution strategies;incremental strategy generation framework;pure equilibrium computation;mixed equilibrium computation;best response optimization;strategies;sum payoffs;optimization process;response strategies;iterative algorithm;neural networks;equilibria;noisy payoff samples;nes;box simulation access;players;action spaces;methods;loop;model;parametric form;environments;function space", "pdf_keywords": "bid auction games;complex symmetric bayesian games;simultaneousauction games;pure equilibrium computation method;mixed equilibria;\ufb01nite strategy;games;equilibria;minimax;optimization process;deep models;mixed bne;complex strategic landscape;box optimization technique;mbne;lower regret;nes;pbne;global convergence method;expressive power;model;environments;classical analytical approach;general class;methods;dimensional generalization;vorobeychik;solutions;smoother topology;distinct type distributions"}, "ecd2b355f250abfd4eb9d6c7c598c33c7cd6bcb0": {"ta_keywords": "regularized minimax conditional entropy;real crowdsourcing datasets;minimax conditional entropy principle;crowdsourcing;unique probabilistic labeling model;labels;objective measurement principle;ordinal labels;ground truth;item difficulty;workers;high quality;principle;worker ability;paper;variety;only method;method", "pdf_keywords": ""}, "0fc01a915cc7bf7025f80d44f805bd54b6425a33": {"ta_keywords": "arbitrary nonintrusive load monitoring;aggregate power consumption signal;device usage;measurement noise;general nilm algorithm;nilm;sampling rate;gaussian;real data;scenarios;algorithm;bounds;probability;general case;case;theory;framework;function;results;error", "pdf_keywords": "nilm algorithms;general nilm algorithm;additive gaussian noise;measurement noise;sampling rate;real data;devices;device usage;scenarios;probability;general case;bounds;scenario;number;building;paper;case;framework;theory;function;\ufb01nite number;error;results;fundamental limits;\ufb01nd"}, "16457c13a40aa589fa06d8533a47b3f96aede474": {"ta_keywords": "canopy;securing;stakes;flexible covering;graphical framework;building;shields;main frame;mutual support;bows;ground;contextual search;shield;vegetables;wall;pack;articles;name disambiguation;back position;email;pair;opposite directions;back", "pdf_keywords": ""}, "639cc01afcc1c78063f7a6bbdae998cd147911c4": {"ta_keywords": "robust parametric utility learning framework;robust utility learning framework;robust utility;utility functions;feasible generalized least squares estimation;heteroskedastic inference;occupant voting data;ensemble methods;inverse optimization;forecasting performance;nash competition;smart building occupants;efficient behavior;energy;continuous game;game;social game experiment;lighting;sustainability goals;data;toy example;noncooperative players;user interaction;scheme;gradient;many smart infrastructure applications;bagging;bertrand;performance;bumping", "pdf_keywords": "robust parametric utility learning framework;robust utility learning;robust utility learning framework;utility learning framework;robust utility;feasible generalized least squares estimation;heteroskedastic inference adaptation;utility functions;heteroskedastic inference;inverse optimization;ensemble methods;energy ef\ufb01cient behavior;models;smart building occupants;forecasting performance;approximated correlations;nash competition;continuous game;sustainability goals;smart building;noise covariance;occupant voting data;game;players;general framework;incentive design;gradient;data;lighting;correlations"}, "03d2af05e41aac58ebae4ab37f09155e53d4b35b": {"ta_keywords": "bit matrix completion;bit observations;probit observation models;matrix completion;maximum likelihood estimate;bit measurements;convex program;suitable constraint returns;likelihood;estimate;accurate estimate;bit;theorems;extreme case;data;concave function;theory;entries;log;requirement;experiments;measurements;distribution;subset;practical applications;small number;paper;implications;suite;probability distribution", "pdf_keywords": "bit matrix completion problem;unquantized matrix completion problem;compressed sensing;convex programming;binary observations;convex programs;binary measurements;unknown matrix;rank;accuracy;bit;pair;problem;upper bounds;paper;theory;setting;distribution"}, "3bfa1fe0a8d031d59dfc0cfa4975c296951ee56c": {"ta_keywords": "integrated speech enhancement;speech recognition;recognition system;rooms;temporal modeling;sounds", "pdf_keywords": ""}, "8873d1369590249113e1f0491ce49d1502395b9c": {"ta_keywords": "trainable compliance network;compliancenet;text compliance;automatic compliance checking;compliance;compliance labels;compliance problem;videos;activity verification;text instruction;natural language instructions;text instructions;vtc dataset;human activity;dataset;video;atomic activities;baseline accuracy;efficient feedback;vtc;world settings;end;novel end;solutions", "pdf_keywords": ""}, "7488429131b8970425a66f3410920d98ff6e9c36": {"ta_keywords": "evaluations;biases;ratings;teaching quality;regularization;students;higher rating;reviews;conference organizers;submissions;ordering constraint;conference;instructors;outcome;higher grades;universities;information;quality;optimization problem;papers;method;external factors;example;items;course;applications;people;authors;work;problem", "pdf_keywords": "debiasing evaluations;regularization;bias;evaluations;evaluation;ordering constraint;peer review;ml;optimization problem;statistics;data;items;estimator;jingyanw;value;such outcome;common applications;method;carnegie mellon university;people;dependent manner;help;set;appropriate amount;school;notion;problem;abstract;dec"}, "579e01c3c864cc98e57c728f84fcf553c5b1bcba": {"ta_keywords": "audible murmur enhancement method;silent speech interfaces;audible murmur;soft whispered voice;microphone;silent speech communication;noise contamination;conductive microphones;acoustic changes;noise;noisy environments;conductive recording;enhancement methods;enhancement performance;promising medium;naturalness;style changes;nam;experimental results;intelligibility;effect;body;framework;evaluation;cases", "pdf_keywords": ""}, "4f1eef4acaf0164593b9e654dba4b8cd3e72421d": {"ta_keywords": "stacked graphical learning;collective classification;graphical learning;efficient inference;base learner;relational datasets;classification;markov random fields;other related instances;datasets;instance;inference;instances;classes;gibbs;dependencies;class;predictions;features;group;times;scheme;kind;notes;experiments", "pdf_keywords": ""}, "31884a623af77136413d997049b5787b394db461": {"ta_keywords": "\u51fa\u529b\u7cfb \u5217\u306e\u9577\u3055\u306e\u6307\u5b9a\u3092\u5165\u529b\u3068\u3057\u3066\u53d7\u3051\u53d6\u308b\u3088\u3046\u30e2\u30c7\u30eb\u306e\u62e1\u5f35\u3092 \u884c\u3044;\u30e6\u30fc\u30b6\u306b\u3088\u308a\u5165\u529b\u3055\u308c\u305f\u6240\u671b\u306e\u9577\u3055\u306b\u5fdc\u3058 \u3066\u67d4\u8edf\u306b\u51fa\u529b\u3059\u308b\u8981\u7d04\u9577\u3092\u5236\u5fa1\u3067\u304d\u308b\u3053\u3068\u306f\u975e\u5e38\u306b\u91cd\u8981 \u3067\u3042\u308a;\u63a2\u7d22\u6642\u306b\u9577\u3055\u306e\u5165\u529b\u3092\u53d7 \u3051\u53d6\u308b;\u6587\u66f8\u8981\u7d04\u5206\u91ce\u306b\u304a\u3051\u308b \u5b9f\u9a13\u8a2d\u5b9a\u3067\u306f\u539f\u6587\u66f8\u3068\u540c\u6642\u306b\u8981\u7d04\u306e\u9577\u3055\u5236\u9650\u3092\u5165\u529b\u3059\u308b \u306e\u304c\u6a19\u6e96\u3068\u306a\u3063\u3066\u3044\u308b;\u5b66\u7fd2\u3092\u901a\u3057\u3066\u51fa\u529b\u9577\u306e\u5236\u5fa1\u80fd\u529b\u3092\u7372\u5f97\u3059\u308b;decoder\u30e2\u30c7\u30eb\u306b\u3088\u308b\u6587\u8981\u7d04\u306b\u53d6\u308a\u7d44\u3093\u3060\u5f93\u6765\u306e\u7814 \u7a76\u3067\u306f;\u6a19\u6e96\u7684\u306a encoderdecoder\u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u3057\u305f\u306e\u3061;encoder;\u51fa\u529b\u3059\u308b\u8981;\u8981\u7d04\u5668\u304c\u6301\u3064\u3079\u304d\u91cd\u8981\u306a\u80fd\u529b\u306e\u4e00\u3064\u3068\u3057\u3066;\u3053\u306e\u51fa\u529b\u9577\u306e\u5236\u5fa1\u3068\u3044\u3046\u70b9\u306b\u3064\u3044\u3066\u660e\u78ba\u306b\u53d6\u308a\u7d44;\u539f\u6587\u66f8\u304b\u3089\u628a\u63e1\u3057\u305f\u3044\u60c5\u5831\u306e\u7c92\u5ea6\u3084\u8981\u7d04 \u3092\u8aad\u3080\u30c7\u30d0\u30a4\u30b9\u306e\u5927\u304d\u3055\u306a\u3069;\u5fc5\u9808\u306e\u80fd\u529b\u3067\u3042\u308b;\u6b8b\u308a\u306e\u4e8c\u624b\u6cd5\u306f\u5b66\u7fd2\u306b\u57fa\u3065\u304f\u3082\u306e\u3067\u3042\u308a;\u308b\u8981\u7d04\u306e\u9577\u3055\u306f;\u6771\u4eac\u5de5\u696d\u5927\u5b66 tokyo institute;\u5948\u826f\u5148\u7aef\u79d1\u5b66\u6280\u8853\u5927\u5b66\u9662\u5927\u5b66 nara institute;\u305d\u306e\u91cd\u8981\u3055\u306b\u95a2\u308f\u3089\u305a;\u672c\u7814\u7a76\u3067\u306f;\u3057\u304b\u3057;technology;\u5b9f\u969b;science", "pdf_keywords": ""}, "2818bd090206ef33f9d7e1be03bc4f742c6762d1": {"ta_keywords": "agglutinative language;agglutinative languages;suffixes;morpheme;several morpheme;large vocabulary asr system;language models;uyghur language;syllable;vocabulary;prefix;words;several asr results;word;julius system;stem;different units;root;explosive nature;result;basis;research;experiments", "pdf_keywords": ""}, "8f99f9409f254134aa32fbf072475100f688d613": {"ta_keywords": "secure regenerating codes;theoretic secrecy capacity;storage networks;distributed storage;storage nodes;eavesdropper;efficient node repair;codes;availability;threat model;reliability;information;nodes;data;repair;access;class;explicit constructions;paper;subset;setting", "pdf_keywords": "theoretic secrecy capacity;secure mbr code;secure msr code;secure mbr;storage nodes;eavesdropper;msr codes;storage system;codes;msr code;message symbols;capacity;random symbols;repair algorithm;threat model;information;nodes;symbols;mbr;side information;explicit constructions;access;\ufb01nite \ufb01eld fq;data;network;present paper;repair;msr;parameters;paper"}, "b130b6387b105ecd9b4718b179b1e128157f9516": {"ta_keywords": "parametric paraphrase models;new short phrase paraphrase tasks;paraphrase database;paraphrase model;compositional paraphrase model;paraphrase;extensive semantic resource;phrase;bigram similarity tasks;ppdb;strong baselines;standard word;confidence estimates;confidences;coverage;models;incomplete coverage;internal scores;list;back;heuristic nature;art results;state", "pdf_keywords": ""}, "191543c7cb084d3af6a48ae771ca3dfd0588ab22": {"ta_keywords": "recommendation tasks;review text;deep learning methods;reviews;recommender systems;latent representations;review;deepconn;neural nets;latent representation;recommendation;second latent representation;text;transnets;layer;target user;recent model;target item;predictive value;information;performance;example;way;training time;art performance;traditional methods;state", "pdf_keywords": "deep cooperative neural networks;recommendation tasks;deep learning methods;neural nets;deepconn;latent representations;review text;actual review wri;latent representation;reviews;recommender systems;representations;second latent representation;recommendation;transnets;convolutional layer;regression layer;layer;recent model;text;william cohen;target item;target user;max;item;example;performance;computer science carnegie mellon university;rose catherine;user"}, "c72cdb5ce7e0911c7f442ab503652d6fdeef35e0": {"ta_keywords": "grounded semantic parsing;semantic parsing;different syntactic ccg parsers;induced ccg parsers;much syntactic supervision;downstream semantic analysis;semantic slot;unsupervised grammar induction systems;declarative sentences;semantics;evaluation;answers;task;extrinsic;new freebase;style questions;spades;dataset;weaknesses;effectiveness;strengths;unique window", "pdf_keywords": "semantic parsing;ccg parsers;semantic evaluation;grammars;semantic information;declarative sentences;ccg categories;words model;sentences;lexicon;pos tags;ccg derivations;words;extrinsic evaluation;useful structure;utility;pos;supervision;answers;task;input;new freebase;bag;extent;spades;\ufb01rst;style questions;systems;goal;strengths"}, "61d2dda8d96a10a714636475c7589bd149bda053": {"ta_keywords": "rnn encoders;review network;rnn decoders;caption generation;cnn;encoder;review step;thought vectors;attention mechanism;review steps;decoder;networks;decoder model;thought vector;decoder framework;input;paper;states;novel extension;number", "pdf_keywords": ""}, "12239e761e8c7cd05e12e18f43dba7b46dfd8ac1": {"ta_keywords": "source neural machine translation;data augmentation approach;data augmentation;source language;multiple sources;single target language;parallel text;target language;multiple languages;different language combinations;such incomplete parts;nmt;significant gains;systems;experiments;paper", "pdf_keywords": "source neural machine translation;source translation systems;machine translation outputs;incomplete multilingual corpora;translations;data augmentation approach;data augmentation;source language;translation;single target language;such incomplete parts;target language;different language combinations;multiple languages;nmt;source examples;yuta nishimura1;input sentence;takayama;data;nara 630;katsuhito sudoh1;sudoh;cho;ikoma;improvements;bleu;abstract;figure;japan 2carnegie mellon university"}, "d2a2be6ce932a0f1939f31cfff4d64ea3d76723d": {"ta_keywords": "adversarial attacks;contemporary classifiers;robustness;explicit training;robust;improved generalization;new benchmark dataset;classification;distribution test datasets;human labels;dataset;human uncertainty;cifar10 test;training;human;like uncertainty;cifar10h;image;full distribution;ability;confers;gap", "pdf_keywords": "adversarial attacks;human category uncertainty;human perceptual similarity;explicit training;human labels;alternative label distributions;human uncertainty;improved generalization;new benchmark dataset;training classi\ufb01ers;distribution test datasets;image classi\ufb01cation;generalization;dataset;like uncertainty;model generalization behavior;models;human;distributional shift;training;evaluations;imagelevel;performance benchmark assessing model \ufb01t;image;scale evaluation;contemporary classi\ufb01ers;cifar10 test;information;paradigms;knowledge"}, "1668b0b9cc631cdfc0dfaf77b71627f5524a866c": {"ta_keywords": "smooth stochastic convex optimization;accelerated directional derivative method", "pdf_keywords": "smooth stochastic convex optimization;smooth stochastic convex optimization problems;smooth stochastic convex;accelerated directional derivative method;novel directional derivative methods;free optimization;accelerated gradient;directional derivatives;accelerated algorithm;optimization;objective function;noisy oracle;free methods;complexity results;algorithms;complexity;admissible noise levels;norms;pavel dvurechensky;algorithm;eduard gorbunov august;methods;corollaries;context;general assumptions;bounds;problem dimension;square root;terms;paper"}, "3e398bad2d8636491a1034cc938a5e024c7aa881": {"ta_keywords": "cnn backbones;pyramid vision transformer;cnn;many dense prediction tasks;cnns;convolutions;various dense prediction tasks;vision transformer;convolutional neural networks;dense prediction;pyramid;convolution;computer vision;object detection;various vision tasks;large feature maps;image classification;transformer;semantic segmentation;high output resolution;image;free backbone network use;many downstream tasks;versatile backbone;unified backbone;vit;pvt;dense partitions;resolution outputs;memory costs", "pdf_keywords": "reduction attention layer;pyramid;transparent object;memory resources;transformer;highresolution;limited computation;wild"}, "115f1366318e7622f89f3a870e5863282670b1ad": {"ta_keywords": "statins;serum creatinine;preoperative use;protective effects;protective factor;independent protective factor;multicenter retrospective observational study;percutaneous coronary intervention;aki;pci;prevention;coronary angiography;sir run run shaw hospital;logical regression;patients;ldl;medical consortium hospitals;analysis model;conclusion;post;yrs;effect;lipid;mean age;multivariate;cag;pc;severe complication;results;72hrs", "pdf_keywords": ""}, "d516daff247f7157fccde6649ace91d969cd1973": {"ta_keywords": "model interpretability;remarkable predictive capabilities;models;mythos;machine;deployment", "pdf_keywords": "interpretable models;interpretability;interpretability techniques;deep neural networks;models;machine learning;technical descriptions;linear models;model properties;different notions;notions;motives;concept;transparency;motivations;incompatibility;assertions;desirability;myriad notions;wild;humans;interest;feasibility;problems;techniques;papers"}, "5ba57ff3c3e6e319586b86a990b6e082f4ecf972": {"ta_keywords": "bayesian speech recognition framework;speech recognition;speech classification;variational bayesian estimation;variational bayesian approaches;speaker adaptation tasks;other bayesian techniques;bayesian approaches;robust acoustic modeling;bayesian information criterion;maximum likelihood approaches;clustering;generalization ability;machine learning fields;vbec;model complexity control;map;statistics;bic;applications;advantages;effectiveness;addition;paper", "pdf_keywords": ""}, "e5d143ae82ede67726aa1a9aeac3de4bf53d8920": {"ta_keywords": "approach knowledge based vision;knowledge graph embeddings;language pretraining;various multimodal tasks;commonsense knowledge;image object tags;learning;okvqa tasks;many realworld tasks;representations;nlvr;logical reasoning;text;models generalization;vqa;transformer;vlp;advantage;baselines;gqa;kb;impressive performance;interpretability;performance;techniques;end;shelf models;experiments", "pdf_keywords": ""}, "7f52e3914a61994f68583635e43bc1bb9203e3b3": {"ta_keywords": "genetic toxicity;tobacco habits;dna damage frequency;experimental smokers;cytogenetic consequences;smoking habits;health effects;chromosome type;chromosome aberrations;biological markers;genetic modifications;cofs exposures;dna modifications;cooking oil fumes;food industry workers;preventive measures;chromatid type;experimental subjects;workers;current study;substantial risk;micronucleus changes;further molecular analysis;cofs;destructive level;working environment;mn;group ii;control subjects;high frequency", "pdf_keywords": ""}, "60a4ad8e8f4389f317d109550f5da2a571cbb515": {"ta_keywords": "factoid question answering;natural language query;large corpus;corpus;retrieval system;answers;posts;queries;subtasks;quasar;trivia questions;various internet sources;datasets;documents;software entity tags;text;relevant sentences;relevant pieces;challenge;cloze questions;query;comments;powerful neural models;cloze;popular website stack overflow;answer;several baselines;gap;fill;background", "pdf_keywords": "question answering by search;natural language query;answer context excerpt;large corpus;queries;quasar datasets;search;answers;reading;various internet sources;quasar;qa;datasets;text;new datasets;passages;side scripting;javascript;language;java;tasks;trivia questions;art machine readers;software entity tags;relevant passages;de\ufb01nitions;popular website stack over\ufb02ow;cloze;scale datasets;research"}, "15513c732d6af975f312307be3b5e2bd674ac0ef": {"ta_keywords": "speech recognition errors;word error rate;automatic speech recognition;utterances;asr errors;perfect transcription;insertion violations;brain potential;asr systems;human brain;asr;brain activities;erp;brain;deletion violations;words;errors;wer;language;whole sentence;mistaken output;effect;potential study;insertions;event;impact;deletions;substitutions;positive shift;results", "pdf_keywords": ""}, "7261b088c48be7eca10263e765739f7347665481": {"ta_keywords": "markovian network equilibrium;variable demand", "pdf_keywords": "markovian network equilibrium;network equilibrium model;network games;classical wardrop equilibrium;variable demand;commodity \ufb02ow;algorithms;players;computational engineering;computational e\ufb03ciency;art optimization software mosek;austin;extensive numerical experiments;math;aeronautics;example;time;quitting option;seattle;computer engineering;dan calderone;tx;oc;electrical;washington;texas;wa;astronautics;state;oct"}, "4fb8009422903f7cb6f9a929409264b7fbca55e3": {"ta_keywords": "noise feature vectors;feature enhancement method;noise features;clean feature vectors;feature enhancement process;high speech recognition performance;extended feature vectors;corrupted feature vectors;feature vectors;piecewise linear transformation;piecewise linear compensation;corresponding clean features;stereo;gaussian mixture components;noise environments;overfitting;linear transformation;splice;neighboring frames;adjacent frames;minimum mean square error criterion;high dimensionality;noise;feasible computational cost;algorithm;addition;subspace;piecewise;efficient operation;changes", "pdf_keywords": ""}, "359dfdfea38f645d5fa49efc846a3b5ebce317fe": {"ta_keywords": "interpretable models;machine learning;software agent;social harm;loan;significant risk;applications;study;arms;sufficient foundation;discomfort;field;matter;anything;calls", "pdf_keywords": "interpretable machine learning;interpretable machine;conceivable interpretation technique;predictive models;supervised learning model;such understanding;electronic health record data;law;stakeholders;practitioners;lending;mortality;doctors;risk;world decisions;various stakeholders;cancer;loan;enforceability;machine;diagnoses;explanation;introduction;debate;prototypical call;meaning;decision;radiologic scans;papers;paper"}, "2c94bc68388517aa4a2d2dfc7d35df95ce24b1a8": {"ta_keywords": "adversarial invariant feature learning;independent image classification;fair classifications;invariant representation;meaningful representations;bias;better generalization;representations;machine learning;benchmark tasks;trait;particular task;detrimental variations;lighting;improved test performance;content;language;data;independent generation;great interest;framework;paper;problem;specific factor", "pdf_keywords": ""}, "5a0c9bbf0432dac8bd357a4aabf82b83a6c95524": {"ta_keywords": "traditional document similarity measures;document similarity;document similarity approach;pairwise document classification task;paper citations;aspect information;similarity;dissimilar documents;research paper pairs;acl anthology;aspect;bert variations;research papers;citation;distinction;lstm baseline;datasets;paper;recommendations;scibert;results;xlnet;quantitative results;label;roberta;section;transformer models;acts;f1;electra", "pdf_keywords": "semantic textual similarity;computing semantic textual similarity;multiple content similarity measures;document similarity;generative language models;word sense disambiguation;statistical machine translation;disambiguation;interactive spoken language systems;spoken recommendations;chinese treebank;query segmentation;global discriminative model;parsing;similarity;dialogues;citations;bert variations;eigenspace similarity;acl anthology;scienti\ufb01c articles;recommender system;research paper pairs;wikipedia;information presentation strategies;ti\ufb01c corpora;entities;scisumm;transformer models bert;datasets"}, "4f74be7e5dd4b8e9113e86132cf792da2c32ca3d": {"ta_keywords": "\u30d1\u30e9\u30d5\u30ec\u30fc\u30ba\u3092\u8003\u616e\u3057\u305f\u6a5f\u68b0\u7ffb\u8a33\u306e\u8aa4\u308a\u7b87\u6240\u9078\u629e;\u8a00\u8a9e\u7406\u89e3\u3068\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3;\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "90720bba46dd79bc340359617a7a07fcecc890c1": {"ta_keywords": "local nash equilibria;continuous strategy spaces;such equilibria;smooth costs;player costs;smooth functions;genericity;structural stability;games;perturbations;dense set;order conditions;respect", "pdf_keywords": ""}, "834fb0d09e764b88ef76ee77e0befb8faeaad7fe": {"ta_keywords": "speech synthesis;speech parameters;initial speech parameters;speech parameter sequence;synthetic speech quality;better synthetic speech quality;speech quality;speech probability distributions;traditional hmm;parameter generation methods;parameter generation method;hidden markov model;unit selection synthesis;acoustic features;rich context models;model selection;synthesis;single gaussian component sequence;em algorithm;maximum likelihood criterion;gmms;flexible modeling;initial parameters;several hybrid methods;quality improvements;hybrid method;frame;hmm;statistical approach;individual segments", "pdf_keywords": ""}, "2507a6924007efbe0c3116048a85108398f23007": {"ta_keywords": "automatic glossing models;interlinear glossed text;collect translations;language documentation projects;linguistic information;tag recall;scholarly papers;linguistic expertise;manual production;igt;format;art baseline;overall accuracy;resource scenarios;lemma;time;state;approach;issue", "pdf_keywords": ""}, "5ad44a9d6b850405da42f989711af431427425b5": {"ta_keywords": "mixed language;multiple languages;single language;hindi;bilingual speakers;languages;target language;language;phonetic space;conversational data;native script;mixed text;english;english text;listening tests;tts database;most text;speech;german text;text;code;spellings;mixing;social media;tts;listeners;input;subjective experiments;same conversation;synthesis", "pdf_keywords": ""}, "d95b66901d72a13d0c96c7e9bfd4a999ed7fb19c": {"ta_keywords": "recurrent neural network language models;gram language models;translation formalisms;english mt tasks;germanenglish;syntactic preordering;domain adaptation;naist smt systems;compound word splitting;smt systems;evaluation campaign;english;ntt;training data selection;generalized minimum bayes risk system combination;iwslt;phrase;systems;string;forest;individual systems;hypotheses;truecasing;paper", "pdf_keywords": ""}, "ad21f0709a3e5d7db91606e2f67926f93e01838d": {"ta_keywords": "contextual games;contextual regret;optimal contextual welfare;contextual regrets;contextual coarse correlated equilibria;game outcomes;available contextual information;contextual information;games;traffic routing experiment;optimal welfare;game;different contexts;individual players;novel online;players;higher welfare;cce;such correlations;regularity assumptions;baselines;correlations;better performance;kernel;correlation;algorithm;theoretic notions;results;means;round", "pdf_keywords": "contextual games;contextual regret;contextual coarse correlated equilibria;optimal contextual welfare;contextual regrets;games;coarse correlated equilibria;different contextual information;optimal welfare;equilibria;regret;game;novel online algorithms;natural benchmark;individual performance;players;cce;cces;typical solution concept;ef\ufb01ciency;new notions;theoretic notions;notion;section;novel class;type;round;new class"}, "f2d5861a24b7aa33036208ba81e11bb9b2090e7c": {"ta_keywords": "output paraphrase generation models;multilingual paraphrasing model;shot paraphrase generation;shot paraphrasing baselines;paraphrases;word embeddings;fluent monolingual rewriting;parallel corpora;autoencoding objective;final softmax layer;effective parameter sharing;languages;human assessment;meaning spaces;fluency;computational metrics;battery;end;training procedure;outputs;diversity;key contribution;novel technique;architectural modification", "pdf_keywords": "multilingual paraphrasing model;shot paraphrase generation;paraphrasing models;unsupervised paraphrasing;paraphrases;word embeddings;common semantic space;parallel corpora;paravmf;decoder;abundant bilingual data;translation objectives;encoder;meaning spaces;tasks;translation;language;languages;\ufb01nal softmax layer;spaces;diversity;sachin kumar carnegie mellon university;input text;inputs;technology madras;primary goal;outputs;yulia tsvetkov university;l2;end"}, "0e02765103001a792b20242b4dee6dc81917b850": {"ta_keywords": "entity recognition;annotation scheme;consistent annotation;gene mentions;gene names;biomedical text;flybase curation;gene name;supervised training;training data;recognizer;biomedical domain;noisy text;bootstrapping;task;new test;extensions;evaluating;technique;problem", "pdf_keywords": ""}, "5b94512a17483595c5dffc503a16ba0b46c347e5": {"ta_keywords": "hypernymy extraction;wiktionary datasets;synonyms;hypernyms;unsupervised sense representations;hypernymy relationships;embeddings;synsets;aware relationships;respective languages;sets;gold standard datasets;standard hearst patterns;sense;english;evaluation;method;paper", "pdf_keywords": ""}, "0e52ce6cfd1385e1e9304dcf71d66b53fdc2d4bd": {"ta_keywords": "news content;news ir;information retrieval;journalism;natural language processing;journalism environment;nlp;entity detection;disambiguation;future data challenge;news;keynote talks;important challenges;focused panel discussion;workshop;challenges;tasks;ir;readers;social streams;events;stories;poster presentations;participants;information;community;time processing;communities;view;conjunction", "pdf_keywords": ""}, "e705255814756178dba75638c29b602095c3cdf4": {"ta_keywords": "deep reinforcement learning;complex downstream tasks;drl agents;sample complexity;simpler environments;useful representations;representations;layers;representation;useful representation;environment;related game;environment states;experiments;policy;drl;transfer;same game;performance;new insight;source;experiment;paper;requirements;scratch;benefits;set;requirement;distinction;majority", "pdf_keywords": "deep reinforcement learning;representations learned;atari games;atari;progressive neural networks;agents;transferability;rainbow agents;useful representations;training;novel model architecture;transplanted layers;transferable;river raid;initial layers;models;transfer;sample complexity;games berzerk;new tasks;experiments;pool;child network;network;features;policy;empirical evaluation;environment states;tuning;freezing"}, "51203e9d5620abdcdf6c9be93b1e221e79cda67d": {"ta_keywords": "external language model;transfer learning;target language;lm fusion transfer;better adaptation methods;resource languages;whole adaptation stage;adaptation;languages;iarpa babel data;external lm;external text data;attention;language;simple transfer;independent asr system;s2s;s2s model;linguistic context;decoder network;unified sequence;vocabulary;hybrid systems;lm;sequence;target;performance gap;final system;architecture;experimental evaluations", "pdf_keywords": "language model fusion;external language model;transfer learning;lm fusion transfer;resource languages;target language;target \ufb01ve languages;languages;better adaptation methods;independent asr system;whole adaptation stage;external lm;simple transfer;attention;adaptation;end asr;language;independent s2s model;adaptation stage1;external text data;decoder network;s2s model;iarpa babel data;jaejin cho2;cold fusion;s2s;linguistic context;vocabulary;sequence;lm"}, "8319786ed7b9cb13e29130b5617bf0aef586cd6f": {"ta_keywords": "cognitive tutor authoring tools;cognitive tutors;cognitive tutor;tutoring;novice authors;expert model;authoring;formative assessment;progresses;heavy programming;feedback;software tools;simstudent;higher accuracy;performance;demonstration;negative feedback;agent;better accuracy;authors;author;efficiency;hint requests;steps;machine;less time;context;ctat;response;same level", "pdf_keywords": ""}, "c37c40db51ccfd6f93004e788102ede72578e5d8": {"ta_keywords": "efficient information extraction;collaborative extraction;reliable information;machine learning techniques;human workers;manual verification;human worker;workers;information;filtering;reliability;extreme reliability;tool;needs;situations;research;crisis;method;efficiency;framework;order;high level;large number;times;amount;setting", "pdf_keywords": ""}, "92259193a9d7377368790bf8517cd9798f30caae": {"ta_keywords": "explainable question answering;question answering;qa;information pollution;xqa system;information;questions;xqa;friendly interfaces;web;interface;transparency;interfaces;explainable question;feedbacks;validate provenance;core concepts;access;roadmap;context;system;challenges;light;interpretation;solution;expectations;validity;iii;end;computational model", "pdf_keywords": ""}, "0e1a665334b1ec35d77ab1cd4f21bd0da9745548": {"ta_keywords": "classifiers;large text categorization problems;categorization problems;classifier;classification;ripper;experts;sleeping;phrases;algorithms;machine;contexts;different ways;different notions;methods;context;different methods;combination;different criteria;differences;wide variety;presence;many other respects;number;spite;absence", "pdf_keywords": ""}, "9ca95a09c8bf2d7d28234ff37ece182836dd8632": {"ta_keywords": "exact imitation learning;parser;imitation;algorithm dagger;task;representation;training data;alpha;actions;novel transition;algorithm;amr;dagger;score;fscore;points;performance;expert;statistical model;development;test set;simple noise reduction technique", "pdf_keywords": ""}, "0aa0131253b832fdba27ac43f8fa78a322763191": {"ta_keywords": "paralinguistic information;speech translation model;output speech;many different possible paralinguistic features;speech translation;speech synthesis components;input speech;automatic speech recognition;machine translation;target language;source language;different languages;prosody;text;duration;end model;communication;text level;rich acoustic cues;features;end;technology;information;power;continuous space;paper;more information;method;methods;people", "pdf_keywords": ""}, "a94ec1cd89839aa5132118916849d46dff861914": {"ta_keywords": "human collaborative behaviors;collaborative tasks;mind tasks;ai agents;situated language communication;interaction;autonomous agents;collaborative partners;human world;human subjects;minecraft;3d virtual blocks world;interactions;mind;belief states;partners;human terms;computational models;world;pairs;information;beliefs;theory;dataset;several theory;situ;abundant opportunities;first step;goal;ideal integration", "pdf_keywords": "collaborative interactions;collaborative agent;situated dialogue;human mental states;collaborative tasks;interaction discourse;situated environments;mindcraft;mutual belief states;mental state;mental states;belief states;autonomous agents;mind;collaborative partner;ai;mind evolve;interaction unfold;visual experience;realistic agents;agent;human world;collaboration partner;viewpoint;communication;environment;virtual environment;human terms;task;computational models"}, "8278e5c2a894793e2c93c6c9f0e7535109e7858f": {"ta_keywords": "sowed herbs on landscape conditions;standing density;dependence", "pdf_keywords": ""}, "c637636a2afd7968bdb893af8d2fd220fd39df8f": {"ta_keywords": "time meeting recognition;time meeting transcription;time meeting analyzer;ongoing group meeting;distant microphone array;distant microphones;meetings;meeting assistance;individual speaker;meeting table;speech signal;conversations;advanced audio processing operations;speaker;utterances;speech;latency monitoring;online manner;low latency;face;omni;channels;directional camera;components;techniques;series;system;center;understanding;goal", "pdf_keywords": ""}, "ffac42087ee4ad50df9203762db715dedd209c0b": {"ta_keywords": "tag propagation;free grammars;free grammar;semantic tags;parse tree;handwritten context;semantic analysis;complete semantic information;semantic information;tags;propagation instruction;propagation mechanism;context;rules;mechanism;method;new method;powerful mechanism;use;idea", "pdf_keywords": ""}, "919c929dfa665cb0595a835b4380f96da4cd0143": {"ta_keywords": "field reconstruction;mobile sensing;field samples;spatial fields;mobile sensors;dimensional bandlimited field;contemporary sampling;random paths;extensive simulations;field;reconstruction;various paths;locations;matrices;performance;strategies;stability;insights;properties;work", "pdf_keywords": "mobile sensing;mobile sensors;random paths;dimensional bandlimited \ufb01eld;extensive simulations;bandlimited fields;interpolation;spatial \ufb01elds;various paths;mumbai;reconstruction;technology bombay;charvi rastogi;electrical engineering indian institute;matrices;multiple strategies;india;dimensional;animesh kumar department;strategies;design;email;\ufb01eld;insights;properties;evaluation;nov;work;main result"}, "59bdf61a81e46a6c9a96c0c5f96f2f77b82ab09f": {"ta_keywords": "x70 steel pipeline;subsurface detonation;weld geometry parameters;dynamic behavior;effect", "pdf_keywords": ""}, "c340b89e7b7fa84fac85cdcf38ba7007e2e71930": {"ta_keywords": "speaker diarization;speaker diarization results;speaker diarization problem;global speaker characteristics;speaker embeddings;local speech activity dynamics;end neural diarization;speaker;diarization errors;term memory;latent representation;attention;clustering;blstm;conventional blstm;other frames;network;self;next hidden states;good performance;eend;end;contrast;addition;problems;ii;state;method;major problems;approach", "pdf_keywords": "global speaker characteristics;neural diarization model;neural diarization system;local speech activity dynamics;attention mechanism;attention blocks;attention;latent representation;higher generalization quality;strong generalization capability;blstm;simulated training set;self;real datasets;remarkable improvements;callhome;end;csj;eend;addition;system;conclusion;ders;experimental results;sa"}, "0fcdf20477f907aa50578876226f5fabf5e074ea": {"ta_keywords": "citation networks;link prediction methods;world citation networks;link predictors;citations;relevant citations;recommender systems;social networks;biased evaluation;bias;exposure bias;academic papers;certain relevant items;true relevance;exposure probabilities;authors;papers;high generalization error;estimators;loss function;greater diversity;example;friends;data;experiments;consequent feedback loops;users;own field;methods;study", "pdf_keywords": "world citation networks;relevant citations;world citation data;true link probabilities;microsoft academic graph;bias;relevant papers;propensity scores;better estimates;true risk;estimators;exposure probabilities;estimation;estimator;papers;consequent feedback loops;feedback loops;feedback loop;loss function;mag;data;greater diversity;experiments;performance;methods;study;\ufb01elds;different fos;section"}, "da1296f071bb2b65ae9e0b016d914d24b4edb2d2": {"ta_keywords": "frontier capital markets;financial stability;undeveloped capital markets;frontiercapital market designation;global investment;capital market development;liquid capital market;foreign direct investment;financials systems ability;international military intervention;economic growth;economic resources;stability;other economic processes;military involvement;theinternational monetary;social prosperity;underlying metrics;basedanalysis;network;effectiveness;such aswealth accumulation;anefficient allocations;achievement;requirement;access;initial step;project;presence;probability", "pdf_keywords": ""}, "916c8553beb3ba4e0d20ba6d7eb2bca365d820c8": {"ta_keywords": "stance detection;bidirectional conditional encoding", "pdf_keywords": ""}, "7f613ab03d776f996eb582f04d258a51868dca03": {"ta_keywords": "lipase;pancreatic lipase;hydrazine insertion;phenylhydrazine;organic chemistry;biocatalyst;synthesis;classic organic compounds;dimethylformamide;hillman ketone;satisfactory yields;efficient method;great potential;morita;optimal conditions;baylis;tolerance;utilization;room temperature;findings;mmol;study", "pdf_keywords": ""}, "2aa85084315a4107e2b9b935506b4e9f11428601": {"ta_keywords": "simulated incipient caries lesions;swir reflectance measurements;bovine enamel;remineralization;remineralization solution;exposure;light images;swir dehydration;lesions;samples;treatment windows;halogen lamp;light sources;absorption band;spontaneous emission source;oct images;water;camera;study;peak;purpose;extended time period;oct;use;\u03bcm;cycling regimen;days;air;changes;nm", "pdf_keywords": ""}, "542ad79bb96fc10c46086778aaafc8f3509c5c18": {"ta_keywords": "gradient descent ascent;adversarial learning;nonconcave objectives;nonconcave minimax problems;generative adversarial networks;nonconvex minimax problems;reduced optimization;stochastic agda;\u0142ojasiewicz inequality;nonconvex;machine learning applications;agda;global convergence;sublinear rate;subclass;faster rate;algorithm;sided polyak;sum structure;variance;class;linear rate;problem;work", "pdf_keywords": "gradient descent ascent;nonconcave minimax problems;nonconvex minimax problems;nonconcave objectives;stochastic agda;adversarial learning;agda algorithm;minimax problems;reduced optimization;generative adversarial networks;agda;global saddle points;nonconvex;lojasiewicz inequality;global convergence;convergent variance;machine learning applications;convergence results;sublinear rate;junchi yang;subclass;class;algorithm;oc;sided polyak;feb;side pl condition;linear rate;stoc;variance"}, "69ee9b3a915951cc84b74599a3a2699a66d4004f": {"ta_keywords": "robotic manipulation;robots;world tasks;precise spatial reasoning;tabletop tasks;transferable concepts;task models;dexterous skills;cliport;unseen semantic concepts;unseen objects;broad semantic understanding;objects pre1;cloths;manipulation;language;agent;explicit representations;object poses;end networks;clip;abstract concepts;symbolic states;syntactic structures;segmentations;end framework;spatial precision;transporter;instance;ability", "pdf_keywords": "robot learning;broad semantic understanding;semantic understanding;imitation;language grounding systems;end learning;natural language processing;agent;cliport;vision;language;manipulation;clip;spatial pathways;spatial precision;machine learning research;end framework;transporter;conference;stream architecture;emnlp;cognitive psychology;end;worlds;\ufb01ne;corl;empirical methods;conclusion;stream hypothesis;framework"}, "fa3826770207f7bf8bd85a8e97c9ac437f46b061": {"ta_keywords": "multiple comparisons;maxt permutation test;other comparisons;unadjusted tests;available test collections;statistical inference procedures;closed testing;scale ir experiments;significant results;bonferroni adjustment;baseline;holm;fewer true differences;trec;multiplicity;query set size;procedures;permutation;rank;experiment;threshold;microsoft learning;mslr;data;values;runs;simulations;software;probability;focus", "pdf_keywords": ""}, "ce89ee7aaeeea2c9d474707690f3ea9d948776a3": {"ta_keywords": "most modern machine translation;machine translation;translations;noisy comments;noisy text;english comments;japanese comments;benchmark dataset;available parallel corpora;language pair;noisy;mt models;datasets;dataset;mtnt;english;noisy inputs;french;sentences;adaptation;robust mt systems;japanese;noise;mt;reddit;domain data;small training;disastrous mistranslations;systems;types", "pdf_keywords": "most modern machine translation;machine translation;noisy text;noisy comments;translations;professional translators;abbreviations;mtnt;english comments;graham neubig language technologies institute carnegie mellon university;frenchenglish;profanities;language pairs;benchmark dataset;close languages;typographical errors;language pair;internet slang;nlproc;noisy source;robust mt systems;japanese comments;distant languages;noisy;english;sentences;mt;testbed;french;social media"}, "7f85b7ee0fc6cdb5b92417035a7049247729545a": {"ta_keywords": "class imbalance;classifiers;random forest;classifier;balanced class distribution;predictive performance;training data size;datasets;classes;na\u00efve bayes;benchmark datasets;predictive power;kappa coefficient;dataset;performance;kappa;logistic regression;empirical study;leaf model;instances;results;groups;sufficient instances;effects;extent;test;study;significant differences;few variables;group", "pdf_keywords": ""}, "ce5a57c0ccc8993f4a8e3a07101140a757024d9f": {"ta_keywords": "automatic memorable spoken quote detection;public speeches;natural expressive speech;public talks;ted talks;quotes;acoustic features;important messages;audience;people;consciousness;results;paper;study;others;several questions", "pdf_keywords": ""}, "61ad8a0778598022e71c0ee3ba9bc53ddd616517": {"ta_keywords": "question answering;semantic parsing;decomposed question sequences;complicated question intents;question sequences;coreferences;answer pairs;normal conversation;questions;complicated questions;existing qa systems;matching words;answers;corresponding entries;phrases;previous questions;wikipedia;associated table;humans;dataset;question;major problems;recent work;total", "pdf_keywords": "sequential question answering;semantic parsing dataset;traditional semantic parser design;wikipedia tables;parser;question sequences;wikipedia;questions;qa systems;answer pairs;knowledge;sqa dataset;dataset;sqa;qa setting;information access;unique sequences;sequential question;neural network;end;natural interface;question;system;different properties;baseline experiments;total"}, "9837207d3f4ee8c493375a97077c6f8b22cadac9": {"ta_keywords": "durational residency tests;state citizenship;constitutional commentary;validity;supreme court;doctrinal explanations;court;invalidity;conclusion;national;newcomers;reasoning;equal treatment;core meaning;despair;claim;sensible pattern;disarray;results;ubiquitous form;unique discovery", "pdf_keywords": ""}, "de9d3a28f9e112a248d097d72ba6ad41a71c8a78": {"ta_keywords": "clause logic programs;logic programs;single horn clause;depth determinate clauses;several practical learning systems;learning one;cryptographic limitations;indeterminate clauses;learning system;machine learning;generalizations;examples;representations;reducibilities;warmuth;dnf;language;consequence;method;primary technical tool;pitt;results;problem;active area;paper investigates;research", "pdf_keywords": ""}, "bcde1ba141078cf37a69a691fd329d8fd7e70b9b": {"ta_keywords": "active learning;criterion", "pdf_keywords": ""}, "83d6b4bfa8701578c291e55f5f1e5e6508aff313": {"ta_keywords": "technology ethics;patient autonomy;medical ethics;autonomy;technology users;consent;technology design;technology;ai;patients;medicine;doctors;decisional capacity;case study;discussion;wellbeing;computer science;critical tools;initial practical suggestions;concepts;mediating concepts;ability;model;scenario;difference;overlap;terms;encounter;heart;people", "pdf_keywords": ""}, "1bc87dba9838b3028b636f456084252f2beac108": {"ta_keywords": "stackelberg game;particle swarm optimization method;nash equilibrium;bilevel optimization problem;occupants;social game;efficient behavior;game;lottery;building manager;greater utility;leader choice;player states;multiple followers;energy;agents;leader;behavior;distribution;complexity;interaction;points;utilities;likelihood;nonconvexities;joint distribution;states;problem;analysis;results", "pdf_keywords": ""}, "f016ac107259d6d222c9f52b37208fca4fa1d6bc": {"ta_keywords": "restricted use case modeling;use case models;ads scenarios;complex traffic environments;autonomous driving domain;operational world model;rucm4ads;ontology;novel use case;applicability;roads;autonomous driving systems;adss;quality adss;requirements;overall applicability;rucm;high quality requirements;terms;pedestrians;methodology;owm;defects;notations;properties;lives;such defects;method;paper;catastrophic losses", "pdf_keywords": ""}, "36c770b79937db2e3416204b8cf177d0c9881f54": {"ta_keywords": "rotorcraft flight visualization;hums data", "pdf_keywords": ""}, "0a485fd94b2cb554e281d0f8d7e9f71db4891ce0": {"ta_keywords": "novel token downsampling method;vision transformers;most vision transformers;softmax;intermediate token representations;token pooling;downsampling;major computation bottleneck;art downsampling;attention;tokens;images;computational cost;layers;attention acts;smoothing;accuracy;computational complexity;high computational requirements;reconstruction error;pass;computation;filter;cost;quadratic complexity;accuracy trade;resource;redundancies;redundancy;set", "pdf_keywords": "novel token downsampling method;intermediate token representations;token pooling;softmax;aware downsampling operator;vision transformers;tokens;downsampling;images;novel nonuniform data;smoothing;ef\ufb01cient clustering;transformers;high computational requirements;layers;reconstruction error;computational complexity;pass;attention acts;cost;features;resource;optimization problem;\ufb01lter;hao rick chang;jenhao chang;redundancies;abstract;computer science;many applications"}, "d1f32060e921b6e06badd7fdb2b750638b2d131c": {"ta_keywords": "acoustic modeling networks;acoustic processing;acoustic modeling;microphone channels;ami meeting corpus;beamforming;absolute word error rate reduction;feature extraction;domain beam;classification;networks;independent processing stages;network;computational network;second network;joint training;filter coefficients;array signals;features;specific objective function;enhanced signal;conventional pipeline;components;conventional features;propagation;stages;signal;back;improvements;parameters", "pdf_keywords": ""}, "98290fb02a844108df202e9a6dc3461e3f14ee32": {"ta_keywords": "optimization problems;surrogate problem;th order taylor approximation;convex;stationary points;stationary point;certain regularity parameters;upper bounds;concave;euclidean diameter;diameter;order;initial problem;problem;reduction;approach;following result;constant factors;terms;success", "pdf_keywords": "nonconcave composite minimax problems;small maximization domain;structured nonconvex;saddle point problems;optimistic dual extrapolation;optimization;nonconvex;decentralized proximal point;stationary points;type method;order;problems;oc;abstract;math;problem;oct"}, "ad26e5105b6019ff68404962e39ea3a1dfb5931d": {"ta_keywords": "incentive design;incentive sequence;temporal logic objectives;incentives;markov decision process;temporal logic formula;finite decision horizon;optimal behavior;mdp;optimal sequence;time algorithm;agent;deterministic transitions;principal;behavior;objective;cost;certain assumptions;problem", "pdf_keywords": "optimal agent behavior;motion planning examples;optimal trajectory;markov decision process;sequential decision;incentive design;\ufb01nite decision horizon;incentives;total reward;mdp;linear optimization problems;reachability;agent;maximum probability;algorithm;time algorithm;objectives;horizon;process;principal;cost;decision;objective;sequence;end;method;\ufb01nite;series"}, "89a8edbc0fe2ea8b9ee703ca37e5d5d6d34c571a": {"ta_keywords": "neural machine translation;end speech translation;translation performance;source transcription;target bidirectional knowledge distillation;transcriptions;automatic speech recognition;bidirectional seqkd;source language information;backward nmt models;single decoder;backward nmt model;backward seqkd;auxiliary task;models;asr;e2e;seqkd;nmt;source;st model;joint training;model capacity;end;target;tasks;full potential;direction;pre;performance", "pdf_keywords": "neural machine translation;end speech translation;target bidirectional knowledge distillation;source transcription;transcriptions;bidirectional seqkd;source paraphrases;automatic speech recognition;backward nmt models;single decoder;backward nmt model;source language information;auxiliary task;backward seqkd;models;asr;nmt;training;e2e;joint training;end;seqkd;st model;target;machine;full potential;tasks;source;lation;performance"}, "daa7e6af585d03e9cb05487413a6495f23400398": {"ta_keywords": "deep learning based resource assignment;feasible assignment solutions;binary assignment problems;permutation matrices;wireless networks;new sinkhorn neural network;deep learning approach;neural network;binary variables;training strategies;set;challenges;letter;structure;end", "pdf_keywords": "deep learning based resource assignment;assignment problem solvers;network assignment problems;binary assignment problems;snn architecture;practical network assignment scenarios;permutation matrices;assignment problems;combinatorial binary constraints;permutation matrix spaces;new sinkhorn neural network;unsupervised training algorithm;wireless networks;neural network;deep learning approach;snn;nonconvex projection problems;binary variables;various networking scenarios;various network scenarios;unsupervised dl framework;sinkhorn;output layer;matching;ieee;member;dl methods;feasibility;set;paper"}, "f11ed27f4640dd8785ea7c4aff9705ddaad2b24d": {"ta_keywords": "fake news detection;fake news attempts;fake news;multimedia content;visual content;multimedia technology;social media;representative detection methods;multimedia;images;effective visual features;videos;rapid dissemination;readers;popularity;consumers;challenging issues;significant negative societal effects;great concern;proliferation;important part;comprehensive review;role;basic concepts;research area;development;chapter", "pdf_keywords": ""}, "ad4b09832454a821e925e45e96e769f0c01bd3d6": {"ta_keywords": "sparse word graphs;statistical topic models;topic models;capturing word correlations;ap corpus;modeling word;topics;sparse;large document collections;words;documents;unsupervised fashion;lda;models;distance;bag;model;representation;new algorithm;techniques;scalable algorithm;attractive framework;work;recent advances;limitations;family;experiments;problem;assumption", "pdf_keywords": ""}, "1f133158a8973fb33fea188f20517cd7e69bfe7f": {"ta_keywords": "transformer encoder architectures;transformer encoder;attention sublayer;attention sublayers;transformers;long range arena benchmark;limited accuracy costs;long inputs;fnet;fourier transforms;unparameterized fourier transform;bert;gpus;glue benchmark;accuracy;training;tpus;simple linear transformations;tokens;input tokens;self;shorter sequence lengths;sequence lengths;model;standard;times", "pdf_keywords": "attention sublayer;attention sublayers;small fnet encoders;transformer encoder architectures;next sentence prediction;transfer learning setting;fnet;limited accuracy costs;small transformer models;language modelling;simple linear transformations;memory footprint;1fnet code;accuracy budget;f_net;sequence dimension;parameterized matrix multiplications;fourier transforms;hidden dimension;accuracy;bert;speed;tuning;input tokens;mlm;glue benchmark;joshua ainslie;tokens;several simple baselines;nsp"}, "c9ce3889c03fee2990b2277423bbc0fb4366df53": {"ta_keywords": "discriminative language modeling;structured classification problem;continuous space model;linear models;lower word error rate;alone model;compact parameterization;baseline scores;other copyright owners;publications;copyright;legal requirements;users;edinburgh research explorer;rights;approach;condition;problem;experimental results", "pdf_keywords": ""}, "2de8019fd7d04e3d1305d5efaeeb591f0d966550": {"ta_keywords": "speech recognition;automatic speech recognition;term memory networks;deep transformers;autoregressive transformer;input speech;asr benchmarks;decoder;kaldi asr system;mask tokens;special mask tokens;asr;input tokens;mandarin;unmasked context;tokens;easiest predictions;cmlm;aishell;training;japanese;example;csj;network;fmlm;difficult ones;7x speedup;performance;possibility;strategy", "pdf_keywords": ""}, "ca2144b895cf6812eec535261df9294896417425": {"ta_keywords": "semantic relation extraction;relation classification task;relation extraction task;end relation extraction model;concept candidate embeddings;scientific papers;subtask;classification;task;attention mechanism;semeval;bansal;miwa;paper;character;end;level;scenario;senerio;official submission;submission;enhancements", "pdf_keywords": "semantic relation extraction;scienti\ufb01c relation extraction;end relation extraction model;information extraction;selectively incorporated concept embeddings;concept candidate embeddings;large scholarly dataset;semantic information;concept selection module;scienti\ufb01c papers;neural models;concepts;classi\ufb01cation;characterlevel;attention mechanism;task;semeval;ir;paper;end;abstract;luanyi;bansal;yi luan mari ostendorf hannaneh hajishirzi university;miwa;ostendor;aug;enhancements;submission;art"}, "3638e5dfc79ba3fb757900f46ac0c7e7f6dadb05": {"ta_keywords": "personal photography;aware cameraphone application;mobile media sharing;image sharing;cameraphone use;photographic practices;image capture;photos;networked digital imaging promise;sharing;imaging;image quality;sharing process;new uses;universal experience;technology;uses;prototype context;users;developments;paper;understanding;prior work;people;cost barriers;empirical study;barriers;vice", "pdf_keywords": ""}, "86eb740bbc54a6d734242be28fccf76fd4d2c1ba": {"ta_keywords": "quadratic dynamic game;game hessian;multiagent control problem;nash equilibrium;convergence guarantees;continuous game;analytical convergence guarantee;time convergence;gradient;algorithms;several numerical examples;singular values;analysis;symmetric part", "pdf_keywords": ""}, "0fdc3efc11526995d192f18e19f07fba062a76f7": {"ta_keywords": "programmatic weak supervision;various weak supervision paradigms;labeling training data;noisy supervision sources;training labels;manual labeling bottleneck;machine learning;pws;conjunction;comprehensive survey;data scenarios;recent advances;survey;approaches;remarkable success;paper;paradigms;addition;major roadblocks", "pdf_keywords": "programmatic weak supervision;labeling training data;deep learning;pws learning paradigm;learning;other representation;manual feature engineering;machine learning;tasks;representative approaches;pws;3snorkel ai;chao zhang2;data types;brief introduction;data scenarios;yueyu;introduction;conjunction;component;abstract;cheng;new state;pws area;survey;addition;jieyuz2;approaches;1university;washington 2georgia institute"}, "66340a93813d8f816a8c82354a8f39fa985de27f": {"ta_keywords": "generic textual entailment system;conceptnet;arc challenge dataset;school science exams;end qa task;science exam questions;large corpus;questions;multiple choice questions;background knowledge;nlp;current qa systems;queries;query reformulation;qa;grade;several strong baselines;ai;text;ai methods;results;scitail;essential terms;science;progress;question;random chance;original source question;rewriter;domain question", "pdf_keywords": ""}, "2ac6b8ade2a5e1ac89b99012ca6548eca4f8323f": {"ta_keywords": "novel topological layer;efficient topological layer;topological features;persistent landscapes;general persistent homology;networks;layer inputs;general deep learning models;layer;subsequent layers;robust dtm function;learnability;tight stability;input data structure;network architecture;arbitrary filtration;input data;noise;outliers;differentiability;critical information;task;respect", "pdf_keywords": "novel topological layer;topological layer;topological features;weighted persistence landscape;signi\ufb01cant topological features;networks;arbitrary network;layer;deep learning models;subsequent layers;learnability;network;dtm function;data structure;outliers;input data;tda;novel adaptation;stability analysis;stability property;main tools;noise;pllay;paper;basic concepts;critical information;section;discussion;\ufb01ltration;alternative way"}, "1fa02e5a5adffe82a41225f61f5f8ce86cf229d0": {"ta_keywords": "normalized cut;new segmentation;spectral cut;kernel cut;mrf models;balanced clustering;markov random field;order mrf constraints;optimization;computer vision;dimensional image;clustering model;mrf;machine learning;depth;texture;objectives;energy;many common applications;different nc formulations;color;standard nc applications;common pairwise;nc;new unary bounds;order nc term;inclusion;motion;other hand;location", "pdf_keywords": ""}, "1cfd9b1db68fc320698da05fc6876dd0ea96fc9b": {"ta_keywords": "connectionist temporal classification;automatic speech recognition;layer pruning;ctc;ctc model;intermediate ctc;model depth;asr;pruning method;gpu;training;devices;device;mobile;transformer;model;accuracy;computational power;energy consumption requirements;reduction;challenging task;various depth;tuning;run;end;same depth;time;time factor;extra fine;demand", "pdf_keywords": "automatic speech recognition;layer pruning;ctc model;intermediate ctc;ctc;connectionist temporal classi\ufb01cation;model depth;pruning method;transformer;prune;layers;model;asr;training;regularization methods;gpu;stochastic depth;devices;device;mobile;energy consumption requirements;computational power;accuracy;depth analysis;performance;reduction;tuning;challenging task;jaesong;various depth"}, "acbb4495dd698b3190db6899d7d35b0817e0a85e": {"ta_keywords": "standard gradient descent ascent;minimax learning problems;generative adversarial networks;minimax optimization algorithm;gans;generalization performance;gdmax algorithms;stochastic gda;maximization subproblems;minimax model;maximization subproblem;generalization analysis;proximal point method;minimization;convex;gda algorithm;generalization properties;optimization algorithm;algorithmic stability;similar learning rates;ppm algorithm;gda;training;vanishing excess risk;excess risk;ppm;iteration;superiority;paper;end", "pdf_keywords": "minimax learners;minimax learning problems;standard gradient descent ascent;minimax optimization algorithm;minimax models;generative adversarial networks;gdmax learners;gans;generalization performance;optimization algorithms;minimax settings;proximal point method;generalization;convex;gradient;algorithmic stability;ppm algorithms;generalization properties;algorithmic stability framework;stochastic gda;training;gda;train;farzan farnia;ppm;stability;asuman ozdaglar;numerical experiments;numerical results;methods"}, "0053f75b7053f43b9787a9955426281e672b147b": {"ta_keywords": "outside recursive autoencoder;unsupervised latent tree induction;outside recursive auto;highest scoring parse;deep inside;encoders;tree;syntax;input sentence;possible binary trees;cky algorithm;representations;diora;inference;unsupervised method;training;dynamic programming;sentence;constituents;word;rest;approach", "pdf_keywords": "unsupervised parser training;unsupervised parsing;outside recursive autoencoders;shallow parses;full syntactic trees;unsupervised latent tree induction;latent tree chart parser;phrase representations;autoencoder language;syntactic structure;unsupervised unlabeled constituency;nli datasets;deep inside;outside representations;unsupervised binary constituency;noun phrases;training data;unsupervised method;entities;tree;new deep learning method;representations;syntax;outside algorithm;diora;young;language;full wsj;information;benchmark datasets"}, "95e8edd26744ecc2bc23996cfaa68fe6252442a9": {"ta_keywords": "aware fake news detection;automatic fake news detection;fake news detection;graph structure learning;graph neural networks;semantic structure mining framework;semantic representations;fake news;contextual semantic information;veracity;semantic dependency;evidence interaction module;structured data;claims;news;evidences;unified graph;graph;evidence;downstream claim;claim;neighborhood propagation;several evidences;relevant snippets;information redundancy;sequences;paper;critical issue;predictions;perniciousness", "pdf_keywords": "fake news detection model;graph structure learning;semantic structure mining framework;evidence graphs;complex semantic structure;contextual semantic information;information propagation;effective graph structure;structured data;semantic dependency;semantics;evidence interaction;claims;unified graph;evidences;downstream claim;graph;claim;neighborhood propagation;effective structure;redundant information;information redundancy;relevant snippets;get;conclusion;paper;redundancy mitigation;module;sequences;work"}, "452059171226626718eb677358836328f884298e": {"ta_keywords": "dynamic memory networks;iterative attention process;speech tagging;dynamic memory network;natural language processing;stanford sentiment treebank;attention;neural network architecture;text classification;episodic memories;sentiment analysis;sequence;input sequences;questions;language input;tasks;most tasks;qa;previous iterations;dmn;ptb;facebook;datasets;babi dataset;inputs;part;end;wsj;question;model", "pdf_keywords": "question answering;episodic memory module;dynamic memory networks;episodic memory;dynamic memory network;hierarchical recurrent sequence model;episodic memories;neural network architecture;speech tagging;natural language processing;sequence modeling;stanford sentiment treebank;neural network;nlp applications;multiple nlp problems;sentiment analysis;questions;input sequences;text classi\ufb01cation;dmn architecture;sequence;single architecture;bedroom;dmn model;dmn;inputs;general architecture;babi dataset;tasks;datasets"}, "c39ac49e2d3feec992e84868256cb0a0ff028346": {"ta_keywords": "convex optimization;optimal algorithms;communications rounds;oracle calls;lower bounds;arxiv preprints;bounds;recent theoretical advances;methods;paper;recent results;details;results", "pdf_keywords": "stochastic optimization method;consensus subroutine;variational inequalities;optimization;graphs;oracle calls;inexact model;time;framework"}, "affb8d759af00540458c19696532220dd1c1373a": {"ta_keywords": "large vocabulary continuous speech recognition;hmm models;text recognition;ocr;hybrid deep neural network;automatic speech recognition;markov models;words;machine translation;neural network;cnn;oov;600k lines;sequence dependency;line image;lines;asr methods;training data;lvcsr;dnn;asr;optical model;tdnn;convolution;challenge;tasks;datasets;hmm;lm;time delay", "pdf_keywords": ""}, "5c5bedaf66cadebbcd9116f38acd3df9ed43d816": {"ta_keywords": "paul wavelet transform;wavelet functions;paul wavelet;seismic data;r\u00e9nyi entropy measurement;seismic time;synthetic seismic trace analysis;spectral decomposition;energy absorption analysis method;frequency analysis;entropy;frequency localization;eopwt;frequency resolution;input signals;nonstationary features;carbonate gas reservoir;gas accumulation;data;southwestern china;compact representation;complicated formulation;attenuation gradient attribute section;time;cwt;continuous wt;other conventional tools;parameter definition;domain;wt", "pdf_keywords": ""}, "bc247abf8180f583a42de392e4f7d2b2a41ad72d": {"ta_keywords": "natural language interfaces;novel parser;natural language questions;most parsers;parser;arbitrary parsers;wikisql;independent interactive approach;databases systems;sql;databases;art parsers;sql technique;enhancing text;text;human;users;piia;loop;complex spider;real systems;significant progress;paper;state;area;experiments", "pdf_keywords": "sql parser;natural language interfaces;question generator;natural language questions;arbitrary parsers;parsers;parser;novel parser;sql;sql technique;independent interactive approach;\ufb01ve base parsers;different base parsers;novel interactive approach;interactive agent;nl questions;databases systems;databases;user feedback result;nl modifier;interaction nl choice question;schema;enhancing text;uncertain tokens;machine intelligence;text;piia;nl modi\ufb01er;human evaluation;abstract"}, "c5bcb690b0aa85ad0a5fd7e7aa4b8c468cd8c69a": {"ta_keywords": "new speech recognition results;discriminative training;differenced mmi;world corpus;backward algorithm;minimum phone error;mmi functionals;mmi;narrow margin intervals;mpe statistics;margin interval;recognition error;maximum mutual information;mpe;dmmi;style loss;objective function;different error levels;margin;indexed forward;edges;mit;small performance gains;close agreement;style error;simple integral;error;broader intervals;finite difference;integrals", "pdf_keywords": ""}, "f300a62d0522d9a623b62f1305052928d8d7170c": {"ta_keywords": "sensitive irony detection;irony detection;emojis;emoji;online abuse;nonverbal cues;social media;harassment;balanced dataset;important task;identification;pipeline;ubiquitous use;applications;structures;role;work", "pdf_keywords": ""}, "50851e9e16b52e14c422b6e937cfd3ed063b6998": {"ta_keywords": "multilingual bidirectional encoders;aligned multilingual bidirectional encoder;multilingual encoders;multilingual representations;sequence tagging;resource languages;xtreme benchmark;sentence retrieval;nlp systems;explicit alignment objectives;sentence classification;retrieval;xlm;amber;learning;transfer;additional parallel data;tasks;different tasks;large model;mbert;shot;paper;average accuracy;parameters;gains;average f1 score;different granularities;experiments;new method", "pdf_keywords": "aligned multilingual bidirectional encoder;multilingual bidirectional encoders;multilingual encoders;crosslingual transfer performance;multilingual representations;sequence tagging;sentence retrieval;explicit alignment objectives;nlp systems;xtreme benchmark;resource languages;retrieval;attention;additional parallel data;transfer;orhan firat2;amber;learning;xlm;sentence classi\ufb01cation;different tasks;tasks;2google research;average accuracy;zeroshot;large model;melvin johnson2;mbert;paper;parameters"}, "37e06f3622c17dc6194b547c944462b2a513b878": {"ta_keywords": "neural abstractive summarization systems;news summarization performance;factual correction models;abstractive summaries;summary quality;summaries;factual consistency;factual inconsistency;source text;automatic metrics;corrections;span;human evaluation;incorrect facts;extractive strategies;span selection;entities;knowledge;fact;auto;terms;challenge;models;system;suite;question;respect;pitfall;order;rouge", "pdf_keywords": "factual correction models;abstractive summarization systems;summary quality;informative text summarization;factual consistency;summaries;factual correctors;factual correctness;factuality;informativeness;summary;spanfact;corrections;present spanfact;automatic metrics;text;span selection;conclusion;human evaluation;entities;empirical results;multiple entity masks;terms;rouge scores;knowledge;span selection mechanisms;challenge;long piece;models;main message"}, "e487f2508e5f62b2745a2e56ceb3c601c286d2e3": {"ta_keywords": "double elimination tournaments;balanced knockout", "pdf_keywords": ""}, "705e6b53f88ec733e3c186c6232c41b268248c01": {"ta_keywords": "netflix prize dataset;netflix ratings;behavioral social choice;computational social choice;social choice literature;social choice outcomes;social choice;behavioral predictions;human preferences;real movie ratings;ratings;real raters;sparse data;rankings;behavioral modeling play;inference;ballots;traditional sampling approach;model dependence;theoretical predictions;data;inference questions;preferences;such data;incomplete observed data;behavioral work;assumptions;notions;small subcollection;population", "pdf_keywords": ""}, "740182c3aa9a3045fcd9370269d446455ae9f623": {"ta_keywords": "neural finite state transducers;string transduction models;finite state transducer;state transducers;different transduction tasks;recurrent neural network;neural finite;interpretable paths;strings;string pair;seq2seq models;markov property;conditional probability distributions;paths;hard monotonic alignments;usual conditional independence assumption;rational relations;path;pairs;nfsts;probability;ordinary weighted fsts;arbitrary function;contrast;experiments;family", "pdf_keywords": ""}, "ba159dbf205193d0cb7c9c18dd01f830d2f56eb8": {"ta_keywords": "automatic linguistic annotation;contemporary natural language processing tools;modern text;contemporary language;historical text;clin27;task;output;goal;quality;effect", "pdf_keywords": ""}, "b694472c13420acb599a5b1d25d5f2bd42eb8c1b": {"ta_keywords": "de novo dna assembly;de novo dna;shot gun data;novo assembly algorithm;dna sequence;data efficiency;novel algorithmic framework;computational efficiency;algorithm;data;several short substrings;sequence;information;procedure;computation;online;offline phase;minimum amount;key idea;space;phases;theoretic perspective;respect;problem", "pdf_keywords": ""}, "71d649dcb3dee2ca57d0775a9679cb68f82f22d5": {"ta_keywords": "speaker adaptation;dnn adaptation technique;sequence summarizing neural network;summarizing neural network;dnn system;acoustic summary;vector extractor;summary vector;utterance;single loss function;ssnn;fmllr;fbank;input;networks;additional improvement;such vector;main network;performance;paper", "pdf_keywords": ""}, "0be998fffc5f44496042f7757fb2ffa8924e54cd": {"ta_keywords": "adaptive scorer;training data;training data instance;scorer network;machine learning model;entire training process;differentiable rewards;training;intuitive reward signal;learnable function;current knowledge level;new skill;scorer;data;tutor;similar gradient;dds;data instance;data usage;much attention;dev;adapts;particular content;practice problems;importance;main model;challenging problem;humans;effect;time", "pdf_keywords": "training data;adaptive scorer;training data usage;current training examples;general reinforcement learning;differentiable rewards;learnable function;current knowledge level;bene\ufb01t learning;scorer network;new skill;differentiable data selection;intuitive reward function;tutor;data instances;ef\ufb01cient alternative;particular content;data;alternative;practice problems;scorer;data usage;model loss;rl;much attention;development set;main model;jaime carbonell;differentiable function;graham neubig"}, "c5bb38b8e3ce21063670dfd81ac64dcb2ecf10b2": {"ta_keywords": "spectral notches;batteaus reflection model;individualized head;head;finer contours;impulse response;residual cepstrum;frequencies;pinna images;fast modelling;transfer functions;linear prediction;sound;hrtfs;hrtf;fast computation;hrir;accuracy;prominent features;pinna;accurate virtualization;method;essential requirement;work;high degree;subsequent use;paper", "pdf_keywords": ""}, "8abd724b770348bd21b16b9aaf2ba0a77596b2ed": {"ta_keywords": "external speech activity detector;speaker diarization;end neural diarization;neural diarization;decoder based attractor calculation;encoder;speaker overlap handling;diarization;attractor calculation module;decoder;eend methods;speakers;output speakers;eend;extensive evaluations;training set;eda;real datasets;iterative inference method;end;pipeline approaches;unknown number;conventional pipeline approach;maximum number;terms;method;paper;results;problem;contrast", "pdf_keywords": ""}, "af787fda38ce6fa1d14ad2fb8568088faf973a21": {"ta_keywords": "evaluating icon;agreement level;design concept intended;mobile phone;method", "pdf_keywords": ""}, "be312e930f6739a709e60547aa0dfb9c3dc44497": {"ta_keywords": "multilingual neural machine translation;strong multilingual nmt baselines;multilingual lexicon encoding framework;neural machine translation;multilingual training;soft decoupled encoding;language pairs;resource languages;languages;bleu;nmt;sde;impressive accuracy improvements;standard dataset;consistent improvements;data;level information;heuristic;new state;gains;art;paper;systems;experiments", "pdf_keywords": "multilingual neural machine translation;multilingual lexicon encoding framework;neural machine translation;multilingual lexicon representation framework;multilingual training;soft decoupled encoding;lexicallevel information;lexical representations;semantic representations;various lexical unit segmentations;resource languages;1language technology institute;languages;language;linguistic concept;word level;iclr;agnostic semantics;speci\ufb01c spelling;xinyi wang1;usa 2google brain;traditional word;words;sde;generalization;nmt;source code;word;arbitrariness;data"}, "e961c8de1df75f70254656e98ca82f9d9fbd640c": {"ta_keywords": "efficient compressive phase retrieval;compressive phase;general compressive phase;phasecode;unicolor phasecode algorithm;multicolor phasecode;unicolor phasecode;sparse;graph codes;memory complexity;efficient algorithms;complex signal;retrieval problems;measurement row vector;measurement vectors;density evolution methods;significant signal components;retrieval problem;graph;time;small constant factor;analysis;instance;ai;main focus;novel family;problem;work;fraction;fundamental limit", "pdf_keywords": "compressive phase retrieval algorithm;compressive phase retrieval problem;sparsegraph;phasecode algorithm;phasecode;sample complexity;memory complexity;ef\ufb01cient algorithms;optimal time;complexity;optimal;mild relaxation;signal components;signal;memory;\ufb01rst constructive capacity;noiseless case;algorithm;more dif\ufb01cult problem;conditions;support distribution;small constant;fact;high probability;measurements;components;novel family;number;support;framework"}, "e2a4e1a9f8e66baf12a49a3e5d8e33291f9347e7": {"ta_keywords": "short text entity linking;neural semantic matching models;aggregated semantic matching;reference knowledge base;public tweet datasets;disambiguation;short texts;semantic information;entity;text fragments;candidate entity;rank aggregation mechanism;novel neural network framework;concepts;task;matching signals;local context;arts;local information;asm;model;representation;interaction;evaluation;different aspects;state", "pdf_keywords": ""}, "f951aad88e244182b37e4918c3d570560108c68c": {"ta_keywords": "robust classifiers;gradients;randomized smoothing;standard convolutional neural network;neural networks;grainy;images;original image;optimization;target class;input;general property;score;version;alternative means;paper;santurkar et al", "pdf_keywords": "randomized smoothing;gaussian data augmentation;perceptual quality;gaussian noise;smoothing paper;gradients;smoothadv;neural networks;neural network;images;robust classi\ufb01ers;convolution;loss function;training;standard crossentropy loss;pgd;paper;number;effects;general property;effect;other concerns;factors"}, "5eaa425af39339e0ae30202b348cc6e253813993": {"ta_keywords": "scientific information retrieval system;russian patent databases;information retrieval system;technological forecasting systems;citation indexes;expert evaluation;expertise process;technology analysis;dependent text corpus;specialized decision support systems;patents;research papers;research projects;russian language;research;experts;grant proposals;relevant documents;forecasting;industry trends;large domain;english;government contracts;production;paper;system;grade;global ones", "pdf_keywords": ""}, "0761a69310f7b8f4ab01495f31a30c6fe53d83b8": {"ta_keywords": "multiscale adaptation;incremental adaptation;large vocabulary continuous speech recognition experiments;incremental adaptations;original incremental adaptation scheme;speech recognition;multiple time scales;single time scale;discriminative speech;temporal changes;macroscopic time scale;language model;adaptation;acoustic model;adaptation mechanism;multiscale properties;kalman filter theory;characteristic change;time evolution system;japanese lectures;model;posterior distributions;own dynamics;robustness;environments;decision process;potential;formulation;nature;importance", "pdf_keywords": ""}, "225767ce707781d0114815068c355622869ee642": {"ta_keywords": "asynchronous hidden markov model;artificial cognitive systems;visual speech recognition;cognition;living systems;audio;neuroscience;computer science;progress;project;research;recent progress;construction;new insights;objective;related fields;major areas", "pdf_keywords": ""}, "91184a2d40be8a0171b5c926b336666ed717ec6e": {"ta_keywords": "peer review;scientific digital library;researchers;library;research grants;analyses;insightful experiments;biases;important open problems;systemic issues;references;various systemic issues;issues;several computational solutions;fraud;detailed writeup;topics;billions;dollars;tutorial;number;complete list;entire careers", "pdf_keywords": ""}, "7d148b46f45e935765e56887d720492b2b716e55": {"ta_keywords": "intrinsic collective dynamics generate;physical connectivity;model neural circuits;neurons;event space;synapses;event time;networks;event timings;larger networks;independent reconstruction theory;event;interevent times;networked systems;space mapping;patterns;coupling;excitatory;theory;social science;biology;reconstruction;absence;illustration;pair;unit;other units;engineering;presence;important role", "pdf_keywords": "synaptic connectivity;synapses;physical connectivity;intrinsic collective dynamics generate;model neural circuits;neuron;neurons;inhibitory synapses;physical network connectivity;event space mapping;observed patterns;event timings;event time;networked systems;network;predictive power;independent theory;direct interactions;excitatory;model systems;conductance;topology;patterns;theory;coupling;general theory;absence;observation;illustration;pair"}, "d3dd80269f2542cc173afb3a1df24b582a1e4af2": {"ta_keywords": "regular languages;machine translation;bit strings;languages;length generalization;language;parity;longer strings;transformers;string;transformer;input strings;attention;perfect accuracy;hahn;bit;theoretical limitation;classification decisions;many tasks;single input symbol;limitation;single position;open question;odd number;self;acceptance;crossentropy;first;third;problem", "pdf_keywords": "bit strings;parity;languages;hahn;layer normalization;language;transformer;odd number;simplest examples;perfect accuracy;limitation;models;lemma;first;open question;ways"}, "920257774e2caee8a8c74968c64c10bcb79a136c": {"ta_keywords": "transmission lines;genetic algorithm;hybrid genetic algorithm;vector fitting based approach;propagation function;corresponding delay times;poles;vector;conventional method;approximation;approach;number;process;work", "pdf_keywords": ""}, "147b954ba0881d643706c918e017f7d66a15b827": {"ta_keywords": "efficient cognitive model discovery;better cognitive model;cognitive models;cognitive model;simulated student;student learning curve data;human learning;algebra learning;art learning agent;human learning curve data;cognitive science;knowledge;agent;human experts;human;simstudent;performance data;matsuda;essential goals;prior work;humans;lee;maclaren;approach;li;factors;cohen;koedinger;general;state", "pdf_keywords": ""}, "3426f000673aae995a55ade9273c842bb484ad18": {"ta_keywords": "monoand multilingual phoneme recognizers;crosslingual phoneme recognizers;phoneme boundaries;phoneme identities;automatic detection;phonemes;phoneme units;audio recordings;segmentations;detection;bantu language;segments;unknown language;monolingual gold standard;boundaries;recall;precision;measure;basaa;technique;quality;paper;performance;way;different configurations", "pdf_keywords": ""}, "89c2cbdf1a5049a4068ca9215aa8859a1a97b1a3": {"ta_keywords": "practical contextual bandit learning algorithm;contextual bandit learning problem;contextual bandits;optimal regret guarantee;reward;general policy classes;observed context;learner;approaches;sensitive classification problems;action;simple algorithm;cost;oracle;access;new algorithm;monster;method;response", "pdf_keywords": "contextual bandits;optimal regret guarantee;prediction performance;similar convex program;optimization;randomized ucb;algorithms;policy class;iterations;oracle;policies;alekh agarwal1;cost;general scheme;algorithm;high probability;sensitive classi\ufb01cation problems;online variant;calls;simple algorithm;warm start;satyen kale3;epochs;certain class;kt;monster;method;access;several baselines;lihong li1"}, "89f7db77a755d44d3aabdbcc7549b743d7debcc5": {"ta_keywords": "conditional preference networks;preference statements;qualitative conditional statements;preferences;uncertainty;features;dependencies;formal tool;nets;objects;particular object;static structures;cp;set;expression;ability;paper", "pdf_keywords": ""}, "18a82459d495fa3ad22a60bd7c9527df8bd55e1e": {"ta_keywords": "regret learning algorithm;network games;dual averaging approach;dual averaging;regret analysis;deterministic network;individual payoff gradients;global objective;nodes;communication graph;network connectivity;learning;local objective functions;dual method;optimization setup;distinct objectives;algorithm;other player;rate;teams;convergence;available observations;local observations;player;paper;actions;case;key correlation;scenario;analysis", "pdf_keywords": ""}, "341f6353547f4a58fdf11fbcc9de3a31083a619b": {"ta_keywords": "tooth surfaces;swir imaging;lesions", "pdf_keywords": ""}, "7a79099447bef9a3ea13b1dc409d04b3dff57320": {"ta_keywords": "automatic music composition;revamped midi;generating music;midi;pop piano music;art sequence models;pop music transformer;piano;plausible rhythmic structure;rhythm;rhythmic patterns;music;musical piece;generative modeling;musical scores;local tempo changes;sequence models;different tracks;attention work;drums;symbolic formats;harmony;remi;like events;events;bass;new event;self;sequence;prior arts", "pdf_keywords": "expressive pop piano compositions;automatic music composition;expressive pop piano music;expressive piano music;music information retrieval;novel midi;art music transformer;music;pop music transformer;overall generative framework;composition;chord recognition;downbeat estimation;deep learning;data representation;event representation;models;modeling;remi;sequence model;mir;taiwan ai labs;human knowledge;beat;generation;concept;components;abstract;aug;conclusion"}, "e9d8db4f5b5c106c43a268f635788c0a94b2916a": {"ta_keywords": "stochastic gradient descent;ascent methods;new efficient methods;variance reduction;coordinate randomization;various machine learning tasks;sgda;unified convergence analysis;classical sgda;compression;ascent;prominent algorithms;arbitrary sampling;svrgda;several new variants;variants;variational inequalities problems;new variance;methods;several advanced extensions;new method;method;qsgda;vip;last few years;large variety;unified theory;general theoretical framework;vr;diana", "pdf_keywords": "coordinate randomization;sgda;compression;svrgda;new variance;methods;method;new method;qsgda;vr;several new variants;sega;approach;diana;\ufb02exibility"}, "b9913ddf94245c864509f0b94847bdbe77899b46": {"ta_keywords": "tonal languages;connectionist temporal classification loss function;tonal prediction;tonal transcription;phonemes;phonemic context;transcription;tones;pitch information;linguistic workflow;phonemic facts;neural network architecture;training data;recognition performance;yongning na;language documentation setting;acoustic signal;chatino;minutes;linguistic consideration;eastern chatino;na;technology;typographical errors;importance;use;changes;promise;findings;efficiency", "pdf_keywords": ""}, "268d347e8a55b5eb82fb5e7d2f800e33c75ab18a": {"ta_keywords": "image classification tasks;cnns;convolutional networks;image recognition;natural language processing tasks;attention;computer vision;transformer architecture;transformers;pure transformer;vision;image;image patches;words;applications;scale;certain components;sequences;overall structure;place;conjunction;reliance", "pdf_keywords": "multiple image recognition benchmarks;image classi\ufb01cation tasks;cnns;image recognition;inference speed;standard transformer encoder;image classi\ufb01cation;transformers;backprop speed;iclr;pure transformer;image patches;tpuv3 accelerator;supervised fashion;image;nlp;model;inference;main models;timing;vit approaches;patches;sequence;conference paper;direct application;art;sequences;interest;state;purpose"}, "4533fd4cf13d2f4dd105edaf612934a1bd85ad5a": {"ta_keywords": "noise removal;spatial correlation prior;frequency dependent covariance matrices;multiple signals;observed signal;posteriori estimation;singletrial event;probabilistic generative model;potential data set;prior information;covariance matrices;related potentials;parameter estimation;signal;potentials;simulated event;event;amplitude;frequency domain;model parameters;time;effectiveness;coefficients;new method;experiment;paper;maximum", "pdf_keywords": ""}, "b62430b9f8810da4d9f28842ac0ca899aa66d422": {"ta_keywords": "", "pdf_keywords": ""}, "d1c41eb99824e8f4752190da1b815378be23b4b9": {"ta_keywords": "catastrophic forgetting;neural machine translation;sequence tasks;autoregressive models;prefixes;sampling;inference time;elastic weight consolidation;input sequence;prefix;systematic experiments;training;model;truth prefixes;bleu;model reliance;exposure bias;strong performance;maximum likelihood estimation;experiments;performance;discrepancy;ground;effect;paper;form;side;approach", "pdf_keywords": "catastrophic forgetting;neural machine translation;sequence tasks;autoregressive models;layerwise relevance propagation;models;output generation process;elastic weight consolidation;output quality;model;input sequence;sampling;systematic experiments;strong performance;exposure bias;model reliance;maximum likelihood estimation;lrp;pre\ufb01x;huszar;computer science;in\ufb02uence;paper;contributions;hypothesis;ewc;andreas vlachos department;university;\ufb01nd;abstract"}, "175b58fe7e49bb5c0c771b73f8834bcff21b59c7": {"ta_keywords": "natural language inference;natural language hypothesis;stress test evaluation;stress tests;linguistic phenomena;encoder models;nli;text;sentence;evaluation;real inferential decisions;models;premise;different genres;evaluation methodology;task;weaknesses;strengths;justifiable manner;future work;systems;standard datasets;impressive results;work;ability;respect;important directions;area", "pdf_keywords": "natural language inference;natural language hypothesis;sentence encoder model;nli models;linguistic phenomena;stress test evaluation;stress tests;stress test;spelling errors;nli;encoder models;stress;tests;graham neubig1 1language technologies institute;comprehensive error analysis;sentence;robustness;weaknesses;evaluation;software research;single word;models;typology;task;strengths;abstract;predictions;adjswap;anaik;premise"}, "49edf7f0dbad8b8c101af9ef95c72f62f545591e": {"ta_keywords": "compact topic embeddings;correlated topic modeling;topic correlations;topic vectors;topic size;document classification;efficient inference;retrieval;small model;poor scaling;quadratic time complexity;correlation results;data scales;problem sizes;high computational cost;paper;magnitude;extensive experiments;closeness;model;space;new model;several orders;quality;method;superior performance;approach", "pdf_keywords": "topic vectors;topic model;latent topics;topic occurrence;topics;topic size;variational inference;rna;correlation modeling;retrieval;vector representations;rrna invade;pubmed;correlation structures;fast sampler;tissue;inference;correlations;costly ctm model;heart time;simple lda;bacteriophage;visualization;substract reconstruct;unfold dna;sequence;correlation results;model;factor;comparable expressiveness"}, "db79a3e55690c5c86cfd0ec97712ed4ad1e47b3b": {"ta_keywords": "sequential ranking algorithm;pairwise ranking;active ranking;ranking;noisy pairwise comparisons;pairwise comparisons;comparisons;luce models;pairwise probability matrix;algorithm;counts;items;confidence intervals;thurstone;number;pair;parametric models;guarantee;data;terry;past work;bradley;point;structural properties;set;logarithmic factors;significant body;parametric assumptions", "pdf_keywords": ""}, "3c37b9ec2ff1828877575acc600b73c3bcde138f": {"ta_keywords": "ef\ufb01cient learning algorithm;rewards;bernoulli payoffs;recommender system;naive approaches;recommender systems;such policy;recommendations;regret;dependent horizons;recent ucb;policy;user type;type;user types;users;multiple arms;algorithm;arm;user;case;same type;setup;tuple corresponds;work;setting;\ufb01nite set;length;response;number", "pdf_keywords": "ef\ufb01cient optimal planning algorithm;optimal policy;such policydependent horizons;additive approximation;bernoulli payoffs;recommendation categories;world datasets;scheme;user types;multiple user types;recursive manner;run;\ufb01nite set;setup;setting;multiple arms;time;\ufb01nd;work;problem"}, "f6f4d30e4740bd92b31acd297a15872d490e7f11": {"ta_keywords": "many ssl heuristics;individual ssl heuristics;traditional supervised classification tasks;bayesian optimization methods;multiple heuristics;specific heuristics;classifiers;heuristics;declarative constraints;ssl;declarative language;novel domain;graphs;general approach;addition", "pdf_keywords": "relation extraction;many ssl heuristics;individual ssl heuristics;declarative ssl framework;ssl constraints;traditional supervised classi\ufb01cation tasks;relation;text classi\ufb01cation;classi\ufb01cation benchmarks;extraction tasks;declarative language;bayesian optimization methods;classes;realistic domains;succinct declarative language;multiple heuristics;heuristics;tasks;link;modest improvements;state;general approach;novel;art results;addition"}, "dab261b25ff8ccd2c9144a5cb3a46b39ac0ac4bd": {"ta_keywords": "ai community;ai;rigorous research;intellectual foundations;machine learning;flawed scholarship;scientific research;discipline;ml;drew mcdermott;self;stymie future research;history;trouble;problems;date;someone;current strength;large body", "pdf_keywords": "machine learning scholarship;language misuse;semantic reasoning;overloaded terminology;examples;alternative hypotheses;machine learning;empirical claims;syntactic \ufb02uency;high predictive accuracy;suggestive de\ufb01nitions;stronger conclusions;misuse;language;knowledge;terminology;ml scholarship;academic dialogue;reader;evidence;ml;empirical investigations;distinct concepts;understanding;datasets;papers;researchers;terminology confusion;rigorous experiments;others"}, "b79dcc5304e557ce200b161d2a884c0ff77f34ec": {"ta_keywords": "spelling correction systems;misspellings;spelling correction;spelling errors;neuspell;misspelt;neural models;source toolkit;richer contextual representations;toolkit;correction rate;character perturbations;correction rates;synthetic examples;english;reverse engineering;richer representations;simple unified command line;models;context;multiple sources;training;web interface;different models;many systems;ii;practitioners;case", "pdf_keywords": "neural spelling correction toolkit;neural spell correctors;spelling correction;neuspell;adversarial attacks;misspellings;toolkit;grammatical error correction;graham neubig language technologies institute carnegie mellon university;source toolkit;synthetic training data;countermeasure;english;available datasets;character;gec;ddanish;several text;usefulness;context;models;level;public use;task;web interface;uni\ufb01ed command line;danish pruthi;strategies;systems;sai muralidhar jayanthi"}, "9b621c0bcd2029006b389bc51395fb6604f9a855": {"ta_keywords": "human answerers;questions game;domain clarification question generation;question examples;dialogue;informative questions;shelf image captioner;natural language processing;questions;answer data;humans;machines;supervised question;communicative success;goal;overarching goal;misunderstandings;question;information;clarification questions;model;framework;ability", "pdf_keywords": "domain clari\ufb01cation question generation;human answerers;captioning data;image captioner;natural language processing;question selection;question selection module;dialogue;question examples;machine interactions;answer handler module;linguistic transformations;machines;semantics;target image;images;image;clari\ufb01cation questions;computational challenge;gabriel poesia computer science stanford university;humans;noah goodman computer science;clari\ufb01cation;candidate;overarching goal;answer;communication game;belief distribution;outputs;question"}, "a84c319fef32b2514af9541576189a1735aac507": {"ta_keywords": "knowledge base completion;language pattern;language;web;independent solution", "pdf_keywords": ""}, "f2de2c9d83b9058695e3272a4fbb7c30e04a1476": {"ta_keywords": "second language learning;english semantic density;second language;l2 word;duolingo;lexical semantics;learning;big data;words;large data;english;large scale;novel predictors;word;big data investigation;mobile app;small scale;predictors;distributional models;accuracy;many relevant factors;data;future research potential;ease;benefits;factors;others;significant effects;such experiments;robust factors", "pdf_keywords": "english semantic density;l2 word;second language;word level factors;lexical semantics;duolingo;novel predictors;english;learning;accurate word;predictors;cognate status;word;accuracy;portuguese speakers;distributional models;naturalistic dataset;several novel factors;mobile app;large scale;large data;factors;significant effects;ease;regression analysis;evidence;big data investigation;effect;paper;questions"}, "5b6c1e9dddc4b55036a5629227ae2cc7d49eb6d0": {"ta_keywords": "structured literature image finder;latent topic models;biomedical literature;interactive relevance feedback;images;slif project;papers;microscopy image;image processing methods;text;inside papers;figures;results;findings;slif;novel extension;scientists;field;fluorescence;primary data;gel;multiple levels;related problems;community;friendly web interface;type;vastness;query;goal;innovative combination", "pdf_keywords": ""}, "a1babdf55a6bff96d533fd0c9bc44864283ec107": {"ta_keywords": "corporate governance variables;depositors aware;corporate governance;banks;depositors;particular bank;stockholders;bank;external auditors;governance;creditors;stakeholders;risk aversion;economists;chairperson;corporation;account;decision factors;lower rate;simultaneous promotion system;president;following;more attention;existence;paper;service;discussion;respect;longer time;standpoint", "pdf_keywords": ""}, "3af5e203368fa2c7959d035493571d181a8682af": {"ta_keywords": "multitrack classical music performance dataset;multimodal music analysis;music information retrieval;music audio datasets;music performances;midi format;novel multimodal tasks;musical score;audio recordings;individual tracks;audio;performances;visual analysis;truth annotation files;video recording;synchronization;dataset;level transcriptions;mir;expressiveness;tasks;evaluation;insights;frame;high quality;assembled mixture;note;challenges;piece;creation", "pdf_keywords": "multimodal music performance dataset;music performance analysis;music audio datasets;music transcription;mir tasks;music performances;polyphonic vibrato analysis;visual analysis;evaluation measures;score alignment;source separation;insights;baseline systems;dataset;future comparisons;urmp dataset;broad range;xinzhao liu;karthik dinesh;research applications;aug;challenges;applications;conclusion;gaurav sharma;ieee;recent work;bochen li;zhiyao duan;fellow"}, "8f43b63ca400a0ea1fdd272f8c83fd67f01d0182": {"ta_keywords": "gene mention tagging;gene mention task;syntactic parsing;conditional random fields;training data;biocreative;information;crfs;features;domain independence;output;paper;system;material;approach;order;flexibility;advantage", "pdf_keywords": ""}, "14a09a04c5c295a93ff25492516112cd86fa0114": {"ta_keywords": "labeled sequence transduction;sequence transduction;decoders;unlabeled data;powerful supervised framework;labels;sequence;model;task;satisfies desiderata;new model;set;experiments;paper;advantage", "pdf_keywords": "labeled sequence transduction;sequence transduction tasks;sequence transduction;sequence transduction problems;morphological in\ufb02ection benchmark;decoders;morphological rein\ufb02ection;generative model;output sequence;input sequence;target words;neural networks;graham neubig language technologies institute;labels;sigmorphon;model state;sequence;example;tasks;model;task;content;large margin;new model;continuous latent variables;various features;lemma;new framework;abstract;data"}, "5e63e47cb3386b032ec43a92ce5980466228c761": {"ta_keywords": "distributed storage systems;new storage code;storage;data recovery;optimal storage efficiency;erasure codes;facebook warehouse cluster;data centers;erasure;warehouse cluster;recovery operations;multiple petabytes;cluster;network challenges;disk usage;terabytes;data;high network;network;facebook;center network;recovery;network traffic;codes;piggybacking;data results;solomon;paper;reed;large amounts", "pdf_keywords": "hadoop distributed file system;distributed storage systems;hdfs;new storage code;erasure codes;traditional erasurecodes;storage;data recovery;erasure;inef\ufb01cient recovery operations;piggybacking framework;data centers;facebook warehouse cluster;recovery operations;warehouse cluster;rs codes;rs code;network infrastructure;network challenges;disk usage;data;codes;code;recovery;solomon;facebook;network;rs;center network;implementation"}, "af44f5db5b4396e1670cda07eff5ad84145ba843": {"ta_keywords": "textual compositionality;words representations;qanta learns word;text classification methods;recursive neural network;factoid question;quiz bowl;paragraphs;sentences;neural network;trivia competition;questions;previous rnn models;string matching rules;rnn;qanta;tasks;entities;such input;level representations;reason;bag;dataset;phrase;model", "pdf_keywords": ""}, "1bd43c91ecbf46098ef2b521c5367e849819960e": {"ta_keywords": "neural machine translation;monolingual data;domain adaptation;translation;language pairs;domain text;translate;weighting strategies;synthetic data;competitive baselines;model performance;improvements;back;sentence;nmt;resource;resource mt settings;target domain;improvement;bleu points;models;data selection;addition;samples;previous iteration;goals;current quality;selecting;common practice;effective method", "pdf_keywords": "neural machine translation;translation baseline;domain adaptation;monolingual data;english datasets;translation;language pairs;best static data selection strategies;iterative back;english;model performance;improvements;competitive nmt models;bleu points;resource mt settings;dynamic data selection;resource;performance;back;better performance;nmt;models;curriculum;mt settings;lithuanian;weighting;effective strategy;strategies;impressive gains;zi"}, "16f0c508aa54e26aa18e3b0f3c91b0c143c6a605": {"ta_keywords": "speech recognizers;minority group user satisfaction;minority groups;representation disparity;minority group;fair models;disparity amplification;machine learning models;empirical risk minimization;fairness;repeated loss minimization;rawlsian distributive justice;autocomplete task;examples;higher loss;groups;demographics;training objective;erm;average loss;world text;risk;dro;improvements;identity;spirit;time;paper;status quo;approach", "pdf_keywords": "ampli\ufb01es representation disparity;minority groups;minority group user satisfaction;unfairness;representation disparity;fair models;speech recognizers;disparity ampli\ufb01cation;fairness;loss minimization;distributive justice problem;repeated loss minimization;machine learning models;distributional robustness;empirical risk minimization;autocomplete task;training objective;demographics;higher loss;examples;erm;dro;ml;discussion;improvements;world text;hongseok namkoong;percy liang;average loss;bene\ufb01t"}, "5c159745fce2b87e8b00307b76f0948b9fa8b1d7": {"ta_keywords": "translation tasks;recurrent neural network language model;syntactic parser;language pairs;target language;translation;asian translation;rnnlm;possible syntactic analyses;fluent output;forest;manual evaluation;nara institute;input sentence;f2s;workshop;baseline f2s system;naist;string;systems;system;addition;highest results;technology;submission;science;paper", "pdf_keywords": ""}, "7a1a202e268ccc910e8044be556e56aa9eb5a94f": {"ta_keywords": "automated dependence plots;dependence plots;bias detection;generative model;machine learning;model selection;datasets;raw feature space;sample behavior;latent space;interesting pdps;single features;example;pdps;model response;model;usefulness;selection;various qualitative properties;multiple use;test accuracy;standard metrics;arbitrary directions;drawbacks;practical applications;method;cases;order", "pdf_keywords": ""}, "c674ce6454d69a87f00797f3ec90d1b38b451063": {"ta_keywords": "dual stochastic gradient oracle method;convex optimization problems;optimal point;networks;batch size;duality gap;convergence;large deviations;iteration sequence;new technique;distance;rate;probability;solution;new analysis method;starting point;proper choice;terms;analysis", "pdf_keywords": "dual stochastic gradient oracle method;stochastic convex optimization;convex optimization problems;dual approach;optimal point;networks;duality gap;batch size;primal;large deviations;iteration sequence;convergence;darina dvinskikh;new technique;nov;distance;pavel dvurechensky;solution;new analysis method;probability;rate;starting point;eduard gorbunov;terms;analysis;proper choice;oc;alexander gasnikov;math"}, "2aecdd190066a57db8fea1e1143dc5fc288050e0": {"ta_keywords": "privacy tradeoff;privacy metric;smart grid operations;privacy;smart grid application;iot;private parameter;adversary;strong adversary model;utility;load control example;monitoring;efficiency perspectives;consumers;internet;data;tradeoff;control;loads;performance;simulation results;proof;general framework;algorithm;frequency;ability;many advantages;operational value;concept;physical systems", "pdf_keywords": ""}, "242cf2e991f0eed4b1309a2a9dff548e8b95900f": {"ta_keywords": "learning based beamforming methods;robust speech recognition;speech recognition;speech recognition task;same speech recognition task;beamforming methods;gaussian mixture model;neural network;generalized cross correlation;maximum likelihood estimation;learning;minimum variance distortionless response;weights;features;traditional delay;mask;gcc;sum;timefrequency;mvdr;tf;methods;paper;comparative study;study", "pdf_keywords": ""}, "b3bd90f630b2d19856ef031b3dddfcb9b041b243": {"ta_keywords": "learning strategies;other learning strategies;tutored problem solving;cognitive skills;learning program;tutor;example study;examples;study;skills;student study;hints;results;feedback;error detection;simulated;advantage;problems;machine;problem;theoretical implications;correction", "pdf_keywords": ""}, "dd3770b2dbc9668578fefdc078d37457ba9c0b9a": {"ta_keywords": "electrolaryngeal speech enhancement;speech enhancement;voice conversion method;noise reduction method;excitation feature prediction;statistical excitation prediction;laryngectomees;electrolarynx;el speech;electrolaryngeal;hybrid enhancement process;excitation parameters;excitation;el;spectral parameters;prediction;hybrid method;pass filtering;evaluation;hybrid approach;device;unvoiced;effect;part;previous work;paper;issues", "pdf_keywords": ""}, "44cabe32482d4b622d9ca00bf23b3ee7950e2710": {"ta_keywords": "ml judgments;machine decision;predictive decisions;predictive decision;ml complementarity;better predictive decision;judgments;machine learning;human psychology;higher quality decisions;decisions;human;unifying optimizationbased framework;complementary strengths;exploratory analysis;ml;unifying framework;criteria;computer interaction;models;variation;systems;context;humans;making differ;insight;optimal ways;making;taxonomy;future work", "pdf_keywords": "machine decision;machine decisions;predictive decision;machine predictions;predictive decisions;ml complementarity;ml predictions;judgments;unifying optimization;formalization;optimal aggregation;general optimization;human;unifying mathematical framework;models;systems;unifying taxonomy;optimal ways;ml;variation;taxonomy;distinctive characteristics;summary;context;special cases;making;framework;scope;factors;various conditions"}, "3ac59132297f4e50d5e83852555392f9ff05d8b4": {"ta_keywords": "decentralized distributed optimization;composite optimization;free method;derivative;applications", "pdf_keywords": "convex composite optimization problem;gradient sliding method;order sliding algorithm;sliding algorithm;convex composite problem;composite optimization problem;smooth part;order oracle;order oracles;nonsmooth part;\ufb01rst method;smooth component;stochastic;order;convergence analysis;zosa;new method;method;zeroth;analysis;lan;details;terms;paper;way;section;oc;knowledge;abstract;sep"}, "ff3b83ef0a153ed376556057269f3a61da3a103a": {"ta_keywords": "symbolic multitrack music;assistive composing tools;multiple instruments;solo music;instruments;different instruments;automatic instrumentation;different genres;game music;string quartets;convincing instrumentations;voices;ensembles;bach chorales;musician;diverse datasets;original solo music;part labels;pop music;part separation;tracks;comprehensive empirical evaluation;notes;parts;performance;keyboard;mixture;machine;modern keyboards;pitch ranges", "pdf_keywords": "voice separation model;part separation;multitrack music;game music datasets;part labels;string quartets;multilayer perceptron;pop music;violins;parts;mlp model;mixture;mlp;algorithm;machine;convincing instrumentations;models;notes;arrangement;test samples;high computation cost;task;sequences;zone;new task;subset;oracle cases;paper;oracle case;feasibility"}, "cb90d5ea3a95b4c6ec904f622f51d752f506636e": {"ta_keywords": "metric learning;deep siamese networks;structured preferences;metric;cpmetric;flexible value alignment system;ai systems;value alignment;ai system;ethical systems;neural network architecture;machines;ethical principles;orderings;preferences;user preferences;nets;recommendations;certain norms;decisions;cp;tools;guidelines;actions;distance;formalism;same formalism;humans;system;approximation", "pdf_keywords": ""}, "d4f5f1a196e203226e4a69d52a04d46823f32fb3": {"ta_keywords": "centric parallel corpus;available parallel corpora;available parallel corpora collection;multilingual nmt models;monolingual corpora;multilingual representation models;parallel sentences;sentence pairs;many corpora;corpora;pivot language;indic language;indic languages;approximate nearest neighbor search;available benchmarks;sentences;document ocr;scanned documents;languages;large collection;samanantar;english;flores;tools;baselines;web;models;human evaluation;utility;samples", "pdf_keywords": "multilingual representation models;multilingual models;multilingual representation learning;indic language translation;monolingual corpora;indic languages;indic language;parallel sentences;many corpora;low resource languages;approximate nearest neighbor search;document ocr;translation;optical character recognition;indictrans;script model;english translation;scanned documents;benchmarks;sentences;english;samanantar;high resource;models;large collection;flores dataset;mining approaches;recent advances;higher performance;quality mt models"}, "d301054c2819e1a21480800fdabbe5ae909abe09": {"ta_keywords": "effective program synthesis;inductive program synthesis;program search;synthesis;natural language annotations;natural language hints;abstraction;programs;dreamcoder;strong library;generalizable machine learning systems;libraries;string editing;joint learning;scenes;image composition;search models;language;generalization;examples;quality libraries;art library;ef\ufb01cient search strategy;task;laps;search ef\ufb01ciency;key ingredients;general paradigm;functions;technique", "pdf_keywords": "learned program synthesis;hierarchical program induction model;learned synthesis;program search model;program learning;reusable program abstractions;synthesis tasks;program search;generative models;compositional generative models;natural language annotations;generalizable library;abstraction;language annotations;natural language;search models;conditional search model;synthesis;hierarchical bayesian models;programs;search model;joint learning;additional annotations;minds;libraries;library;new tasks;language guides;brains;language"}, "27b7489bd54dfd585edd2ba0da3920a31e7fd8b5": {"ta_keywords": "continuous sensorimotor games;human sensorimotor;economic game theory;teleoperation;games;discrete decision;behaviors;machines;such games;agents;predictive models;behavior;other agents;game;interaction;learning;imperfect information;predictions;machine;natural model;experiments;neuromechanical setting;empirical observations;dynamic closed loop;humans;beliefs;quadratic cost;environment;perspective;linear system", "pdf_keywords": ""}, "af38829cdb55ee7b71d49399f71397d975e40a95": {"ta_keywords": "question answering;conditional answers;answerable questions;long context documents;extractive questions;answer conditions;dataset conditionalqa;compositional logical reasoning;questions;conditionalqa;multiple answers;answers;complex questions;qa models;long documents;qa;dataset;complex ways;information;certain conditions;combination;further research;addition", "pdf_keywords": "conditional answers;challenging dataset conditionalqa;extractive questions;compositional logical reasoning;answer conditions;conditionalqa dataset;answerable questions;qa models;competitive qa models;conditionalqa;long context documents;complex logic;questions;complex questions;multiple answers;answers;long documents;document;conditions;models;dataset;correct answers;conclusion;baselines;complex ways;information;combination;further research;addition;order"}, "2c2234548de4694b6455a19cd0d85a9d6c473456": {"ta_keywords": "approximate search methods;new search methods;search methods;search quality;similarity;space access methods;metric spaces;benchmarks;spaces;approximate answers;library;tools;code;other applications;fewer exact solutions;results;methods;technical details;document;main focus;art;variety;goal;state", "pdf_keywords": "extendable crossplatform similarity search library;similarity search methods;multimedia datasets;comprehensive toolkit;nmslib;fastmap;fast algorithm;indexing;toolkit;\ufb01rst library;data;visualization;objectives;project;history;mining;evaluation;goal;volume;principled support"}, "c00ba15810496669d47d2ed5b627e6c7d2b1f6aa": {"ta_keywords": "generative tasks;language modeling paradigm;texts;target text;retrieval;many languages;information retrieval;translation;paraphrase;sequence model;several tasks;sequence;random initialization;self;strong performance;shot performance;marge;aspects;reconstruction;objective;set;alternative;likelihood;range;tuning;date", "pdf_keywords": "multilingual autoencoder;language modeling;generative tasks;natural language understanding;sequence model;texts;target text;generates;many languages;content;encodes;models;generation;document;documents;retrieves;task;appropriate inputs;marge;reconstruction;self;\ufb01ne;strong performance;best reconstruction;new approach;original;results;target;step;range"}, "4b890b6ded71f005414e55adb87c23efd437ef95": {"ta_keywords": "statistical parametric speech synthesis;synthetic speech quality;concatenative speech synthesis;synthetic speech;voice conversion;speech parameter trajectories;ms utterance;natural speech;speech;utterance;delay synthesis;generation algorithm;conventional generation algorithm;hidden markov model;clustergen;gmm;level postfilter;tts;modulation spectrum;gaussian mixture model;gv;postfilters;vc;text;ms;quality;segment;global variance;hmm;feature", "pdf_keywords": ""}, "1006d191e9eb5b4dbc35fc0bb389328ddc75cba7": {"ta_keywords": "language models;token sequences;byte sequences;byte;character sequences;raw text;free models;bytes;standard transformer architecture;tokens;pipelines;characters;text;new model architectures;inference speed;language;prone text;minimal modifications;subword units;pronunciation;level models;sequences;spelling;word;tasks;level counterparts;cost;parameter count;training flops;technical debt", "pdf_keywords": "multilingual tasks;bytelevel models;nlp pipeline;multilingual t5;tokenization;generative tasks;vocabulary building;decoder models;byte sequences;encoder;byte;language labels;level encoder;pronunciation;byt5 outperforms mt5;inference speed;spelling;level tasks;text preprocessing;decoder depth;tasks;word;level counterparts;minimal modi\ufb01cations;standard transformer architecture;level models;free variant;byt5;longer id sequences;training flops"}, "041b2510e54b2504890cb9f58b9bbc5601f35e3e": {"ta_keywords": "level nlp course;assignments;assignment;nlp;parse trees;students;inference algorithms;lstms;dynamic programs;modern neural architectures;weak supervision;training methods;approximate search;tags;logical forms;level research;students hands;sequences;structure;course;graduate;several key types;transformers;set;goal;end;experience", "pdf_keywords": ""}, "399ab2a0eddf7a7abf776241d5c0a2c4cd5bf313": {"ta_keywords": "weighted finite state transducer;speech model;speech recognition;discriminative training approaches;language models;discriminative model;language model layers;input speech signal;decoder;weight parameter optimization;speech;search network;better recognition performance;conventional maximum likelihood;large network;searches;recognition;models;knowledge source;lexicon;separate knowledge sources;log;appropriate label sequence;model size;linear distributions;parameters;wfst;graph;possible combinations;paper", "pdf_keywords": ""}, "4b9bc5b5985bbfbc860039b98f233f8a43ad9171": {"ta_keywords": "numerical partial differential equations;pdes;pde;neural network;dimensionality;random coefficients;physical quantities;input coefficients;physical quantity;coefficient fields;variability;few features;physics;uncertainties;equations;engineering;accuracy;simplicity;space;function;interest;approach;notable examples;such observation;curse", "pdf_keywords": "convolutional layers;neural network;simple convolutional neural network;inhomogeneous potential;pdes;elliptic equation;nonlinearity;ground state energy;inhomogeneous media;nlse;network;2d case;numerical experiments;translational symmetry;e\ufb00ective conductance;linear map;numerical results;architecture;pooling;unit;dimensions;such function;relu;implementation details;\ufb01nal output;domain;sum;main part;section;e\ufb00ectiveness"}, "302face5b5a0944cab13665a2d4e07ef3aaf5240": {"ta_keywords": "domain question answering;domain qa benchmark;weakly supervised learning;new topics;strong baseline models;questions;new task;answer pairs;unambiguous answer;ambigqa;ambignq;task;nq;domain questions;ambiguous;dataset;significant future research effort;ambiguity;original question;data;question;plausible answer;domain question;rewrite;benefit;paper;set", "pdf_keywords": "question disambiguation model;strong baseline models;weakly supervised learning;open dataset;opendomain qa benchmark;partial supervision;\ufb01rst baseline models;questions;multiple answers;full nq;new task;ambigqa;tosequence model;ambignq;task;nq;dataset;open;new components;data;sequence;democratic cotraining;art qa model;question;domain questions;development data;shot;future work;signi\ufb01cant future research effort;one"}, "d86227948b6000e5d7ed63cf2054ad600b7994a0": {"ta_keywords": "deep unordered composition rivals syntactic methods;natural language processing tasks;text classification;sentiment analysis;deep learning models;simple deep neural network;word order;compositionality;factoid question;syntax;tasks;aware models;such models;input;many expensive computations;network;inputs;model;fraction;similar errors;training time;cases", "pdf_keywords": ""}, "8c4b187bdaf91bf068adfe005a0463c4f9c36387": {"ta_keywords": "powerful deep architectures;deep learning;topological features;iterative refinement;wise losses;automatic delineation;wise loss;final prediction;aerial images;new loss term;linear structures;delineations;refinement pipeline;accuracy;predictions;same classifier;topological impact;previous delineation;complexity;many current approaches;mistakes;art methods;quality;wide range;data;same model;step;paper;model constant;state", "pdf_keywords": "road segmentation;segmentation;pixel labeling;crack detection method;segmentation methods;neuronal boundaries;natural images;neural network;cracks;cracktree;image patches;aerial images;resolution recursive approach;roads;ldnn;detection;iterative re\ufb01nement pipeline;centerlines;neuronal membranes;delineations;autocontext;iterative re\ufb01nement;recent detection;re\ufb01nement pipeline;new loss term;accuracy;wise loss;predictions;linear structures;regression"}, "8147a495b9a933742f06458244f7c5df00767c4e": {"ta_keywords": "open information extraction;current supervised open ie systems;extraction likelihood;natural language sentences;aware learning;extractions;open ie model;additional binary classification loss;open ie;training samples;domain assertions;iterative rank;assertions;confidence modeling;iterative learning process;different sentences;ie;likelihood;recall;confidence measure;precision;trial;task;quality;model;key step;error", "pdf_keywords": "open information extraction;assertion generation;natural language sentences;neural models;domain assertions;aware learning;iterative rank;extractions;rerank;neural network model;binary classi\ufb01cation loss function;iterative learning approach;base model;graham neubig language technologies institute carnegie mellon university;open ie;generate;model;abstract;conclusion;substantial improvement;end;ie;formulation;end performance;loss function;task;cl;pengcheng yin;\ufb01ne;paper"}, "43e8e371449aaef34c2f43ae90f2157fd5a617bd": {"ta_keywords": "pricing mechanisms;nash equilibrium;selfish agents;weighted pricing;optimal feedback control strategy;optimal cost;pricing;dynamic games;social planner;feedback control;coordination;cost;agents;fairness;riding;methods;notion;problem;use;means;addition;impact;difference", "pdf_keywords": ""}, "830a396a4a77567caad1c155dd3b22597314e9f3": {"ta_keywords": "algorithmic fairness;fairness metric;computational social choice;fairness;machine learning research;social choice;personalized recommendation;aware systems;system outcomes;institutional logics;technical systems;constrained optimization;stakeholders;real world;promising framework;applications;application;multiple perspectives;example;abstract model;larger context;poor match;multiple classes;integration;exercise", "pdf_keywords": ""}, "5083d9e25113a09faeba7d56b7808e2f77b5c15e": {"ta_keywords": "large symbolic knowledge base;several learning tasks;alternative implementations;efficient differentiable implementations;entities;simple models;neural model;memory trade offs;new operation;order;triples;kb;kbs;millions;techniques scale;tens;competitive performance;different time;number", "pdf_keywords": "deep learning;memory;memory trade offs;lstm controller;alternative implementations;large symbolic kbs;neural ilp system;kb completion;learning;scalable implementation;many different architectures;neural model;entities;simple qa tasks;component;kbs;reasoning;monolithic architecture;relations;appropriate implementation;facts;single new operation;relation;new operation;relationset following;end settings;operation;framework;end;millions"}, "4b762c0344f14bb00d590f5666c27b3aac7b0a7d": {"ta_keywords": "dependency recurrent neural language models;microsoft research sentence completion challenge;sentence completion;recurrent neural network;dependency rnn;language model;language modelling;syntactic dependencies;neural models;rnn;sentence;models;word;count;accuracy;relevant contexts;focus;points;recent work;performance;effect;paper;approach", "pdf_keywords": "dependency rnn language model;neural language models;novel neural language model;dependency rnn;recurrent neural network;syntactic dependencies;syntactic dependency parse;microsoft research sentence completion challenge;novel language model;language model;rnn;rnn formulation;sentence;accuracy;word;relevant contexts;outperforms;kavukcuoglu;mnih;ant;results;performance;mikolov et al;paper;conclusions;effect;teh;points;top;work"}, "bcd45c86e1bcf8d1411eb6704c4c58d0831b5b4f": {"ta_keywords": "multinomial distribution;classification tasks;statistical models;occurrence;binomial distributions;text;words;poisson;more classes;models;higher frequencies;analytic tractability;simplicity;negative;desirable properties;paper;wide range;sensible manner", "pdf_keywords": ""}, "0ad8284dbae11901a725cc71318a165c08852278": {"ta_keywords": "voice conversion;voice conversion studies;speaker gmm;gaussian mixture model;speaker model;parallel corpus;joint density gmm methods;few parallel utterances;utterances;target speakers;joint density model;probabilistic densities;probabilistic formulation;training data;same linguistic content;probabilistic integration;speakers;gmm;joint vectors;target;transformation;source;addition;training effects;sufficient quality;paper;amount;novel approach;approaches;plenty", "pdf_keywords": ""}, "b21b927c251c415b601b6d7f785a42cc5c292635": {"ta_keywords": "scientific information extraction;scientific knowledge graph;coreference clusters;scientific literature;annotations;scientific articles;sciie;scierc;tasks;entities;span representations;dataset;relations;information;unified framework;specific features;domain;previous models;experiments;framework;construction", "pdf_keywords": "coreference clusters;relation extraction;coreference resolution;scienti\ufb01c information extractor;scienti\ufb01c entities;annotations;entities;entity;span representations;span boundaries;scienti\ufb01c articles;relations;sentences;tasks;sciie;scierc;features;art scienti\ufb01c ie systems;new dataset;dataset;uni\ufb01ed framework;model;pipeline processing;conclusion;paper;previous state"}, "34fb3e21a63fb2987f7a87f88ecf49aea53cff36": {"ta_keywords": "cooperative persuasive dialogue policies;framing", "pdf_keywords": ""}, "95cedaeb3178a4671703a05171a144e6b964a819": {"ta_keywords": "neural language models;language models;neural lms;hybridizing count;mixture weights;statistical models;novel hybrid models;vocabulary;words;probability distributions;models;probabilities;count;distributions;single modeling framework;lms;other discrete symbols;generalizing;formulation;sequences;desirable features;varieties;experiments;approaches;set;advantages", "pdf_keywords": "neural language models;language models;language modeling exist;gram models;neural lms;gram lms;hybridizing count;novel hybrid models;statistical models;vocabulary;models;words;lms;mixture weights;count;mixture;generalizing;single modeling framework;probability distributions;other discrete symbols;distributions;probabilities;superior modeling performance;weights;sentence;formulation;sequences;major paradigms;desirable features;sep"}, "a13d8400813743adb22ba0bd0570c49af2675a39": {"ta_keywords": "long recording speech separation;continuous speech separation;speech separation;separation performance;long recording;separation;level separation models;level separation;path rnn;recording;length blocks;overlap;dprnn;block;free targets;architecture;straightforward extension;sentence;such simple extension;css;task", "pdf_keywords": ""}, "54316d2861eb3d575a8c7d071f4cf7c2fc30be01": {"ta_keywords": "adversarial performance;adversarial manifold;adversarial attacks;empirical robustification;robust classifiers;image translation model;randomized smoothing;image reconstruction;smoothing;denoiser;classifiers;robustifers;randomized smoothing element;classifier;robust fashion;accuracy;retraining;multiple classifiers;fidelity;losses;image;quality;inference time;costly procedure;entire pipeline;recent technique;network;architectures;preprocessing methods;real sense", "pdf_keywords": ""}, "73bbd0b53044e9f518a3596a3607521bbce12fc2": {"ta_keywords": "regularized segmentation losses;cnn segmentation;gradient descent;loss functions;crf regularization models;segmentation;complex neural networks;basic local optimization;loss function;loss;alternative optimizer;optimization methods;global solvers;mrf;training;simplicity;more attention;architectures;gd;context;adm;network design;art;work;default method;state", "pdf_keywords": ""}, "a5b1d1cab073cb746a990b37d42dc7b67763f881": {"ta_keywords": "semantic parsing;form nl questions;nl sentences;natural language;form nl text;language models;structured data;tables;textual;tabular data;nl;database tables;understanding tasks;lms;tabert;text;joint understanding;tasks;representations;lm;reasoning;such models;paper;recent years;burgeoning", "pdf_keywords": "semantic parsers;different semantic parsing paradigms;parallel nl utterances;nl utterances;learning benchmark wikitablequestions;speci\ufb01c parser;parser;nl text;latent db queries;contextual representations;utterances;utterance token;tabert;db tables;sql dataset;bert;tabular data;db queries;purpose feature representation layer;structured schema;benchmarks;table column;classical supervised learning;task;joint understanding;strong results;spider text;execution results;\ufb01ne;pasupat"}, "7e870eb8d580fb1b8b7a8f97d94d67555a225635": {"ta_keywords": "intelligent message addressing;expert search;message addressing problems;recipients;recipient contact;email users;email;large corpus;potential recipients;intelligent auto;different email users;queries;completion;completion experiments;persons;auto;baselines models;neighbors algorithm;nearest;significant performance improvements;few initial letters;related task;message;mrr;task;formal models;combinations;performance;models;fusion techniques", "pdf_keywords": ""}, "267b94325028e0e2e6da1ae2cbe7f7a93284722e": {"ta_keywords": "walk similarity measures;extended similarity metrics;structural graph;lazy graph walk;contextual search;social networks;email data;name disambiguation;email messages;graphs;content;graph;email;documents;other documents;timeline;detailed instantiation;appropriate learning methods;header information;further improvements;other messages;use;baseline methods;paper;instance;other objects;framework;many interesting settings;schemes", "pdf_keywords": ""}, "a309ad4c4088843d230be1a85806960e633e1e46": {"ta_keywords": "data curation;nlp community;deep learning models;curation;annotation artifacts;datasets;data;social biases;models;resources;spurious patterns;more research;alternative;world;progress;development;arguments;point;careful design;lot;position paper maps;kinds;specific signals", "pdf_keywords": "data curation;ai ethics;nlp community;nlp;computational linguistics;social data science;deep learning;ethical perspectives;curation;data;natural language processing;data2;deep learning models;emnlp;interdisciplinary tension;arguments;uncontroversial conclusion;9th international joint conference;resources;ijcnlp;more research;abstract;empirical methods;world;development;china;proceedings;conference;qualitative approaches;core"}, "1be28ce9a1145c2cf4f78e6c494a4c15397fbac3": {"ta_keywords": "large biomedical knowledge graphs;knowledge summarization graph;efficient knowledge graph summarization;drug interaction prediction;subgraph summarization scheme;massive external biomedical knowledge;pharmacological effect prediction;subgraph extraction module;interpretable prediction;low data relation types;drug interactions;binary ddi prediction;subgraph;sumgnn;datasets;relevant subgraphs;neural network;ddi predictions;drug;reasoning paths;prediction;adverse ddi;data integration module;reasoning path;machine learning models;ddi;attention;best baseline;new method sumgnn;results", "pdf_keywords": "knowledge summarization graph;subgraph summarization scheme;knowledge summarization module;subgraph extraction module;subgraph information;massive external biomedical knowledge;subgraph;local subgraph module;relevant subgraphs;neural network;sumgnn;attention;graph;data integration module;reasoning path;ddi predictions;new method sumgnn;predictive outcome;biological insights;predictive performance;drug interaction prediction;conclusion;interpretability;world datasets;pathway;results;addition;self;gaps;kg"}, "ce6143e24a455edc233f12933e9903426b963799": {"ta_keywords": "latent dirichlet allocation;statistical topic models;variational em algorithm;various sized document collections;parallel implementations;variational em;lda;implementations;dramatic improvements;scalability;unsupervised fashion;attractive framework;model;speed;version;experimental evaluation;work;ups;setting", "pdf_keywords": ""}, "51bf7a3aee6b1f61b902625f6badffedf200d31a": {"ta_keywords": "deep generative model;generative models;gan;associative memory;deep network;linear associative memory;several interesting structural rules;such rules;specific rules;layers;physical rules;rule;target distribution;layer;manipulation;network;formulation;paper;rich set;art;algorithm;entry;state;new problem;problem", "pdf_keywords": "deep generative model;generative models;generative model;linear associative memory;associative memory;deep generator;deep network;gan;layer stores latent rules;nonlinear convolutional layer;hidden features;layers;layer;several interesting structural rules;user interface;speci\ufb01c rules;concept applications;manipulation;rules;idea;novice users;rule;formulation;value relationships;paper;several proof;users;art;entry;algorithm"}, "990c7726dd31723f97a364828d5191080fe7ec2d": {"ta_keywords": "universal topological quantum computing;chiral topological superconductor;majorana edge mode;integer factorization algorithm;tricritical ising model;shor;example;application", "pdf_keywords": "universal tqc;conventional quantum circuit models;quantum circuit model;quantum gates;quantum models;conformal \ufb01eld theory properties;layer tsc system;fibonaccitype anyons;\u03c7mems;mems;article;advantages;main goal;ii"}, "6fae71765a5e86dfef2f93bbe03c4a2e20f827b5": {"ta_keywords": "naist english speech recognition system;english automatic speech recognition;spoken language translation;core speech processing technologies;deep neural net;recognizer output voting error reduction;asr systems;separate language models;decoding;acoustic models;asr;weighting approach;lattice rescoring;recognition;rank;evaluation campaign;annual evaluation campaign;international workshop;dnn;naist;score;nara institute;rover;system combination;iwslt;various frontends;track;application;contribution;stages", "pdf_keywords": ""}, "b9e6c65aacfe8ecc1b7833b47803672273a918ec": {"ta_keywords": "\u78ba\u7387\u7684\u30bf\u30b0\u4ed8\u4e0e\u30b3\u30fc\u30d1\u30b9\u304b\u3089\u306e\u8a00\u8a9e\u30e2\u30c7\u30eb\u69cb\u7bc9", "pdf_keywords": ""}, "cf08bef866885edb8b001deb18e582eec94c51de": {"ta_keywords": "domain ted talk summarization;automatic speech summarization;spontaneous speech summarization;speech summarization;human summarization;domain ted talks;free talks;meaningful messages;semantic similarity;acoustic features;disfluencies;topic;new evaluation method;addition;challenges;system;fillers;paper;use;problem;methods;experiments results", "pdf_keywords": ""}, "b790c3e712c92065d596364af81a494adbc62c39": {"ta_keywords": "neural generative models;generative models;robust optimization;model selection heuristics;inner maximization objective;optimization;realistic nlp tasks;training machine learning models;parameter search;distributions;models;uncertainty set;related data distributions;gradient;specific selection;uncertainty;case distribution;model;toy settings;simple alternatives;large scale;relaxation;loss;comparable baselines1;careful design;collection;kl;dro procedure;dro;dro problem", "pdf_keywords": ""}, "43d5c00938bd2acb1aca8e81a7d220025eddbc23": {"ta_keywords": "normalisierung historischer deutscher texte;guidelines f\u00fcr", "pdf_keywords": ""}, "6695d3b92e7cd7f2359f698a09c7b3dc37996329": {"ta_keywords": "label augmented multimodal pretraining;such label augmentation;visual objects;stage pretraining;labels;language pairs;vision;quality vision;auto;tasks;various downstream tasks;task;novel label;lamp;practice;potential benefit;alignment;interest;use;large volume;values;paper;requirement;problem", "pdf_keywords": "shot image retrieval;visual objects;label alignment task;labels;textual description;vision;image;imagebert;task;downstream tasks;language pairs;art models;novel label;lait;auto;alignment;lamp;\ufb01ne;results;distortion;new object;value;effectiveness;paper;analysis;insuf\ufb01cient coverage;state;quantitative results;problem"}, "887d84c1310c6e71a0f89874ef9985b65a44c855": {"ta_keywords": "acoustic feature space;discriminative feature;noisy speech recognition experiment;speech recognition community;feature transform;feature compensation;transformed features;recognition performance;discriminative criterion;gaussian mixture model;features;dmmi criterion;train feature;gaussian;mmi;maximum mutual information;compensation techniques;transformation;posterior probability;mpe;gmm;much interest;paper;use", "pdf_keywords": ""}, "46bf4bece58764d22764acfd3d232b50fb7767f9": {"ta_keywords": "3d deep convolutional neural networks;structural mri data;alzheimer;hippocampal formation;ad classification;deep learning;mri affirms;cnns;disease classification;longitudinal scans;classifiers;classification;classification studies;generalization performance;imaging modalities;ad;prominent feature;data;other disorders;disease;diagnosis;training;regional analyses methods;signatures;finding;prominence;results;study;evidence;anatomical seat", "pdf_keywords": ""}, "6f173939f6defe3ebae8fb12f19349ba96b7b5c4": {"ta_keywords": "accurate diarization results;end diarization methods;diarization;unsupervised clustering;diarization results;wise diarization results;unsupervised clustering process;end diarization;whole recording;wise embeddings;subsequences;subsequence;short subsequences;speakers;output speakers;attractors;vectors;attractor;dihard iii datasets;sequence;frame;training;callhome;di;number;unseen number;end;large number;work;one", "pdf_keywords": "acoustic features;speaker waveform;transformer encoders;speakers;wise embeddings;invariant training;diarization;diarization results;input sequence;training data;attractor;attractor calculation part;vectors;short subsequences;subsequence;local attractors;sequence;frame;mixture;rest permutation;extraction part;system;residual output;maximum number;number;pit;unseen number;large number;rest;method"}, "1fb88c130bedcd2e75fd205b70af2999c6a8c49d": {"ta_keywords": "malicious edges;graph neural networks", "pdf_keywords": ""}, "6ad56b1b776a2c448fc90c543b50756941e5a119": {"ta_keywords": "demand response programs;energy consumption patterns;utility companies;consumers;consumer interaction;incentives;consumer;utility function;utility company;agent problem;revenue;iterative algorithm;many motivations", "pdf_keywords": ""}, "bb6317bbd2c4a81e94cf3d7eb1b73da246a022db": {"ta_keywords": "nearest neighbor language models;neural language model;nearest neighbor search;nearest neighbors;original lm training data;memorization;next word;similarity;text;lms;text collection;point improvement;neighbors;distance;lm;additional training;language;original training set;model;augmentation;long tail;sequences;space;generalization;results;new state;effective approach;art perplexity", "pdf_keywords": "nearest neighbor language models;effective domain adaptation;neural language model;language models;new language modeling approach;nearest neighbor;representation learning problem;simple nearest neighbor scheme;pre\ufb01x embeddings;nearest neighbors;memorization;similarity;next word distribution;training data;training examples;effective similarity function;knn;transformer lm;larger training sets;contexts;representation;transformer;generalization;representation function;model;lms;lm;prediction problem;implicit notion;strong evidence"}, "b31eb3428320342dfde042693ff2ca106dabed0d": {"ta_keywords": "abstractive summarization;sequence learning framework;contrastive learning;text generation;cnn;learning objective;sequence;evaluation metrics;dailymail dataset;absolute improvement;large margin;free evaluation problem;quality estimation;scoring systems;models;performance;reference;simcls;powerful framework;minor modification;simple framework;new level;paper;art performance;bart;experimental results;gap;state", "pdf_keywords": "abstractive summarization;text summarization;sequence learning framework;contrastive learning;text generation;candidate summaries;learning objective;evaluation metrics;mle training;sequence;parameterized evaluation model;free evaluation problem;abstract;quality estimation;test stages;training;reference;large margin;models;performance;mle loss;seq2seq model;paradigm;simple framework;powerful framework;minor modi\ufb01cation;jun;topscoring systems;carnegie mellon university;simcls"}, "5b1516c87818084dc5d195cc274e1ee8923210d2": {"ta_keywords": "lingual named entity recognition;bilingual word embeddings;entity recognition;translations;rich languages;natural language processing models;languages;lexical items;annotated resources;attention;word order;word order differences;competitive ner performance;ner;minimal resources;mapping;transfer;lower resource requirements;resource;self;robustness;respect;flexibility;state;degree;past approaches;art;method;appealing capability;methods", "pdf_keywords": "new lexical mapping approach;discrete word translations;lexical mapping;translations;target language;seed lexicon;different languages;word order differences;languages;project embeddings;discrete dictionary;unsupervised transfer;nearest neighbors;bwe space;words;source code;space;data;challenge;paradigm;model;major challenges;extreme scenario;paper;methods;above issues;advantages"}, "1ce0664989e0b28ceea223cab68f885ed18c39c4": {"ta_keywords": "speech modeling;speaker clustering;gaussian mixture model;speech dynamics;hierarchical mixture model;gibbs sampling;speaker cluster;speech;mixture components;bayesian information criterion;utterance;gibbs;wise temporal scales;time scale;gaussian;bayesian treatment;corresponding time unit;model;bic;dynamics;instance;extension;m3;intervals;aim;serious local optimum problem;time;addition;potential;approach", "pdf_keywords": ""}, "2154bdb9ce841eb98b9fd13bf7bf0a42f11f89a6": {"ta_keywords": "iterative averaging protocol;decentralized training;imagenet;preemptible compute nodes;speed networking;dedicated clusters;multiple compute nodes;deep neural networks;protocols;large datasets;competitive gossip;heterogeneous unreliable devices;protocol;strong theoretical guarantees;moshpit sgd;efficient;speedup;efficiency;communication;optimization;moshpit all;reduce;large;strategies;global average;scratch;work;albert;scale;experiments", "pdf_keywords": "heterogeneous compute nodes;multiple compute nodes;deep learning;deep neural networks;sgd;ef\ufb01cient decentralized training;dedicated clusters;speed networking;specialized message;protocols;moshpit sgd;large datasets;heterogeneous unreliable devices;protocol;learning;training;cloud;centralized local;exponential convergence rate;optimization;unstable network;implementation details;many realworld applications;vector institute;unreliable devices;strong theoretical guarantees;communication ef\ufb01ciency;communication;yandex;mipt"}, "d9212b207e49a3aa6806fb2ddadb303b7b1d47a8": {"ta_keywords": "hierarchical procedural knowledge;hierarchical modular networks;level tasks;situated agents;natural language;agent command;nl instruction;planner;agents;hierarchical control;nl intents;program execution;programs;executable programs;modeling paradigm;simple actions;command;hierarchies;procedures;particular task;alfred datasets;nl;formalism;framework;environment;information;humans;control;literature;iqa", "pdf_keywords": "level programming language;hierarchical procedural knowledge;hierarchical modular networks;level tasks;natural language;situated agents;complex tasks;python;graham neubig language technologies institute carnegie mellon university;programs;hierarchical control;planner;nl instruction;program execution;agents;nl intents;modeling paradigm;executable programs;particular task;procedures;alfred datasets;framework;abstract;environment;information;iqa;humans;control;example;predictions"}, "8fcd012e8ed2ea8190163369c9f222178e70a19d": {"ta_keywords": "hmm asr systems;connectionist temporal classification;conventional automatic speech recognition;end asr;single deep network architecture;joint decoding;conventional dnn;attention end;language models;conventional asr systems;neural network;asr;hidden markov model;mandarin chinese;scale asr benchmarks;attention;attention mechanism;acoustic frames;multiobjective learning;end architectures;linguistic resources;sequential problems;dnn;ctc;hybrid ctc;end;learning method;pass beam search algorithm;ctc scores;dynamic programming", "pdf_keywords": ""}, "49418122bba375fa02907d38b0be80689f750b39": {"ta_keywords": "neural network architectures;image classifiers;redundant computations;machine learning algorithms;decoding function;code;encoding function;redundant computation;unavailable predictions;encoding;learning;machine learning;unavailable computation results;approximate reconstructions;codes;mnist;unavailable outputs;training methodology;fashion;functions;network;failures;compute infrastructure;such unavailabilities;temporary slowdowns;large scale;available ones;unavailabilities;extensive experimental results;promising approach", "pdf_keywords": "neuralnetwork;erasure codes;neural network architectures;unavailable class predictions;unavailable predictions;code;novel learning;encoding;image classi\ufb01ers;approximate reconstructions;cifar10 datasets;codes;mnist;machine learning;unavailable computation results;unavailable outputs;training methodology;fashion;functions;jack kosaian1;paper;extensive experimental results;jun;effectiveness;approach"}, "49f657d704a1b80ce3dba0d8a9e5479ec1d703d4": {"ta_keywords": "term memory networks;speech recognition;deep transformers;input speech;machine translation;training input tokens;decoder;kaldi nnet3;asr;csj benchmarks;inference computation cost;aishell;end model;mask tokens;network;latency;special mask;performance;art end;context;chain model setup;real scenarios;possibility;preliminary results;production usage;large margin;paper;serious concerns;method;consideration", "pdf_keywords": "automatic speech recognition;input speech;novel nonautoregressive training framework;decoder;different nonautoregressive transformer structure;special mask tokens;mask tokens;unmasked context;input tokens;asr;cmlm;fmlm;classical dependency;tokens;easiest predictions;training;example;most dif\ufb01cult ones;frameworks;framework;network;goldberg;right;strategies;strategy;elhadad;paper;connection;conclusion;consideration"}, "a1321f4527559836509c27008329afaf11f8ea89": {"ta_keywords": "learning agent;cognitive skills;learning transfer;interleaved problem orders;interleaved problem order;effective learning;interleaved problem order yields;study;skill benefits;problem order;next problem type;problem orders;problem order implications;math;simulation study;interleaved order;student;problems;examples;agent;problem;fraction addition;better opportunities;error detection;effective performance;simstudent;results;science domains;machine;order", "pdf_keywords": ""}, "da46a0b5ddf0f4bf4caad9d29d6b4a93dd2eb2d2": {"ta_keywords": "bandit;initial heuristic algorithms;agent;games;modeling;specific problem;preliminary work;style problem;baselines", "pdf_keywords": ""}, "8ff54aa8045b1e30c348cf2ca42259c946cd7a9e": {"ta_keywords": "sequential question answering;novel dynamic neural semantic parsing framework;question answering;semantic parsing;neural structured learning;sequential context;normal conversation;art qa systems;sequential question;reward;task;complicated questions;search;complex questions;humans;state;model;recent work", "pdf_keywords": ""}, "aaaff6b99684cb5b5e0a68e214bd8bbd4bf2e231": {"ta_keywords": "entity recognition systems;syntactic parsing;conditional random fields;hidden markov model;biomedical full papers;datasets;new dataset;such systems;data;systems;evaluation;paper;challenges;terms;material;experiments;weaknesses;strengths", "pdf_keywords": ""}, "956e096b1e8422c91989938b9508272b956d3070": {"ta_keywords": "graph walks;graph walk performance;lazy random graph;reranking approach;reranking performance;supervised learning;nodes;local gradient descent algorithm;graphs;gradient descent algorithm;traversed paths;personal information management;graph;edges;entities;empirical evaluation;global approaches;features;tasks;best results;transition probabilities;relations;different approaches;methods;paper;multiple corpora show;domain;global properties;framework;setting", "pdf_keywords": ""}, "a4a8e91995ae8c8b203dd857bdc0915facddeebe": {"ta_keywords": "supervised learning;imagenet;annotated examples;worker quality;simulated noisy workers;annotation;noisy crowd;labels;models;many examples;coco;minimization proceeds;example;generalization error;data;model;algorithm;new algorithm;disagreement;loss function;rounds;ms;experiments;current estimate;threshold;current model;previous approaches;benefits;multiply", "pdf_keywords": "supervised learning;new supervised learning algorithm;noisy crowd workers;learning algorithm;labeled data;learning;annotated examples;noisy crowd;minimization proceeds;worker quality;workers;labels;generalization error;models;em algorithm;new algorithm;noisy singly;algorithm;many examples;model;ground truth;data;disagreement;loss function;worker qualities;current predictions;conference paper;iclr;may;rounds"}, "ca3535dcdda9849350ad7c991a60660b22844f2f": {"ta_keywords": "decomposable sequence tasks;searchable hidden intermediates;searchable hidden representations;speech translation;hidden intermediates;beam search;sequence model;end models;external models;compositionality;french test sets;fisher;intermediates;intermediate stages;model;test sets;end framework;callhome;english;instance;overall performance;domain data;multi;end;work;must;previous state;framework;network;aforementioned benefits", "pdf_keywords": "searchable intermediate representations;decoder model;searchable hidden intermediates;speech translation;englishfrench test sets;discrete transcript sequences;regressive encoder;decomposable sequence task;continuous hidden representations;callhome test sets;asr;compositionality;complex whole;bleu score improvement;fisher;test sets;parts;intermediate stage;model;english;baroni;callhome;previous state;output;auto;aforementioned bene\ufb01ts;ef\ufb01cacy;theart;must;introduction"}, "d56244c6abf3141900386d6911dd9097697a346b": {"ta_keywords": "simple web page classifier;page classifier;words classifier;hub pages;category anchor wrappers;anchor extraction;link analysis;pages;base classifier;unseen web site;categorization;page structure;link structure;learner;simple hub structure;wrappers;third learner;accuracy;restricted wrapper;features;site;results;paper;performance;bag;error rate;world test cases;technique;original bag;half", "pdf_keywords": ""}, "42605c1ee030721cb38a3c225992d63297a6ace0": {"ta_keywords": "practical language revitalization technologies;language technology;documentary linguists;other language technology;language documentation;language community members;corpora;language;dictionary extraction;natural language processing;social media analysis;workshop;first workshop;speech transcription;social media;speech;search tools;revitalization;technologies;such technology;text;bots;conservation;technologists;recent advances;carnegie mellon university;prototypes;phone;orthography;application", "pdf_keywords": "language technology;practical language revitalization technologies;language documentation;arapaho language;other language technology;documentary linguists;languages;language community members;irish gaelic;lakota language;conversational database;lakota speakers;arapaho;natural language processing;workshop;first workshop;video format;technologies;culture;cayuga;inuktitut;seneca;san juan quiahije chatino;aditi chaudhary1;patrick littell10;ojibwe;shruti rijhwani1;such technology;prototypes;mi 7university"}, "c8d0e13de2eaa09a928eff36b99d63f494c2f5ec": {"ta_keywords": "semantic parsing;syntactic neural model;purpose code generation;target programming language;language generation task;underlying syntax;natural language descriptions;target syntax;purpose programming language;grammar model;source code;novel neural architecture;python;prior knowledge;data;general;paper;previous work;methods;problem", "pdf_keywords": "neural semantic parsing model;neural code generation model;abstract syntax tree;neural code generation approach;sequence code generation model;semantic parsing;grammar model;syntax;target syntax;novel neural architecture;seq2tree;neural network model;python;latent predictor network;generation;generation story;derivation ast;production rules;sequential application;lpn;terminal tokens;prior knowledge;data;lapata;purpose pls;actions;backbone;paper;end;approaches"}, "9c03d14520c897ca8536e165507f568d1980dabd": {"ta_keywords": "machine comprehension test;machine comprehension;coreference resolution;lexical matching method;strong lexical matching method;natural language processing;question types;task;text;multiple context windows;datasets;machine learning;relative simplicity;baseline;goal;richardson et al;research;recent work;method;domain;methods;paper;account;great deal", "pdf_keywords": ""}, "2ea226a7fadde6a45f537c714e0832e83136f861": {"ta_keywords": "biomedical event extraction;structured prediction;structured prediction framework;sensitive classification tasks;bionlp;search;task;joint inference method;models;strong pipeline;score;searn;cost;points;performance;approach", "pdf_keywords": ""}, "708f8c0eb5032edd6f31663a27febbb0529cbcf3": {"ta_keywords": "neural syntax learner;syntactic representations;parsing;visual grounding;gold parse trees;captions;natural images;linguists;text;training data;concreteness;explicit supervision;images;vgnsl;nsl;matching scores;structures;constituents;vg;f1 scores;approaches;respect;model;terms;mscoco data;random initialization;approach;similar measure;experiments;amount", "pdf_keywords": "neural syntax learner;neural syntax acquisition;syntactic representations;syntactic structures;parse trees;language structure acquisition;textual representations;natural language;language learning;explicit supervision;syntax;learning;nsl;art text;models;vg;vgnsl;structures;acquisition;figure;more data;effective model;discussion;sep;itcs;kgimpel;toyota technological institute;paper;institute;goal"}, "06e36261b21af2943e464a562c92c09dac292a82": {"ta_keywords": "decompiled variable retyper;learned variable names;compilation;meaningful variable names;decompiler output;decompiler;typed variables;developers;useful abstractions;level languages ease;binary;programs;level language;abstractions;original types;github;dirty outperforms;types;original names;comments;empirical evaluation;novel dataset;loops;prior work approaches;quality;paper;novel technique;sizable margin;time", "pdf_keywords": "meaningful variable names;decompiled variable retyper;decompiler variable retyper;meaningful variable types;decompiler output;code documentation;variable types;encoder;decoder architecture;source tool;developers;code;novel deep learningbased technique;variables;sequence transformations;dirty outperforms;novel dataset;understandability;original names;names;original types;semantic types;types;readability;github;neural network architecture;prediction target;empirical evaluation;neural network;sequence"}, "54e7de06a97b4b6c41e185c0bee60c838a15265a": {"ta_keywords": "articulatory controllable speech modification framework;articulatory controllable speech modification;speech waveforms;unobserved articulatory parameters;articulatory manipulation method;articulatory parameters;gaussian mixture models;articulators;statistical inversion;inversion mapping;sequential inversion;speech;production mapping;\u7b2c16\u56de\u97f3\u58f0\u8a00\u8a9e\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0;framework;report;\u97f3\u58f0", "pdf_keywords": ""}, "7771aa7badc3375a31bfac8dc47755ff5d5c7780": {"ta_keywords": "morphological complexity;orthographic word types;text entropy values;specific subword levels;typological characteristics;nlp;different writing traditions;languages;language;subword;similar distributions;few bpe merges;words;different types;bpe merges;word;characters;distributions;level distributions;probability distributions;other factors;feature;findings;wide range;study;turning point;major challenge;light;ongoing discussion;interaction", "pdf_keywords": "different morphological complexity;morphological complexity measure;varied subword tokenizatons;orthographic word types;general linguistics;text entropy values;speci\ufb01c subword levels;corpus;subword sequences;typological characteristics;subword units;languages;subword;nlp;different writing traditions;informationtheoretic measures;diverse languages;shannon entropy;entropy;words;similar distributions;texts;byte;1urpp language;pair encoding;few bpe merges;word;characters;vasques1 christian bentz2 olga sozinova1 tanja;distributions"}, "79c93274429d6355959f1e4374c2147bb81ea649": {"ta_keywords": "modality encoder representations;language encoder;object relationship encoder;object prediction;encoders;language modeling;language connections;language reasoning;visual concepts;language semantics;transformers;reasoning task;sentence pairs;vision;lxmert;nlvr2;visual question;model;image;understanding;feature regression;label classification;datasets;image question;modalities;scale transformer model;art results;alignment;relationships;vqa", "pdf_keywords": "challenging visual reasoning dataset;modality encoder representations;language encoder;image qa datasets;object prediction;object relationship encoder;encoders;language modeling;visual concepts;language reasoning;language semantics;vision;language connections;sentence pairs;reasoning task;transformers;image;visual question;model;nlvr2;datasets;modalities;image question;understanding;vqa;lxmert;art results;feature regression;scale transformer model;label classi\ufb01cation"}, "03e4f33c0ccc4cb8c7e1589158a5377cdf5241d2": {"ta_keywords": "conditional preference networks;qualitative preference relations;ethical priorities;subjective preferences;subjective preference;ai system;ethical principles;ai systems;many complex decisions;decisions;guidelines;agent;computer science;same constraints;community;cp;nets;systems;lives;distance;human;order;humans;set;chapter", "pdf_keywords": ""}, "d5f22dbc8f4b9e99f62e6ecf886bc4b9a0372e4d": {"ta_keywords": "hierarchical exploratory em algorithm;hierarchical exploratory em approach;exploratory em algorithm;hierarchical classification;seed class hierarchy;text datasets;seed hierarchy;incomplete ontology;seed class instances;seed class f1;class hierarchies;hierarchy;clueweb09 corpus;relevant entities;entities;unlabeled web;nell ontology;classes;subsets;rise;extension;new challenges;experiments;method;paper;exponential growth;input;way", "pdf_keywords": ""}, "680e61a17e27a1e8e121276c7ec53fc4fd40babb": {"ta_keywords": "linguistic acceptability;linguistic signal;utterances;language comprehension;language users;language level;language;uniform information density;linguistic unit;language production;acceptability data;reading time results;uid hypothesis;typical interpretation;communication channel;uniformity;information;preference;mean surprisal;predictions;hypothesis;explanatory power;sentence;phrase;operationalizations;uid;document;strongest trend;lack;signal", "pdf_keywords": "mean information content;uniform information density;uid hypothesis;information content;linguistic acceptability judgments;local information rate;language;communication;natural language;acceptability data;information;language users;language comprehension;uid formulation;hypothetical noisy channel;entire language;typical interpretation;theoretical interpretation;uid;reading;processing effort;sentences;explanatory power;operationalizations;predictive power;hypothesis;strongest trend;levy;preference;psychometric data"}, "34f8214cbaa0655794c2c9570898abf15649b079": {"ta_keywords": "reverberant speech;automatic speech recognition;reverberation time;dereverberated speech;reverberation;mllr adaptation;adaptive training;variance adaptation;dynamic variance compensation;novel adaptation scheme;word error rate;variance compensation;relative error rate;speech;dynamic mismatches;dereverberation preprocessing;dereverberation;final error rate;recognition;noise;model parameters;performance;expectation maximization algorithm;appropriate interconnection;dynamic components;parametric model;presence;paper;method;order", "pdf_keywords": ""}, "3aba582b62d1abfcd95264e6c7b32aab4c9db4b8": {"ta_keywords": "neural text classifiers;neural classifiers;text classifier;selfexplain;predicted label;relevance score;selfexplain show sufficiency;interpretable layer;selfexplain augments;explanations;model predictions;influential concepts;self;concepts;novel self;predictions;phrase;local input concept;model;training;human judges;contribution;architecture;baselines;sample", "pdf_keywords": "neural text classi\ufb01cation approach;neural text classi\ufb01ers;text classi\ufb01cation tasks;novel selfexplaining model;neural classi\ufb01ers;selfexplain;local interpretability layers;neural networks;richer interpretability;interpretable layer;text classi\ufb01er;interpretable statistical classi\ufb01ers;in\ufb02uential concepts;concepts;self;endtask performance;local interpretability;predictions;generalization power;classi\ufb01ers;\ufb01rst self;phrase;predicted label;lil layers;relevance score;gil layers;model;training;architectures;transformer models"}, "e5a5888966be6b5f9c0e8a82facd604086a1ee4c": {"ta_keywords": "speech tags;syntactic parser;full paper corpus;annotation;simple morphological rule;tagging;hmmbased systems;classifier;grammatical relationships;sentences;bioner systems;user feedback;gene names;recall;features;feedback chapter;performance;more general representation;improvement;score;systems;system;section;previous sections;lemmas;part;output;context;precision;users", "pdf_keywords": ""}, "73271677da83a3f55523148d1b43a0501f0a35dd": {"ta_keywords": "online learning dynamics;game theory;game formulation;sum games;online learning;regret dynamics;invariant equilibrium;equilibrium;minmax theorem;seasonality;classical learning results;periodic zero;competition;exogenous environmental variations;unique equilibrium solution;poincar\u00e9 recurrent;natural model;behaviors;week trends;von neumann;time;week;day effects;theorem;average sense;players;robustness;broad classes;model;case", "pdf_keywords": "online learning dynamics;sum matrix games;sum polymatrix games;sum bilinear games;unconstrained strategy spaces;time gda learning dynamics;game evolution;sum games;\ufb01nite strategy spaces;periodic payoffs;time ftrl learning dynamics;invariant equilibrium;games;average equilibrium convergence;poincar\u00e9 recurrence;network generalizations;archetypal online;behaviors;poincar\u00e9;natural model;robustness;time;class;intuition;natural subclass;hurdle;proof methods;case;fact;counterexamples"}, "74fb2834c820d2297b08201cb72de1c1d3d27f54": {"ta_keywords": "privacy preservation;privacy;side privacy;accent masking tasks;sensitive personal attributes;biometric information;downstream speech tasks;certain security concerns;computing services;cloud;side processing models;client devices;raw data;bandwidth devices;unique technical challenges;users client;server;tradeoffs;fidelity;compatibility;client;adaptability;users;unique challenges;performance;models;complexity;efficiency;direct manipulation;none", "pdf_keywords": "side privacy algorithm;side privacy approaches;side privacy;adversarial training;multiple privacy metrics;raw speech data;speech data;speech recognition;accent information;asr service;client devices;bandwidth client devices;biometric information;side processing methods;side processing models;downstream asr systems;representation learning;cloud;raw data;asr model;client;limitedbandwidth devices;downstream asr;unique technical challenges;speech;signal processing;different client;direct manipulation;server;audio signal"}, "030d7d7ae48a9f81700b2c1f7cf835235777b8e7": {"ta_keywords": "scalable neural retrieval model colbert;openqa retrieval;domain question answering;extractive openqa performance;large corpus;openqa;efficient weak supervision strategy;learned component;relevance;candidate passages;colbert;answers;vector representations;reader;retriever;questions;passages;qa;own training data;triviaqa;much recent work;open;natural questions;datasets;supervision;system;abstract systems;squad;state;art", "pdf_keywords": "scalable neural retrieval model colbert;recent neural retrieval model colbert;openqa retrieval;recent colbert retrieval model;openqa retrievers;retrieval quality;ef\ufb01cient weak supervision strategy;extractive openqa results;new openqa datasets;retriever modeling;retriever;own training data;openqa pipeline attains state;colbert;openqa;training paradigm;ef\ufb01cient iterative strategy;supervision;relevance;strong transfer;scalable strategy;results;popular datasets;weak heuristic;examples;end;\ufb01ne;large gains;end system;qa"}, "7c655ef6f0de8c1a219cdb796c77f4ae3c389b82": {"ta_keywords": "acm conference;1st aaai;aaai;conference;conference website;ai;ethics;new orleans;event;hilton new orleans riverside;february;attendance measures;society;registration;people;overlap;louisiana;order;resounding success;paper;logistical support;download", "pdf_keywords": ""}, "b2b0fbf9033f1c36bea8bb11c173f14378c60db9": {"ta_keywords": "translation systems;emphasis;s2s;many speech features;level emphasis;s2s system;individual languages;languages;speech;different languages;language;english;analysis;f0;estimation;duration;word;other people;power;value;study;order", "pdf_keywords": ""}, "262c0e54370dfc03a7ad53d79930568d18dd448c": {"ta_keywords": "communication bottlenecks;matrix multiplication;computation;algorithms;runtime;stragglers;straggler nodes;performance;communication cost;workers;uncoded shuffling;data matrix;homogeneous workers;tex;worker;systems;exponential tail;scale systems;subtask;theoretical gains;inline;ratio;cost;machine learning algorithms;codes;formula;machine learning;constant fraction;messages;common message", "pdf_keywords": "computation framework;computation;data processing;computation phases;algorithms;matrix multiplication;machine learning algorithms;available storage;codes;kangwook lee;data;redundancy;kaist;communication;key primitives;electrical engineering;core blocks;novel way;school;plethora;excess"}, "14a058a1e41459a30327bb5fb480d51430b6a096": {"ta_keywords": "geneid ranking;geneid finding;geneid;gene;biocreative challenge;genes;curation process;ranking;search framework;database identifier;ranked list;model organisms;finding;yeast;graph;fruitflies;mice;task;system;problems;step;article;document;relaxation;extended abstract", "pdf_keywords": ""}, "a6d505a6e46c15ef0d213b9a4349ce2f852be894": {"ta_keywords": "negative classifier;mixture proportion estimation;negative classes;unlabeled examples;best bin estimation;classifier1;mixture proportion estimator;positive examples;unlabeled data;pu learning;learning;simple objective;conditional value;cvir;estimate;risk;simple techniques;methods;bbe;small subset;alternates;model;mpe;final algorithm;previous approaches;subtasks;formal guarantees;fraction;pu;modern approach", "pdf_keywords": "best bin estimation;binary classi\ufb01cation datasets;statistical guarantees;consistent estimates;training epoch;learning;bin;pure top bin;unlabeled positive examples;bias;cvir objective;\ufb01nite sample convergence;simple objective;bbe;highest loss;mpe;sample;cvir;objective;examples;mild assumptions;risk;superior performance;text datasets;extensive experiments;purity;previous methods;simple techniques;conditional value;effective technique"}, "b08545e1281c1eb748e4474687eb61fd3b25d1a6": {"ta_keywords": "new york times word innovation types;novelty;novel english words;novelty class;novel words;nytwit;contextual prediction;dialectal variation;new york times;art nlp systems;lexical derivation;dataset;compounding;class;improvement;baseline results;blending;collection;room;march;november;state", "pdf_keywords": "linguistic novelty class annotations;lexical enrichment;nlp systems;corpus;nyt corpus;annotation;linguistic analysis;gram information;contextual information;novel words;contexts;1context article excerpts;novelty;neologisms;twitter bot;words;word form;retrieval document;word;categories;context;sentence;novel dataset;oovs;articles;english relative;\ufb01rst resource;task;other parts;new york times"}, "43fae0a7af211d91557d115d2f82e3c46d8bf022": {"ta_keywords": "evaluating natural language generation;natural language generation;nlg tasks;different nlg tasks;automatic alignment prediction models;nlg;text summarization;automatic evaluation;summarization;interpretable metrics;dialog;text;diverse tasks;compression;information change;creation;metrics;style transfer;complexity;unifying perspective;art metrics;key aspects;gold reference data;specific objectives;tasks;transduction;human judgement;knowledge;broad range;comparable correlations", "pdf_keywords": "diverse nlg tasks;nlg evaluation;nlg tasks;language generation tasks;summarization;information alignment;human annotation datasets;information alignment accuracy;dialog;diverse tasks;interpretable metrics;general evaluation framework;human references;information change;quality aspects;style transfer;key aspects;representative tasks;uni\ufb01ed evaluation framework;content preservation;many key aspects;metrics;aspects;unifying perspective;intuitive metrics;compression;engagingness;relevance;creation;output"}, "b0894f5c914cd90cc3b3e16b15bec11efe317b14": {"ta_keywords": "peer grading;assessment tasks;assessment task;peer review;peers;peer;strategic behaviour;output rankings;promotions;exams;various peer;test;strong false alarm guarantees;misreport evaluations;experiment;students;agents;strong detection power;detection ability;homeworks;subjects;final ordering;hiring;patterns;data;own final standing;independent interest;curve;order;dataset", "pdf_keywords": "strategic behavior;grading;strategic behaviour;strategic manipulations;peer;rankings;test;evaluation;assessment system;assessment setup;impartial aggregation mechanisms;exams;real participants;principled test;experiment;experimental data;homeworks;grant proposals;manipulations;tool;detection;detection power;subjects;statistical framework;answers;scale;strong detection power;accuracy;system designers;patterns"}, "f481d6dea08e348cecd5eb23a813d47373e62a94": {"ta_keywords": "natural language specifications;natural language;natural language elements;programming languages;collaborative programming communities;programming;automatic explanation;nlp researchers;software engineering;automatic generation;source code;language;code;programs;machine learning models;tutorial;computers;humans;communication;users;information;tasks;analysis;methods;similarities;intersection;techniques;interesting opportunities;research interest;world", "pdf_keywords": ""}, "c7424d651d60ef9f052e91bff18efd88782225a3": {"ta_keywords": "election;breaking ties;stage voting rule;ties;computational complexity;parallel universes tie;breaking;winner;chair;result;problem;np", "pdf_keywords": "election;stage voting rule;ties;tie;computational complexity;parallel universes tie;breaking;winner;control;chair;breaking function;form;result;opportunities;problem;np"}, "19a6e362840d3a2d27d0fa5509eaa4d4597a2859": {"ta_keywords": "adversarial perturbations;sequence models;sequence;meaning", "pdf_keywords": ""}, "b145a46718f293429054f0a9a4cdd2de94813b37": {"ta_keywords": "successful link analy sis algorithms;next generation web search;sites;survey;art;field;state", "pdf_keywords": ""}, "5ea3c08614e9673a109f581cf114af488f3aa601": {"ta_keywords": "automatic embryo staging;residual networks;embryo;embryos;downstream classifier;region proposal network;region selection;reinforcement learning;blastocyst stage;transition prediction error;developmental stages;earlier stages;predictions;small subregion;decoder;loss;lapse data;truth bounding boxes;image;smaller data;best numbers;several sources;frame accuracy;structure;ground;likely monotonic sequence;programming;methods;new method;time", "pdf_keywords": "automatic embryo staging;sequence level;embryo;embryo detection;residual networks;morphokinetic stages;prediction;region proposal models;monotonic predictions;transition prediction error;embryo classi\ufb01er;predictions;dynamic programming;temporal context;lapse videos;weak supervision;dynamic programming technique;transition times;sequence;fertility clinic;dataset;lapse data;model architecture;incubators;video;region;preprint;variants;frame accuracy;small region"}, "6ab36d2577f7c9487b28b2bcdf236191ba901aad": {"ta_keywords": "dialogs;such dialogs;dialog system;end learning;conversation;neural tod;unseen flowcharts;explicit annotation;flowchart;task;novel technical challenges;specific flowcharts;flonet;utterance;agent;additional manual pages;end;shot transfer;tod;future research;strong baseline;car;test time;novel problem;experiments;user;problem;ability;domain;clarification question", "pdf_keywords": "dialogs;dialog system;dialog;end learning;task;novel task;tod system;different troubleshooting \ufb02owcharts;faqs;flowchart;toend learning;end;corpus;tod dataset;agent;problems;tod;new \ufb02owchart;conclusion;\ufb02owchart;ibm research;different \ufb02owcharts;car;technology;novel problem;shantanu agarwal;dataset;results;scenario;user"}, "1b114486d67252ff83fc90d4a8607636045c54ce": {"ta_keywords": "code retrieval;source code corpora;mine parallel natural language;code summarization;code synthesis;natural language;snippets;code;mining methods;classifier;correspondence features;python;stack overflow;nl;features;java;examples;neural network model;structure;data;correlation;accuracy;tasks;coverage;models;test beds;quality;method;sets;experiments", "pdf_keywords": ""}, "518cb6d4247bdebf21e2811f296b0c7372602a0a": {"ta_keywords": "masked language models;masking;principled masking strategy;such uniform masking;corpus;bert;pointwise mutual information;training objective;gram;mlms;shallow local signals;pretraining;mlm;suboptimal downstream performance;high collocation;spans;common flaw;inefficiency;concept;flaw;pmi", "pdf_keywords": "masking;principled masking strategy;such uniform masking;corpus;unmasked text;training objective;pointwise mutual information;text;shallow local signals;suboptimal downstream performance;training;high collocation;collocations;gram;training time;mlm;task;spans;performance;mlm approach;paper;tion;concept;pmi;above approaches;subset;intuitions;approaches;inef\ufb01ciency;heart"}, "aa9e0bf1e22563fca053578315b857688a0817cb": {"ta_keywords": "dialogue systems;user simulator;reinforcement learners;dialogues;completion dialogues;example dialogues;simulator;available simulation framework;movie ticket booking;conventional dialogue corpora;agents;movie seeking;several agents;own agent;reinforcement;learning;tasks;interaction;empirical algorithmic comparisons;corpus;movie;data;task;humans;booking domain;appropriate dataset;popular approach;real environment;rules;framework", "pdf_keywords": "user action generation;user simulation;dialogue systems;user simulator;natural language generation;completion dialogues;dialog;dialogue history;completion dialogue setting;natural language;reinforcement;utterance level;dialogact level;user state;nlg;agents;user state update;sequence;sequences;stack;act2 level;discussion;like representation;domain knowledge;state transition;granularity level;agenda;stacks;task;learning"}, "6b4ca249b3b28d3fee65f69714440c08d42cee64": {"ta_keywords": "unregularized gan training;gan training;more general gans;gans;generative image models;wgan;generator distributions;simplified gradient penalties;training methods;local convergence;wasserstein;generator;datasets;convergence results;distributions;discriminator updates;generator update;little hyperparameter tuning;lower dimensional manifolds;continuous data;convergent;data distribution;resolution;absolute continuity;variety;prototypical counterexample;gp;practice;penalties;other hand", "pdf_keywords": "unregularized gan training;gan optimization;gan training;gans;more general gans;wgan;regularization strategies;simpli\ufb01ed gradient penalties;local convergence;training methods;training dynamics;convergence properties;gradient;wasserstein;convergence results;discriminator updates;generator;convergent;generator update;data distributions;stability problems;example;distributions;lower dimensional manifolds;gp;absolute continuity;simplicity;prototypical counterexample;equilibrium point;paper"}, "993c184553c41ca9134f149a3eb71b5bfab298b5": {"ta_keywords": "collective threats;hong kong protestors;narrative maneuvers;broader digital campaign;digital campaigns;chinese international reputation;global crisis;twitter;organized masqueraders;chinese state;distinct narrative;individual adversaries;communitarian;distinct strategic units;groups;national solidarity;network information maneuvers;accounts;negative language;positive language;information operations;network analytics;critics;psycholinguistic tools;egalitarian echo;mvmc;methodology;network maneuvers;national strength;activity", "pdf_keywords": ""}, "6916118de98cb5293425c8f74919395a003e6076": {"ta_keywords": "text categorization;several ilp methods;english textwith;propositional counterparts;propositional analogs;text;eeectiveness;order representation;flipper;foil;performance diierence;task;beneet;diierences;domain;paper", "pdf_keywords": ""}, "affdfafb0293b44412ec99ff39b114de5e83eb98": {"ta_keywords": "unconventional tight reservoirs;depth analyses", "pdf_keywords": ""}, "88347f9f12b50590f50aefce4cf71b3a3f0bd138": {"ta_keywords": "language grounding;3d game engine;attention architectures;natural language instruction;trainable neural architecture;autonomous agents;natural language instructions;3d environments;attention mechanism;standard reinforcement;language;visual elements;imitation;perceptual knowledge;text representations;actions;tasks;meaningful representations;task;input;environment;novel environment;raw pixels;image;challenges;policy;environment states;instructions;model;end", "pdf_keywords": "language grounding;imitation learning;multimodal fusion;3d game engine;trainable neural architecture;attention mechanism;attention;novel multimodal fusion mechanism;natural language instruction;visual modalities;3d environments;perceptual knowledge;3d environment;language;reinforcement learning;end architecture;image representation;representations;joint state representation;input;instruction;raw pixels;architecture;task;environment;novel environment;environment states;challenges;multiplicative interactions;end"}, "5e10a61b34867c6e5b32ed7a1359bd47bbfb5e2d": {"ta_keywords": "multiple inconsistent explanation problem;calledabductive explanation;incorrect explanations;themultiple inconsistent explanation problem;domain theories;training example;formalization;learning;theories;knowledge;domain theory;formal analysis;negative examples;explanation;many different contexts;abductive explanation;information;ebl;such assumptions;level ebl;possible explanations;techniques;certain type;problem;solution;ts;convergence properties;paper;extension;set", "pdf_keywords": ""}, "e3862b1ff18dbb6a421b9efd1c0db22e09644b6d": {"ta_keywords": "wetland ecosystems;co2 fluxes;european russia", "pdf_keywords": ""}, "6f69fcacdf53a811ef18c5e9ac8ec58035dc43fc": {"ta_keywords": "recurrent neural network transducer;standard rnn;best automatic speech recognition;rnn;different transducer losses;training lattices;transducer;new transducer;graph representation;decoding procedure;sum training;transduction;connectionist temporal classi\ufb01cation;ctc;like lattice;asr;supervision;lattice;labels;graph;alignments;monotonic alignment;different transition rules;better optimization;production;objective function;systems;speci\ufb01c rules;set;better results", "pdf_keywords": "training lattices;equivalent rnn;standard rnn;rnn;decoding procedure;like lattice outperforms;asr system;different transducer losses;like lattice;asr outputs;asr;like transducer;ctc;transducer;graph representation;new transducer;gtc;gtct;better optimization;labels;monotonic alignment;alignments;different transition rules;example;ef\ufb01cient framework;wers;objective function;terms;time frame;better results"}, "31dc1e65d61a431964c75bf2eec167bcd9dca0fa": {"ta_keywords": "approximate control rules;high utility", "pdf_keywords": ""}, "86471bf927401bf88af83626797228c2bf10a282": {"ta_keywords": "causal attribution;social attribution;accurate attribution;attribution;faithful causal chains;contrastive explanations;causality;social behavior;behavior;human behavior;causal format;faithfulness;alternative causal chain;causal chain;interpretation;model interpretations;highlight explanations;social science;misaligned faithful highlight interpretations;borrowing concepts;formalization;decisions;concept;model;misalignment;process;steps;various failures;requirement;issues", "pdf_keywords": "arti\ufb01cial intelligence explanations;contrastive explanations;highlight explanations;causal attribution;social attribution;highlights explanations;accurate attribution;interpretation method;faithful interpretation;faithful causal chains;causality;social behavior;causal format;alternative causal chain;behavior;rigorous formalization;nlp;causal chain;shortcomings;faithfulness;intent;knowledge;de\ufb01nitions;useful explanation;classi\ufb01cation;plausibility;concept;accurate representation;decision making;verify model"}, "aa30949af5b59624224980e7d741ad8c084271ec": {"ta_keywords": "pandemic conspiracy theories;vaccine;vaccinations;vaccines;vaccination;tweets;conspiracy theories;social media;ongoing coronavirus disease;unique tweets;misinformation;severe acute respiratory syndrome coronavirus;infectious diseases;latent dirichlet allocation topic modeling;international concern;content;world health organization;youtube videos;video transcripts;trust;interventions;future policies;public health emergency;autism;sars;high uptake;crucial role;february;bill gates;english", "pdf_keywords": ""}, "d35534f3f59631951011539da2fe83f2844ca245": {"ta_keywords": "generative adversarial networks;latent codes;diverse images;pairwise training scheme;photographs;latent spaces;common identity code;shelf face verification system;images;discriminator;identity portion;identity;contingent aspects;identities;generator;lighting;sample;subjects;human judges;same individual;manifold;new algorithm;algorithm;pairs;experiments;observation portion;same subject;order;ability", "pdf_keywords": "semantically decomposed generative adversarial networks;decomposed gans;generative adversarial networks;gans;dcgan;siamese architecture;latent codes;discriminative feature;latent spaces;human annotators;latent space;novel discriminator;discriminator;deep face recognition;variation;semantically;iclr;end;art face veri\ufb01cation algorithm;sd;genetics stanford university;faces;image pairs;unmatched pairs;samples;identity;identities;commonalities;music university;brie\ufb02y"}, "61a07d1e4eaa831152e253b96b91808ef3a184b4": {"ta_keywords": "crowdsourcing natural language data;efficient natural language data annotation;crowdsourcing;public crowdsourcing marketplaces;largest crowdsourcing marketplaces;data labeling;world language resource production task;labeling process;efficient label collection;label collection project;yandex;participants;unique industry experience;tutorial;engineers;researchers;introduction;key components;practical session;portion;hands;scale;experiment;settings", "pdf_keywords": ""}, "aead4418733b998792deb9cbf198a834449e00d2": {"ta_keywords": "neural sequence models;systematic generalization;sequence models;generalization;distribution generalization;symbolic brittleness;symbolic mathematics;test set;manual test suites;test performance;genetic algorithm;failures;compositionality;predominant modeling;robustness;many tasks;challenges;maximum likelihood estimation;structure;training;problem domain;controllable manner;distribution performance;large collections;difficulty;verifier;methodology;breakthroughs;gap;importance", "pdf_keywords": "conventional neural sequence models;sequence models;systematic generalization;generalization;adversarial problem sets;unrealistic sequences;distribution generalization;robustness;genetic algorithm;test set;compositionality;manual test suites;challenges;failures;terms;predominant modeling;undesirable properties;controllable manner;distribution performance;large collections;structure;task;introduction;problem domain;symbolic integration;aspects;veri\ufb01er;different aspects;importance;probabilities"}, "9f7e317c6ef0bb15aacc9b19f0f0d00fee6c9a36": {"ta_keywords": "memorization;memorization values;training examples;training data labels;subsampled influence;training data;training example;outliers;accuracy;experiments;compelling explanation;algorithms;compelling evidence;estimation;insights;influence;theoretical explanation;significant research interest;key ideas;test example;phenomenon;quantities;data points;recent work;such fitting;feldman;theory;propensity;work;combination", "pdf_keywords": "deep learning algorithms;memorization;memorization values;training examples;training example;several standard benchmarks;highest accuracy;long tail theory;examples;neural networks;training algorithm;similar test examples;accuracy;useless labels;generalization;labels;outliers;noiseless data;algorithms;randomness;test example;estimation consistency;subset resampling;different neural network;estimation;data distributions;results;compelling explanation;fel19;experiments"}, "a1a8eeb64c0846070b10531061c18fed6d566f8c": {"ta_keywords": "manipulating vote;strategic voting;ties matter;computational complexity;random vote;complexity;tie;candidates;scoring rules;unique winner;candidate;manipulation;breaking;order;np;relationship;set;means;impact", "pdf_keywords": ""}, "c4919feb50c514e32eb0f4131399180c6f9a0d7d": {"ta_keywords": "polynomial procurement cost functions;procurement cost function;online resource allocation;procurement costs;procurement cost;pricing mechanism;optimal surrogate function;cost function;cumulative procurement cost;resource procurement;total allocation;multiple customers;optimization framework;dual algorithm;surrogate function;competitive ratio;customers;reward;function design;incoming customer;algorithm;seller;first design method;requests;objective;resources;preferences;order;analysis;setting", "pdf_keywords": "polynomial procurement cost functions;optimal surrogate function;quasiconvex optimization;procurement cost function;procurement cost functions;dual algorithm;optimization framework;surrogate function;optimal design parameters;polynomial functions;polynomial function;second design method;\ufb01rst design method;competitive ratio;surrogate;polynomials;algorithm;design technique;special class;general class;\ufb01nd;techniques;setting;order;section;technique;art;state;assumption"}, "df56ccda14b5bc255a07fc061c50839e75563c5a": {"ta_keywords": "parking traffic;traffic;other traffic;parking;different parking zones;classical routing game;seattle downtown area;parking zone;street parking;overall congestion;route choices;queue;account parking;game model;urban centers;route;game;modeling paradigm;network;other drivers;addition;usefulness;cost;practical examples;block;particular objective;face;subsections", "pdf_keywords": ""}, "4218563e1fe927440e00bf0abe5cb1e037deaf71": {"ta_keywords": "target domain accuracy;model confidence;average thresholded confidence;accuracy;unlabeled target data;dataset reproduction;datasets;optimal predictor;confidence;imagenet;threshold;training;distribution shifts;shift;unlabeled data;source data;performance drops;unlabeled examples;distribution performance;target;breeds;mnist;world machine;model;cifar;novel subpopulations;wilds;atc;several model architectures;synthetic corruptions", "pdf_keywords": "target domain accuracy;unlabeled target data;unlabeled target;accuracy;target;distribution performance;dataset reproduction;unlabeled data;unlabeled examples;datasets;training;world machine;threshold;average thresholded con\ufb01dence;source data;performance drops;imagenet;distribution shifts;model con\ufb01dence;model;distributions;iclr;several model architectures;source;brain team;mismatches;mnist;deployments;atc;hanie sedghi google research"}, "2d6d26c118f43f3ab314d07f58c20df6e89a13af": {"ta_keywords": "influenza virus;vaccine;like particles;generation;system", "pdf_keywords": ""}, "92a8f7f09f3705cb5a6009a42220a6f01ea084e8": {"ta_keywords": "actionable steps;actionable knowledge;large language models;language models;level tasks;interactive environments;step examples;admissible actions;world knowledge;natural language;demonstrations;plans;prior work;explicit step;further training;conducted human evaluation;lms;executability;breakfast;llm baseline;evaluation;possibility;llms;paper;procedure;recent virtualhome environment;method;correctness;promising sign;set", "pdf_keywords": "level tasks;actionable steps;natural language;reasonable expressiveness;step examples;programs;program length;lms;explicit step;further training;breakfast;prior work;procedure;paper;possibility;set;appropriate balance;\ufb01nd"}, "59653e5cfa854a17c2ffcb86f2a454f27e12c716": {"ta_keywords": "neural machine translation;machine translation;human translations;translations;gender pronouns;real translations;nlp researchers;ground truth candidates;bias;diversity;various training heuristics;decoding;deterministic outputs;search strategies;heuristic techniques;nmt;bleu scores;bleu score;salient source;metrics;variety;distributional differences;label smoothing;sampling;systems;conditional mode;respect;cost;study;agreement", "pdf_keywords": "other diversity metrics;diversity diagnostics;neural machine translation;machine translation;diversity;translations;ground truth translations;decoding;distributional similarity;neural information processing systems;translation;real translations;distributional differences;ground truth candidates;sentence length;nmt;nmt outputs;nmt systems;softmax temperature;gender pronouns;search;metrics;bleu scores;distributions;grams;ncrobert;neurips;copy rates;bleu;gneubig"}, "ac41e0ef30b6f9ee4930ac85dc46a9b50a1963d2": {"ta_keywords": "crowdsourcing;labels;incentives;incentive;machine learning;training data;partial knowledge;expertise;experts;approval voting;knowledge;requesters;workers;approval;single choice;quality;options;compatible compensation mechanism;true answer;set;important part;interface;paper;need;issues;factors", "pdf_keywords": ""}, "76f02d20e02c6baf39fee8f115cd94e4ceacf32b": {"ta_keywords": "novice reviewers;peer review;competent reviewers;reviewer pool;reviewers;bias;review pipeline;reviews;potential bias;review;computer science conferences;modern machine learning;submissions;peer;skepticism;several conferences;machine learning;submission;previous submission history;lower overall score;resubmission;authors;papers;trial;recommendations;paper;recent graduates;quality;knowledge;information", "pdf_keywords": ""}, "bf0beed35ea09aab56027d64c744098cc963fbde": {"ta_keywords": "dynamic cusum algorithm;dynamic cumulative sum;unknown transient durations;quickest change detection;transient dynamics;transient phases;final persistent distribution;algorithms;algorithm;durations;cusum;false alarm;average run length;initial distribution;asymptotic optimality;practical implementation;series;recursions;relative rate;arl;change;numerical results;earlier work;theoretical results;infinity;lorden;problem;criteria;pollak;respect", "pdf_keywords": "quickest change detection;transient dynamics;qcd;\ufb01nal persistent distribution;persistent phases;transient phases;cusum algorithm;information theory;initial distribution;wd;ieee international symposium;asymptotic analysis;heuristic approach;change;theory;weights;numerical results;material;dec;june;isit;paper;selection;aachen;state university;\ufb01nite regime;st;performance;germany;part"}, "f1005edfa1fbc4ea0d9a90345388bda8a01e69ed": {"ta_keywords": "confluent vessel trees;vessel trees;such standard undirected tubular graphs;discrete tubular graphs;confluence;minimum arborescence;arc construction;graph;reconstruction accuracy;curves;simple flow;bifurcations;efficient practical algorithm;directedness;limitations;empirical tests;typical errors;new general concept;order property", "pdf_keywords": "con\ufb02uent vessel trees;vessel trees;discrete tubular graphs;geodesic tubular graphs;minimum arborescence;accurate bifurcations;tree structure;graph;bifurcation localization;curves;bifurcations;capillary vasculature;bifurcation;unsupervised reconstruction;e\ufb03cient practical algorithm;canada 2vector research institute;canada 3robarts research;common techniques;quantitative improvements;symmetric pairwise costs;variants;mst;new accuracy;learning;supervision;mar;maria;con\ufb02uence;thousands;order property"}, "794b0a1e9719d809ebdf2ef87ff84c2039bfdd52": {"ta_keywords": "wirelesshart protocol stack;software protocol stack;qp architecture;protocol stack;qp event;protocol;data service;industrial process control;several state machines;events;architecture;design;layer;reliability;active objects;security;field;same time;object;paper;simplicity;series;functions", "pdf_keywords": ""}, "ae30f8fc5a969d2d14ae066db4cd07d86fadbf42": {"ta_keywords": "opiate receptors;methionine5;enkephalin sulfoxides;sulfones;agonist activity;recommendation;information;classification;content;social;herein", "pdf_keywords": ""}, "ffe1416bcfde82f567dd280975bebcfeb4892298": {"ta_keywords": "end speech recognition;recurrent neural networks;automatic speech recognition;connectionist temporal classification;neural network architecture;rnn;tosequence transformation tasks;language model integration;overall training speed;naive language model;transformer;word error rate;asr;ctc;transformer baseline;lium;fast iteration speed;many sequence;training;training stage;end;effective joint training;lm integration;wer;sequential operation;lm;wers;tasks;example;architecture", "pdf_keywords": ""}, "c50f98961c951fe3fbdb6f375beb28e40a6b0581": {"ta_keywords": "effortful reviews;review slots;reviewers;vcg auction;review process;quality submissions;auction;incentives;quality reviews;reviews;paper submission;novel prediction market;submissions;information elicitation literature;bid;paper;papers;publications;peer;quality;research community;revenue;necessary effort;overwhelming demand;ideas;style mechanism;authors;dipp;large volume;stage mechanism", "pdf_keywords": "stage peer review mechanism;scienti\ufb01c peer review;information elicitation literature;effortful reviews;information elicitation;review process;reviewers;review slots;quality submissions;novel prediction market;quality reviews;review scores;prediction market;paper submission;related work;auction;peers;general proposals;main contributions;proposals;revenue;submission stage;style mechanism;community;previous work;recent work;veri\ufb01cation literature;machine;mechanism tackles;dipp"}, "3febb2bed8865945e7fddc99efd791887bb7e14f": {"ta_keywords": "deep contextualized word representation;deep bidirectional language model;contextualized word representations;large text corpus;model polysemy;word vectors;linguistic contexts;word use;semantics;deep internals;deep;uses;downstream models;syntax;new type;internal states;different types;network;analysis;functions;complex characteristics", "pdf_keywords": "deep contextualized word representations;deep contextualized word representation;nlp tasks;challenging nlp problems;deep context;question answering;linguistic contexts;textual entailment;dependent representations;semantics;word use;representations;model polysemy;large improvements;elmo;models;uses;syntax;bilms;new type;abstract;broad range;conclusion;cl;complex characteristics;washington;quality;mar;analysis;engineering"}, "aa2bd932a2ecb6e07c768bcf0dc119f0cd20f6e0": {"ta_keywords": "name matching;textual similarity measures;duplicate database records;information integration;same entity;authors;methods", "pdf_keywords": ""}, "85a18aafcffdcc4eafcb9e5eda0abb8aa5cb8c3b": {"ta_keywords": "sdn;big data platforms;apache hadoop;networking;ossified architecture;commodity servers;big data;network managers;network;flexible architectural support;architecture promises;storage;architectural support;network behavior;internet;cluster;moore;hardware industry;hardware advances;platforms;hardware technology;software;massive amounts;data;technological revolution;technological trends;law;capability;processing;large amounts", "pdf_keywords": ""}, "d89f4534d1a87005cdf470ec5d8154998d5abdc7": {"ta_keywords": "parm;parity models;single parity query;parity query;fast encoders;parity model;high query rates;neural networks;inference tasks;prediction;machine learning;unavailable predictions;object localization;source prediction;low latency;tail latency;slowdowns;decoders;median latency;many machines;latency;speech recognition;erasure coding;resource;high resource;multiple queries;replication;latency targets;strict latency targets;image classification", "pdf_keywords": "fast encoders;parity models;parm;erasure coding;prior coding;inference tasks;decoders;prediction;efficient resilience;source prediction;machine learning;speech recognition;predictions;slowdowns;tail latency;classification;tasks;resilience;latency;resource;ing system;failures;inference;challenges;resilience techniques;localization;systems;ideas;curacy;tion"}, "e95a96dec775cc792b763f4eec13343c22e850e1": {"ta_keywords": "new information officer;information officer;education activities officers;acm sigai;annual activity report;additional column editors;intelligent user interfaces;autonomous agents;officers;intelligence;knowledge representation;membership numbers;knowledge discovery;human language technologies;search;computer systems;planning;chief;study;robotics;machine learning;cognitive modeling;scope;percent;website;june;july;areas;terms;realization", "pdf_keywords": ""}, "49984bc327ef6952118c4b871eeef2a907f7a4ed": {"ta_keywords": "regularized learning;faster convergence rates;adversary;individual regret decays;approximate optimum;normal form games;learning algorithms;fast convergence;games;recency bias;multiplayer;efficiency;algorithms;equilibria;game;faster rates;utilities converges;class;box reduction;natural classes;worst case;algorithm;player;sum;form", "pdf_keywords": "regret algorithms;costminimization games;adversarial opponents;regularized learning;faster convergence rates;normal form games;regret dynamics;fast convergence;rapid convergence;games \ufb01rst identi\ufb01ed;games;learning algorithms;optimal welfare;hedge;recency bias;multiplayer;equilibria;alekh agarwal microsoft research;roughgarden;vasilis syrgkanis microsoft research;natural classes;worse poa;cce;class;haipeng luo princeton university;princeton;form;ef\ufb01ciency;abstract;ny"}, "c460fd4a0dc86bc518f9a8e982bc48faf1efb942": {"ta_keywords": "online social platforms today;social platform users;timeline information exchange process;timing broadcasts;facebook;twitter;instagram;collective attention;large audiences;massive popularity;timelines;timing;broadcast scheduling problem;broadcasts;information exchange;social marketing gurus;circadian rhythms;diverse audiences;information overload;attention;content;many startups;behavioural phenomena;competitive marketplaces;phenomena;services;interest;cultures;frequency;monotony aversion", "pdf_keywords": "scheduling broadcasts;microblogs;twitter;consecutive tweets;broadcast scheduling problem;bursty circadian rhythms;online social platforms today;social platform users;facebook;broadcasts;timelines;circadian rhythms;timing;instagram;time;information overload;information exchange;\ufb01rst time;content;flickr;qatar computing research institute;sina weibo;doha;attention;behavioural phenomena;frequency;vine;follower;oct;network"}, "1a9c89cb2e57e06dadd4c2fab5fae1bfdbb3b6d5": {"ta_keywords": "probabilistic conditional preference networks;cpnet aggregation;probabilistic preference structure;several pcp;pcp;nets;cp;probability distribution;single structure;collection;methods;paper;compact representation;result", "pdf_keywords": ""}, "f5a0c6593ba95d23c025608ce9280848da8b929f": {"ta_keywords": "gene mention task;gene name mentions;substrings;lowest scoring submissions;biocreative ii workshop;sentences;results;submissions;task participants;brief descriptions;best result;statistical analysis;systems;teams;methods;use", "pdf_keywords": ""}, "92891a984b45df5fc764d81bf9bcd42e7e7ed1c7": {"ta_keywords": "local nash equilibrium;epidemic model;equilibrium;global equilibrium;differential game;quadratic pricing scheme;nonlinear dynamics;network managers;malware;security;spread;conditions;loop;method;addition;problem;results", "pdf_keywords": ""}, "3cc790174d138d7904189df997d5763f1793dedf": {"ta_keywords": "common annotation tasks;annotated word forms;agreement measures;annotations;normalization task;labels;wordforms;task;krippendorff;different degrees;paper;means;important aspects;class;ii;novelty;method;new method;fleiss;way", "pdf_keywords": ""}, "1d255aeabcb87929742280251007fd8c01bbe914": {"ta_keywords": "pmo11fe clusters;composite pmo11fe;pmo11fe cluster;polyoxometalates cluster;cyclooctene epoxidation results;pmo11fe;transition metal iron;cyclooctene;better catalytic activities;composite materials;recyclability;oxidant;h2o2;immobilized process;superior recyclability;sba;keggin structure;reactions;3d pore wall;functionalities;nh2;transmission electron microscopy;multiple characteristic methods;coordinative interactions;conversion", "pdf_keywords": ""}, "737f9a32d7f4007aa9526556c256ed4a182aec69": {"ta_keywords": "optimal nash equilibrium;quadratic game;convex program;equilibrium;convex conditions;feedback strategies;small parameter perturbations;players;prices;small deviations;respect;addition;similar analysis", "pdf_keywords": ""}, "4aa72e4232ae809ea1a9fe142275da25ba930655": {"ta_keywords": "linear quadratic games;global nash equilibria;quadratic games;nash equilibrium;classic reinforcement learning setting;reinforcement learning problems;nash equilibria;gradient dynamics;such games;gradient algorithms;ricatti equations;play;action spaces;state space;local convergence;classic game setting;continuous action;guarantees;gradient;only critical points;players;policy;local guarantee;convergence;benchmark;popular approaches;sum linear;cycles;player;conditions", "pdf_keywords": "policy gradient dynamics;quadratic games;nash equilibrium;nash equilibria;player lq games;lq games;classical optimization;agents;optimal control settings;competitive environments;agent;classic game setting;gradient;play;\ufb01rst policies;game;players;algorithms;policy;neighborhoods;benchmark;small neighborhood;guarantees;player;critical point;straightforward setting;convergence;point;sum linear;paper"}, "b62ce3135ed6065863c0dec26037fd07c081abba": {"ta_keywords": "counterfactual target label;natural language inference tasks;natural language processing;classifiers;spurious features;spurious associations;spurious patterns;indirect causal effects;causality;sentiment analysis;training models;unnecessary changes;language;initial labels;original data;internal coherence;genre;vice;alarm;resources;data;documents;models;document;standard statistical frameworks;term;machine;mentions;coherent meaning;methods", "pdf_keywords": "natural language processing;twitter sentiment dataset;yelp reviews;amazon reviews;spurious associations;counterfactually;spuriousness;spurious patterns;statistical learning;standard statistical learning toolkit;genres;training models;magazines;dataset challenge;models;machine;augmented data;resources;term;data;exploratory paper;appliances;causality;yelp;questions;documents;fashion;coherent notion;classi\ufb01ers;human"}, "ca86a63362e51eea2e213ae2d3faed668ec1ad74": {"ta_keywords": "commonsense knowledge representation;semantic similarity detection;concept extraction;robust knowledge bases;semantic similarity detection technique;knowledge bases;sentiment analysis;unrestricted english text;reasoning support;web search enhancement;categorization;topic gisting;reasoning;concept;specific concepts;graph;social process modeling;additional matches;document auto;solutions;potential applications;approach;wide variety;work;fields;level opinion;problems;addition", "pdf_keywords": ""}, "a1da1d600acd506b80c8870d293a756c70791683": {"ta_keywords": "bilingual lexicon induction;bilingual lexicons;unaligned word embeddings;distribution matching;languages;isometric assumption;isometry;spaces;novel hubness filtering technique;bliss;assumption;bli;larger set;question;recent work;technique", "pdf_keywords": ""}, "f184908270fc934ab74438a0aaac7a43a5eae6d2": {"ta_keywords": "neural summarization models;document summarization models;single document summarization;explicit sentence dependencies;latent sentence relations;summaries;explicit coreferring mention graph;modeling document structure;sentences;comparable summary lengths;summary;explicit structure;long sequences;aware encoders;abstraction;latent;structure;sequence;intermediate structure;document;extensive analysis;source document;richer content;tokens;contrast;end;structsum;traditional preneural approaches;current state;art", "pdf_keywords": "standard encoderdecoder summarization models;summarization models;document summarization models;structure attention module;human readable summaries;structured document representations;aware document representations;abstractive summaries;summarization framework;attention module;text summarization;summarization task;summarization;structured representations;external linguistic structure;cnn;external linguistic structures;sentences;coreference links;long source documents;explicit dependencies;content;standard encoderdecoder architecture;rich structure;source documents;document;novel components;source document;latent;dm dataset"}, "99ac83b990af1fc591db5b676300a7c002905dae": {"ta_keywords": "multiple views;data view;hierarchical class constraints;labels;linear programming;mixed integer linear programming formulations;optimal assignment;consistent class assignments;optimization;baselines;f1 score;em framework;ssl method;instances;sets;scores;number;techniques;paper;method;art performance;state;use;terms;presence", "pdf_keywords": ""}, "3f90668994d6e5949a530dfc84a10b492ff35cfa": {"ta_keywords": "shallow semantic parsing;semantic labels;materials science procedural text corpus;semantic structures;similar sentences;corpus;sentences;wet lab protocol corpus;formulaic writing;rich similarity metric;scientific procedural text;similar sentence;instance level approach;relations;labels;instance;instance level copy network;training set;prior methods;paper;baseline;parametric model;f1;experiments;light;high coverage;opportunity;such specific domains;approach;small number", "pdf_keywords": ""}, "fce19dd512a82693ab9070049ed426179eca8856": {"ta_keywords": "textual content analysis;natural language processing;textual content;web forums;mass collaboration;nlp;debate platforms;wikis;blog comments;content;traditional analysis tools;web;resources;ongoing efforts;artifacts;perspectives;user;recent advances;recent years;means;chapter;help;amount", "pdf_keywords": ""}, "0d22ce72a62419086fd4860a4671991846cd492b": {"ta_keywords": "lightweight block ciphers;aes;advanced encryption standard;nsa;privacy;us national security agency;speck families;simon;internet;things;applications;life;constrained environments;aid", "pdf_keywords": ""}, "fb6ef2d6fbd1ea4905070077ab6c5b0108f2c38a": {"ta_keywords": "sarcasm detection;large czech twitter corpus;tweets;czech language;twitter;classifiers;czech;english datasets;language;languages;machine learning approach;english;features;community;brazilian portuguese;research;further research;outperforms;strong baseline;first attempt;various combinations;art methods;experiments;independent approach;state;measure;paper;work", "pdf_keywords": ""}, "b8e49216e5b4a017342b0be5f6fbbd79e690a1c7": {"ta_keywords": "optimal auctions;auction;optimal auction design;optimal auctions auctions;deep learning;compatible auction;multilayer neural network;constrained learning problem;incentive;optimal mechanism;revenue;intricate task;powerful tool;tools;pipelines;design;accuracy;novel mechanisms;standard machine;solutions;settings;high degree;approach;recent research results", "pdf_keywords": "optimal auction design;neural network architecture;auction;constrained learning problem;layer neural network;network architecture;network;frame;economic theory;standard machine;ic mechanisms;pipelines;components;computational progress;standard pipelines;level overview;cornerstones;years;introduction;characterization results;more detail"}, "f297e939212780637705eba8798c9a386befd771": {"ta_keywords": "pivot translation;pivot language model;target translation models;high translation accuracy;language pairs;pivot;translation time;translation;third language;triangulation stage;triangulation method;parallel data;target model;data;novel approach;additional information source;source;paper", "pdf_keywords": ""}, "8a902a848c3710290f04f2d59030f5670d3433f8": {"ta_keywords": "morphological complexity;morphology;morphological features;nlp models;simple languages;complex languages;languages;language;error prediction;error analysis;conjectures;common conjectures;errors;tasks;different tasks;ii;importance;effect", "pdf_keywords": ""}, "ab48fb72541653f40523caa9fcaac9cb84bf3373": {"ta_keywords": "joint source separation;speaker automatic speech recognition;independent vector analysis;neural source model;stable iterative source;clean mixtures;noisy data;asr module;iva frontend;asr loss;channels;dereverberation;frontend;iva;training;end system;algorithm;offs;end;trade;parameters;paradigm;various number;testing", "pdf_keywords": "joint source separation;multispeaker;independent vector analysis;automatic speech recognition;neural source model;asr module;stable iterative source;asr loss;iva frontend;end system;clean mixtures;frontend;frontends;noisy data;dereverberation;iva;eess;shinji watanabe3;robin scheibler1;end;previous systems;algorithm;yanmin qian2;3carnegie mellon university;1line corporation;xuankai chang3;tokyo;usa;competitive performance;china"}, "3c5d3bbb73aa0e3e969a25487a81b5b1f0c14044": {"ta_keywords": "knowledge graph;knowledge graph identification;probabilistic soft logic;scale knowledge graph identification;joint inference;ontological information;ontological constraints;probabilistic modeling framework;facts;world dataset;extraction confidences;information;psl;millions;building models;rich structure;domains;precision set;structure;hours;practice;inclusion;scalability;process;challenge;method;noise", "pdf_keywords": ""}, "5ede529879d162d2779d410a5775d3f6cd6be3f4": {"ta_keywords": "neural generative models;robust optimization;generative models;model selection heuristics;training machine learning models;inner maximization objective;realistic nlp tasks;optimization;uncertainty set;distributions;parameter search;models;related data distributions;uncertainty;specific selection;gradient;case distribution;model;loss;simple alternatives;large scale;toy settings;comparable baselines1;relaxation;kl;careful design;collection;dro procedure;dro;dro problem", "pdf_keywords": "distributionally robust optimization;robust optimization;robust accuracy;training machine learning models;dataset bias;toxicity detection;realistic nlp tasks;models;related data distributions;minmax;neural generative models;uncertainty set;best model;uncertainty;speci\ufb01c selection;iclr;realistic setting;demographic groups;comparable baselines1;oracle stopping;greedy;dro yields models;tatsunori hashimoto computer science department stanford university;training time;case distribution;second player;groups;framework;applications;conference paper"}, "c6b462aaca52d0325db3118d2779865915b266c3": {"ta_keywords": "rule induction methods;rule induction;new pruning techniques;induction methods;large training sets;benchmark problems;asymptotic complexity;world learning problems;noisy data;totic time complexity;conquer;accurate hypotheses;rule;improvement;methods;accuracy;runtime;magnitude speedup;formal analysis;formal arguments;noise;claim;degree;asymp;experiments;form;set;paper;order;goal", "pdf_keywords": ""}, "dfb35ebe4fd754f59053d27c78f555bb5e7ccbff": {"ta_keywords": "thin structure estimation;curvature regularization;orientation estimation;coordinate descent;early vision framework;curvature;detection likelihoods;vision;thin structures;novel algorithm;detection variables;joint optimization;surfaces;boundary edges;lines;estimation;objective function;neurons;center;simple block;blood vessels;roads;location;previous approaches;level applications;many applications", "pdf_keywords": "thin structure estimation;curvature regularization;quadratic curvature regularization;orientation estimation;curvature;subpixel delineation;detection likelihoods;vision framework;variational inference;thin structures;vision;detection;boundary edges;simultaneous detection;general energy formulation;surfaces;optimization algorithm;centerlines;optimization method;different optimization technique;estimation;posteriori distribution;separate tangents li;objective function;neurons;trust region frameworks;blood vessels;delineation;xi;roads"}, "cd5a9a0061de6a6841c63e60281133207b2d6763": {"ta_keywords": "neural description model;description decoder;natural language;global contexts;other global context;urban dictionaries;wordnet;immediate local context;dictionaries;context encoders;interpretation;definitions;phrases;expressions;meaning;phrase;wikipedia;definition generation;search documents;task;dataset;datasets;important clues;web;oxford;questions;contrast;model;humans;previous work", "pdf_keywords": "polysemous words;unknown phrases;unfamiliar words;urban dictionaries;general words;wordnet;urban dictionary;phrases;natural language descriptions;oxford dictionary;global contexts;internet slang;slang;rare idioms;description decoder;expressions;idioms;neural description model;wikidata;wikipedia dataset;various application contexts;wikipedia;entities;text;de\ufb01nitions;novel senses;context encoders;industrial communities;datasets;toyoda"}, "89b8153a86708b411bd21357c5b6006142104fc9": {"ta_keywords": "relevance corpora;public speeches;corpora;memorable quotes;public awareness;useful words;ted;people consciousness;wisdom;quantitative evaluation;consciousness;analysis;generic pearls;purpose;system;people;study;construction;paper;others", "pdf_keywords": ""}, "91ef95907dc637ad3c29ac3cc0e682b9c1985a37": {"ta_keywords": "simultaneous speech translation;machine translation system;optimal segmentation strategy;segmentation strategies;segmentation;automatic evaluation;new algorithms;greedy search;dynamic programming;algorithm;heuristic methods;search;words;input;performance;experimental evaluation;paper;contrast;same score;terms;method;methods;number;conventional methods;times", "pdf_keywords": ""}, "1f3c381eedfe8914b81e93070bfdb00cf86ac943": {"ta_keywords": "graph classification benchmarks;graph level representations;visual representation learning;graphs;classification benchmarks;graph diffusion;graph;node;views;benchmarks;structural views;learning;encodings;relative improvements;self;linear evaluation protocol;binary;order neighbors;example;art results;reddit;performance;best performance;baselines;art;new state;number;previous state;cora;approach", "pdf_keywords": "contrastive representation learning;visual representation learning;visual contrastive learning;graph level representations;graph encodings;graph encoders;graph classi\ufb01cation benchmarks;simple graph readout layer;graph classi\ufb01cation tasks;graphgraph;hierarchical graph pooling methods;graphs;views;general graph diffusion;graph diffusion;representations;normalization layers;learning;structural views;regularization;different structural views;encodings;diffpool;differentiable pooling;better performance;node;order neighbors;best performance;performance;art results"}, "4abdea830316d80ab0b29fb94ee0786216f6a1cd": {"ta_keywords": "joint phrase alignment;machine translation tasks;unaligned sentence pairs;step word alignment;inversion transduction grammars;phrase extraction approach;phrase table;phrases;several language pairs;phrase;unsupervised model;probabilistic model;itgs;extraction;novel formulation;many granularities;model;accuracy;competitive accuracy;key contribution;experiments;original size;use;fraction", "pdf_keywords": ""}, "d6b3effdeb3d38ac9ee43c3b8292b0937a295c30": {"ta_keywords": "conversational speech recognition;standard multitask training;multitask learning;hierarchical multitask learning;decoder speech recognition;deep encoder;hierarchical multitask approach;neural encoder;auxiliary phone loss;auxiliary tasks;auxiliary loss function;pretraining;word error rates;telephone;performance improvements;eval2000 test sets;level ctc model;intermediate layers;performance;intermediate layer;subword;data experiments;resource settings;best results;interpolation;previous work;effects;number;position;relationship", "pdf_keywords": "hierarchical multitask learning;decoder speech recognition;layer phonelevel ctc loss;standard multitask training;hierarchical multitask;conversational speech recognition;speech recognition;deep encoder;hierarchical multitask approach;neural encoder;phonetic recognition;level ctc model;word recognition;vanilla multitask approach;ctc;auxiliary phone loss;auxiliary task;auxiliary tasks;word error rates;hierarchical;intermediate layers;pretraining;main task;single task interpolation constant;learning;intermediate layer;telephone;hour training;performance improvements;connectionist temporal classi\ufb01cation"}, "3c78c6df5eb1695b6a399e346dde880af27d1016": {"ta_keywords": "neural paragraph;individual paragraphs;document qa data;multiple paragraphs;normalization training objective;training models;entire documents;confidence scores;documents;models;score;input;level question;results;web portion;training;triviaqa;large improvement;model;previous best system;solution;f1;method;correct output;art pipeline;problem;state;case", "pdf_keywords": "question answering systems;paragraphlevel qa model;multiple paragraph selection;paragraph con\ufb01dence scores;single paragraph;retrieval mechanism;idf heuristic;training models;context;section;pipelined method;triviaqa;tf;end;training;approach;paper;system;method;prototype end;performance;model;art results;demonstration;general question;reimplementation;state"}, "7c3a2e953d2c07ff4f150865112e4ceec14090ea": {"ta_keywords": "electrolaryngeal speech enhancement;speech enhancement;voice conversion method;excitation feature prediction;statistical excitation prediction;proficient laryngectomees;laryngectomees;noise reduction method;intelligible el speech;electrolarynx;electrolaryngeal;el speech;mechanical excitation;excitation parameters;excitation;el;spectral parameters;prediction;device;evaluation;pass filtering;hybrid method;hybrid approach;unvoiced;part;previous work;issues", "pdf_keywords": ""}, "73fe797b4f4f2d18784246bb74626426a8fe108e": {"ta_keywords": "pointer graph networks;graph neural networks;latent graph structure;dynamic graph connectivity tasks;graphs;deep sets;static graphs;possible graphs;data structures;pointer;classical data structures;unrestricted gnns;edges;pgns;parallelisable variants;cut trees;gnn;gnns;useful structural inductive biases;vast search space;static input structure;improved model expressivity;theoretical computer science;unions;pointing mechanism;disjoint;operations;link;augment;machine", "pdf_keywords": "pointer graph networks;ef\ufb01cient latent graph inference;dynamic graph connectivity tasks;graphs;deep sets;parallelisable data structures;wise structural supervision;complicated data structures;neural algorithm execution;data structures;pgn model;unrestricted gnns;classical data structures;pgns;pointer;edges;pgn work;sparse;parallelisable variants;improved model generalisation ability;gnns;algorithms;cut trees;models;structure;augment;purpose algorithms;useful inductive biases;link;supervised method"}, "8b652c4d7a8d5836925ce0fe28a91dc661778524": {"ta_keywords": "large neural language models;many nlp tasks;comparative questions;ai conference;linguistic competence;neural lms;reasonable questions;bert;world knowledge;entities;deep model;such lms;lms;speci\ufb01c benchmark problems;recent results;models;human;broad notion;country;level performance;performance;vancouver;art results;sort;study;best place;accu;blank task;question;ing claims", "pdf_keywords": "large language models;lexical level;humanauthored comparative questions;comparative questions;language model;lexical phenomena;linguistic structures;related entity;entities;linguistic competence;domain examples;speci\ufb01c entities;comparisons;bert;neural lms;world knowledge;broad notion;domain questions;reasonable questions;deep model;recent results;accuracy;human judgements;country;models;such lms;predictions;speci\ufb01c benchmark problems;domain;high performance"}, "f53aa1d2676689c94429944f6a69431f96e05ae1": {"ta_keywords": "unsupervised topic models;membership latent variable models;gibbs sampler;approximate inference;membership methods;indicative features;supervision;topic;generative process;same mixed membership model;document labels;entity;such models;models;labels;feature;features;documents;present methods;introduction;description;methods;technique;stronger forms;task;different forms;form;corresponding change;performance;experimental results", "pdf_keywords": ""}, "57676e07d66b102f3335a5c538735ebff9076623": {"ta_keywords": "feedforward loop network motif", "pdf_keywords": ""}, "ba1823889a80c231966a0f24e57c6cf4a569ff8c": {"ta_keywords": "multimodal fake news detection;diverse multimodal fake news;multimodal entity inconsistency;diverse multimodal clues;multimodal fusion framework;fake news detection;multimodal clues;visual entities;entity;text;detection;novel entity;celebrities;images;fake news;news;level semantics;mutual enhancement;basic semantics;original text;landmarks;complementation;effective diffusion;things;framework;performance;supplement;help;severe issue", "pdf_keywords": "fake news detection;multimodal fake news detection;diverse multimodal fake news;multimodal fake news;fake news;multimodal entity inconsistency;intelligent information processing;diverse multimodal clues;detection;news;highlevel semantics;artificial intelligence;multimodal clues;entity;novel entity;multimodal feature fusion;china 2university;visual entities;multimodal fusion framework;yingchao yu6;china 5zhengzhou university;original text;chinese academy;text;qin he6;xirong li4;beijing;huan liu5;chenyang guo6;zhengzhou"}, "499ada382b7ce8f1cbd890e8c21500d95e20f2fe": {"ta_keywords": "audio representations;purpose audio representation;audio;environmental sound;holistic evaluation;music;benchmark suite;human ear;downstream tasks;hear;speech;evalu;neurips challenge;tasks;common api;spirit;tuning;scenarios;model;purpose;aim;source;participant;everyday domains;wide range;domains;strong basis;exchange;variety;ates", "pdf_keywords": "audio representations;audio representation models;\ufb02exible audio representations;purpose audio representation;audio;representation learning;holistic evaluation;environmental sound;machine learning research;hear participants;natural language processing;speech;nlp;music;new models;models;hear;benchmark suite;human ear;source;vision literature;paragraphs;challenge;researchers;purpose;development;greater insight;trends;variety;fast development cycles"}, "aa2428e1c4ea6d6bb347cfa59beead8736e19c46": {"ta_keywords": "virtual knowledge base;differentiable", "pdf_keywords": ""}, "95ee674a03ad23eaaf4837121fc8aea30d885088": {"ta_keywords": "structured preference representations;compact preference representations;novel metric learning approach;deep siamese networks;novel neural network;deep neural networks;kendal tau distance;preferences;net formalism;metric function;classification task;distance;distance function;partial orders;high accuracy;dimension;cpdist;approximation algorithms;network;popular cp;sets;less computation time;objects;descriptions;regression;solution space;small number;use;samples;performance", "pdf_keywords": "structured preference representations;metric learning;siamese network;novel metric learning approach;preference representation;novel neural network;net formalism;novel neural network model;novel autoencoders;deep neural networks;cpmetric;autoencoder;partial orders;present cpmetric;laplacian matrices;compact representations;nets;net;metric function;cp;preferences;popular cp;list;kendal tau distance;pairs;distance;transfer;value;function;domain"}, "683bbb665bdaea8688834e97559d63842242ee1f": {"ta_keywords": "deep reinforcement learning;reinforcement learning;atari games seaquest;intrinsic fear;dqns;reward;learning objective;catastrophe;catastrophes;catastrophic mistakes;toy environments;agent;dangerous states;sisyphean curse;policies;asteroids;wild;supervised learning;freeway;steps;guards;probability;paper;approach;score;problems;second model;new method;short number", "pdf_keywords": ""}, "13d9d24ff2ba69de4cedcebd8f59371a5c1de7ed": {"ta_keywords": "word sense disambiguation;individual context words;useful contextual cues;diverse lexico;simple word distance;different knowledge;syntactic information;knowledge;learning framework;usefulness;benchmark datasets;conventional window;significant improvements;approach;modeling;methods;experiments", "pdf_keywords": ""}, "788aa828a194a6d6c4e5ab1d4b46fc5f987159b0": {"ta_keywords": "oil painting creation;digital image processing technology;big data;influence;application;era", "pdf_keywords": ""}, "3df97e8237c7d98c7343fc025eacbbc2b96a10ae": {"ta_keywords": "exosomes;small extracellular vesicles;immunomagnetic beads;cells;hedgehog;pathological processes;body;important regulatory role;release;development;efficient capture;occurrence", "pdf_keywords": ""}, "a43d6fa0e96d56d0200e8d5e4407be8befc4e063": {"ta_keywords": "fast food industry;moral myopia;advertising;social responsibility;overview", "pdf_keywords": ""}, "b2fac3812885e3c8101cc729b6846f9108ac4d70": {"ta_keywords": "ai bot tournaments;crowdsourcing;bias;mle;likelihood optimizer;pairwise comparisons;pairwise comparison data;fairness;peer grading;likelihood estimator;underlying ground truth domain;estimators;bradley;accuracy;luce;search results;sports;bots;btl;teams;minimax;optimality;maximum;effectiveness;btl model;improved rate;item parameters;mean squared error;items;terry", "pdf_keywords": "btl model;crowdsourcing;peer grading;ai bot tournaments;btl;pairwise comparisons;pairwise comparison data;btl parameters;mle;peer;search results;bias;model;grades;luce;logistic function;bradley;students;accuracy;marketing;quality;items;item;likelihood estimator;item parameters;consumer choice;fairness;teams;bots;minimax"}, "8e56db786a685b4b9c7f1b750f60a81baebff0b5": {"ta_keywords": "nonaudible murmur enhancement;silent speech communication;speech quality;statistical voice conversion methods;intelligible speech;unvoiced speech;whispered voice;normal speech;target speech;speech;nam enhancement methods;whisper;quiet environment;nam enhancement;speaker;noisy environment;noisy environments;audible sound;listener;nam;conversion process;intelligibility;evaluation;experimental results;method;kinds;situation;report;issue", "pdf_keywords": ""}, "418349df9bf28e2b1290b758a4ebcf0d812c7288": {"ta_keywords": "political blogs;blog network;seed blogs;classification accuracy;classes;datasets;algorithm", "pdf_keywords": ""}, "e00f0a9e184a9d2afd8bb344908ca25d8bdc9e04": {"ta_keywords": "natural language computer;natural language;extant automatic programming system;language programming environment;nlc;processing;nl;matrix problems;system;duke university;year;research;activities;initial implementation;site report;ajcl;design;first version;ballard;summer;report;biermann;areas", "pdf_keywords": ""}, "692320cf5ae6980bc6b2b2d7bc48df961b545c22": {"ta_keywords": "high speech quality;real video conferencing room application;conferencingspeech challenge;video conferencing;single microphone array;conferencingspeech;recording facilities;real speakers;speech mos;clean speech;noise mos;challenge database;noise datasets;room;open source;challenge;subjective evaluation;absolute category ratings;real setup;participants;mean opinion score;practical application;algorithms;task;final ranking;field;baseline system;far;time track;mos", "pdf_keywords": "speech enhancement problem;real video conferencing room application;superior subjective speech quality;video conferencing rooms;conferencingspeech challenge;microphone arrays;real conference rooms;real meeting room scenario;clean speech;conferencingspeech;real speakers;speech;noise datasets;superior perceptual quality;excellent perceptual quality;real video;challenge database;low latency;open source;participants;challenge;scenarios;subjective evaluation;frame;intelligibility;dereverberation;simulation scripts;far\ufb01eld;task;baseline system"}, "87d50fc84c71ed9860ed02b0149266b74c446c9c": {"ta_keywords": "hmm parameters;hidden markov model;speech processing;time series pattern analysis;adaptive training;variational techniques;bayesian treatment;linear regression;likelihood;parameters;hmms;objective function;hmm;log;model topology;paper;hyper", "pdf_keywords": ""}, "dc3adb99f682a11fe0507dcbc5dc2958199c5af1": {"ta_keywords": "optimal gene circuit design", "pdf_keywords": ""}, "48685f26b32d199e6a4d80f6c61e62cc9738e403": {"ta_keywords": "event extraction;support vector machine classifiers;bionlp;rule;component;strong baselines;baselines;domain;task;relative simplicity;performance;approaches;good performances;state;approach;paper;external resources;effect;art", "pdf_keywords": ""}, "e107beee5e84cd11d6460f7040676687a51a378b": {"ta_keywords": "unrolled reconstruction operator;reconstruction network;image reconstruction;end reconstruction operators;reconstruction approaches;variational methods;tomography;classical variational framework;reconstruction;unpaired training data;variational setting;variational problem;deep neural network;inverse problems;unsupervised methods;unrolled operator;regularizer;distortion;excellent initialization;ct;distributions;data;example;fewer iterations;convergence;measurement space;method;end;output;new approach", "pdf_keywords": "ct reconstruction;reconstruction operator;tomography;reconstruction approaches;unrolled adversarial regularization;corresponding variational objective;regularization penalty;unsupervised methods;end reconstruction;unsupervised techniques;variational setting;posedness;total variation;ct;optimal transport;supervised data;uar method;training protocol;uar approach;regularizer;\ufb01ltered back;projection;uar framework;uar;lpd method;strong numerical evidence;classical model;postprocessing;example;tv"}, "9f1d9dfb0b30d9fc5881d07b8e7f508815296c93": {"ta_keywords": "statistical parsing concerns;specific parser;training tree substitution grammars;parser;probabilistic syntactic models;domain adaptation;syntactic structure;corpora;sentences;syntax;sentence;text;domains;less domain;multiple domains;features;data;self;specifies;single genre;field;different senses;model;process;way", "pdf_keywords": ""}, "51ec4e93d8ae4c62453fdb34c6866696da0527b1": {"ta_keywords": "fake news detection;fake news attempts;fake news;multimedia content;visual content;multimedia technology;social media;representative detection methods;multimedia;images;effective visual features;videos;rapid dissemination;readers;popularity;consumers;challenging issues;significant negative societal effects;great concern;proliferation;important part;comprehensive review;role;basic concepts;research area;development;chapter", "pdf_keywords": "fake news detection research;fake news detection;representative multimedia datasets;forensics features;multimedia;representative detection methods;fake news;context features;visual content;semantic features;statistical features;e\ufb00ective visual features;visual features;authorities;information;tools;text;available data repositories;relevant competitions;challenging issues;different perspectives;whatsapp;software systems;searchwins;concept;di\ufb00erent types;types;mob;india;role"}, "a16cecbaf87d965e396e610f251f710a807b70ad": {"ta_keywords": "hearing impairment simulation method;hearing impairment simulation;hearing impairment simulation systems;hearing impairment level;normal hearing persons;impairment simulation;auditory perception;auditory characteristics;auditory charatecteristics;hearing;audiogram;phoneme confusion tendency;personalization;intelligibility;experimental evaluation;accuracy;individual differences;experimental results;word;persons;method;person;people;approximation;correct rate;effective technique", "pdf_keywords": ""}, "f49065750931c1c3c9edaf7d2f4bc8ea1342450a": {"ta_keywords": "neural autoregressive model;regularization;translation quality;probable short sequences;beam search;large beam;smaller beam sizes;token decrease;model distribution;degradation;model;performance;loss contribution;experiments;rate;observations;bleu;strength;positions;main reason;rank;effect;outcome;degenerate case;probability;high degree;set;third", "pdf_keywords": "neural machine translation systems;neural machine translation;neural autoregressive sequence models;neural machine translation task;neural autoregressive sequence;translation quality;regularization;regularization scheme;repetitive sequences;many possible sequences;tion;wmt tasks;sequence;model distribution;performance;degenerate ones;lmb;abstract;different datasets;kyunghyun cho new york university;large beam width;diverse set;size;rank;set;genentech cifar fellow;log;experiments;major aspects;dynamic range"}, "b0b1112b06898733faefc32f54940aa4e84bc383": {"ta_keywords": "paralinguistic information;speech corpora;conversation corpus;digit corpus;speech;input speech;language barrier;different languages;languages;emphasis;parallel sentences;japanese;translation;communication;speaker;english;parallel digit strings;s2s;other high level information;current s2s systems;sentence;emotion;information;focus;various types;analysis;limitations;people;type;study", "pdf_keywords": ""}, "c55bc339122ad8cdba1ae74d1336be3d2f089699": {"ta_keywords": "stochastic convex optimization problems;gradient sliding algorithm;optimization methods;smooth objective functions;affine constraints;dual approach;primal functional;dual problem;optimization problem;spdstm;optimality;stochastic;dual modification;special penalization technique;inexact proximal step;algorithms;primal case;stm;rrma;similar triangles method;oracle calls;novel methods;sstm_sc;order oracle;several methods;lipschitz;node;approaches;same problems;methods", "pdf_keywords": "stochastic convex optimization problems;stochastic convex optimization;optimal decentralized;dual approach;stochastics;information transmission problems ras;algorithms;a\ufb03ne constraints;darina;several methods;nov;eduard;5national research university higher school;germany;economics;russia 2sirius university;russia;russia 4weierstrass institute;february;1moscow institute;russia 3institute;applied analysis;oc;technology;abstract;math;science;physics"}, "6cf3bdcdee6236f9f04e7773e3601dbbb8fbc61e": {"ta_keywords": "entity recognition;ner datasets;domain sentences;domain experts;shot ner;entities;ner;simple natural language questions;domain resources;datasets;erated datasets;resource models;models;target domain;domain;dictionaries;benchmarks;resource;labels;domain question;model;human;marks;generate approach;f1 score;new state;system;competitive performance;edge;vast engagement", "pdf_keywords": "entity recognition datasets;entity recognition;domain corpus;ner datasets;phrase retrieval model;quality ner datasets;candidate entities;entities;standard ner models;shot ner models;dataset generation framework;ner;\ufb01nal ner performance;better ner performance;gener;phrases;many different entity types;evidence sentences;dataset;datasets;seunghyun yoon2 jinhyuk lee1 1korea university 2adobe research;simple questions generate;astronomical object;conference;text;wikipedia;award;domain question;speci\ufb01c types;jaehyo"}, "a0f00d5ea3727151b1c2fc8c407404f0c6641051": {"ta_keywords": "la style phrase structure parser;other parsers;la parsers;parses;pcfg;lexicon probabilities;available pcfg;ckylark;sentences;fine analysis;failures;genre;failure;new techniques;possible causes;process;paper;competitive performance;intermediate results;probabilities;contrast;millions;experiment", "pdf_keywords": ""}, "3b7321832ba109cf47bfd13595c3b58acd4cb080": {"ta_keywords": "transnets;review generation", "pdf_keywords": ""}, "3400b8bf1ffde3ef3d35dfcea893e6506427aa21": {"ta_keywords": "single speech sequence;decode multiple label sequences;speech recognition functions;source separation;multiple speakers;utterances;isolated source signals;hidden vectors;sequence framework;additional training data;effective learning;mixture;new sequence;senone alignments;end system;end manner;end;similar hypotheses;new objective function;task;contrast;techniques;paper;interest;earlier works", "pdf_keywords": "end multispeaker speech recognizer;single speech sequence;speech mixture;speech recognition functions;conventional automatic speech recognition;decode multiple label sequences;speech signal;multiple label sequences;single utterance;recognition modules;source separation;hidden vectors;sequence framework;explicit separation;new sequence;separation;free training;asr;multiple hypotheses;mapping;model;end works;new objective function;similar hypotheses;transformation;end;relative improvement;systems;order;contrast"}, "3ce0f00d6c949192107f1bd6a167c03e1fb7393a": {"ta_keywords": "traditional deterministic parsing algorithms;parser;novel deterministic dependency;dependency structure;easiest arcs;sentence;complete tree;structures;attachment point;order;attachment preferences;efficient algorithm;algorithm;actions;shift;complex structures;right;features;easy;reduce framework;left;few words;approach;decisions;possible set;step;incorporation;drawback", "pdf_keywords": "parsers;parser;english dependency;novel deterministic dependency;dependency structure;dependency;algorithms;computer science pob;easiest arcs;ef\ufb01cient algorithm;deterministic algorithm;algorithm;easy;negev department;conll;right;new category;ensemble system;different structures;dataset;graph;abstract;simple combination scheme;michael elhadad ben gurion university;state;israel;inclusion;good candidate;art results"}, "b9f5115b0353c268999fcc2f49c4b8e03a223994": {"ta_keywords": "intervention outcomes;evolutionary causal matrices;interventions;multipurpose simulation program;diverse interventions;computer simulations;computer simulation model;outcomes;term outcomes;python classes;social policy;markov chain;classes;model;pilot implementations;present study;researchers;processes;long term;practitioners;society;scale laboratory data;paper;practical method;order;issue", "pdf_keywords": "simulation program;new multipurpose simulation program;simulation module;simulation model;simulations;computer simulation model;python;python classes;hypothetical dataset;outcomes;interventions;diverse interventions;hypothetical data;diverse intervention conditions;real lab dataset;pilots implementations;real experimental data;policy makers;psychology;single dataset;term outcomes;education;previous psychological studies;small data sets;class;ecm;model;prospective uses;markov chain;educators"}, "cc4cc594c7dd38482c46a2db440135b8f26ff54f": {"ta_keywords": "pt catalyst;proton exchange membrane fuel cells;o2 fuel cell;pt surface;zn nanocubes;pt78zn22;catalyst;sluggish oxygen reduction reaction;pt skin;expensive pt;pt bond;adsorption energy;pt;magic concave pt;cathode;surface;electronic structure;h2;ultrahigh peak power density;orr;orr activity;high durability;kb;theoretical calculations;mass activity;high dosage;commercialization;specific activity;length;rhe", "pdf_keywords": ""}, "e2f015bbddd7bade7caca693e37f84c4cf70a7f5": {"ta_keywords": "speech bases selection;automatic speech recognition;noisy asr task;matrices;spectral information;phonemes;speech;utterance;mnmf;nmf;bases;simultaneous optimization;asr;indicator latent variables;cluster;initialization;initialization method;initial value dependencies;spatial;target;parameters;initial values;performance;other hand;paper;larger number;experiments", "pdf_keywords": ""}, "f8d7b263e8d663583cd22d5988c8ea4a49ed2840": {"ta_keywords": "relation extraction;end relation extraction;joint entity;relations;entity information;entities;relation model;distinct contextual representations;entity model;encoders;global context;input features;inference time;standard benchmarks;small accuracy drop;scierc;input layer;ace04;ace05;importance;speedup;efficient approximation;end;new state;pass;simple approach;approach;work;careful examinations;art", "pdf_keywords": "relation extraction;entity recognition;entity information;entities;entity;relation model;relations;distinct contextual representations;entity model;previous joint models;relation f1;encoders;models;independent encoders;input features;global context;model;extensive analyses;simple pipelined approach;input;standard benchmarks;importance;absolute improvement;scierc;ace04;ace05;superior performance;paper;new state;work"}, "249b7517a746b1389991e10fd618cad62e66c4df": {"ta_keywords": "synonym extraction;graph based similarity measures;word synonyms;similarity measures;corpus;syntactic vector;constrained graph walk variant;parsed text;graph;task;approach;similar settings;art;past;state", "pdf_keywords": ""}, "0718237a30408609554a0e2b90d35e37d54b1959": {"ta_keywords": "based subword mining;word embeddings;subword mining algorithm;subword structures;subwordmine;mined subwords;finest meaningful semantic granularity;downstream language modeling task;compound words;words;most word;suffixes;word;entropy;prefixes;phrases;fasttext;representations;medical literature;vectors;technical domains;traditional onehot representations;algorithms;mapping;recent literature;data;root;paper;model;thought", "pdf_keywords": ""}, "771c1cb5fb161231e9aaa0a189caba672256a880": {"ta_keywords": "vocabulary neural language models;character sequence models;morphological knowledge;vocabulary language model;morphemes;sophisticated linguistic knowledge;basic linguistic facts;morphological analyzer;full word forms;words;possible word type;characters;word;generative processes;spaces;models;character;extrinsic measures;model;other strong baselines;structure;na\u00efve;open;sequence;mixture;hand;experiments", "pdf_keywords": ""}, "7374494ee88608ef76f74b58a8f8c26ab06adfb9": {"ta_keywords": "diarization methods partition frames;end diarization methods;diarization;end diarization method;end diarization model;speaker end;clustering;conventional clustering;speaker;speech;clusters;speakers;frame;end;region;method;methods;paper;flexible number;post;problem;utilization;number;results;other hand;weakness", "pdf_keywords": "clusteringbased diarization;clustering;diarization results;callhome dataset;end diarization model;telephone conversations;callhome;algorithm;dihard ii datasets;overlap assignment;baseline system;system;jer;evaluations;der;method;end;ami;state;various types;paper;performance;conclusion;art methods;experimental results"}, "6276bbe6cc56234d430725a31a27939eeec88149": {"ta_keywords": "quotability identification;quotability;roberta sequential sentence tagger;bert;literature;poetry;documents;multiple languages;document;evaluations;journal articles;novels;genres;passages;models;datasets;english;passage;feature;strong performance;best model;multiple types;news;task;average rho;latin;plays;experiments;problem", "pdf_keywords": "quotability;quotability identi\ufb01cation;quoting labels;computational linguistics;multiple source genres;journal articles;source genres;content;quotation;document;passages;scripture;models;large collection;bert;passage;similarities;novels;multiple models;jstor;poems;features;modeling performance;patterns;differences;\ufb01ve;task;computer science;scale datasets;prior work"}, "96d5e1f691397dfb51e8b818a21a2d11eee46a59": {"ta_keywords": "modern multicore processing architecture;multicore setups;sparse linear codes;optimal runtime;computational times;minimum possible time;computation;master node;computing setup;uncoded schemes;workers;worker;exponential tails;times;order;theory principles;fi;rest;solution;problem;number;use", "pdf_keywords": ""}, "75fe6c3ffdea2608794b4f21119c5a4dec07663a": {"ta_keywords": "autoregressive conditional sequence generation;neural machine translation;sequential latent variables;generative flow;latent variable models;most sequence;sequence length;flow;flowseq;sequence;neural networks;benchmark datasets;models;nmt;seq2seq;complex distributions;model;conditional density;conditioning;tokens;comparable performance;several layers;state;paper;effective model;art;time;elegant technique", "pdf_keywords": "autoregressive conditional sequence generation;neural machine translation;sequential latent variables;nonautoregressive nmt models;autoregressive generation;neural sequence;nonautoregressive models;latent variable models;generative flow;translation outputs;generative \ufb02ows;most sequence;benchmark datasets;sequence;nmt;models;flowseq;neural networks;generation;chuntinz;complex distributions;prior distribution;carnegie mellon university 2facebook ai;model;ef\ufb01cient model;conditional density;seq2seq;conditioning;1language technologies institute;comparable performance"}, "aa0b93501f79d57fe8542e72ccc8843ea50443c9": {"ta_keywords": "multilingual features;multilingual models;multilingual feature techniques;automatic speech recognition;various multilingual approaches;attention networks;hmm system;conventional hidden markov model;seq2seq system;babel data;seq2seq;training strategies;features;sequence;asr;output layer;ctc;hmm;sbn;neck;systems;set;finding;benefits;applications;combinations;bottle;various architectures;paper;effectiveness", "pdf_keywords": "sequence speech recognition systems;multilingual seq2seq model;multilingual sequence;multilingual models;automatic speech recognition;multilingual features;multilingual feature techniques;language transfer learning;various multilingual approaches;conventional hidden markov model;hmm system;attention networks;seq2seq model;seq2seq system;seq2seq;sequence;training strategies;babel data;asr;takaaki hori3 matthew wiesner2;shinji watanabe2;features;ctc;output layer;honza;murali karthick baskar1;jan;systems;hmm;technology1"}, "de971e50d70bc4d66f7debfab242942b0d1cae34": {"ta_keywords": "cascade speech summarization model;speech summarization;summarization performance;bert module;text summary;text summarization;automatic speech recognition;attention;several asr hypotheses;speech;bidirectional encoder representations;bert;summary;subtasks;fusion module;asr system;asr errors;asr;multiple hypotheses;ts;large training datasets;sum;ts system;transformer;transformers;vectors;cascade approach;input;posterior values;art models", "pdf_keywords": "cascade speech summarization model;speech summarization experiments;bert module;expert voice;bert;several asr hypotheses;attention;asr system;asr;bertsum att;free online ventriloquism lesson video clip;bertsum con\ufb01dence;asr errors;summary;professional comedian;ted;example;how2 dataset;fusion;fusion module;ventriloquists;multiple hypotheses;ts system;sound;tips;posterior values;vectors;reference;sum;dataset"}, "e0ab89821af308f51647bfe872f114d775fd8818": {"ta_keywords": "multilingual medical data;multilingual speech recognition system;multilingual conversations;chinese speech recognition systems;speech translation;medical conversation;asr system;source language;utterances;medical domain;target language;language barriers;speech;s2st;web servers;medical situations;english;overall speech;network;system;recent development;order;development;problems;difficulties;paper;experimental results", "pdf_keywords": ""}, "fba7ad8f63a42111b3618e51e3493ed70aafdcd0": {"ta_keywords": "conversation data;conversations;general word distribution;word use;speaker;own earlier word use;trust;probabilistic model;multiple people;people;japanese;previous speakers;influences;english;behavior;speakers;meeting data sets;companions;effectiveness;model;method;experiments;level", "pdf_keywords": ""}, "1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03": {"ta_keywords": "amazon review sentiment;complaint politeness;linguistic properties;bureaucratic response times;causal effects;lexicons;language model;bias;text;causal quantity;classifiers;distant supervision;effect;effects;writer;observational data;intent;noisy proxies;bert;estimator;interest;case study;predictions;method leverages;assumptions;quality;adjustment;method;approaches;access", "pdf_keywords": "latent linguistic properties;amazon review sentiment;complaint politeness;linguistic properties;bureaucratic response times;causal effects;language model;text;textcause;causal quantity;effect;distant supervision;effects;social science researchers;intent;writer;case study;observational data;bert;noisy proxies;results;method leverages;assumptions;quality;paper;interest;method;conclusion;approaches;algorithm"}, "c37ecbccecab1774b545a5a5804b575718218f7d": {"ta_keywords": "dnn bottleneck features;emotional speech recognition;cnn bottleneck features;emotional speech;bottleneck features;deep neural network;other feature transformation methods;input speech;cnn;acoustic model;asr quality;layer;other layers;nodes;smaller number;addition;results;mismatch;tandem approach;methods", "pdf_keywords": ""}, "ae5a34c20fee705ad7094c93a711d5f724d535f0": {"ta_keywords": "aware tensor recommendation framework;traditional matrix factorization methods;new sensitive latent factor matrix;recommendation quality;tensor;tensors;sensitive information regularizer;fairness;recommender systems;sensitive features;novel fairness;other latent factors;sensitive information;recommendations;effective algorithm;framework;quality;optimization model;promise;key aspects;ii;extension;methods;iii;previous efforts", "pdf_keywords": "aware tensor recommendation framework;recommendation fairness;recommendation quality;traditional matrix factorization methods;implicit recommender systems;aware tensor;tensor approaches;recommender systems;fairness;tensor;novel fairness;recommendation;bias;traditional matrix scenario;matrix;sensitive information;quality;novel framework;generalizability;ommendation quality;sparsity;fatr;aspects;effectiveness;ii;scenarios;promise;computer science;iii;methods"}, "ff187722c5b5462ac2066a737ae97650ffa177ed": {"ta_keywords": "automatic pronunciation assessment;automatic speech recognition;speech recording;call classroom;assisted language learning;pronunciation errors;assessment system;pronunciation;noise reduction technique;utterances;proficiency level;foreign language education;stereo;individual students;compensated feature sequences;student;asr;latter utterances;background noise;piecewise linear compensation;splice;active students;call;systems;gop;performance;environments;same class;technologies;recent years computer", "pdf_keywords": ""}, "0f61621206e363367db85b39e8e4325e425afcb4": {"ta_keywords": "statistical singing voice conversion;converted singing voice;singing voice characteristics;natural singing voice;speech quality;direct waveform modification;voices;waveform generation;source singer;conversion accuracy;converted spectral parameter trajectory;conventional diffsvc;singer identity;diffsvc method;vocoder;target singer;diffsvc;spectrum;smoothing;quality;global variance;objective evaluations;techniques;various factors;results;paper", "pdf_keywords": ""}, "94c3fd8eea08008cecd98f4aace024cf63954ead": {"ta_keywords": "malicious sensor observations;malicious sensor detection;secure estimation;higher attack detection probability;unknown sensor subset;sensor observations;remote estimation;multiple sensors;injection attacks;small false alarm rate constraint;sensors;estimation scheme;other sensor measurements;filtering algorithm;novel filtering;novel detector;optimal filter;linear gaussian process;sequential measurements;fusion center;observations;squared error;algorithm;estimates;additional side information;numerical results;order;gain;time;problems", "pdf_keywords": "secure estimation;secure remote estimation;fdi attack detection;attack detection;attack detection probability;fdi attacks;fdi attack;safe sensor subset;detection scheme;unknown sensor subset;anomaly detection;small false alarm constraint;safe sensors;detection algorithm;attack;unbounded gaussian noise;various sensor subsets;kalman;\ufb01lter gain matrix;estimation error;detector;simultaneous perturbation stochastic approximation;anomaly;estimates;algorithm;like \ufb01lter;prior literature;spsa;ii;linear system"}, "473021db54cbae9c4546597cd7e4b5d687a51c7f": {"ta_keywords": "crowdsourcing;crowdsourcing platform;crowdsourcing platforms;label;approval voting;expertise;unlabeled items;training data;partial knowledge;incentives;experts;knowledge;approval;requesters;single choice;information;workers;proper scoring rules;options;list;machine learning applications;items;goal;key shortcomings;ii;interface;set;true answer;article;need", "pdf_keywords": "incentives;incentive;partial knowledge;expertise;knowledge;deep learning;experts;optimality;requesters;labels;rigorous theoretical guarantees;machine learning models;demand;workers;approval;big data era;compatible compensation mechanism;single choice;data;options;complexity;mechanism;large amounts;quality;set;true answer;paper;interface;simple axiomatic characterization;unprecedented scale"}, "042959b54176ad2c4f9d0966490ec407b6057527": {"ta_keywords": "federated learning framework;data protection;design procedure", "pdf_keywords": ""}, "90dd676184a796e3e5835c8e1f6a632985ce3e89": {"ta_keywords": "embryo morphokinetics;late fusion nets;dynamic decoders;videos", "pdf_keywords": ""}, "80cb8981af401d9e4df0096626553c514d9e6600": {"ta_keywords": "mn4;y2ti2;optical spectrum;xsnxo7;solid solution;line energy;intensity", "pdf_keywords": ""}, "12b12ea73652da56023e0e4776211e4f4301f339": {"ta_keywords": "annotated argumentation corpora;argumentation mining;argumentation theories;argumentation theory;argumentation;annotation studies;argument components;annotation scheme;german newspaper editorials;corpus types;blogs;corpus properties;literary devices;english documents;document;forums;task requirements;information seeking perspective;comments;tasks;web;structures;findings;paper;size;actual application needs;realistic data;length;function;register", "pdf_keywords": ""}, "77b919c4f4f37415d8f1019b1b04191d46de426c": {"ta_keywords": "retrieval models;constrained random walks;random walks;retrieval tasks;retrieval problems;proximity measures;similarity;walk;fast query execution;fingerprinting;large scientific publications corpora;random walkers;nodes;proximity;many recommendation;pcrw distributions;pcrw;several recommendation;learning;metadata;truncation strategies;edge labels;particle filtering;documents;approximations;query;accuracy;edges;path;graph", "pdf_keywords": ""}, "e862e5f9a17938f1817017b2730e10463d94fb54": {"ta_keywords": "bliss", "pdf_keywords": ""}, "2826ac3621fdd599303c97cb9e32f165521967b2": {"ta_keywords": "direct uncertainty prediction;uncertainty via classification;high expert disagreements;machine learning;machine learning models;human experts;uncertainty scores;uncertainty score;classifier;medical second opinion;medical second opinions;raw patient features;disagreements;patient cases;medicine;dup;data instances;model;central methodological finding;output distribution;ubiquitous one;issue;step process;work", "pdf_keywords": "direct uncertainty prediction;high expert disagreement;uncertainty via classi\ufb01cation;training data;machine learning models;high expert disagreements;uncertainty scores;uncertainty score;image blurring detection task;label disagreement;raw patient features;medical imaging task;dataset;multiple noisy labels;extensive evaluations;histogram;gaussians;models;uvc models;medical imaging application;dup;performance;uvc;dup models;synthetic setting;disagree;classi\ufb01er;discussion;majority;data instances"}, "a7f30bae9303825adbc333a8df8a03398dea5151": {"ta_keywords": "elmo embeddings;sentiment classification;different sentiment classification models;elmo;logic rules;visualizations;contrast;complex inputs;importance;different models;distillation model;accuracies;proper averaging;first contribution;performance;better performance;analysis;random seeds;ability;place;analysis addresses;hu et al;research", "pdf_keywords": "sentiment classi\ufb01cation systems;sentiment classi\ufb01cation;different sentiment classi\ufb01cation models;word embeddings;ambiguous sentiment labels;sentiment;complex sentences;complex syntactic structures;inherent sentiment;sentences;contextualized word;logic rules;syntacticallycomplex inputs;ambiguous sentences;crowdsourced experiment;crowdsourcing;negative;ambiguity;inherent ambiguity;rules;elmo;baseline models;visualizations;data;importance;striking correlation;indian institute;metastudy;model;bigger picture"}, "203da29a37a983c487ce75a894b0d70698077bf5": {"ta_keywords": "problematic news sources;problematic content;news media sources;problematic information;disinformation;contemporary media ecosystems;coordinated inauthentic behavior;facebook;media manipulation;news stories;false content;coordinated link sharing behavior;recent electoral processes;widespread concern;attempts;spread;fact;bad actors;checkers;prevalence;studies;proliferation;automatic detection;clsb;paper;wider ecological focus;intrinsic elusiveness;efforts;signal;higher risks", "pdf_keywords": ""}, "7f588b1d2a5b199a19a4c3bad6bd5154c7355817": {"ta_keywords": "immunomagnetic beads;abundant blood proteins;human serum albumin;protein corona camouflage;fetal bovine serum;protein corona;protein premodification;certain proteins;protein corona utilization;proteins;immunoglobulin;imbs;biological properties;blood samples;blood;transferrin;unwanted nonspecific absorption;new biological identity;tumor cell;leukocytes;enrichment performance;fibrinogen;enrichment;composites;capture performance;downstream analyses;isolation benefits;complex biological environment;nanomaterials;novel environment camouflage strategy", "pdf_keywords": ""}, "44aa9a79cfc9eef9ac3f861cfa58a172cb863bd2": {"ta_keywords": "", "pdf_keywords": ""}, "aeffb61024e5ccac5021ca0bf9d199d9196a0521": {"ta_keywords": "markov decision process congestion games;congestion game framework;coupled congestion costs;congestion costs;minimum toll value;congestion;toll;tolls;transportation networks;markov decision process;fidelity game model;adaptive constraint satisfaction;population distribution constraints;constraint satisfaction;transportation;taxi;constraint;constraints;stochastic dynamics;mdp;limousine commission;driver earnings;players;myopic update algorithm;population distribution;player;population;accurate modeling;nyc;new york city", "pdf_keywords": "markov decision process congestion games;mdp congestion game;mdp congestion games;tolling algorithm;unknown congestion costs;congestion costs;congestion;iterative tolling method;tolling;adaptive constraint satisfaction;transportation networks;constraint satisfaction;level constraints;population distribution constraints;constraints;systemlevel operators;gradient descent problem;inexact gradient oracle;af\ufb01ne population distributions inequalities;algorithm;game;gradient;nyc tlc;system;conditions;inexact oracle;world data;application;class;convergence"}, "dc1d1f64503578d9c5d906da4556f631d4178b04": {"ta_keywords": "vehicle collision prediction algorithms;best cnn;large accident data;vehicle collisions;modern cnn architectures;deep learning;prediction accuracy;accident data set;crash;collision;efficient prediction algorithms;collision data;video games;real world;danger;accuracy;popular video game;challenge;best rule;source;rule;today;algorithm;recent developments;large amount;one;approaches;several variants", "pdf_keywords": ""}, "de5057c1da9391269e926d4661d4558072db9f18": {"ta_keywords": "end speech recognition;attention fusion module;universal feature extractor;automatic speech recognition;parallel encoders;streams;ufe features;stream model;attention mechanisms;relative word error rate reductions;encoder outputs;encoders;level fusion;stage training strategy;substantial memory;ufe;joint training;parallel data;diverse information;end;promising direction;components;strategy;data;several conventional combination methods;different views;previous study;previous approach;previous method;massive amounts", "pdf_keywords": "highlevel ufe features;level prediction fusion;universal feature extractor;asr performance;level fusion models;several conventional fusion strategies;level fusion;end asr;mem;parameterized parallel encoders;wav alignment;stage training strategy;stage training scheme;frame concatenation;rover;array framework;level;stage strategy;level frame;models;signal;available data;word;set;burden;addition;conclusions;table;results;initialization"}, "281605579936538ee92bc4b0baad1b83c683c076": {"ta_keywords": "abstract meaning representation parsing;dependency parse tree;parse;language generation;generation task;dependency tree;text linearizer;semeval;amr;amr graph;subtask;task;sequence;nodes;words;transition;content;actions;data;rename edges;focus;approach;benefit;paper;sheffield;remove;greater amount;fact;advantage;submission", "pdf_keywords": ""}, "4ae0c4a511697e960c477ea3e37b3e11bf3e0e02": {"ta_keywords": "robust convolutional networks;robust global representations;imagenet classification validation;imagenet;convolutional neural networks;local receptive fields;sketch;networks;local representations;like images;predictive signals;texture;local predictive power;image;categories;earlier layers;new dataset;intuitions;predictive power;global structures;category membership;color;scale;data;humans;paper;frequency patterns;method", "pdf_keywords": "benchmark domain adaptation tasks;wise adversarial regularization;robust convolutional networks;imagenet;convolutional neural networks;visual recognition;imagenet classi\ufb01cation validation;global concepts;generalization;learning scheme;convolutional neural network;local representations;concepts;global concept;categories;intuitions;new dataset;images;like images;earlier layers;predictive power;predictions;robustness;patterns;label;regions;local signal;object;sketch;classi\ufb01ers"}, "ce4db7a32724e0abc8afe27f74d33e32e099b8e6": {"ta_keywords": "porcine fit1 promoter activity;porcine fit1 gene;myogenic expression;porcine fit1;fit1 gene;myogenesis;muscle development;promoter activity;myod1;fit1;myod;pork meat quality;novel activator;human diseases;c2c12 differentiation;direct novel target;sequence;first evidence;attention;kb;potential role;correlations;role;overexpression;region;further analysis;better knowledge", "pdf_keywords": ""}, "7506626f776f211afac2c2d1138aca0e0479e5c3": {"ta_keywords": "generative adversarial networks;gans;original gan formulation;gan;latent vectors;plausible images;latent space;images;stochastic;mapping;gradient;precise recovery;technique;experiments;box method;time", "pdf_keywords": "generative adversarial networks;gans;original gan formulation;gan;stochastic clipping;latent representations;latent vectors;unseen images;plausible images;gradient descent;latent space;precise recovery;images;iclr;workshop track;gradient;mapping;unique encodings;technique;components;new technique;feb;box method;method;time;experiments;abstract;san diego;california"}, "712cd873d7370db280f4ceaaf000dc49f76b59fe": {"ta_keywords": "adversarial perturbations;adversarial attacks;adversarial examples;untargeted attacks;machine translation;sequence models;robustness;attacks;seq2seq models;source side perturbations;perturbations;weaknesses;example;output sequence;seq2seq;models;sequence;new evaluation framework;large changes;input;semantic equivalence;evaluation;additional constraints;output;model;changes;aforementioned assumption;effective way;meaning;mt", "pdf_keywords": "adversarial training;adversarial robustness;adversarial perturbations;adversarial examples;adversarial attacks;adversarial inputs;machine translation;untargeted attacks;sourcemeaning;automatic evaluation;robustness;attacks;semantic similarity;various automatic metrics;seq2seq models;human judgments;new evaluation framework;semantic equivalence;evaluation;general evaluation framework;human judgment;french sentence pairs;point;manual evaluation;example;source;target;meteor metrics;test performance;reference"}, "1c8d9d5558dc43f3505fa37fc50247e3ce0d2f54": {"ta_keywords": "unobserved confounder;small deconfounded observational dataset;deconfounded data;confounder;causal graph;causal inference;selective deconfounding;clinical trial;observational dataset;average treatment effect;data;cancer;only data;world dataset;graph;genetic mutation;practitioner;benefit;benefits;inclusion;accuracy level;ate;further properties;theoretical results;paper;quantity;collect", "pdf_keywords": "small deconfounded observational dataset;deconfounded data;confounder;causal inference;selective deconfounding;causal e\ufb00ects;observational dataset;genetic mutation;ate estimation error;observational data;natural benchmark;cancer;data;policy owsp;empirical results;factor improvement;world dataset;bene\ufb01ts;bene\ufb01t;relative performance;ate;accuracy level;case gains;case gain;nsp;theoretical results;introduction;case;inclusion;approach"}, "4d86b32ea80e2d9df2283fac39892d6dbd87ea87": {"ta_keywords": "discriminative training methods;classifiers;pattern recognition;minimum classification error;classification tasks;error classification;discriminant functions;svm;new mce training method;geometric margin;high robustness;geometric margin value;patterns;general class;training;methods;mce;prototype;new method;wide range;attention;various types;computation power;effectiveness;relationships;interest;experiments;recent dramatic growth;great deal", "pdf_keywords": ""}, "8786ddc38ae0763e772337bf9331436252452918": {"ta_keywords": "fake news detection models;fake news detection;fake news detectors;fake news detection methods;entity bias;unintended entity bias;entity debiasing framework;news veracity;news contents;news pieces;fake news;past news;entities;entity;chinese datasets;future data;world data;example;models;data;knowledge;donald trump;extensive offline experiments;model;superiority;generalization ability;cause;english;lower training loss;contents", "pdf_keywords": "entity debiasing framework;fake news detection models;entity bias;fake news detection;fake news detectors;fake news detector;news veracity;entities;news contents;fake news;wide dissemination;chinese datasets;future data;china 2university;artificial intelligence;intelligent information processing;inference;shengqiang18z;china 4sklsde;zhuyongchun18s;fuzhen;china 3institute;future;prediction;individuals;beijing;superiority;computing;lishuokai18z;chinese academy"}, "9d0e4e9c9343b85311b1adff145fdbdfb69486ff": {"ta_keywords": "hubble space telescope observation scheduling;expert systems tools", "pdf_keywords": ""}, "cc74ef901219dfd26efbbb8b7b87d1b7b7d38634": {"ta_keywords": "normalization;neural network models;historical texts;normalisierung historischer sprachdaten;anwendung neuronaler encoder;decoder;historische dokumente;digitalisierter form verfugbar gemacht;vorliegende arbeit untersucht;modelle fur die;zunehmend", "pdf_keywords": ""}, "cd06dfa789bfe491130ac7440e55d9d407396a43": {"ta_keywords": "conjugate descent methods;acceleration strategy;stochastic spectral;importance sampling;rcd;conjugate directions;linear rate;extra directions;augmentation;method;coordinate directions;condition number;rate;paper;above development;set;limitations;several negative results;new type;number", "pdf_keywords": "conjugate descent methods;coordinate descent;stochastic spectral;acceleration strategy;optimization problems;rcd;conjugate directions;methods;extra directions;linear rate;dmitry kovalev;big dimensions;coordinate directions;method;variants;art methods;augmentation;condition number;feb;state;paper;rate;set;elnur gasanov;eduard gorbunov;math;oc;number;new type"}, "aacaad6ab396e085799052b1a667c965d6465e32": {"ta_keywords": "protein emulsion;oil droplet interface membrane;emulsion stability;emulsion;emulsion droplet size;emulsifiers;soybean protein isolate;protein membrane;oil droplets;protein;disulfide bonds;myofibrillar protein;disulfide bond formation;white protein isolate;protein molecule;intermolecular interaction;sulfhydryl groups;egg;nem content;similar effects;internal structure;nem;spi;reduction;restriction;epi;types;subtle difference;addition;same time", "pdf_keywords": ""}, "d5810f15cfdd59da549ffa648c5a05d806d94eb7": {"ta_keywords": "journalistic setting;relevant textual evidence;journalism;news articles;journalists;evidence supports;document collection;user interface;user study;misinformation;user friendliness;fact;feedback;platform;workflow;transparency;paper;evaluation;final verdict;essential task;concerns;collection;efforts;claim;system;architecture;importance;choices;piece", "pdf_keywords": "factchecking platform;information retrieval;fact checking;retrieval tasks;automated fact;retrieval results;question answering;user study;journalism;user studies;usability testing;evidence sentences;information extraction;journalistic setting;information systems;ai;bbc news labs london;news articles;journalists;evidence sentence;computing;evaluation;essential task;evidence;news room;nlp;hci;bbc monitoring london;evaluation methodologies;technology"}, "a5148776955ef523de318a2fb45f8256e966b98e": {"ta_keywords": "label propagation;label propagation through lists;entity mentions;labeling approach;information extraction;distant supervision;nodes;coordinate list structures;mentions;shelf classifiers;graph;noise;data;good performance;procedure", "pdf_keywords": ""}, "05c2bb89a5c42ad7932420bb39df2e566df6e1ec": {"ta_keywords": "annotated data;annotators;annotation;human annotators;annotated training data;java abstract annotation editor;natural language processing;natural language;friendly editor;nlp;stochastic processing;stochastic methods;data;team;user;recent trends;expensive process;lot;most cases", "pdf_keywords": ""}, "2127bea25859ba9c5997e2d15e17899a75ef6cb3": {"ta_keywords": "statistical programming tools;big code;programming;software engineering;programs;interesting programming challenges;programming languages;program;dagstuhl seminar;such statistical tools;github;open source repositories;computer science;deep expertise;seminar;bitbucket;machine learning;millions;opportunity;availability;top experts;natural language processing;building;term;effort;area;outcomes;new kinds;report;others", "pdf_keywords": ""}, "3e2bac2abfb5b33a43fe56db5a868e17e38c616a": {"ta_keywords": "master students;master studies;projects;students;project topics;russian academy;project work;performance computing classes;research laboratories;machine learning;theoretical classes;experienced mentors;institutes;university;collaboration;ural federal university;sciences;employment;partners;partner companies;experience;world problems;theoretical basis;approach;result;high;addition;positive effect", "pdf_keywords": ""}, "baf47cd0b471a9bb7b2230fec0b680fc9b3c4783": {"ta_keywords": "explicit pragmatic inference aids;pragmatic speaker;previous pragmatic models;pragmatic listener;pragmatic inference;natural language instructions;pragmatics;language generation;speaker models;art listener models;human instructions;listeners;base listener;alternative descriptions;sequential tasks;speakers;candidate descriptions;models reason;certain instructions;instructions;interpretation;humans;evaluation;diverse settings;state", "pdf_keywords": "explicit pragmatic reasoning abilities;explicit pragmatic inference;pragmatic inference;instruction generation;language generation;pragmatic behavior;pragmatics;human listener;human instructions;generation tasks;sequential instruction;human speaker;instruction;listener models;simple reference games;speaker models;art listener models;inference procedure;single short utterance;speaker;listener;speaker model;tasks;interrelated tasks;instructions;accuracy;models;explicit model;humans;evaluation"}, "00cc6deb3cf2c9281ddcf4875aad3ee14c92e52f": {"ta_keywords": "entity recognition;machine translation systems;large annotated corpora;machine translation;shelf machine translation systems;lingual ner;entity projection;entities;diverse languages;phonetic similarity;prior entity;languages;projection methods;sentences;distributional statistics;dataset;current state;system;subset;matches;points;approach;art methods;average", "pdf_keywords": "entity recognition;machine translation systems;machine translation;large annotated corpora;shelf machine translation systems;lingual ner;largescale ner corpora;entity projection;monolingual baseline;shelf translation systems;phonetic similarity;entities;resource language;prior entity;languages;identi\ufb01es matches;german;distributional statistics;spanish;sentences;armenian;chinese;hindi;dataset;projection methods;tamil;diverse set;sep;matches;abstract"}, "be360de73689dc4af56f7adcee7e38d7acfed1e1": {"ta_keywords": "aggregate orderings;aggregate ordering;fairness;orderings;rankings;race;algorithm;impossibility;smallest possible size;impossibility theorem;list;notion;new game;set;arrow;available online;basis;classical results;work;certain properties;problem", "pdf_keywords": ""}, "0f5bb9ae0c060b349597c0b2582bf271a5a2156a": {"ta_keywords": "supertags;bidirectional lstms;pos tagging;syntactic information;several neural models;ccg;forward architectures;feed;models;model;complete sentence;performance;paper;long range;approaches;art performance;absolute gain;new state", "pdf_keywords": ""}, "ce268e0942ce0d1f6942e4d7e7e2aa6464f1b577": {"ta_keywords": "pronunciation learning;pronunciation lexicon;automatic speech recognition;pronunciation lexicons;proficiency speakers;pronunciations;native speech;standard asr systems;grapheme;asr;linguistic experts;phoneme;recognition accuracy;same recognition accuracy;new words;knowledge;zero knowledge;non;g2p;converter;improvement;performance;iterative fashion;previous method;design;new ones;system;method;previous study;degradation", "pdf_keywords": ""}, "cb53f9558bd13c853026f97dce3bbe3d989ca97d": {"ta_keywords": "argumentation fallacies;daily argumentation;argumentation;successful serious game platform;language;argotario;effective campaigns;controversies;german context;serious game;game;topic selection;corpus;dissemination strategies;qualitative aspects;behavior;article;study;users;data;substantial adaptation;initial data creation;steps;order", "pdf_keywords": ""}, "57dd2bd5fb6677191f9b36b589c91bb171e217ff": {"ta_keywords": "web using queries;textual similarity;database;like access", "pdf_keywords": ""}, "a4dd375c18709b1554249cc5cb88d8ba6acfea10": {"ta_keywords": "machine translation;machine translation systems;first computers;enormous steps;dream;paper;level;real use;major elements;appearance;many years", "pdf_keywords": ""}, "a95400c70c4beb609c77cc500677b2f1ed852e8e": {"ta_keywords": "question generation;paraphrase detection;coreference resolution;semantic understanding;human annotators;multiple sentences;semantic analysis;sentence approach;texts;questions;language learners;choice answers;assessment perspective;inference steps;specific inference steps;choice questions;evaluation;multiple;novel approach;technology perspective;approach;prior work;system;larger number", "pdf_keywords": ""}, "63d99a61e798d7cb714f336a8d581ae2b75672ee": {"ta_keywords": "zero resource speech challenge;phonetic metric;contrastive predictive coding;deep cluster;lexical metric;phoneme;discriminative representation;syntactic metric;supervised manner;kmeans;librispeech 460h data;autoregressive model;round clustering;additional autoregressive model;transformer layer;outputs;final layer;cpc network;relative improvement;small;cpc;system;conformer layer;further gain;baseline method;experimental results", "pdf_keywords": "zero resource speech challenge;speech representation learning combining conformer cpc;deep cluster method;deep cluster;zerospeech challenge;contrastive predictive coding;phonetic metric;lexical metric;wei chen2;syntactic metric;cpc network;yuya fujita1;conformer cpc model;cpc;kmeans;shinji watanabe2;xuankai chang2;sd;outputs;tokyo;1yahoo japan corporation;takashi maekaku1;japan 2carnegie mellon university;librispeech 460h data;li;abstract;baseline method;addition;relative improvement;alexander rudnicky2"}, "d4305b3bf233e5f192a5d17dde114b771b621d92": {"ta_keywords": "influence relation estimation;lexical entrainment;conversation", "pdf_keywords": ""}, "de3c3eb590065a6d78ec8566161f8236ab2a7435": {"ta_keywords": "translation results;asian translation;automatic evaluation server;mixed domain subtasks;tasks;wat2017;4th workshop;submissions;results;paper;institutions", "pdf_keywords": ""}, "ffb562d3ac7d86b5c527863f5a3e72e1aa22a809": {"ta_keywords": "optimal joint incentive mechanism;incentive mechanism;prediction elicitation;crowdsourcing;elicit heterogeneous agents;multiple agents;agents;private information;prediction algorithm;agent;prediction;heterogeneous rational agents;accurate prediction;costs;crowd;minimal cost;mechanism;cost;best interest;effort;several valuable engineering insights;joint design;different capabilities;highest capability;principal;opinions;analysis;same time;cope corresponds;problem", "pdf_keywords": ""}, "076b2ba158c35bd2941769864ce7455cf76ecd8e": {"ta_keywords": "peer review;review discussions;reviewers;various cognitive biases;herding;review process;biases;rejection decisions;more senior decision makers;human decision making;peer;independent opinion;discussion;others;large scale randomized controlled trial;humans;process;academia;final acceptance;papers;first argument;pipeline;paper;impact;case;backbone;cornerstone", "pdf_keywords": "\ufb02agship machine learning conference;top tier machine learning conference;abstract peer review;review process;reviewers;review discussions;large scale randomized controlled trial;paper submissions;machine learning;international conference;discussion initiator;peer;discussion;testing;trial;outcome;papers;rejection decisions;process;academia;\ufb01nal acceptance decision;icml;research question;paper;more senior decision makers;computer science;independent opinion;following research question;intervention;others"}, "80b747af8d86541cf53198519c8fa51109eed4f9": {"ta_keywords": "unsupervised data augmentation;data augmentation;complex data augmentation;clever augmentation techniques;nlp;labeling tasks;unlabeled data;semisupervised technique;text classification;standard supervised setting;examples;words;consistency loss;algorithm confer benefits;consistency;predictions;uda;translation;prior work;empirical study;model;back;open questions;popularity;main contribution;method;meaningful gains;benefits;differences;use", "pdf_keywords": "unsupervised data augmentation;sequence tagging;data augmentation;data augmentation techniques;word label distributions;unlabeled data;naive augmentation;uniform random word replacement;classi\ufb01cation datasets;text classi\ufb01cation;language model;augmentation;unlabeled component;classi\ufb01cation tasks;datasets;learning objective;various augmentation strategies;example;uda;examples;word;domain data;improvements;models;replacements;same example;tasks;sequence;predictions;consistency loss"}, "b033400e9a80915a928f4603582e5e8bf7656a85": {"ta_keywords": "unimodal baselines;multimodal techniques;single modality performance;multimodal domains;unimodal approaches;visual navigation;baseline;dataset biases;majority class baselines;capture;performance;important comparison;future research;best practices;qa;concrete recommendations;surprising strength;work", "pdf_keywords": "multimodal tasks;multimodal counterparts;unimodal models;deep architectures;visual navigation;benchmarks;vision;synthetic questions;language descriptions;egocentric question;tasks;navigation;images;models;language;qa benchmarks;agents;unimodal ablations;full models;similar biases;environments;simulation;baselines;figure;performance gap;\ufb01rst person;real homes;question;paper;recent papers"}, "c0099a15bd3251083c62ebd47c9705a16309b974": {"ta_keywords": "early vision;image processing tasks;image representation;level", "pdf_keywords": ""}, "a16ae67070de155789a871cb27ecbf9eaa98b379": {"ta_keywords": "nlg evaluation;natural language generation;nlg researchers;human evaluations;training evaluators;evaluators;contradictory reasons evaluators;judgments;text;gpt2;text domains;accuracy;gpt3;examples;fluency;news articles;stories;recipes;models;inconsistent results;machine;study;recommendations;approaches;ability;role;art models;detailed instructions;domains;gold standard", "pdf_keywords": "nlg evaluation;human evaluations;current human evaluation practices;training evaluators;untrained evaluators;different evaluator training methods;current nlg models;nlg researchers;evaluator;evaluators;contradictory reasons evaluators;level text qualities;humanlikeness;gpt3and human;judgments;humanand machine;text;examples;accuracy;gpt2;gpt3;text domains;models;nonexperts;study;inconsistent results;quality;approaches;conclusion;art models"}, "ece56ab633f11d1592a3d4f9386412d3f48fcf95": {"ta_keywords": "argument reasoning comprehension task;implicit warrants;correct implicit warrant;automatic warrant reconstruction;comprehension;scalable crowdsourcing process;logic skills;language models;argument;language understanding;warrants;authentic arguments;several neural attention;common sense;news comments;task;premise;reconstruction;dataset;claim;solution;identification;basis;substantial step;current approaches;paper;goal;2k;experiments;methodology", "pdf_keywords": "argument reasoning comprehension task;scalable crowdsourcing;scalable crowdsourcing process;computational linguistics;implicit warrants;authentic arguments;human language technologies;task;warrants;new task;quality dataset;iryna gurevych;identi\ufb01cation;naacl;dataset;henning wachsmuth;basis;means;conference;reconstruction;article;paper;benno stein;north american chapter;publication;main contributions;association;methodology;2k;consecutive steps"}, "2232808cf3161ca4c434126e35f47ee33c0c8219": {"ta_keywords": "explanations;teacher model;student model;teacher aid students;predictions;salient features;student;training;accuracy;test time;many methods;value;work;framework", "pdf_keywords": "question answering;attention regularization;multitask learning;explanations;classi\ufb01cation tasks;deep learning models;explanation quality;student model;prediction;text classi\ufb01cation;predictions;teacher model;student performance;tasks;different student model architectures;numerous attribution methods;teacher aid students;accuracy;comprehensive discussion;speci\ufb01c input features;trivial strategies;evaluation;metrics;gold labels;broad approaches;introduction;sub\ufb01eld;question;approaches;human"}, "228f2efe7b06b6db3b2c6c0a61d7b33daee1d641": {"ta_keywords": "word sense disambiguation;semantic similarity;different lexical semantic resources;similar word sense;russian;target word;input word;synset;sparse one;synsets;rand index;mnogoznal;unsupervised system;traditional vector space model;sense;context;datasets;relevant sense;sentence;sparse mode;evaluation;system;dense mode;present system;architecture;paper;respect", "pdf_keywords": ""}, "301352755a94d7524312b7c7f2fab7d3fd3d334d": {"ta_keywords": "dominance queries;preference orderings;qualitative conditional preferences;efficient dominance procedure;nets generalise cp;individual agents;probabilistic uncertainty;aggregation method;optimality;dominance;weighted cp;nets;pcp;uncertainty;cp;tractable approximation;collection;way;set;formalism;experimental setting;use;experimental results", "pdf_keywords": ""}, "035595ebf6821031a543ee1c30386a6230fc7a41": {"ta_keywords": "novel online speaker diarization algorithm;speaker permutation information;speaker regions;online diarization;speaker;consistent diarization outputs;input frames;several input frames;buffer;attention network;recording;buffer mechanism;frames;actual latency;supervised self;attention mechanism;previous chunks;outputs;variable chunk;current chunk;csj;permutation problem;self;callhome;eend;correlation;online sa;paper;method;size", "pdf_keywords": "online speaker diarization;end speaker diarization;novel online speaker diarization algorithm;end neural diarization;speech processing;speaker recordings;diarization;corpus;speaker;term memory;eend;supervised self;recording;attention mechanism;lstm;attention;datasets;csj dataset;kenji nagamatsu1;shinji watanabe2;eess;end method;straightforward online extension;simulated dataset;real datasets;language;yawen xue1;online saeend;yusuke fujita1;shota horiguchi1"}, "8328508dc12c295165f997e02d74d00a42971c01": {"ta_keywords": "effective context modeling;context modeling methods;semantic parsing;context;frequent contextual phenomena;complex contextual phenomena;exploratory study;datasets;limited scenarios;considerable attention;significant improvements;representative models;world;potential research directions;state;previous works;light;methods;best model;art performances;analysis", "pdf_keywords": ""}, "d36e39aedd802aea4be1ea303c70dc56e97dbc3c": {"ta_keywords": "abstractive summarization models;qags;generated summary;summarization datasets;frequent factual inconsistencies;automatic evaluation protocol;factual consistency;summaries;consistent text;factual inconsistencies;interpretability;summary;human judgments;promising tool;answers;kags;questions;xsum;cnn;input;dailymail;tokens;source;intuition;respect;model;similar answers;natural form;practical applications", "pdf_keywords": "conditional text generation;generated summary;abstractive summarization;summarization datasets;annotation interfaces;annotation task;factual inconsistencies;factual consistency;summaries;automatic evaluation protocol;underlying model quality;text;automatic model;inconsistencies;texts;qags;human judgments;conclusion;cnn;evaluation metric;qags1;robustness;input;xsum;metric;model;general framework;ablations;number;respect"}, "6c6975750207f787c318627ff7cb63a649165a8d": {"ta_keywords": "intelligent tutoring agent;free grammar learner;display representation;software user interfaces;user interface layout;dimensional displays;probabilistic grammars;human expert;learning algorithm;skills;probabilistic context;skill;various displays;representation;agent;temporal information;webpages;real world domains;perceive two;dimensional space;tables;synthetic domains;simstudent;algorithm;people;effectiveness;domains;day;complex problem;experimental results", "pdf_keywords": ""}, "1a671afdac8e7b759cf3b5ec7d03d485c76a989c": {"ta_keywords": "automatic speech recognition;different speech recognition tasks;connectionist temporal classification;mask ctc;mask ctc model;sequence models;greedy ctc outputs;end asr model;neural sequence;decoder;mask prediction;ctc;transformer encoder;autoregressive model;asr;standard ctc model;less inference time;ctc probabilities;significant inference time reduction;sequence;tokens;confidence tokens;outputs;rtf;target sequence;output length;python implementation;output;iterations;many iterations", "pdf_keywords": "automatic speech recognition;different speech recognition tasks;speech processing;mask ctc model;mask ctc;mask ctc framework;end asr;mask predict;decoder model;decoder;transformer encoder;mask prediction;standard ctc model;asr;ctc;language model;mask;autoregressive model;connectionist temporal classi\ufb01cation;joint ctc;less inference time;outputs;sequence;cmlm;rtf;communications;language;target sequence;model;predict objectives"}, "38ff6cf441050a1db10df85ac0771ccc88dea748": {"ta_keywords": "efficient peer review;peer review;review systems;conference peer;conflict graph;conflicted reviewer;reviewers;reviewer;review settings;aggregation;conflicts;final rankings;such conflicts;reviews;submissions;day peer;conference;social choice;authorship;strategyproofness;checks;such strategic behavior;strategic manner;paper;own papers;assignment;natural efficiency property;unanimity;flexible framework;requisite property", "pdf_keywords": "conference peer review;peer review settings;authorship graph;gnu linear programming;aggregation;reviewer;algorithm;iclr conference;partitioning method;simplex algorithm;lp;submission data;assignment;generalization;implementation;strategyproofness;strategic behavior;glpk;work;kit;method;level framework;simple trick;requisite property;unanimity;simple property;problem;natural e\ufb03ciency property;makhorin"}, "97ca917f66d60f5277651a74f233804b03cb5e3d": {"ta_keywords": "morphological segmentation;morpheme boundaries;russian language;deep convolutional neural networks;f1;task;score;present paper;problem", "pdf_keywords": ""}, "49989dc4d77b9df775b284ab7682ba76c080be12": {"ta_keywords": "hidden markov models;texture classification algorithm;classifiers;various classification algorithms;deformable objects;parts models;statistical template;object;hmms;observations;structure;underlying structure;basis;course;window approach;approach", "pdf_keywords": ""}, "51d735419392dbe961c60bff7eee95388b8d6d3d": {"ta_keywords": "labeled grammar induction;unsupervised grammar induction;unlabeled dependency trees;clean linguistic classes;word clusters;minimal supervision;limited human supervision;inductive bias;dependencies;frequent words;cluster;text;gold part;first time", "pdf_keywords": ""}, "b26ca2bb882c2d3526fb4ac7f544fb87c39ded62": {"ta_keywords": "scalable kernel optimization;sequential pattern recognition;pursuit method;improved kernel gradient;conventional kernel gradient;kernel gradient;dimensional features;classification;large scale datasets;kernel;optimal parameter vector;basis vector set;orthogonality constraints;basis vectors;efficient optimization;probabilistic models;approximation technique;linear combination;various models;aim;paper;various problems;small number;use", "pdf_keywords": ""}, "2cd7c3ed5a06c461b259694376820dcfcfbe94a9": {"ta_keywords": "generative neural parsing;discriminative neural models;generative models;external parsers;level beam search;effective inference;search space;feasible search procedure;basic candidate selection strategy;coarse pruning function;output;conventional action;accuracy;alternative;use", "pdf_keywords": "neural generative constituency parsers;generative neural parsing;generative parser;generative neural models;external parsers;generative models;discriminative neural models;generative model;lexical actions;structural actions;effective inference;beam search;level beam search;constituency;choe;inference procedure;feasible search procedure;high performance;conventional action;charniak;abstract;output;related state;self;state;berkeley;art results;alternative;california;jul"}, "19a3af37df22c7c646cc99efad3af96cda6e80f0": {"ta_keywords": "wmt17 multimodal translation task;multimodal machine translation task;neural machine translation;multimodal nmt model;translation system;attentional encoder;target language descriptions;nmt;translation;decoder;wmt;hierarchical phrase;language pairs;hiero;neural networks;naist system;hiero system;best output;source sentence;french;english;images;model;image;additional inputs;significant gains;paper", "pdf_keywords": ""}, "51546584aa394d159edcc08f2412ae30dd316f6c": {"ta_keywords": "prediction depth;deep learning;deep models;prediction accuracy;prediction;early layers;accuracy;difficult examples;easy data;networks;confidence;layers;dependent information;interpretable groups;understanding;computational difficulty;input;data;simple relationships;few numbers;insights;uncertainty;model;simple functions;speed;data point;coherent view;groups;phenomena;number", "pdf_keywords": "prediction depth;adversarial input margin;deep learning;prediction;predictions;accuracy;inputs;learned solution;training;input;dependent information;hidden embeddings;validation splits;uncertainty;model;data;extreme forms;brain team;output margin;data point;con\ufb01dence;middle layer;hartmut maennel google research;computational di\ufb03culty;speci\ufb01c form;speed;simple relationships;example di\ufb03culty;dramatic improvements;measures"}, "ca73cc17ca69fa0807e566c22c7c1711da916281": {"ta_keywords": "approximate nearest neighbor search;similarity searching;exact search;high dimensional spaces;dimensionality;data structures;small world approaches;comprehensive empirical evaluations;vast range;complexity;comparative analysis;few theoretical results;best tradeoffs;empirical analysis;many methods;efficiency;gap;results;computer science;methods;applications;effectiveness;curse;various fields", "pdf_keywords": ""}, "56501a3441c2074bbbbe31015d6d41c57d9d285b": {"ta_keywords": "paraphrastic sentence representations;paraphrastic sentence models;monolingual semantic similarity;unsupervised semantic textual similarity;inference speed;mining tasks;sentencebert;bert;inference;gpus;languages;language;gurevych;code bases;parallel data;gpu;reimers;english;models;more cpu cores;devices;prior work;arabic;speed;cpu;chinese;functionality;suite;use;little difference", "pdf_keywords": "paraphrastic sentence embeddings;semantic similarity tasks;semantic similarity;paraphrase data;bilingual parallel data;sentence embeddings;sentence pairs;unsupervised english;paraphrase;sentences;inference;languages;language;training models;detailed comparisons;cosine similarity scores;lowmemory training;learning;millions;low ram usage;evaluation data;models;tens;theart performance;data;code;list;ef\ufb01cient;new experiments;bitext"}, "ce458be308f2c75edc53366272fa6e744fda7902": {"ta_keywords": "word sense disambiguation;different lexical semantic resources;semantic similarity;similar word sense;russian;sparse one;target word;mnogoznal;context;traditional vector space model;rand index;sense;sparse mode;synset;unsupervised system;datasets;sentence;dense mode;gold standard dataset;preliminary evaluation;present system;architecture;paper", "pdf_keywords": ""}, "9195186cf44876d0d1d03b87756c464b760a7f4e": {"ta_keywords": "offline speech translation track;long context modeling;audio segmentation;speech translation;speech recognition;translation tasks;unified encoder;decoder model;multiple short segments;training data;dedicated decoders;espnet;target language spaces;best e2e system;level knowledge distillation;e2e;conformer encoder;iwslt;tst2021;search;end;data side;single references;model;seqkd;architecture side;sequence;bleu;st group;architecture", "pdf_keywords": "of\ufb02ine speech translation track;speech translation;long context modeling;better segmentation;voice activity;model ensembling;level knowledge distillation;segment merging algorithm;pseudo labeling;conformer encoder;multiple short segments;neural network;seqkd;baseline conformer performance;novel algorithm;segment;vad;iwslt;cascade systems;sequence;end;vad systems;mt systems;espnet;algorithm;e2e;mt;section;table;data side"}, "4fd6488e38043d680c592170bf7f651c079d0e98": {"ta_keywords": "tier poisson network model;average downlink data rate;stochastic poisson process;handoff outage periods;mean throughput;tier network structure;frequent data outage;average throughput;poisson line process;independent poisson process;mobile users;handoff;aggregate power constraint;average data rates;stochastic geometry;mobile;macro base stations;network;micro base stations;static users;unchanged mean data rates;handoffs;same base station;different transmit powers;homogeneous network;network equivalence property;heterogeneous structure;speed;mean total number;constant speed", "pdf_keywords": "heterogeneous cellular networks;small cell networks;mobility management;tier poisson network model;high mobility;macro base stations;tier network structure;frequent handoff;mobile users;cell planning;micro base stations;aggregate power constraint;mobile;mean throughput;handoff;different transmit powers;frequent data outage;network;larger cells;network equivalence property;poisson;stochastic poisson process;static users;data rate;heterogeneous structure;independent poisson process;unchanged mean data rates;poisson line process;stochastic geometric analysis;macro"}, "4ab7b65e1a3b76eb3db064523c862f1325e04971": {"ta_keywords": "different speech recognizers;automatic speech recognition systems;individual speech deficits;art automatic speech recognition;word error rate;phonetic units;parkinson;speech;spanish language corpus;new asr systems;deep neural network;hidden markov models hybrid systems;error rates;assistive technologies;asr;pd;computer;error patterns;control speakers;disease;speakers;performance;characters;systems;motor capabilities;patients;developmental stage;analyses;attention;differences", "pdf_keywords": ""}, "3f79b71b887d2ccb733926867a62f69902fcbdab": {"ta_keywords": "adaptive ontology mapping approach;ontologies;ontology constraints;competition neuralnetwork;other aggregation methods;performanceof similarity;structural similarity;oaei benchmark tests;mapping accuracy;information retrieval techniques;adaptiveaggregation;adaptive method;harmony;neural network approach;benchmark testsat;vector space model;approach \ufb01rst measuresboth;harmonies;measure;arti\ufb01cial intelligence;theexperimental results;interactive activation;good estimator;campaign;systems;gation theory;estimator;approach;solution;theperformance", "pdf_keywords": ""}, "7954b31ce1f6ad935808b7cf62c34bc118d20a9a": {"ta_keywords": "world healthcare datasets;judges;causal inference problem;different decisions;contexts;cases;clinical knowledge;heterogeneity;large causal effect;leniency;variation;conditional covariance;patients;doctors;regions;maker disagreement;certain drug;decision;personal preferences;preference;offenses;treatment;same context;certain types;instance;examples;maker;types;individuals;region", "pdf_keywords": "generalization;world healthcare datasets;world healthcare dataset;training data;iterative optimization algorithm;intuitive regions;regions;iterative algorithm;variation;clinical knowledge;heterogeneity;practical heuristics;algorithm;region;data;region size parameter;contexts;objective;cases;disagreement;patients;line diabetes treatment;decision;intuition;\ufb01nite sample version;maker;performance;subset;sections;section"}, "4bf5084d21f681c09409bd890daa4bf1c4f9b691": {"ta_keywords": "treatment platelet reactivity;platelet reactivity tests;antiplatelet drug administration;periprocedural myocardial infarction;smoking;hpr;retrospective study;related letter;cohort;statistical significance;significant role;study;concerns;role;opportunity", "pdf_keywords": ""}, "c3490ec9b8f695bed2187fb4a4164b1509389ca8": {"ta_keywords": "neural machine translation;first workshop;proceedings", "pdf_keywords": ""}, "7d94d4c6b2db490e08beabd2661df009f1a06d6c": {"ta_keywords": "noun synsets;large open wordnet;crowdsourcing;like thesaurus;russnet;synsets;russian;yarn;project;people;evaluation results;means;organizational principles;lessons;part;paper;future plans;first stage", "pdf_keywords": ""}, "02a757548da783d43ffcfd4b60f2cbb0ac71a4bc": {"ta_keywords": "enforcing subjective individual fairness;fairness elicitation;subjective fairness;subject fairness constraints;individual fairness;fairness constraints;fairness;criminal recidivism dataset;judges;subjective notions;particular individuals;individuals;efficient algorithm;accuracy;task;sample;compas;generalization theorems;notion;behavioral study;constrained pairs;provably convergent oracle;contrast;pairs;panel;means;preliminary findings;framework;dwork et al;error", "pdf_keywords": "subject fairness constraints;fairness constraints;fairness violations;fairness;compas recidivism prediction dataset;criminal recidivism dataset;unconstrained learning;accurate prediction;constraints;learning problem;human subjects;subjects;generalization bounds;pareto curves;compas;di\ufb00erent human subjects;accuracy;guarantees;accurate model;behavioral study;algorithm;oracle e\ufb03cient algorithm;sample;experiments;set;respect;preferences;reduction;terms;variability"}, "f7247fefc9efb57ace33425a2981d6aba08da3b7": {"ta_keywords": "statistical dialogue management;statistical dialogue framework;intention dependency graph;dialogue evaluation;observable markov decision process;policy function;user simulation model;transition probabilities;intentions;hierarchical graph;deterministic graph structure;pomdp;information;system;conventional rule;framework;method;model;idg;way;reasonable constraint", "pdf_keywords": ""}, "23e42bc79f10234bdceef31441be39a2d9d2a9a0": {"ta_keywords": "neural logic programming;knowledge base reasoning;multiple knowledge base benchmark datasets;logical rules;structure learning;neural controller system;freebase;learning problem;differentiable model;structure;wikimovies;parameters;parameter;continuous space;order;discrete space;prior work;operations;framework;method;end;problem", "pdf_keywords": ""}, "06064617f152f5032137204aec739c0c82dbb836": {"ta_keywords": "automatic speech recognition;microphone;speech separation;asr systems;reverberation;chime;recognition challenge;asr;datasets;track;everyday environments;multiple background sources;tasks;challenge;domestic environment;performance;baseline performance results;detailed description;challenging goal;world;reference;baselines;initiative;paper;rationale", "pdf_keywords": ""}, "14047a24b23d9e392776229f9d40bee9f8243e4c": {"ta_keywords": "sensor subset selection;active sensor selection;dynamic sensor activation;sensor networks;stochastic approximation;active sensors;efficient tracking mechanism;global optimality;tracking;cyberphysical systems;optimal solutions;learning;unknown parameter vector;unknown parametric distribution;infinite horizon;algorithm;low complexity;internet;gibbs;squared error;constraint;energy;process;time;key ingredients;things;mean number;high performance;main challenge;method", "pdf_keywords": ""}, "0dd1b9ad5aeda250dc61f38cf7018e7a014e91c0": {"ta_keywords": "traffic congestion;land use;gwr model;data;impact;study", "pdf_keywords": ""}, "a67face220a88b6b36f3343a6a017a3536562d5b": {"ta_keywords": "visual guessing games;successful guessing games;visual question answering;iterated experience learning;artificial agent;neural representations;agent;games;play;novel nlp;downstream tasks;supervised learning scenario;prototypical instance;spiel;generalization power;novel way;empirical study;self;vqa;paradigm;ways;work", "pdf_keywords": "visual guessing games;guessing games;neural representations;games;representations;prototypical instance;games data;generalization power;dialogues;supervised learning phase;play epoch;novel combinations;play;agents;agent;models;datasets;image;new datasets;paradigm;epochs;interactive phase;oliver lemon1 1heriot;questioner parameters;empirical study;self;phases;guesswhat;phase;target object"}, "970383c0a41d7ae1ec4b8abaa3033778203377b9": {"ta_keywords": "factoid question answering;question answering;synthetic corpus;noisy sentences;virtual assistants;speech recognition;automatic speech recognition systems;machine translation;human corpora;natural language processing systems;qa;speech;quizbowl;questions;noisy inputs;tasks;noise;optical character recognition;unreliable inputs;train models;instance;jeopardy;effects", "pdf_keywords": "noisy sentences;downstream neural qa systems;synthetic corpus;factoid question answering;structured recurrent neural networks;automatic speech recognition systems;sentence level;decoding;quizbowl;human corpora;information retrieval;asr;highest test accuracy results;neural model;weak supervision;noisy channel techniques;tasks;accuracy;qa;train models;unknown words;noise;negative results;task;experimentation;jeopardy;good approximation;model;lattice;ir one"}, "3193766c0439ff29a0a3d176628f8144d6e77231": {"ta_keywords": "supervised sentiment analysis;czech social media;reprint", "pdf_keywords": ""}, "b38ec68c8bab031138606a9b00e9d817be3e1d22": {"ta_keywords": "topic models;entity link;topics;mixed membership stochastic block models;protein interaction;protein interactions;proteins;entities;entity;enron email corpus;protein;social networks;joint modeling;links;functional category prediction;corpus;latent groups;abstracts;text information;scientific publications;datasets;text;dataset;link;model;data;ppi dataset;observed interactions;perplexity;pairs", "pdf_keywords": ""}, "3f256b31d446015d8cd0f9f3996009cdf2034c5e": {"ta_keywords": "monolithic multilingual asr system;speech recognition;joint language identification;automatic speech recognition;single multilingual model;independent neural network architecture;connectionist temporal classification;hybrid attention;target languages;several asr benchmarks;new languages;asr systems;languages;pronunciation dictionaries;asr;character sets;language;appropriate character set;linguistic information;end architecture;text;independent end;speech;output symbols;ctc;model;training;architecture;end;union", "pdf_keywords": ""}, "c56aced0f0c5cfebefadb530cb08d736c3ac5c05": {"ta_keywords": "retrieval augmented code generation;code summaries;code generation;source code;summary generation behavior;dense retrieval technique;software development;summarization models;software developers;code;retrieval database;summarization;retrieval;summaries;developers;relevant code;documentation;software;python;redcoder;benchmark datasets;java;extensive analysis;framework;supplement;promising results;lot;effectiveness;art;experiments", "pdf_keywords": "retrieval augmented code generation;code generation;summary generation behavior;summarization framework;summarization models;source code;summarization;quality source code;code;short text descriptions;summaries;software development;retrieval database;retrieval;documentation;python;relevant code;software developers;redcoder;associated text;source repositories;java;benchmark datasets;developers;github;framework;supplement;learning;extensive analysis;abstract"}, "a4ce6cd06bc73d81651f7888efa4337fd82a60f0": {"ta_keywords": "unknown word detection;unknown word perception;spoken dialog systems deals;related brain desynchronization responses;unknown words;brain waves;words;communication;event;chance rate;system;time;characteristics;most work;results;appearance;user", "pdf_keywords": ""}, "04b364d56995de2228cb1acfb320a935cbcf4440": {"ta_keywords": "weakly supervised segmentation;standard semantic segmentation;weakly supervised training;level segmentation;regularized losses;robust trust region;new robust trust region approach1;pixel labels;regularizers;pixel;geometric priors;training data;neural network optimization;losses;level solvers;order generalization;acquisition;quality;art results;discrete ones;state;classic chain rule;approach", "pdf_keywords": "neural network optimization;regularized losses;hidden optimization subproblems;neural network training;gradients;order optimization technique;new robust trust region approach1;divergence;segmentations;order generalization;regularizers;level solvers;derivatives;robust version;classic chain rule;functions;chain;kl;composition;space;different metrics;discrete ones;theart results;paper;introduction;state;approach"}, "fa774368fcf51cc0fa1bfda59b6a606e163c64b1": {"ta_keywords": "symmetrical counting problems;counting constraints;control synthesis;constraints;dimensional systems;aggregate abstraction procedure;correct controllers;symmetry;heterogeneous systems;systems;thousands;states;linear inequalities;tens;subsequent formulation;solution;work;key ingredients", "pdf_keywords": "counting constraints;symmetrical counting problems;symmetric systems;control synthesis;aggregate abstraction procedure;individual subsystem dynamics;constraints;dimensional systems;abstraction;construction synthesis methods;subsystems;heterogeneous systems;integer linear system;symmetry;entire state space;single subsystem;systems;symmetric high;permutation;states;correct controllers;scalable sound;thousands;simple speci\ufb01cations;low dimensionality;dimension;number;\u03b7nx;formulation;linear inequalities"}, "9abf14d4f89bf6c297e1bbd637cd54e1a0335e71": {"ta_keywords": "automatic compositor attribution;compositor attribution;bibliographic task;document;compositors;orthographic variation;visual features;clustering;visual details;novel unsupervised model;pages;paper;shakespeare;first folio;analysis;page;type;inspection;individual", "pdf_keywords": "bibliographers;visual sources;attributions;compositor attribution;orthographic variation;compositors;novel unsupervised model;ocr;compositor assignments;similarity;orthography;text;document;unsupervised model;generative model;visual features;pages;variation;shakespeare;images;manual judgements;cluster pages;latent variables;patterns;first folio;paper;model;glyphs;whitespace;evidence"}, "ffdbd7f0b03b85747b001b4734d5ee31b5229aa4": {"ta_keywords": "efficient prompt tuning;frozen language models;prompt tuning;soft prompts;prompt ensembling;soft prompts confers benefits;model checkpoints;discrete text prompts;model tuning;large models;models;specific downstream tasks;code;frozen model;multiple downstream tasks;examples;backpropagation;model weights;strong performance;robustness;billions;t5;model size;ablations;signals;experiments;gap;transfer;parameters;burden", "pdf_keywords": "frozen language models;autoregressive language models;large language models;language models;ef\ufb01cient prompt tuning;prompt tuning;prompt ensembling;traditional model tuning;popular superglue benchmark;unlearning span corruption;soft prompts;soft prompts confers;superglue score;downstream tasks;span corruption objective;task performance;purpose models;encoderdecoder architecture;frozen model;robustness;t5 models;rfou noah constant google research;model size increases;transfer;competitive technique;techniques;gap;effective mechanism;wide success;range"}, "1a3fcb1e2a416cbc79a011f1a1916aa53f7a2a09": {"ta_keywords": "dramatic action verbs;dramatic action theory;dramatic action;body language;body postures;emotion;emotion adjectives;emotional states;stick figure;stick figures;active verbs;body postures aligns;intent verbs;stick figure configurations;second stick figure;neutral pose;comfort;representation;theater;participants;effort;role;terms;others;connote intent;effectiveness;study;theory;dyad;set", "pdf_keywords": ""}, "e63c9eb5b623baad0a7805e839e5d9fabad37fce": {"ta_keywords": "worldtree explanation corpus;readable explanations;explanation regeneration tasks participants;baseline information retrieval model;natural language questions;detailed gold explanations;knowledge base;large relative improvements;detailed explanations;answers;standardized elementary science exam questions;information combination;supervised training data;detailed human;shared task;difficulty;facts;analyses;absolute performance;mean average precision;systems;system;question;ability;use;methods;map;state;art", "pdf_keywords": ""}, "ab8174a1f1810c1122f90649276a552d2eb1ccd4": {"ta_keywords": "deep segmentation;order losses;optimization;level", "pdf_keywords": ""}, "7618c65685c98fa88526555ae3f62cd5645066ad": {"ta_keywords": "relation extraction;relation entailment;wikidata relation hierarchy;relation hierarchies;relations;semantic understanding;textual information;relation;question answering;entities;summarization;representation learning;task;text;new task;future work;task characteristics;basis;words;previous work;insights;dataset;meta;paper;end;several methods;applications;expensive human intervention;existence;experiments", "pdf_keywords": ""}, "6e78e32481218e9391a88e6d0e30c0062ae71bec": {"ta_keywords": "gesture style transfer;gesture generation;unique gesture style;gestures;style transfer;unique style embeddings;style embeddings;same input speech;generative models;target speaker;styles;mix;audio;pose;speaker;multiple speakers;stage;style;stage model;new dataset;new model;single model;mixture;model;art approach;end manner;transcript;content;conditioning;key challenge", "pdf_keywords": "gesture generation;gesture style transfer;unique gesture style;gesture style;gestures;style transfer;unique style embeddings;generative models;multiple speakers;speaker;style preservation;audio;poseaudio;speech;stage;mix;styles;stage model;new style;single model;style;mixture;input audio signal;end manner;new model;model;art approach;conditioning;new dataset;end"}, "f3bca263a92b69c6da872a9a3268f260ba43f690": {"ta_keywords": "recurrent neural network language models;recurrent neural network language model;large vocabulary continuous speech recognition task;discriminative language models;discriminative training;automatic speech recognition;gram language model;discriminative training method;acoustic models;discriminative criteria;discriminative method;long word context;discriminative criterion;lm baseline;training criterion;rnn;words;lm;correct words;asr hypotheses;asr;dlm;training;criteria;tasks;addition;ce;references;paper;accomplishment", "pdf_keywords": ""}, "53880036fb85cc737103c480c613e1912c416010": {"ta_keywords": "structured wrapper induction system;wrapper;job postings;builders;other builders;new builder;information;architecture;extensible architecture;sites;core operations;strength;bias;systems;part;small set;system;set", "pdf_keywords": ""}, "a2f4731258830c76af7e3bdb96c4488823219585": {"ta_keywords": "frequency masking;underdetermined blind source separation;frequency masking method;robust automatic speech recognition;input speech recognition;binary mask;cepstral mean normalization;recognition performance;target speech;reverberant environment;soft mask;underdetermined bss method;sparseness;frequency;noise;interferences;asr;target signal;distortion;bss;time;cmn;technique;terms;representative;problems;facts;paper;experiments", "pdf_keywords": ""}, "341c72f55a89572915aa476db7f525c2e0b60eba": {"ta_keywords": "cluster similarity indices;many cluster similarity indices;clustering algorithms;similarity measure;validation measures;correlation;thorough analysis;analysis;systematic analysis;requirements;arccosine;desirable properties;list;particular task;open problem;paper;problem", "pdf_keywords": "cluster similarity indices;best cluster similarity index;similarity index;similarity;validation measures;indices;suitable validation index;index;asymptotic constant baseline;production systems;performance;constant baseline;systematic analysis;analysis;extensive theoretical analysis;desirable properties;bias;various applications;list;importance;notion;rand;theoretical framework;properties;particular application;pair;theoretical approach;methodology;contrast;methods"}, "143183584a8ebaad93490f4550295a9cb6cf9817": {"ta_keywords": "statistical relational learning;scalable statistical relational learning;probabilistic logics;semantic parsing;many natural language processing;probabilistic inference;nlp;information extraction;text classification;inference;coreference resolution;sentiment analysis;srl;machine learning methods;tutorial;tasks;gentle introduction;interdisciplinary research area;applications;theoretical foundation", "pdf_keywords": ""}, "fc78af26fd7644867af1abb8fbf2c37b47ad8257": {"ta_keywords": "lexicon induction evaluation dictionaries;downstream lexicon induction;language pairs;new dictionaries;embeddings;distant languages;pos tagging performance;multilingual setting;languages;language;dictionary collection;english;standard english;hub language;baselines;evaluation;new challenges;space;triangulation;recent work;hub;field;analysis;vast majority;general guidelines;light;default;choice;methods;suitability", "pdf_keywords": "lexicon induction performance;language similarity;downstream lexicon induction;word embeddings;distant languages;language pairs;language family membership trees;new dictionaries;languages;morphological complexity;shot pos tagging performance;multilingual settings;embeddings;hub language;typological distance;dictionary collection;english;standard english;spanish;portuguese;belarusian;russian;turkish;slovak;spaces;baselines;czech;ru;galician;hub"}, "682660c7a014e806b924fdf1a2a3d999a9ac13cf": {"ta_keywords": "abstractive summarization;guided neural language generation;summarization performance;neural language generation stage;abstract meaning representation;summarization results;neural encoder;later parses;parses;shelf parser;gold standard amr parses;decoder approach;source document;amr;guidance;previous work;larger dataset;points;paper", "pdf_keywords": "abstractive summarization;abstract meaning representation;guided neural language generation;summarization results;neural language generation stage;neural encoder;nlg mechanism;decoder;parses;gold standard amr parses;nlg;abstract;nlg stage;shelf parser;summary;text;amr;amr dataset;amr graphs;document;source document;guidance;baseline seq2seq model;progress;information;proxy report section;previous work;shef\ufb01eld;objective;recent work"}, "9d698e034d83eedc05237e629eaad1c0c4e5bbb9": {"ta_keywords": "learnable recursive clause;learnable recursive programs;free recursive logic programs;clause programs;equivalence queries;polynomial time;oracle;algorithms;depth determinate clause;certain classes;nonrecursive clause;difficult learning problem;classes;basecase;depth determinate;class;function;natural way;companion paper;results", "pdf_keywords": "learnable recursive clause;learning recursive logic programs;free recursive logic programs;single recursive clause;clause programs;recursive literals;depth determinate programs;largest learnable class;single nonrecursive base clause;depth determinate clause;oracle;equivalence queries;polynomial time;algorithms;cial intelligence research;standard learning model;certain classes;clause;pac;depth determinate;abstract;constant number;class;mountain avenue;murray hill;function;arti;journal;nj 07974 usa"}, "bfe6d67ed1c9119f91774e62fe0f4f328830526e": {"ta_keywords": "neural conversation models;conversation agent;specific conversation data;conversation data;speaker roles;role adaptation;speaker;persona;model training;traits;responses;speakers;baseline model quality;styles;significant improvements;other types;data;problem;experiments;approach;lack;large amounts;paper", "pdf_keywords": "neural conversation models;conversational models;conversational data;conversation data;speaker roles;individual speaker;speaker;human evaluation;autoencoder;seq2seq model;role;textual information;decoder parameters;responses;domain expertise;models;speakers;nonconversational data;mtaskm;bleu score;istics;ability;user;conclusion;data;other types;expressive styles;baseline system;speci\ufb01c information;signi\ufb01cant improvement"}, "ca879ec1c04b94de274954dfd09dddfde6cbb4f3": {"ta_keywords": "statistical singing voice conversion;statistical voice conversion;voice conversion;voice timbre control method;novel voice timbre control technique;voice quality control;singing voice;voice timbre;voices;singers;perceptual age;singer;prosody;age;song;listener;svc;individuality;experimental results;perceptions;varieties;limitation;physical constraints;notable characteristics;use;paper;adverse effect;previous work", "pdf_keywords": ""}, "bd6c708a535af588d90025a0e6cf17407bf65434": {"ta_keywords": "evaluating model explanations;deception detection models;fake hotel reviews;explanation control;popular local explanations;crowdsourcing study;words model;machine learning models;attributions;model confidence;classifier;reviews;models;fresh reviews;explanation case;predictions;bert;researchers;evaluation;model;understanding;explain;features;participants;rethinking user study design;understand;attempts;edit;class;training", "pdf_keywords": "deception detection models;fake hotel reviews;deception detection task;crowdsourcing study;bert model;remarkable predictive accuracy;explanation control;deep learning models;hotel reviews;popular local explanations;words model;machine learning models;attributions;bert;fresh reviews;reviews;supervised learning problems;model;people;participants;explanation case;model con\ufb01dence;explanation;linear bag;classi\ufb01er;evaluation;feature coef\ufb01cients;training;linear model;class"}, "bf7481685e63b85ef2586de3f6098f1a5fbe0e2d": {"ta_keywords": "active sampler coupling osmotic pump;spe sampler;spe samplers;measured concentrations;spe cartridge;organic contaminants;free active sampler;sampler;spe cartridges;target analytes;solid phase extraction;organic pollutants;surface water;phase extraction;situ sampling;op inlet chamber;osmotic pump;daily spot samples;herbicides;exchange resins;average concentration;spe;water;river;novel solution;ion;ops;constant flow;average;widespread applications", "pdf_keywords": ""}, "72579f6ce4a413585445c4ef8c8c2fa63ea1b8bc": {"ta_keywords": "privacy;private data;private information;deep neural inference;deep neural networks;cloud;stochastic representations;optimal stochastic perturbations;stochastic perturbations;cloak;dnn;dnns;stochasticity;offline gradient;service;home automation;data;discovery;key idea;machine vision;weights;inference;world datasets;raw input;advertising;information content;inference request;input data;essential pieces;rich set", "pdf_keywords": "preserving prediction privacy;privacy;privacy protections;features;essential features;security;cloud;neural networks;target prediction task;information theory;computer vision tasks;ccs concepts;provider;services;fact;machine;computing methodologies;ahmed taha;abstract;mathematics;usability;fatemehsadat mireshghallah mohammadkazem taram ali;subset;feb;dean tullsen hadi esmaeilzadeh;university"}, "80edd01d46228fac7ec0cd14aea1666253b28f4d": {"ta_keywords": "voting environment;other voter preferences;other voting profiles;voter;voters;heuristics;vote;missing votes;true preferences;many collective decision;decisions;single winner;utility;candidate;preferences;agents;effort;strategy;better outcome;such situations;behaviors;information;scenarios;people;alternative;situations;humans;complete information;effectiveness;paper", "pdf_keywords": "uncertain approval voting environments;voting environment;computational social choice;heuristics;collective decision making;voting;many collective decision;heuristic strategies;voter;elections;high utility candidates;individual preferences;decisions;other voting profiles;candidate;single winner;missing votes;trivial utility;behavioral results;utility;uncertainty;negative utility;others;approval;computational issues;aggregation;behavioral experiment;preferences;agents;situations"}, "1da3a9c194a01c0bff7b6ecda79db9d673810bee": {"ta_keywords": "recurrent neural network;morphological inflection generation;recurrent models;level nlp tasks;transliteration;historical text normalization;recurrent sequence;sequence models;level transduction tasks;phoneme conversion;grapheme;level transduction;batch size;large enough batch size;sequence;level tasks;transformer;character;strong baseline;other character;feature;crucial role;few works;performance;various word;empirical study;contrast;simple technique", "pdf_keywords": "level nlp tasks;universal morphological rein\ufb02ection;recurrent neural network;sequence models;conll sigmorphon;level transduction;sigmorphon;sequence;transformer;conll;character;jan;various word;pages;xuniversity;proceedings;abstract;qeth;cambridge;shared task;acc;brussels;vancouver"}, "28e81f96eab94e99febcaaee00637825c8a3e664": {"ta_keywords": "interpretable machine learning;machine learning;models;iml;model debugging;complex models;trust;real human decision;reasoning;technology;various stakeholders;use cases;concerns;society;emergence;people;field;inability;making;past decade;goal", "pdf_keywords": ""}, "faf494d0aa25a17aa25930ffb4c750fa59c44849": {"ta_keywords": "unsupervised tts embeddings;speaker verification;speaker classification loss;minimal phonetic information;asr transcripts;manual transcripts;tts decoder;kaldi phone alignments;tts reconstruction objective;embeddings;tts inputs;speaker;tts;textual input;datasets;representation;voxceleb1;libritts;eer;networks;end tacotron;model;information;finer resolution;end;self;regard;latter;effectiveness;work", "pdf_keywords": "speaker encoder;speaker veri\ufb01cation task;minimal phonetic information;tts decoder;speaker veri\ufb01cation;embeddings;manual transcripts;tts reconstruction objective;speaker;representations;tts;tts blocks;representation;tts criterion;sv task;textual input;end tacotron;networks;endto;datasets;information;self;rest;latter;effectiveness;work;fashion"}, "7efb1788b5e0fa3b4d9932722286ba1753b42f91": {"ta_keywords": "taskspecific ontology;natural language descriptions;task specifications;language description;semantics;schemata;tasks;intents;task;unseen tasks;conversations;dialogue;key information;names;such information;tod;system developers;slots;completion;notations;systems;system;terms;shot transfer;state tracking;benchmarks;better understanding;higher performance;data efficiency;convention", "pdf_keywords": "descriptiondriven dialogue state tracking;dialog modeling;dialog;dialogue;task speci\ufb01cations;language description;schema descriptions;tasks;conversations;intents;unseen tasks;state tracking;task;description;schema;systems;information;key information;active slots;effective dst model;system;services;tod;completion;inputs;identi\ufb01cation;d3st;abstract;other plan options;relevant slots"}, "9688671a573651955c26d710c12617de26715e78": {"ta_keywords": "repair msr codes;interference alignment;rate msr codes;miser code;mds codes;exact repair;msr;network storage;code;repair;systematic nodes;such code;codes;replacement node stores data;minimum storage;data file;mds;crucial component;node;symbol extension;maximum distance;data;impossibility;explicit construction;paper;download;2k;size;construction;nonexistence proof", "pdf_keywords": "regenerating codes;solomon codes;repair msr codes;mds codes;miser code;interference alignment;msr codes;msr code;codes;code;data recovery;storage;ieee;systematic nodes;reed;constructions;repair;mds;explicit construction;symbol extension;exactrepair;crucial component;impossibility;paper;construction;class;problem;sep;cut;principal results"}, "148efaba70165d9faef0dac28d5fa2538cfa662d": {"ta_keywords": "cognitive biases;ai model predictions;collaborative decision;bias;ai accuracy;second user experiment;confirmation bias;collaborative performance;ai;ai model;time allocation strategy;cognitive science;first user experiment;availability bias;human decision;artificial intelligence;stakes applications;effectiveness;time;low confidence;knowledge;researchers;explanation;perception;people;makers;research;understanding;human;humans", "pdf_keywords": "ai collaborative;ai collaboration;time allocation policy;collaborative decision;collaborative accuracy;explainable ai;time allocation strategy;ai accuracy;cognitive biases;collaborative performance;ai;bias;human decision;cognitive science;optimality;\ufb01rst user experiment;knowledge;allocation problem;resource;novel resource;machine learning algorithm;time;researchers;maker;interplay;assumptions;making;work;setup;conceptual framework"}, "a6219725a9ad2079536c091f02fda2d4da6d62ac": {"ta_keywords": "exact regenerating codes;storage systems;minimum storage point;multiple simultaneous node failures;peer systems;linear code;storage;node failure;code;nodes;peer;codes;same node;subspace approach;reliability;system performance;bandwidth;failure;system;scheme;sufficient conditions;variable number;certain suitable parameters;paper;additional property;explicit construction;applications;techniques;crucial role", "pdf_keywords": ""}, "3c1001c04866647650216201feb54c927af3a05b": {"ta_keywords": "concept description language;special antecedent description language;grammatically biased learning;constrained language;predicates;learning system;explicit antecedent description langu;concept;horn clauses;most learning systems;background knowledge;incomplete theories;horn theories;theories;explicit input;overgeneral theories;constraints;clause;target theory;many diierent types;additional input;hypotheses;possible applications;antecedent;system;large part;clich es;technique;set;use", "pdf_keywords": ""}, "60f0af1dbc2775a69f64e4351d969ac966659fb2": {"ta_keywords": "automatic synset induction;synset induction methods;input synonymy graph;synonymy dictionaries;similar synset clusters;synsets;input dictionaries;input dictionary;datasets;sparseness;incompleteness;russian language;missing edges;graph;sparsity;such methods;structure;first one;pre;second one;quality;performance;paper;approaches;impact;different approaches", "pdf_keywords": "synset induction methods;synonymy dictionaries;synset induction method;input synonymy graph;synonymy graph;synsets;input dictionaries;input dictionary;datasets;russian language;global clustering;sparseness;watset;watset state;incompleteness;extensive error analysis;inherent sparsity;sparsity;such methods;prominent alternative methods;graph;structure;di\ufb00erent approaches;maxmax;approaches;paper;quality;performance;experiments;art"}, "22616702da06431668022c649a017af9b333c530": {"ta_keywords": "automated fact checking;fact checking;natural language processing;misinformation;journalism;inconsistent terminology;knowledge representation;articles;fact;relevant papers;papers;machine learning;research;truthfulness;task formulations;research communities;task;claim;authors;paper;substantial progress;understanding;databases;further progress;methods;disciplines;related disciplines;focus;future directions;methodologies", "pdf_keywords": "automated fact checking;automated fact;fact checking;natural language processing;future nlp research;knowledge representation;nlp;fact;social media analysis;evidence;misinformation;task formulations;machine learning;task;datasets;research;claim;papers;databases;common concepts;de\ufb01nitions;abstract;truthfulness;work;paper;methods;use;modelling approaches;computer science;survey"}, "6b7f2f30840b0d72484784a15b3be670868a9f95": {"ta_keywords": "universal dependency treebanks;dependency parsing;only source corpus;syntactic tasks;target languages;distant languages;new interlingual latent;pos tagging;tagging;unsupervised adaptation;languages;dependency;unlabeled target data;generative model;source data;english;art discriminative models;speech;invertible projection;invertible projections;direct transfer method;dataset;part;input;absolute improvement;pos;paper;space;state;methods", "pdf_keywords": "language category distant;target languages;language distances;multiple source languages;additional language;distant languages;syntactic analysis tasks;dependency parsers;linguistic distance;language names;uriel linguistic database;linguistic features;dependency model;selective model parameter sharing;croatian;turkish;portuguese;pos tagging;indonesian;korean;hindi;arabic;swedish;english;persian;japanese;spanish;bulgarian;hidden markov model;german"}, "eebc1811c55c2e5e8b3b78d0b0382ad50f22e32a": {"ta_keywords": "adversarial natural language inference;adversarial fact verification;factual revisions;fact verification models;typical fact verification models;wikipedia revisions;consistent text generation;slight factual changes;evidence sources;automatic edits;evidence pairs;previous resources;revisions;evidence;claims;resources;content;fact;benchmark;accuracy;underlying fact;vitaminc;examples;claim;language;challenging cases;nli;additional tasks;relevant words;training", "pdf_keywords": "adversarial natural language inference;adversarial fact veri\ufb01cation;factual revisions;textual sources;wikipedia revisions;fact veri\ufb01cation models;factual claims;vitaminc dataset;contrastive contexts;evidence pairs;scale fact veri\ufb01cation dataset;fact;underlying fact;evidence;vitaminc;wikipedia;resources;revisions;automatic edits;relevant words;accuracy;claim;data;new questions;truthfulness;recent years;additional tasks;intense research interest;nli;training"}, "6dd1e4d97dbdb370a36c25f82a9a9baaa16c836c": {"ta_keywords": "ebola virus glycoprotein;ebola virus gp;ebola virus;mutant vesicular stomatitis virus;peptides;efficient antiviral agents;coil motif;coiled;alanine substitutions;receptor;gp2;hydrophobic residues;coil;fusion protein;infectivity;gp function;host cells;residues;important role;effects;results;entry;functional significance;functional importance;region", "pdf_keywords": ""}, "7e122cc1a62e2f30951e14b91811896e1866dd7c": {"ta_keywords": "adversarial losses;symbolic music generation;other gans;art music transformer;gan;music;sequence generation;learned loss;new discriminative metric;classifiers;samples;models;human evaluations;negative log;autoregressive model;nll objective;likelihood maximization;quality;long sequences;likelihood;sequences;transformer;nll;failures;observed sequence;exposure bias;baseline;exploration;phenomenon;approach", "pdf_keywords": ""}, "c7af06170f3d81ab761873a4c1fe0af2736eb0a2": {"ta_keywords": "affective communication;dialogue system;affective interaction;natural conversation;emotional responses;emotion triggers;television talk shows;affective process;emotion;spoken language technologies;emotional triggers;computer interaction;automatic prediction;responses;prediction;response;computers;events;action;knowledge;natural manner;occurrences;users;analysis;paper;great potential;ability;advancements;study", "pdf_keywords": ""}, "8dd3b88ac87372c9f4428029ac12288ff3405199": {"ta_keywords": "density lipoprotein cholesterol;blood lipid levels;blood lipid;ldl;blood lipids;nlr values;diabetes mellitus;nlr value;hdl;inflammation;lymphocyte ratio;risk factors;neutrophil;nlr;statins;atorvastatin;variability;elective percutaneous coronary intervention;standard error;pci;subgroup analysis;subgroups;regression coefficients;total sample;linear regression;retrospective study;patients;association;relationship;conclusion", "pdf_keywords": ""}, "36b6abfb32ea56208a2858b558acbdd001c965e9": {"ta_keywords": "neural machine translation;computational linguistics;linguistic structure;domain adaptation;generation;data augmentation;second workshop;document;models;annual conference;inadequate resources;acl;proceedings;findings;papers;concert;analysis;association;research trends;particular interest", "pdf_keywords": "neural machine translation;ef\ufb01cient neural machine translation;neural mt;neural network optimization;model distillation;nmt systems;basic model architectures;nmt;solid engineering work;workshop;second workshop;task;generation;submissions;precision calculation;ef\ufb01cient;results;ef\ufb01ciency;paper;\ufb01rst iteration;best practices;research advances;valuable contributions;participants;conclusion;number;characteristic;area"}, "47b6023808002dfde031c17b34dcb1b522d3b326": {"ta_keywords": "jssd;development on;35th annual conference", "pdf_keywords": ""}, "743d1aae44a12fb37b743ec947fad41cba9831b8": {"ta_keywords": "conditional text generation;text generation;standard language generation tasks;pragmatic modeling methods;computational pragmatics;language production;pragmatics;language learning;output text;text;distractors;informativeness;speaker;listener;cognitive science;speakers;information preservation;original input;listeners;explicit modeling;less attention;game;models;techniques;such approaches", "pdf_keywords": "traditional language generation tasks;structured meaning representations;pragmatic modeling methods;language generation problems;text generation;pragmatic reasoning;explicit pragmatic modeling procedure;pragmatics;rational speech acts;distractors;other natural language texts;referents;summarization;descriptions;input meaning representation;reference resolution;text;explicit modeling;lingustic content;models;generation;speakers;customer rating;descriptors;cheap coffee shop;strings;rsa;listeners;canonical presentation;people"}, "ba5e3559a2d54bb0e8d7678c9905b4a77da63f71": {"ta_keywords": "incentive properties;truthful feedback;simple reward mechanism;informative responses;truthful behavior;reward;truthful responses;square root agreement rule;objective evaluations;incentivizing;verifiability;responses;online platforms;evaluations;evaluation;peer;observational biases;empirical findings;mild subjectivity;such platforms;such guarantees;agent;products;additional assumptions;popularity index;robustness;response distribution;mechanism;commits;services", "pdf_keywords": "incentive properties;agent responses;distributional information;arbitrary mutual information measure;ks mechanism design framework;homogeneous responses setting;mutual information measure;mechanism design framework;observational biases;homogeneous response;homogenous responses;truthful behavior;square root agreement measure;empirical \ufb01ndings;responses;mechanism;mild subjectivity;single evaluation;agent;payments;\ufb01rst mechanism;multiple tasks;generic adaptation;robustness;leverages;sra;truthfulness;evaluation;design;ks"}, "52824fb6eb5d3b55fb6634c77dc80f5826964464": {"ta_keywords": "inductive logic programming methods;specification recovery;machine learning techniques;software;instrumented code;general description;representative test cases;examples;methods;techniques;behavior;specifications;aspect;task;system;shelf;domain;technique;number;hand", "pdf_keywords": ""}, "0cd693f1a1223f25e89c1f5efdedd7c3b7846691": {"ta_keywords": "overall traffic congestion;traffic;arterial traffic volume data;traffic vehicles;level traffic;congestion;parking data;curbside parking;curbside parking contributes;parking;average occupancy rate;travel time;high occupancy arterials;city;percentage increase;data;municipalities;network;proportion;probability;high volumes;viable metric;addition;estimate;block;model;day;time;paper;face", "pdf_keywords": "\ufb01nite capacity queues;urban parking;curbside parking;parking;queue;deterministic service times;city planners;markovian relaxation;maximum allowable time;networks;network topology;neighborhood;mean rate metrics;such networks;network;temporal heterogeneity;seattle;service;washington;available server;assumptions;tasks;belltown;model;drivers;driver;search;article;example;new model"}, "1f0524971c20a06d745ab784689eb8833435fde1": {"ta_keywords": "factoid claims;first fact extraction;wikipedia;evidence;verification;participants;task;results;entries;commonalities;systems;fever;teams;paper;innovations;summary;baseline", "pdf_keywords": "sentence extraction;fact extraction;fever fact extraction;wikipedia sentences;information retrieval approach;syntactic features;language modeling;sentences;bidirection attention;fact checking;entailment classi\ufb01er;inforcement learning;relevant evidential sentences;nlper;potential evidence;evidence;fever;relevant documents;wikipedia article;evidence f1 metric;layer multilayer perceptron;veri\ufb01cation challenge;transformer networks;10th;larger memory;veri\ufb01cation;classi\ufb01cation;components;claim;high precision"}, "68731c68773b117250f04509103031109b222d27": {"ta_keywords": "information extraction;translatingbased objective;individual sentences;world corpora;relation phrases;level extractions;entity;global structure constraints;local context;distant supervision;global structural signal;remine;sentence;local context signal;novel open ie system;joint optimization problem;other open ie systems;unified framework;robustness;different domains;effectiveness;experiments;paper;quality", "pdf_keywords": ""}, "fd8e176087335355ff5e81821a616d15ec8d3346": {"ta_keywords": "training labels;indirect supervision sources;weak indirect supervision;noisy supervision sources;label relations;recent weak supervision;unseen labels;different output label spaces;training sets;text classification tasks;industrial advertising application;plrm;usable sources;generalization;image;mismatched output spaces;model;probabilistic modeling approach;baselines;distinguishability;challenge;scope;margin;ws;frameworks;wis;test;user;advantages;new research problem", "pdf_keywords": "weak indirect supervision;indirect supervision sources;weak supervision sources construction;training labels;label relations;training sets;standard supervised learning;label relation structures;probabilistic label relation model;data annotation;machine learning;unseen labels;text classi\ufb01cation tasks;generalization;yujing wang1;yaming yang1;china 4carnegie mellon university 5snorkel ai;wis formulation;yujwang;iclr;jing;technology;human efforts;new notion;baselines;wis;abstract;xiangchen song4;model;challenge"}, "e34f9e9163b13de00707157feda6a8b853c5c82d": {"ta_keywords": "crowdsourced lexical resources;fuzzy duplicates;lexical resources;deduplication problem;high quality thesauri;resource;expert;knowledge;quality;key idea;short time span;approach;low price;aim", "pdf_keywords": ""}, "e1d35deec12d18e53ca97a3cf4071526ad47968d": {"ta_keywords": "large pretrained language models;transformer language models;linguistic knowledge;attention configuration;lms;training objectives;lm checkpoints;models;training;significant improvements;adjunct islands;scale transformer lms;improvements;analyses;architectural decisions;recent progress;several subcategories;ability;none;modifications;acquisition;negative polarity items;focal loss;changes;kinds;computational constraints;self;various factors;suite;experiments", "pdf_keywords": ""}, "e2ebf18e0b88752bd3ff905d2fba74213dcd2c51": {"ta_keywords": "physical electrolarynx;electrolarynx;excitation sounds;laryngectomees;time vibration control;statistical f0 prediction;mechanical excitation;electrolaryngeal;el speech;prototype system;contour prediction;speech;excitation;unnatural fundamental frequency;time prediction method;type prediction;statistical f0;f0 patterns;el;f0;aid device;patterns;batch;improvements;method;use;naturalness;time;previous work", "pdf_keywords": ""}, "595a79ca667258ca2a4f5e7775e95a0fb0a0f024": {"ta_keywords": "derivative free gradient play;derivative free gradient;monotone games;unconstrained optimization;improved rates;complexity;e\ufb03ciency estimate;target accuracy;known e\ufb03ciency guarantee;distance;method;in\ufb02uential work;solution;paper;bravo et al", "pdf_keywords": "stochastic gradient play;derivative free gradient play;monotone game;monotone games;smooth cost functions;unconstrained optimization;optimal rate result;update players;improved rate;games;improved rates;gradient;cost functions fi;player game;algorithms;monotone;algorithm;known e\ufb03ciency guarantee;tighter analysis;e\ufb03ciency estimate;target accuracy;distance;sets;\u03b52;method;\u03b53;continuous actions spaces;xi;apr;natural class"}, "36f7827bc344f9c2198dcb29732c525c68dc637a": {"ta_keywords": "shapley allocations;transport costs;tractable allocation techniques;transportation settings;vehicle transport setting;shapley value;synthetic euclidean games;complexity;road network;cost;deliveries;world tours;games;goods;sampling;problem instances;scenarios;good proxies;tsg;location;proxies;rules;solutions;number;applications;novel methods;problem;day;analysis;size", "pdf_keywords": "transport costs;shapley allocations;vehicle transport setting;transport;cost;world tours;euclidean games;tractable proxies;proxies;dynamic programming;good approximations;underlying tsp;dynamic programming solution;shapley value;auckland;computation;cities;canberra;gold coast;exact evaluation;sydney;consumer goods businesses;tsp;location;game;problems;australia;approximation;dp;hardness proof"}, "ead1e044d284f3deecd32c2d5cc89fe513195a0a": {"ta_keywords": "synonymy graph augmentation;input synonymy graph;synonymy relation;transitive edges;graph;russian language;potential synonyms;equivalence property;datasets;preliminary evaluation;addition;paper;quality;approach", "pdf_keywords": ""}, "7e63be5285e6596fbbc6c56bc89f7b6fd8bbe8c5": {"ta_keywords": "model debugging;model contamination;explanations;deep network;explanation methods;model predictions;training examples;defective models;model errors;several explanation methods;diagnose;data contamination;spurious correlation artifacts;attributions;spurious background bug;prediction;model;time contamination;researchers;tools;guidance;distribution inputs;methods;test;challenge;response;class;higher layer parameters;results;addition", "pdf_keywords": "model debugging;model contamination;model explanations;model errors;training examples;standard supervised learning pipeline;diagnose;model prediction;spurious correlation artifacts;tests;training;model;di\ufb00erent contamination classes;data contamination;spurious correlation;labeling errors;bugs;time contamination bugs;several explanation methods;wheaten terrier;test;time contamination;distribution inputs;input;data;time test;stage reinitialized weights;framework;ilaria liccardi massachusetts institute;unintentional frozen layers"}, "bd8922f8cc8284553dc9e6db529af309298451fe": {"ta_keywords": "transcribed speech;decoder networks;attention;character error rate;nearby languages;text;test languages;other languages;only text;augmentation technique;side text;average relative improvement;models;relative contributions;data;relative reduction;sources;network parameters;sufficient target;shortcoming;part;paper;small amounts;approach", "pdf_keywords": ""}, "25ddddbd0bd1cfebf1548b2ee91bb1bbd05fdff1": {"ta_keywords": "complex human instructions;neural agents;compositional tasks;multimodal transformer;natural language instructions;episodic transformer;language inputs;visual observations;synthetic instructions;visual appearance;subtasks;training;dynamic environments;transformer;actions;intermediate representation;full episode history;joint training;interaction;navigation;environment;variations;long sequence;challenges;performance;significant challenges;history;paper", "pdf_keywords": "compositional tasks;complex human instructions;neural agents;language navigation;many subtasks;natural language instructions;subtasks;challenging alfred benchmark;episodic transformer;task;actions;navigation;synthetic instructions;challenges;dynamic environments;vision;unseen test splits;main challenges;joint training;significant challenges;vln;transformer;performance;interaction;abstract;long sequence;inria;history;art;approach"}, "0805cb1b26577f08f84190445992f7f0584e4742": {"ta_keywords": "opera system;end information extraction;isi;cmu;knowledge bases;languages;usc;english;questions;multiple media;results;ukrainian;domain;hypothesis creation;russian;end", "pdf_keywords": ""}, "352ac73b7d92afa915c06026a4336927d550cec3": {"ta_keywords": "novel graph;neural network;gnns;natural language sentences;more accurate relations;propagation module;supervised datasets;dataset;parameters;transition matrices;generator;model;inputs;message;human;gp;paper;procedure;qualitative analysis;significant improvements;experimental results", "pdf_keywords": "many natural language processing tasks;relational reasoning;relation extraction;relational reasoning task;relational message;natural languages;natural language;unstructured text inputs;novel graph;graph generation problem;natural language sentences;unstructured inputs;gnns;neural networks;neural network model;graph;unstructured input;entities;more hops;relationship;parameters;rich text information;text;models;task;layer;model;level;gp;paper"}, "b53689b8c28353106f327f0981b108eb67816053": {"ta_keywords": "syntactic preprocessing approaches;syntactic preprocessing;machine translation;syntactic information;several preprocessing techniques;syntax;successful preprocessing method;englishjapanese pbmt;smt;rule;pbmt;significant improvements;motivated rules;phrase;output;quality;accuracy;sort;paper;gains", "pdf_keywords": ""}, "21d45b4923ad165fbb6612e08d06f9d786f9b4cc": {"ta_keywords": "commonsense knowledge graphs;neural commonsense model;commonsense knowledge graph;commonsense models;commonsense model;knowledge distillation;causal commonsense;general language models author;commonsense capabilities;general language model teacher;general language model;commonsense;critic model;knowledge;teacher model;larger models;neural model;careful prompt engineering;diversity;smaller models;machine;text;student;empirical results;different type;alternative;quantity;prior art;quality;human", "pdf_keywords": "commonsense knowledge graphs;symbolic knowledge distillation;commonsense knowledge sources;automatic knowledge graphs;commonsense models;commonsense model;causal commonsense;general language models author;general language models;general language model teacher;commonsense;commonsense research;general language model;knowledge;critic model;careful prompt engineering;student;art models;new conceptual framework;machine;highquality alternative;novel methodology;alternative;different type;work;human;quality;promising new role;aspect;state"}, "53e0abebd9aef5915f72147d3674596a0051748c": {"ta_keywords": "personalized ai services;data protection;ai services;privacy;personalization;privacy implications;user services;user data;ai levels;ai;different protection approaches;such ai;services;artificial intelligence;edge research;better support;many challenges;requirements;technology;system;advances;different research communities;management;ii;different levels;today;context;unacceptable face;article", "pdf_keywords": "data protection;ai services;data;ai;new data;artificial intelligence;user services;introduction artificial intelligence;personalization;megabytes;connected devices;advances;survey;fourth industrial revolution;key driver;human being;better support;process;today;technical university;christian meurisch;max m\u00fchlh\u00e4user;germany;darmstadt"}, "b6145cc19acfbec31373446a2dba210cc9b1eb7f": {"ta_keywords": "relation extraction;structured corpora;instance extraction;joint learning;relation;relation arguments;related tasks;supervised ie;corpora;document structure;bootstrapping;concept examples;such sections;soft constraint;correspond;sections;examples;concept;significant improvements;novel use;several state;good precision;art approaches;second argument;small well;framework;performance;same type", "pdf_keywords": "ordinary text corpus;large corpus;distant labeling methods;earlier bootstrapping methods;corpus;retrieval results;label propagation;classic bootstrap;more patterns;standard classi\ufb01cation learner;title entity;distant examples;more instances;new examples;document name;available resource;new patterns;substantial improvements;relative improvements;seed instances;extensive experiments;riloff;kb;latent variables;new instances;ir perspective;structure;effective way;relation;iterative fashion"}, "181e1d4b08dc62237277a6a743576facd8c5e572": {"ta_keywords": "speaker number estimation;speaker voice activity detection;speaker diarization;libricss meeting corpus;speaker;speech;vector estimation;real conversations;speakers;initial diarization system;fusion;frame;estimate;der;systems;number;improved initialization;target;vad network output;vad;unknown number;numbers;ts;variants;level decisions;steps;approach;original model;method;promising results", "pdf_keywords": "libricss meeting corpus;form recordings;recording;separate diarization model;different diarization methods;region proposal networks;vector estimates;single best initialization;speakers;improved initialization;fusion;initialization technique;vad network outputs;frame;ts;vad;systems;variants;der;\ufb01xed ts;number;relative improvement;numbers;limitations;same system;unknown number;level decisions;approach;method;work"}, "4236a5f650f5b7ced7512b5072a062b521220b31": {"ta_keywords": "traffic speed prediction;transfer learning framework;traffic speed;intelligent transportation;temporal semantic features;recent supervised machine;kernel regression model;smart city;historical data;other dataabundant areas;iot applications;classic regression models;such urban areas;target areas;historical time;aim;various spatio;series data;wide range;vast amount;competitive performance;approaches;methods;experimental results", "pdf_keywords": ""}, "e25ce2a7b28699e1d57803ef977175937ce50923": {"ta_keywords": "pronunciation estimation;word segmentation;efficient corpus construction;natural language processing;corpus;partial annotation;annotation techniques;linguistic resources;particular words;words;high information content;traditional sentence;word;entire sentence;evaluation;estimation process;accuracy;document;particular sentence;other decisions;decision;manual creation;techniques;benefit;smaller number;point;steps;order;paper;wise estimator", "pdf_keywords": ""}, "0e532d1489d7420cff7ff8aa211ded08e7d57fe9": {"ta_keywords": "convex learning algorithms;learning algorithm;online learning;learning;pegasos algorithm;generalization ability;convergence rate;high probability;course;rounds;online;round;example;cs;hypothesis;current hypothesis;sequence;correct label;paper;contrast;main application;lens;beginning", "pdf_keywords": ""}, "1109f787fc8d51feb3bae9bf6e1945dc4a1191e7": {"ta_keywords": "ai team performance;explainable ai;ai;team accuracy;explanations;method user studies;complementary performance;many researchers;accuracy;tasks;explanatory approaches;participants;recommendations;improvements;recommendation;appropriate trust;task;solo;studies;human;humans;correctness;best team;datasets;result;decision;new challenges;prior studies;chance;conditions", "pdf_keywords": "ai collaboration;ai communities;ai;natural language processing;interactive systems;hci;new interaction methods;confidence;machine learning;coordination strategies;explanation approaches;human;explanatory approaches;computing;empirical methods;empirical studies;explanations;tools;researchers;critical challenges;new challenges;complementary team performance;conference;ccs concepts;computing methodologies;appropriate trust;action;understanding;complementary performance;paper"}, "328a9fe143639810d6413c2cc901ec3afa6aa607": {"ta_keywords": "discretized lps models;optimal linear peridynamic solid;continuum model;md displacements;discretizations;nonlocal models;molecular dynamics;learnt model;md data;constrained optimization algorithm;peridynamics;posedness conditions;posedness;model;validation data sets;dimensional tests;peridynamic;mechanical property tests;peridynamic influence function;robustness;such solvability conditions;materials;external loadings;data;different domain shapes;integral operators;thermal noise;integrands;lps;physical system", "pdf_keywords": ""}, "350e5f5a89cbb3a23442c9d0d3e59fc50d665dbb": {"ta_keywords": "electricity market;electricity system;ahead scheduling;energy offers;clearing prices;dispatching;system load;greece;ancillary services;costs;market;cost components;units;day;reserve;das problem;simplified model;analysis;problem;frequency;minimum;design;load;different cases;das;main aspects;data;illustrative example;grounds;shut", "pdf_keywords": ""}, "2226f5a13e3e9faac2e228e95175d3e612b52395": {"ta_keywords": "acm sigai leadership committee;new acm sigai chapters;acm sigai;monthly acm sigai leadership teleconference;diversity officer;acm sigai newsletter;ai;major ai conferences;acm special interest group;international officers;intelligence;srm institute;autonomous agents;diversity;marion neumann;female officers;new officers;knowledge representation;aaai conference;royal institute;intelligent user interfaces;chief;machine learning;officers meetings;human language technologies;washington university;search;officers teleconferences;computer systems;study", "pdf_keywords": ""}, "c102ac8c779ee0a53dc8e4ee20b4088ac2c7e186": {"ta_keywords": "joint connectionist temporal classification;lstm language model;automatic speech recognition;deep convolutional neural network;encoder;decoder predictions;decoder network;cnn;decoder;attention;ctc network;ctc predictions;characters;ctc;beam search process;art end;end;vgg network;asr;model;top;state", "pdf_keywords": "end speech recognition;japanese asr systems;attention model;encoder;mandarin;end asr model;attention end;end asr system;end asr;conventional mandarin chinese;chinese tasks;decoder;chinese speech;traditional hybrid asr systems;deep convolutional neural network;rnn;cnn;attention;art hybrid asr systems;end model;joint ctcattention;ctc network;connectionist temporal classi\ufb01cation;morphological analyzer;current best end;linguistic resources;joint ctc;end;pronunciation dictionary;vgg network"}, "1144cc3e86b1cc4160aedddb085d7861d4b528dc": {"ta_keywords": "softmax;rnn;automatic speech recognition;auxiliary ctc losses;transducer;minibatch;strong accuracy;streaming;vocabulary;model accuracy;memory consumption;high memory consumption;training;end;small subset;many advantages;architectures;development;distributions;critical problem;work;friendly property", "pdf_keywords": "sampled softmax;end speech recognition;softmax;automatic speech recognition;rnntransducer;auxiliary ctc loss;auxiliary ctc losses;rnn;wise sampling strategy;memory;minibatch;huge memory reduction;minibatch setting;ctc;memory consumption;ef\ufb01cient training;model accuracy;transducer;baseline model;vocabulary;example;joint ctc;accuracy;csjaps;extensions;librispeech;end;ef\ufb01cient implementation;1naver corporation 2carnegie mellon university;shinji watanabe2"}, "69e9a040ef633c60533843442529cc68c5f12932": {"ta_keywords": "power iteration clustering;scalable graph;effective cluster indicator;wise similarity matrix;dimensional embedding;spectral methods;truncated power iteration;dataset;real datasets;data;ncut;method;pair;pic", "pdf_keywords": ""}, "3dc4580a154df87f3a56aa3d16b00c5a935ebe15": {"ta_keywords": "citation bias;citations;peer review;prospective reviewers;reviewer expertise;citation;cite;reviewing;reviewer;review process;researchers;scienti\ufb01c impact;evaluation;positive evaluation;many anecdotes advice authors;paper quality;observational study;algorithmic economics;study;machine learning;\ufb02agship conferences;analysis;submission;careers;higher score;score;factors;own work;key factor;terms", "pdf_keywords": "citation bias;citations;cite;researchers;other biases;scienti\ufb01c impact;peer review;\ufb02agship machine learning;algorithmic economics;research question;\ufb02agship publication venues;observational studies;observational study;reviewing;economics;machine learning;evaluation;conferences;contributions;study;\ufb02agship conferences;international conference;peer;1carnegie mellon university 2university;review process;acm conference;technology;careers;analysis;discussion"}, "3cfdec4f1664fcdc20fd5a6d3f86e7b40cf19f70": {"ta_keywords": "neural encoder;output sequence length;encoder;decoder outputs;decoder models;many sequence generation tasks;output length;decoders;length;learning;previous work;situations;paper;methods;great success", "pdf_keywords": "summarization methods;summarization task;degrading summary quality;output sequence length;decoder models;neural encoder;output sequences;output length;standard encoderdecoder models;learning;length;training process;rouge score;results;capability;methods;lenemb;paper;leninit;process"}, "7a070c558cdb9c525559d1ad48159551381750c9": {"ta_keywords": "large search space;gram machines;symbolic meaning representations;gram machine;encode knowledge;encoded knowledge;search space;sentences;encoding objective;sequence models;babi tasks;reinforce;knowledge;tasks;sequence;ngm;complexity;babi;structure;scalability issue;auto;text size;stories;end;programs;questions;tweak procedure;whole system;williams;approach", "pdf_keywords": "deep qa models;network text understanding models;large corpus;gram machines;natural language text;memory;sentences;scalable end;entire text;sequence component;structured storage;text;content;new qa system;symbolic representations;text size;questions;qa pair examples;encoding component;weak supervisions;schema;sequence;text auto;trainable system;knowledge store;babi;millions;scalability issue;edge storage;end"}, "6516b800482100731f0eb348f678ad30799c839f": {"ta_keywords": "distributional semantics paradigm;distributional semantics;distributional semantic analysis;semantic sparsity;neologisms;semantic neighbors;large diachronic corpora;new linguistic application;neology;semantic neighborhoods;new words;linguistic question;language change;language;sparsity;english;phenomenon;frequency growth rates;frequency growth;statistical analysis;internal factors;external factors;factors;process;case;importance;study;role", "pdf_keywords": "word emergence;neologisms;distributional semantics paradigm;distributional semantics;semantic neighborhood sparsity;semantic neighbors;semantic neighborhoods;semantic area;prior linguistic intuition;semantic sparsity;neology;new words;words;emergence;language;discourse;language change;frequency growth rates;external factors;factors;area;latter hypothesis;hypothesized factors;demand;re\ufb02ection;analyses;average frequency growth rate;importance;ideas;more support"}, "ac03cf22e2a831ab030ae33b5ddf5f9864917a17": {"ta_keywords": "acm sigai job fair;attendance;acm sigai job;aaai;popular event;resumes;recruiters;retrospective;job fair;event;students;other job seekers;year;companies;similar growth;event space;other representatives;hundreds;third installment;last several years;steady growth;number;team;public book", "pdf_keywords": ""}, "0a7f95adbaf0e46c93b5f82c74a26f5874c861ac": {"ta_keywords": "isolated traffic ramp metering problem;ramp metering;robust feedback control design;based hybrid model;dynamics model;godunov;weak solution shock;system parameters;parameter approximation;numerical scheme;controllers;rarefaction wave properties;model;approximation;uncertainties;uncertainty;system;detailed analysis;analysis;paper", "pdf_keywords": ""}, "c5e4eafd85949e6aac9d8e98d5e03b2acf444046": {"ta_keywords": "other adversarial datasets;adversarial data collection;adversarial data;question answering;challenging datasets;elicit incorrect predictions;datasets;questions;domain evaluation sets;examples;human workforce;models;diverse collection;workers;researchers;scale randomized study;results;model;study;variety;question;adc;real time;superficial patterns;scale;paper;loop;ii;efficacy;standard fashion", "pdf_keywords": "adversarial data collection;question answering;natural language inference;such diverse natural language processing;nlp;question samples;elicit incorrect predictions;nli;most questions;bert model;examples;sentiment analysis;researchers;popular benchmarks;spurious associations;crowdworkers;bert;questions;data;models;qa;incentive;tasks;particular dataset;results;guidance;type questions;key differences;electra;electrarandom"}, "575ac3f36e9fddeb258e2f639e26a6a7ec35160a": {"ta_keywords": "intermediate parsing;language parsing;universal dependencies treebanks;semantic lu;explicit syntactic knowledge;semantic natural language understanding;language modeling;shot language transfer experiments;lu tasks;downstream lu task performance;large neural models;monolingual english;transformer networks;syntax;downstream lu performance;neural models;transformers;transformer;representation spaces;training;context;intermediate target;lm;head;usefulness;questions;answers;ipt;tuning paradigm;self", "pdf_keywords": "downstream language understanding;supervised syntactic parsing bene\ufb01cial;language understanding tasks;downstream target languages;neural language models;semantic language understanding;treebanks;syntactic structures;english ud treebank;shot language transfer;multilingual transformers;semantic lu;traditional nlp;source language;language transfer settings;downstream \ufb01ne;english transformers;english;tasks;bert;transformer networks;context;usefulness;lm;xlmr;xlm;lu;data;theart;ipt"}, "b437cc7c0ae672b188df078b5dd80f97e8dde978": {"ta_keywords": "lexical units;lexical learning;lexical information;machine translation;language processing systems;natural language processing systems;speech recognition;unsupervised learning;human annotations;annotation bottleneck;speech;languages;agglutinative languages;words;annotated data;units;text;supervised systems;word;continuous speech;explicit white space delimiters;processing;fundamental unit;definition;models;analysis tools;streams;insights;addition;applications", "pdf_keywords": ""}, "69ba64b20d0a1849ef08d63c39bfafbaac909087": {"ta_keywords": "behavior constrained thompson sampling;online ai systems;online rewards;online exploration;constrained policy;behavioral constraints;novel online agent;exploitation;online learning;reward feedback;agent;ai systems;constraints;additional constraints;online setting;exogenous constraints;policy;ethical priorities;priorities;teacher agent;ethical principles;actions;decisions;daily life;regulations;observation;preferences;set;bcts;criteria", "pdf_keywords": ""}, "40bbd3046f1fa86a50e526b3848b4f2bd3a1d873": {"ta_keywords": "soluble lithium salt;o2 batteries;li anode;conventional electrolytes;perfluorinated polyelectrolyte;o2 battery;flammable polyelectrolyte solution;electrolyte;capacity li;lif;li;perfluorinated anion;perfluorinated backbone;nafion;low charge overpotential;performance li;large discharge capacity;conductivity;dendrite growth;concentration polarization;sulfonic group;ln;severe performance degradation;safe;excellent cycling performance;mah;practical applications;round performance improvement;rich sei;transfer number", "pdf_keywords": ""}, "059f515bf53bcddeca031fd4a4071c911999a3c6": {"ta_keywords": "invariant pedestrian representation;unsupervised apparel;invariant feature representation learning;invariant feature learning;different clothes;simulation gan;apparel;gan;deep learning methods;cloth;reid tasks;target cloth;reid performance;images;quality cctv videos;baseline models;reid;several datasets;viewpoint;many public datasets;same person;several baselines;performance;world;work;proposal;problem;aifl;rise;framework", "pdf_keywords": "discriminative feature;invariant feature learning;invariant pedestrian representation;invariant feature embeeding;different clothes;apparel;invariant feature;reid problem;reid performance;similar cloth cases;baseline models;images;different persons;contribution;threefold;framework;cases;aifl;same person;work;proposal;approach;sec;experimental results"}, "c96363c42bc8c465902c22b8c33c8704233f519e": {"ta_keywords": "code generation;multiple natural languages;theart code generation systems;natural language commands;new languages;multilingual dataset;english code;natural language challenge;code summarization;languages;programming languages;code pairs;english counterparts;english;benchmark;dataset;challenges;nl;conala;performance;difficulties;technology development;quantitative evaluation;gap;recent burgeoning;state;applications;intersection;methodology;systems", "pdf_keywords": "multilingual code generation;multiple natural languages;multilingual encoder;languagecomprehensive approaches;code synthesis;code generation;multilingual understanding;code intelligence;theart code generation systems;code models;code summarization;code snippets;natural language;programming languages;benchmark evaluation dataset;python code snippets;code snippet pairs;english;spanish;nl intent;intents;natural intents;benchmark;data benchmark;mconala dataset;russian;dataset;mconala;executable programs;resource"}, "70a321f12a655e305781e2de0ca9617d96e462c3": {"ta_keywords": "data market;aggregators;single central data aggregator;strategic data sources;multiple data aggregators;aggregator;nash equilibrium;nash equilibria;data;social optimum;high quality data;statistical estimation;competitive settings;competition;such estimates;much social welfare;game;anarchy;sources;users;interactions;aversion;preliminary model;more realistic models;recent research;price;collection;mechanisms;continuum;ways", "pdf_keywords": "data market;strategic data sources;data buyers;incentive mechanisms;incentives;pricing mechanisms;strategic buyers;nash equilibria;data sources;competitive outcomes;marketplace;competition;buyers;games;game;personal objectives;ef\ufb01ciency;outcomes;equity;mechanisms;outcome;behavior;conditions;social standpoint;many cases;model;numerical exercises;existence;future work;particular form"}, "bee52c51cbd37d0e48c3ea5f71a08f177d2aff73": {"ta_keywords": "online discriminative training method;adaptive regularization;multiclass classification;binary classification;phoneme conversion;efficient training;phoneme error rate;grapheme;weight vectors;overfitting;phoneme;aggressive weight update method;noisy data;margin infused relaxed algorithm;dataset;training time;outlier;conversion;g2p;addition;update rule;evaluation;mira;terms;current example;art approach;arow;approach;current state;problem", "pdf_keywords": ""}, "7129b62be18487db5e9602e353bb10a4c79a9b92": {"ta_keywords": "neural reverse engineering;executables;reverse engineering;diverse assembly code patterns;compiler optimizations;debug information;binaries;augmented control flow graphs;neural textual models;static analysis;procedure names;syntactic information;flow graph;cfg;call sites;evaluation;representations;structure;humans;predictions;target name;art;models;main idea;methods;control;novel approach;low amount;state;challenging problem", "pdf_keywords": ""}, "f4cf4246f3882aa6337e9c05d5675a3b8463a32e": {"ta_keywords": "visual language understanding models;language tasks;compositional tasks;action learning;language task datasets;natural language instructions;alfred tasks;egocentric vision;actions;action space;level language instructions;vision;language;household tasks;mapping;realistic environments;benchmark;coffee maker;level goals;research benchmarks;directives;alfred;mug;world applications;sequence length;sequences;significant room;baseline model;right;gap", "pdf_keywords": "visual language understanding models;robots;language tasks;egocentric vision;natural language instructions;language;interaction mask predictions;vision;agents;alfred;actions;interaction;new benchmark;benchmark;real world;navigation;environment dynamics;computer sci;simulation;community goal;significant room;sequences;gap;conclusions;baseline model"}, "8f11643b42976433fc3a2ec19feef486929527a1": {"ta_keywords": "argument mining;proceedings;5th workshop", "pdf_keywords": ""}, "d9e56aa9f69e18c9d37799b86b50d36709cbf711": {"ta_keywords": "hypatia referees;ami bar;thanks;jones bat", "pdf_keywords": ""}, "59a228f48a83eb0905391f7e454fde0eeb6680ee": {"ta_keywords": "automatic speech recognition;phoneme lattices;finite state transducers;language model;only continuous speech;continuous speech;learned vocabulary;learned model;asr phoneme error rates;acoustic model;lexical units;principled learning algorithm;lattice input;gibbs;linguistic constraints;speech demonstrate;learning problem;lms;statistical framework;lm;asr;training;complexity;expressive power;simple handling;implementation;adult;use;size;wfsts", "pdf_keywords": ""}, "8b7a8f9a27b8dc73a5b0b62ada14bbab047084fc": {"ta_keywords": "silent speech enhancement;silent speech interface;speech enhancement systems;statistical voice conversion;electrolaryngeal speech enhancement;audible speech;whispered voice;natural voice;electrolaryngeal speech;digital signal processor;digital signal processor implementation;conversion accuracy;computational cost;dsp;vc;time vc;devices;practical use;implementation;nam;promising approaches;computational resources;sufficient computational resources;several methods;time;paper;situations;problem", "pdf_keywords": ""}, "4100256a125d7b56cac693a436bba2b00fae3fa3": {"ta_keywords": "audio captioning;audiocaps datasets;audio neural networks;audioset;audio samples;natural language descriptions;model training;encoder;transformer decoder;art asr techniques;clotho dataset;acoustic signals;model;auxiliary input;panns;convolution;model architecture comprises;evaluation splits;conformer;end;transformer;tags;task;clotho;end manner;validation;paper;state;work;limited availability", "pdf_keywords": ""}, "306c59458cebb35c2d520dd129f09d5c6cc2985f": {"ta_keywords": "compositional paraphrase model;paraphrase database;erratum;acknowledgements;authors;correction;list", "pdf_keywords": "parametric paraphrase models;paraphrase tasks;short paraphrases;paraphrase;phrase pairs;nlp community;embeddings;art word embeddings;hyperparameters;rnn composition;ppdb;paragram vectors;compositional models;phrase;recursive neural network;rnn;models;new datasets;datasets;other downstream tasks;tables;batch size;epochs;results;sl999;gap;performance;coverage;\u03bbww;internal scores"}, "bba9b93ab8d9b98cd54001a5ba9673e513a35219": {"ta_keywords": "lstm;recurrent neural networks;lstms;rnns;simple lstm network;medical data;clinical data;electronic health record;sequence data;term memory;raw time series;multilayer perceptron;multivariate time series;diagnoses;patient visit;models;sensor data;data;clinical measurements;patterns;multilabel classification;several strong baselines;long short;features;metrics;popular models;patient;model;episode;irregular sampling", "pdf_keywords": ""}, "cc352ea39f820c3effc40ce09369cf59afe361df": {"ta_keywords": "cloud services;cloud computing environment;telemedicine practice system;cloud;azure cloud;ict systems;communication technologies ict;software platforms;automatic management storage;medical practice;automation;efficient resource utilization;physical computers;high administrative overheads;systems;house client;such applications;energy consumption;processing;dedicated networks;demand scalability;archiving;implementation;traditional paper;costs;stovepipes;many serious limitations;paper;experience;approach", "pdf_keywords": "electronic health;cloud services;cloud computing environment;cloud computing;telemedicine practice system;public cloud platform;ict systems;medical practice management system;healthcare applications;virtualised cloud computing environment;cloud;windows azure cloud computing platform;azure cloud;traditional ict;microsoft azure;service;azure;automation;software platforms;server;windows azure;automatic management;medical practice;technology;physical computers;communication technologies;efficient resource utilization;applications;application;deployments"}, "589e651c69251ee20a89e075d015eb03b35cf17d": {"ta_keywords": "speech encoder;speech translation;competitive translation quality;fast inference speed;encoder;decoder architecture;inference speed;decoders;novel nar e2e;benchmarks;translation;e2e;nar;better translation;text;art ar e2e;speed;negligible overhead;large length beam;models;conditional dependencies;various length candidates;target tokens;st systems;st;orthros;ar;st framework;end;parallel", "pdf_keywords": "nar decoder;speech encoder;dual decoders;ar decoder;encoder;novel nar e2e;best nar e2e model;ar decoders;decoders;uni\ufb01ed nar;nar;inference latency;e2e;translation;text;inference;st task;conditional dependencies;art ar transformer model;target tokens;st framework;ar;better candidate;parallel;speed;recent progress;bleu score;orthros;st;framework"}, "d5123ab81f511027cbe11dc92d99e116fd193158": {"ta_keywords": "single energy harvesting source node;energy harvesting;infinite horizon markov decision process theory;optimal source node;remote sensing;remote sensing setting;instantaneous channel quality;available energy;channel probe outcome;probed channel state;discrete time instant;energy;discrete time instants;threshold policy;minimization;decision variables;wireless link;information;time;instantaneous age;data;process;multiple processes;sink node;aoi;eh node;eh source;source;scenario;age", "pdf_keywords": "single energy harvesting source node;energy harvesting;aoi minimization;aoi minimization problem;power selection;optimal source node;available energy;in\ufb01nite horizon markov decision process theory;harvesting source;packet transmit energy;average aoi expression;remote sensing setting;transmission scheduling;energy;optimal policy structures;minimization;remote sensing;\ufb01nite battery capacity;minimal age policy;threshold policy;average aoi;aoi;single source eh server;sampling;hop network;decision variables;discrete time instants;instantaneous channel quality;instantaneous age;in\ufb01nite time horizon"}, "ddfd297531f56121b8383bd1eb2bb09189ab2e2b": {"ta_keywords": "emphasis translation task;speech translation systems;emphasis transfer;attentional neural network models;speech translation;traditional speech translation systems;lstm;emphasis values;continuous emphasis values;emphasis;paralinguistic information;term memory;attention mechanism;neural networks;target sentence;word alignments;linguistic content;languages;recent focus;hard;distance dependencies;subjective evaluation;objective evaluation;model;source;new model;significant improvement;information;art model;paper", "pdf_keywords": ""}, "f0a498014c4ef67c0b72ceb18d95e0d25087fd57": {"ta_keywords": "neural machine translation;neural machine translation systems;japanese bidirectional translation tasks;softmax;binary code prediction;binary code;bleu scores;vocabulary size;output layer;memory requirements;memory usage;computation time;x10;models;speed;cpus;x5;word;order;paper;new method;method;best case;experiments", "pdf_keywords": "neural machine translation models;binary code prediction;binary codes;binary code;binary representation;softmax;output words;convolutional error;nmt system;bit array;output layer;memory requirements;viterbi;codes;mistakes;representation;model improvements;robustness;hybrid prediction model;correct word;vocabulary size;algorithm;word;model;addition;error;computation time;redundancy;face;method"}, "88e2beccbc89b3e3dd793e2502b17c1fa551151d": {"ta_keywords": "storage;bandwidth point;node stores;node;repair;network;data;codes;minimum;units;tradeoff;amount;subset", "pdf_keywords": ""}, "f4c8539bed600c9c652aba76a996b8188761d3fe": {"ta_keywords": "neural machine translation;nmt implementations;basic nmt models;improvements;algorithmic improvements;task systems;stronger baselines;language;stronger experimental systems;vanilla systems;baseline;higher bleu scores;new techniques;inherent weaknesses;new research;techniques;vanilla;several other techniques;literature;effectiveness;context;experimental conclusions;data scenarios;specific methods;work;significant gains;interest;relative gains;state;art production", "pdf_keywords": "adam training;nmt systems;byte pair encoding;training approach;adam;vanilla nmt;rate annealing;ensembles;models;phrase extraction;bleu scores;substantial improvement;bleu;stronger systems;key weaknesses;model;techniques;speci\ufb01c techniques;step size annealing;multiple restarts;system extensions;reliability;data;experimental results;depth;effectiveness;other types;independent model;step size;technique"}, "3e3254bce9c321310d2e9825ed52b30da9879173": {"ta_keywords": "utterance classification experiments;speaker adaptation experiments;speech segments;speech segment;asr decoder;weighted finite state transducer;gram networks;dependent hmm topologies;new feature representation;word features;decoder outputs;wfst decoder output;boa representation;asr;finite state machine;boa;features;output;counts;lexicons;bag;search network;wfst networks;wfst;additional overhead;arcs;algorithms;wer;addition;change", "pdf_keywords": ""}, "285c50d98dab741a82649b1abcaca8273cb8f253": {"ta_keywords": "online discriminative training method;adaptive regularization;phoneme conversion;binary classification;multiclass classification;structured learning problem;margin infused relaxed algorithm;grapheme;overfitting;weight vectors;phoneme error rate;phoneme;noisy data;dataset;g2p conversion;aggressive weight update method;conversion;training time;g2p;outlier;evaluation;paper;terms;current example;art approach;mira;approach;arow;current state;problem", "pdf_keywords": ""}, "55bdc4ad158e272ccf796ae52b0ab7086a834352": {"ta_keywords": "tutoring systems;student modeling;student models;student model;good student model;student behavior patterns;instructional decisions;student;important instructional implications;such models;model;task difficulty;agent;better instruction;manual construction;useful information;simstudent;art machine;problems;paper;substantial human effort;content;related problems;approach;errors;probability;key factors;transfer;state;distinctions", "pdf_keywords": ""}, "c3177616ad35ef7850ea1e62da1fa3be36943e8b": {"ta_keywords": "recursive neural network paraphrase identification;dialog retrieval;word representations;dialog;recursive autoencoders;sentences;user input query;representations;vocabulary;oov;example matching;words;example;sentence;database queries;oov cases;recursive structure;dynamic pooling;pair database;arbitrary length;interactions;potential;same meaning;handling;confusion;approach;inadequate handling;weakness", "pdf_keywords": ""}, "49a049dc85e2380dde80501a984878341dd8efdf": {"ta_keywords": "speech representations;speech audio;speech input;latent representations;learning;speech;powerful representations;latent space;quantization;librispeech;contrastive task;data;outperforms;hour subset;tuning;other test sets;wer;self;hour;previous state;first time;amount;framework;experiments;times;art;masks", "pdf_keywords": "latent speech representations;speech representations;speech audio;approach encodes speech audio;contextualized representations;latent representations;raw audio data;representations;speech;layer convolutional neural network;language modeling;contrastive loss;contrastive task;powerful representations;raw waveform;context network input;distractors;learning;true latent;masks spans;facebook ai;alexei baevski;michael auli;model;transformer network;targets;henry zhou;abdelrahman mohamed;self;conclusion"}, "5f1bbc96a22a630d3662b3fceb3160091e4bd814": {"ta_keywords": "robust voice activity detection;voice activity detection;noisy speech signals;gaussian weights;weight normalization;noise gmms;kalman filter;gaussian;estimation method;silence;noise;observed signal;clean gmms;gmms;models;gmm;distributions;optimality;frame;model;vad;paper;method;previous work;local characteristics;characteristics", "pdf_keywords": ""}, "bf0105bdd5b0dfc09580697739fb84590d031d0b": {"ta_keywords": "cognitive tutor authoring tools;simulated student;cognitive skills;cognitive model;human students;classroom experiments;simstudent;real students data;real students;agent;testing;demonstration;training;demonstrations;steps;tool;log;machine;ctat;solutions;applicability;such data;building block;problems;authors;group;problem;hand", "pdf_keywords": ""}, "8ec127925a8680928d546df7248963e772e07a5d": {"ta_keywords": "optimal employer policy;traditional economics papers address screening models;job candidates;employers;multiple tests;tests;worker skill;interviews;efficient candidate;dynamic policy;subject candidates;employer;further tests;candidate;previous tests;single noisy signal;same decision rule;fairness;other noisy signals;noise levels;skill level;worker;same outcomes;groups;skill;results;fundamental impossibility;implications;same number;number", "pdf_keywords": "multiple tests;optimal employer policy;higher false positive rates;allocated tests;tests;threshold policy;further tests;previous tests;job candidates;test;greedy policy;speci\ufb01ed false positive rate;dynamic policy;candidates;same decision rule;same outcomes;subject candidates;candidate;policymakers;fairness;employers;policies;groups;regulatory body;e\ufb03cient candidate;hire;employer;skill level;noise levels;fundamental impossibility"}, "a34954d9e36ea6c57743f55124a6ae444b951c2c": {"ta_keywords": "training points;training point;deep neural networks;neural network;representer points;excitatory training points;deep neural network;test point prediction;representer point selection;deeper understanding;positive representer values;representer values;weights;activations;inhibitory points;predictions;point influence;training set;network;importance;negative values;parameters;more insight;set;linear combination", "pdf_keywords": "deep neural networks;training point activations;deep neural network;learned parameter;neural network;representer values;modi\ufb01ed representer theorem;weights;representer points;machine learning models;activations;particular prediction;training examples;prediction;training points;training point;importance;activation;model;scale models;image datasets;experts;network;parameters;clear understanding;linear combination;values;value;discussion;sum"}, "ce4eadb324026191c075f1af876403a847329d5b": {"ta_keywords": "feature vectors;text categorization problems;featurevector representation;many decision tree;feature vector;nominal features size;features;most learning systems examples;feature;setvalued feature color;strings;nominal values;algorithms;world learning problems;order representations;black dog;value;set;example;rule;length;species;components;extension;real numbers;instance;problems;size", "pdf_keywords": ""}, "63bc09c11a792abfcbb2d9e2809aa67929f09262": {"ta_keywords": "distributional semantics;word embeddings;semantic relations;word subsumption projections;various natural language processing tasks;russian language;hyponymy;hypernym projections;tensorflow machine learning framework;common sense reasoning;hypernymy;hyponym;words;relations;subsumptions;gpus;open source software;popularisation;significant attention;cpus;experiments;series", "pdf_keywords": ""}, "cfb1b39d1a6733f42cc5e8cfd60dc68cafa01d28": {"ta_keywords": "adequate multimodal representations;natural language processing;nlp;modal content;machine translation;structured prediction tasks;resource languages;deep learning;language;directed research;machine learning phd level;machine learning methods;neural networks;advanced multi;cgpa;algorithms;coursework;professor chris dyer;objective;research area;advisor;professors noah smith;introduction;graham neubig;statistics", "pdf_keywords": ""}, "2b110fce160468eb179b6c43ea27e098757a56dd": {"ta_keywords": "controlled paraphrase networks;paraphrase networks;adversarial example generation;paraphrase systems;paraphrase quality;paraphrases;adversarial examples;paraphrase;syntactic transformations;constituency parse;parser;syntactic form;syntax;human evaluations;backtranslation;training data;sentence;scpns;task;target;large scale;baseline;target specifications;combination;process", "pdf_keywords": "uncontrolled paraphrase generation systems;paraphrase generation;paraphrase quality;paraphrases;syntactic variation;adversarial examples;neural encoder;parser;paraphrase;constituency parse;decoder models;syntactic modi\ufb01cations;syntactic template;lexical variation;syntactic form;neural backtranslation;encoder;syntax;decoder model;training data;sentence;scpn;input;human evaluations;target speci\ufb01cations;transformations;data;model;target;\ufb01rst learning approach"}, "cf0860ab99c63cb7cbd5317fca7cf1fe70e8fb63": {"ta_keywords": "knowledge bases;virtual knowledge base;natural language inputs;contextual representations;textual data;corpus;index mention encoder;maximum inner product search;neural module;text;mentions;entities;virtual kb;kb;drkit;hop questions;metaqa;task;relations;special index;points;step;matrix tfidf indices;accuracy;gradient;gap;negative examples;paths;end;module", "pdf_keywords": "virtual knowledge base;large text corpus;contextual representations;corpus;textual data;natural language questions;maximum inner product search;entities;complex qa;google research;neural module;query;special index;relations;task;metaqa;kb;hop case;mentions;iclr;step;differentiable reasoning;abstract;gneubig;paths;conference paper;graham neubig1;drkit;ef\ufb01cient;manzilzaheer"}, "024091a3c0223f27d6456b1a27db18fb08d41e5a": {"ta_keywords": "binarized neural network joint model;machine translation accuracy;machine translation;neural network language model;contrastive estimation;binary classifier;bnnjm;nnjm;nnlm;neural network;large vocabularies;word source context window;high normalization cost;mle;joint model;standard maximum likelihood estimation;words;context;nce;input;noise;alternative;computation cost;paper;large gains;problems", "pdf_keywords": ""}, "629323c5b9f7c64afac9300212538e488569bd1e": {"ta_keywords": "synonym dictionaries;ontology induction;ontology induction approach;structured lexical knowledge;semantic relations;word embeddings;dictionaries;projections;structures;paper", "pdf_keywords": ""}, "33aa6c70eac0e4b7eb28d8386e5e4113fdd55203": {"ta_keywords": "choice question answering system;modular automatic question;world history entrance exam;qa;answer choice;uima;english questions;cmu;veriable assertions;testing set;lab;context;specic instructions;system;training set;question;phase", "pdf_keywords": ""}, "2e820673ca861a9ece8d36f2b93793b5d2c7e1da": {"ta_keywords": "lightweight block ciphers;advanced encryption standard;current cryptanalysis;aes;nsa;speck families;implementation results;us national security agency;algorithms;design rationale;simon;applications;constrained environments;paper;aid", "pdf_keywords": ""}, "49d415cf593be38c6cd97a183dadc7d7b48bab72": {"ta_keywords": "faster employment growth;faster revenue growth;firm growth;ai;industries;firms;firm labor demand;firm wage inequality;productivity;innovations;labor demand;artificial intelligence;labor;capabilities;data;new era;decades;evidence;machine;reshape demand;event study;impact;algorithms;worker;degree;text;output;challenge;combination;disappointment", "pdf_keywords": ""}, "2225950d1d3e02bc0d88a0c78325d00e0122b576": {"ta_keywords": "speech separation;speech separation methods;multiple simultaneous speech signals;separation;automatic speech recognition;deep learning;deep clustering address;speech signals;joint training framework;deep learning system;deep network methods;transcriptions;large scale training;isolation;mixed signals;recognition;mixed data;training;end;tighter integration;wide range;asr;challenging cocktail;components;additional benefit;door;data;tasks;realistic data;modules", "pdf_keywords": ""}, "05fb5a180214bf092eeda30baf9f16fb6bd15727": {"ta_keywords": "speech parameter sequence;duration correction;dynamic time warping;waveform modification;native speech;direct waveform modification;temporal warping;durational patterns;speech;english speech;japanese;modulation spectrum;quality degradation;synthesis process;dtw;evaluation;spectral parameters;analysis;experimental evaluation;segments;quality;use;method;reference;typical approaches;approach;report", "pdf_keywords": ""}, "649c1148439a4e875dab414ba67bf8c80350af4a": {"ta_keywords": "neural abstract syntax parser;neural semantic parser;abstract syntax description language;semantic parsing;new abstract syntax description;formal meaning representations;natural language;code generation;syntax;tranx;transition;information flow;transition system;nl;new types;target mr;output space;mr;mrs;allowable structures;information;model;major advantages", "pdf_keywords": "semantic parsing;abstract syntax parser;asdl grammar;code generation;grammars;intermediate meaning representation;dependent grammar;generalization ability tranx;neural networks;tranx;ast;asn;django;asts;modular architecture;transition;geo;atis;datasets;tasks;wikisql;task;speci\ufb01cities;mind;construct;strong performance;procedure;purpose;process;system"}, "86d84c1c9b0a500f930696ab27c83a4b30477560": {"ta_keywords": "paraphrastic sentence embeddings;phrase corpora;lingual tasks;para;art baselines;bitext;intermediate step;orders;model;outperforms;complex state;time;magnitude;methodology", "pdf_keywords": "monolingual similarity;bilingual sentence representations;large bilingual corpora;english paraphrastic representations;many language pairs;parallel corpora mining;paraphrase datasets;parallel sentence pairs;language pair;related languages;encode sentences hundreds;english datasets;opensubtitles corpus;languages;random encoders;representations;task;epochs;en;average sts performance;sts;bitext;fact;best results;performance;lison;sp overlap10;models;work;art results"}, "65c53ed3575e160eb1e7d0a516353ba52de7e7e5": {"ta_keywords": "bid leakage detection;russian procurement auctions;bid leakage;particular auction;specific auction;auctions;bidders;bid;unlabeled classification;direct classification;winners;participants;sample;positive;lower price fall;posterior probability;prior probability;data;deadline;higher reserve price;key idea;lower number;last hour;problem", "pdf_keywords": "russian procurement auctions;bid auctions;bid auction;auctions;bid leakage;earlier auctions;bids;auctioneer;public procurement;russian requests;russia;stealed;leakage;opponents;corrupt scheme;participants;rubles;procurer;price;higher reserve price;data;high number;dataset;participant;nov;annual gdp;annual total volume;probability;winner;third"}, "a9e6222e71dd101d444b7192b3a0636c71edb0a4": {"ta_keywords": "contextual representations;knowledge bases;natural language inputs;contextual representation encoder;virtual knowledge base;textual data;corpus;neural module;maximum inner product search;mentions;text;entities;kb;task;metaqa;negative examples;hop questions;relations;points;special index;matrix tfidf indices;drkit;step;gradient;accuracy;gap;module;paths;end;combination", "pdf_keywords": ""}, "6536f36648d39f0f9f6105562f76704fcc0b19e8": {"ta_keywords": "persistent spatial semantic representation;persistent spatial semantic representation method;level natural language instruction execution;robotic agents;robot actions;persistent representations;hierarchical reasoning;agent;natural language;expressive interface;term tasks;long execution horizons;language;alfred benchmark;art results;step;step instructions;state;approach;key;gap", "pdf_keywords": "spatial semantic representation;persistent spatial semantic representation;mobile manipulation tasks;natural language task descriptions;hierarchical language;spatial representation;mobile manipulation task;robot observations;mobile manipulation actions;interactive 3d environment;natural language instructions;modular representation learning approach;spatial model;challenging instruction;actions;horizon tasks;term memory;3d environment;detailed sequential instructions;hierarchical approach;hierarchical model;level;world;art performance;alfred benchmark;figure;paper;discussion;limitations;state"}, "2c0f2a03c3a427cc61359b5e2c31cfefe9850a31": {"ta_keywords": "domain information extraction method;html corpus;concept names;large corpus;concept;instance pairs;hearst patterns;html tables;similar terms;several datasets;clusters;terms;novel approach;method;large numbers;earlier approaches;contrast;problem;experimental results", "pdf_keywords": "term clusters;html corpus;novel clustering method;agglomerative clustering algorithms;large corpora;domain information extraction technique;rich corpora;clustering algorithm;cluster purity;instance pairs;html tables;instances;concept;terms;table columns;coordinate terms;table;candidate concept;triplets;time complexity;rand index;fm index;means;pasca method;method;new method;van durme;approach;coordinate;precise coordinate"}, "ed2cc779c7eb0004bd6dd50538a2cafca092c94f": {"ta_keywords": "spelling normalization;historical language data;historical german texts;linguistic annotation;automatic normalization;historical texts;speech taggers;normalization;pos tagging;historical data;punctuation marks;modern part;data;word;processing;task;set;techniques;paper;regard;character;different methods;specific problems;chain combination", "pdf_keywords": ""}, "5bcd9117899bc2c91db83532dcf587b9d8f8888b": {"ta_keywords": "federal judiciary;supreme court opinions;casebook;constitutional provision;concise edition;wield book;certain topics;historical note material;federalism;unabridged edition;other primary documents;law;aspects;freedom;free speech;pages;raw case;teachers;equal protection;students;own generalizations;separation;due process;text;religion;role;powers;materials;own ways;course", "pdf_keywords": ""}, "3d1cfefdbe40f7535ada772c260c192bb63bb9fe": {"ta_keywords": "new scienti\ufb01c document similarity model;grained scientific document similarity;textual supervision;aspect matching;close paper relatedness;sparse multiple matches;textual descriptions;textual guidance;texts;single aspects;aspects;documents;multiple papers;papers;sentences;earth mover;tors correspond;text;level aspects;distance;sentence;fast method;\ufb01ne;optimal transport mechanism;source;novel form;methods;supervision;model;fine", "pdf_keywords": "grained scienti\ufb01c document similarity;new scienti\ufb01c document similarity model;textual supervision;document similarity;documentlevel similarity;aspect matching;contextualized sentence embeddings;textual guidance;sparse multiple matches;single aspects;aspects;sentences;texts;paper abstracts;aspect;documents;text;level aspects;multiple papers;sentence;vectors;papers;tom;paper;fast method;earth mover;terms;level matches;source;1university"}, "5e74d4e041a25e7752a596e2891975df5ba65aa2": {"ta_keywords": "channel mask prediction networks;speech recognition accuracies;improved mvdr beamforming;speech recognition word error rates;mask prediction;important beamforming method;speech recognition purposes;microphones;covariance prediction;minimum variance distortionless response;speech;spatial covariance estimates;single mask;masks;noise;background noise;mismatched training condition;mvdr;minima;steering vector;level quality measures;performance;reliable way;single;high level;best result;terms;various ways;yields;recent studies", "pdf_keywords": ""}, "a0ab4106dabd6bc067c7b3e4db06807e2c0f6036": {"ta_keywords": "many nlp tasks;efficient learning framework tlm;large general corpus;language models;general corpus;language modeling objective;tlm;classification datasets;task data;scale pretraining1;task;training flops;queries;strong performance;results;tiny subset;domains;scratch;orders;standard approach;magnitude", "pdf_keywords": "large general corpus;training corpus;language modeling objective;entire general corpus;general corpus;corpus;language model;joint learning;recurrent ai;task data;task objective;data selection;scale pretraining;lm objective;encoder;tlm;framework tlm;ef\ufb01cient framework;movies;task;model;comparable results;retrieved data;small scale;relevant data;bert;tiny subset;interdisciplinary information sciences;queries;lucas"}, "a4f2e6c38454c9e7b4068a456813d622b91f2663": {"ta_keywords": "speech diadochokinetic;ddk rate measurement;ddk rate calculation;ddk rate;ddk measurement;routine clinical assessment;ddk;rates;substantial differences;methodological problems;data;calculation;studies;differences;data collection;such differences;norms;type;methods;detailed protocol", "pdf_keywords": ""}, "d408be961d0db8b97c0ca6b2fc7afd3c9dc914e7": {"ta_keywords": "available mobility options;mobility providers;new mobility modes;transportation management platforms;art mobility planning applications;open trip planner;transportation demand management policies;microservices;new routing algorithms;commuters;modularity;manageability;communities;platforms;community stakeholders;monolithic applications;extensibility;guidelines;patterns;policies;system;societal relevance;paper;principles;future practitioners;update;state;ability;critical properties;field", "pdf_keywords": ""}, "4fe70c172cc38c2eb15103f0f1eac4e6766c60e6": {"ta_keywords": "robust voice activity detection;weight normalization;estimation method;gaussian;noise;frame", "pdf_keywords": ""}, "efe9fe804f34b18524708b18293508191bda78eb": {"ta_keywords": "static scheduling;redundant hardware;permanent faults;reactive tmr;deactivate faulty components;cores;dynamic task;tmr;high power consumption;redundancy;tasks;baseline tmr;fault;efficiency;separate executions;reliability;energy consumption;energy;efficient approach;faulty execution;novel energy;management;severe detriment;detailed evaluation;same program;proposal;work;key idea;operations;stages", "pdf_keywords": ""}, "395044a2e3f5624b2471fb28826e7dbb1009356e": {"ta_keywords": "paraphrastic sentence embeddings;universal sentence embeddings;sentence embeddings;paraphrase database;textual similarity datasets;lstm;term memory;compositional architectures;supervised tasks;neural networks;training data;new baseline;black box feature extractor;complex architectures;resources;domain data;supervision;prior;purpose;other domains;further work;hope;wide range;research community;same distribution;problem", "pdf_keywords": "universal sentence embeddings;universal paraphrastic sentence embeddings;paraphrastic sentence embeddings;textual similarity datasets;embeddings;paraphrase database;arbitrary word sequences;compositional models;learned models;noisy phrase pairs;sentences;compositional architectures;representations;neural networks;regularization;training data;other models;high cosine similarity;similar meaning;tasks;ppdb;new baseline;model;ef\ufb01cient;natural questions;abstract;other domains;domains;il;iclr"}, "14551d2bf2584bb1ea7ad69f9a64419bab82bb6e": {"ta_keywords": "sound event detection;sound event class;sound events;background sound;audio data;data augmentation;cnns;global features;convolution;event;local features;foreground;sounds;transformer;macro f1 score;conformer;global information;validation set;addition;local information;method;baseline method score;performance;single architecture;paper;novel architecture;sed;various types;experimental results;various characteristics", "pdf_keywords": ""}, "469ad889bd628e2cf46424f7097c4830719ec740": {"ta_keywords": "automatic vowel space estimates;vowel space area;vowel space representations;vowel space;f2 vowel space;vowels;vowel;point vowels;talker intelligibility;pronunciation;talker;intelligibility scoring;dependent intelligibility differences;significant talker;pitch range;automatic estimation;individual intelligibility;intelligibility;better predictors;rhythmic patterns;variability;low dimensional space;feature;large scale analysis;approximate convex hull sampling;improved performance;measurements;several dimensions;correlations;space expansion", "pdf_keywords": ""}, "d9944e13a38e5ca685985c9b5c050ec6d300e104": {"ta_keywords": "interactive multimedia application", "pdf_keywords": ""}, "ba602ea9aaecab5a3ad243211f110ae7db4cc66a": {"ta_keywords": "performative risk minimization;risk minimization;risk minimizers;strategic classification;performative prediction;performative risk;classifier;applicant pool;multiple local minimizers;gradient flows;performative alignment;term behavior;algorithms;data distribution;real world situations;term;mapping;dependent distributions;current employee demographics;policies;example;trajectories;loop behavior;various equilibria;convergence;initial demographics;general properties;notion;decision;attraction", "pdf_keywords": ""}, "ef6a4d8bf248944ca1d0cfdc107d3bb107f57bff": {"ta_keywords": "\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "6c68866e6486923d2e8b999de57d450c9d4febab": {"ta_keywords": "neural machine translation;traditional statistical machine translation;machine translation;nmt output;translation rule table;nmt;nmt outputs;decoding;standard phrase;smt model;pbmt;smt;traditional smt;phrase;search space;cost;main challenge;fluency;sake;algorithm;advantages;method;approach;adequacy", "pdf_keywords": ""}, "c2b22a18ea2ed444c6c1f5bb27ab55bda2b44567": {"ta_keywords": "emphasis speech translation;emphasis transfer;attentional neural network models;traditional speech translation systems;speech translation;paralinguistic information;conditional random fields;neural networks;new model;task;crfs;paper;recent work;approach", "pdf_keywords": ""}, "b799d66c710dd82a1b925b9c31e55a0d2d99b624": {"ta_keywords": "hidden markov model;urban dynamics;life mobility dataset;rich urban dynamics;urban states;urban space;human activities;activities;whole city;temporal dynamics;general hmm;interests;state;people;semantics;population;sshmm;crucial socio;region;economic task;pois;type;different time slots;point;suitable methods;volume;scale;method;functions;results", "pdf_keywords": ""}, "0c39c0dc296a902e4a5eb85182209f7b9e6053b0": {"ta_keywords": "various dynamic nn architectures;recent deep learning;dataflow graph construction;dynamic nns;dynamic dl models;dynamic network structure;tensorflow fold;dataflow;static vertex function;dynamic models;vertex;dynamic ones;dynamic instance;dynamic declaration;programming models;memory management strategies;batching;backpropagation;static network;network structure;graphs;training;models;dl;example;processing;centric programming interface;trees;dynet;specific graph", "pdf_keywords": "deep architectures;deep learning;various dynamic nn architectures;dynamic nns;tensorflow fold;static graph optimization techniques;vertexcentric programming interface;expensive graph construction;dynamic dl models;dynamic network structure;neural networks;nns;batching;memory management strategies;backpropagation;batched execution opportunities;dynamic instance;optimization strategies;different graphs;training;dl;new programming interface;tasks;dependencies;dynet;art frameworks;order;use;cavs;challenges"}, "57026b2d45fa59c6326b5a1d2e27626403f083ba": {"ta_keywords": "alone artificial intelligence ethics course;ai ethics;ai educators;ai courses;ethics;general artificial intelligence course;artificial intelligence practitioners;artificial intelligence;philosophical issues;curriculum;many educators;instructors;students;philosophical impacts;practical case studies;society;resources;links;concrete suggestions;interest;article;use;recent surge", "pdf_keywords": "ai ethics;ai educators;term ai;alone arti\ufb01cial intelligence ethics course;autonomous decision maker;ais;general arti\ufb01cial intelligence course;software agents;intelligence;robots;basic ethical perspectives;machine learning case studies;skynet;tasks;decisions;mind;resources;discourse;case studies;viewpoints;practical case studies;topics;daily lives;action;ultimate goal;social world;economy;article;links;concrete suggestions"}, "653add540adae12491fade7e18ec4e1e4288b4a7": {"ta_keywords": "course selection;career paths;course planning;advisor relationship;support software tools;colleges;undergraduates;support tool;student;students;multiple majors;large state university;lessons;surveys;decision;detailed questions;preferences;terms;theoretic;person", "pdf_keywords": "computer programming course;students;student relationship;advisors;good advisors;computer science;attitudes;future courses;explanation system;advisor;college system;past students;subjective analysis;semesters;colleges;responses;personal attention;deep understanding;university;engineering;multiple majors;\ufb01rst course;surveys;arguments;support system;framing;situation;creative problem;introduction;cs group"}, "6fe62b967376361d7cd55e1033ab968895841d67": {"ta_keywords": "interpretable deep learning text mining algorithm;focused concept miner;concept discovery;blackbox classifiers;concept diversity;unique concepts;concepts;higher recall;higher interpretability;interpretable benchmarks;interpretability;concept;training data;corpus;superior predictive performance;neural network model;interpretable baselines;reviews;text data;level concepts;competitive predictive performance;coherent corpus;level insights;online newsgroups;fcm;product quality;accuracy trade;crowdfunding platform;online purchases;dataset", "pdf_keywords": ""}, "29001ac04e61dfffb8e24ffd3e351ece12ce44af": {"ta_keywords": "speech enhancement;independent speaker separation;phase mask;phasebook layers;phase estimation;source separation systems;frequency masks;channel speaker;additional phase reconstruction steps;deep learning;convex softmax activation;phase;mixture signal;mask;frequency representation;magnitude estimation;mixture;art mask;classical sigmoidal units;phase wrapping issues;domain signal;layers;corpus;target source;2mix dataset;magbook layers;complex time;magnitude;estimate;discrete representations", "pdf_keywords": "independent speaker separation;various complex mask representations;channel speaker;frequency masks;magnitude mask;convex softmax activation;softmax layer;convex softmax activation function;corpus;various magnitude representations;theart mask;magnitude codebook;2mix dataset;additional phase reconstruction steps;discrete representations;complex codebook;phase;magnitude;complex time;layers;factorization;target interval;alternate representation;continuous representation;values;performance;interval;state;combination;combook"}, "5dce0fd43a21825bebd8121fd0a28155d524c44c": {"ta_keywords": "", "pdf_keywords": ""}, "4b2d583e22f378f9104814d9f63cda411ddd5825": {"ta_keywords": "linguistic knowledge bases;sememe prediction;minimum semantic units;dimensional semantic space;many nlp tasks;other languages;human languages;sememes;sememe;most languages;words;world datasets;important knowledge sources;model correlations;baseline methods;task;model;novel framework;significant improvements;experimental results", "pdf_keywords": ""}, "f1513d72cb5dd6d70541cce0da36b77467128d13": {"ta_keywords": "entrance exam pilot task;minimum error rate training;qa4mre;threshold;model;questions;mert;certainty;weights;main task;score;clef;nara institute;science;system;paper;novel method;core;addition", "pdf_keywords": ""}, "838fbfd9066dbbac6c10059c5b183046fb1cd9d1": {"ta_keywords": "deep bayesian active learning;bayesian active learning;deep active learning;active learning;natural language processing;deep learning;supervised learning;bayes;uncertainty estimates;empirical study;multiple tasks;multiple datasets;multiple models;data dependence;dropout;validation;several recent papers;acquisition functions;al;backprop;scale empirical study;results;model;world problems;open question;full suite;al affords;disagreement;applicability;paper", "pdf_keywords": "deep active learning;bayesian active learning;active learning;entity recognition;semantic role labeling;various annotation budgets;deep learning;nlp;sentiment classi\ufb01cation;srl tasks;dataset;multiple tasks;ner;active;multiple datasets;models;uncertainty estimates;bayes;acquisition functions;multiple models;various acquisition functions;empirical study;figures;results;dropout;model;acquisition function;srl;data requirements;performance"}, "5693c74eb8ffde1490ba480fdc963f008243906a": {"ta_keywords": "crowd annotation framework;crowd annotations;sequence tagging;data annotation framework;rapid tagging;active intelligent recommendation;sequence labeling tasks;new annotations;annotations;automatic crowd consolidation;active learning;multiple annotators;entity recognition;active learned model;informative unlabeled instances;auto;sequence;ner;models;alpacatag;inconsistent labels;source web;tasks;recommendations;users;time interannotator agreement;comprehensive solution;consolidation;time model deployment;end", "pdf_keywords": ""}, "a8239258abded4f08d1bf270c2e86662f4dc1760": {"ta_keywords": "learner errors arise;prior conceptual knowledge;weak prior knowledge oboru matsuda;weak prior knowledge;student learning;specific prior knowledge;learning;complex skill changes;computational model;synthetic student;computer science;simulation study;school;carnegie mellon university;simstudent;introduction;domain;prone process;paper;error;question;complex problem;system;general;differences;andrew lee;usa abstract;innovative application;nature;rate", "pdf_keywords": ""}, "a182a8a0678857df5c513d52469fa707c32e69ec": {"ta_keywords": "statistical machine translation;continuous space rule selection model;continuous space rule selection;appropriate translation rules;rule selection;dependent rule selection;syntax;better generalization;maximum entropy;discrete representations;neural network;vector representations;smt;sentence context;csrs model;models;words;csrs;features;context;feed;forward;model;contrast;mers;paper;major challenges", "pdf_keywords": ""}, "4e3935ef7da6bcbb202ec7f8b285c313cadcd044": {"ta_keywords": "question answering systems;natural language processing papers;other qa tasks;nlp practitioners;nlp practitioner;qa;entire papers;document;content;questions;answers;qasper;complex reasoning;task;full text;paper;such tools;information;models;data;evidence;claims;abstract;further research;dataset;f1 points;humans;multiple parts;difficulty;question", "pdf_keywords": "large corpus;natural language query;natural language processing papers;answers;powerful neural models;qasper;quasar;queries;search;questions;paragraphs;tasks;qa;reading;best model performance lags;text;entire papers;datasets;software entity tags;models;dataset;answer;academic research papers;information;humans;several baselines;unsolved problems;clozestyle;lag;evidence"}, "85e148ac629b1b38556c5fe5f8d657f2eb01a701": {"ta_keywords": "mds queue", "pdf_keywords": ""}, "a997d6e253f08a3e589432c611d6d2a3097d7629": {"ta_keywords": "collaborative online research tool;usability studies;usability;online reader;openreview apis;undergraduate research students;young researchers;research;tool;many users;prototype;large scale deployment;pdf solutions;users;functionality issues;several additional features;issues;huge undertaking;concepts;product;immediate peers;future work;fly;constant guidance;professors;graduate;integration;goal", "pdf_keywords": ""}, "3ec37205c9201fc891ab51da200e361fdc34bfb3": {"ta_keywords": "reading comprehension tasks;word embeddings;novel deep learning architectures;reading comprehension;vocabulary tokens;architectural choices;past machine;representation;focus;test time;comparative study;final performance;use;minor choices;design;larger impact;research", "pdf_keywords": "reading comprehension tasks;word embeddings;reading comprehension;word vectors;embeddings;vocabulary tokens;novel deep learning architectures;neural models;comprehension;rc datasets;representation;test time;test;past machine;consistent results;focus;performance;minor choices;access;outof;comparative study;\ufb01nal performance;conclusions;different architectures;choice;cl;fractions;use;larger impact;carnegie mellon university"}, "cfad4dc5f1f7fcaf7ca318acf672ad92d47f8413": {"ta_keywords": "workforce imbalance;hiring paradox;federal contract compliance programs;employment;same legal conflict;bias;labor department;legal sanctions;aware legal solution;wells fargo;companies;issues;office;inequality;microsoft;ofccp;paradox;scrutiny;ins;proactive measures;recent run;destefano hold;ricci", "pdf_keywords": "ethical hiring goals;illegal discriminatory practices;legal analysis;workforce imbalance;employment practices;employment pipeline;employment;biasaware technique;candidates;equal opportunity;candidate;certain algorithmic approaches;legal practice;legal literature;screening practice;mathematics;law;rankings;analysis;ability scores;committees;imbalance;screening stage;methods;seeming paradox;practice;techniques;companies;example;contradiction"}, "f889723a4427e914e4e32547dfd0ca4996170180": {"ta_keywords": "converted speech;voice conversion;latest voice conversion challenge;target text prediction;prosody modeling;source speech;automatic speech recognition;prosody;conversion similarity;speech;prosodic clues;speech naturalness;conversion;speaker;linguistic representation;speaker mismatch;ttp;tts;asr;linguistic contents;text;input;target;vcc;model;vc;modeling;training;system;promising results", "pdf_keywords": "voice conversion;latest voice conversion challenge;converted speech;prosody modeling methods;on prosody modeling;prosody modeling;mandarin speakers;automatic speech recognition;mandarin target speakers;source speech;speech;proper input representation;ttp;asr;spt;tts;linguistic contents;input;text;cer;chin huang1;vcc;vc;performance;comparable performance;wer;sd;model;tomoki toda1;system"}, "f4cca8ea79e26fa20a91c3d3b769c9f7b82a6207": {"ta_keywords": "virtual spherical microphone array;3d audio;virtual spherical array;microphones;spectral notches;spherical array;median plane;head related impulse response;elevation ambiguity;lower elevation angles;actual pinna walls;extraction;fourier bessel series;pinna;hrir;fast method;experimental results;psn;resemblance;high degree;method;novel approach;cipic database;results;other hand;work;paper;utilization", "pdf_keywords": ""}, "8c38bffc058d558e7c734032ba63942865e05ae4": {"ta_keywords": "knowledge base queries;ideal knowledge base;deductive reasoning;logical queries;queries;deductive closure;kb queries;faithful embeddings;kb entities;kb inference;answers;qe systems;qe;practice kbs;generalization;kb;relaxation;world answers;experiments;space;techniques;paper show", "pdf_keywords": ""}, "e4a6bc3ac385b8982bbbe0a2a5ac0c79101ec979": {"ta_keywords": "overgenerality;generality", "pdf_keywords": ""}, "9bbeb4f0e48032df19f9f6a08839da5d2e60e8eb": {"ta_keywords": "noisy speech recognition;noisy automatic speech recognition;distant stereo microphones;speaker adaptation;environment speech applications;second chime challenge;dnn system;discriminative training;deep neural networks;noisy asr;reverberant;multiple dnns;sound sources;binary masking;binary masking algorithm;discriminative methods;dnns;asr;prior distributions;interference;challenge;wer;different features;prior knowledge;home;arrival;time difference;environment;system combination;scenario", "pdf_keywords": ""}, "8f963beca679cb1129df0a944c6de4b126e20fd5": {"ta_keywords": "lingual asr setup;multilingual asr;term memory;librispeech corpus;lstm;seq2seq decoder;final label inference;memory cell;memory cell state;iarpa babel swahili model;memory;language;shallow fusion baseline;memory cell update;fusion methods;external lm;main seq2seq;mlasr base model;multilevel decoding;librispeech;stage transfer baseline;lm;mlasr;transfer;cer;model;base model;best model;eval;hidden state", "pdf_keywords": "language model integration based on memory control;recurrent neural network lm;neural machine translation;speech recognition;lingual rnnlm;seq2seq model;rnnlm;lingual asr setup;model decodes;multilingual asr;lm;librispeech corpus;decoder;level decoding;nmt model;sequence;language;deep fusion;jaejin cho1;najim dehak1;base model;nmt;mlasr;jesus villalba1;word;transfer;takaaki;character;merl;2mitsubishi electric research laboratories"}, "b2c47dd46bf7087b754aed45f06b6196cf2b1c28": {"ta_keywords": "acute abdomen;diagnostic imaging;computed tomography findings;radiologic approach;german edition;clinico;image analysis;heidelberg;diseases;aspects;translation;berlin;springer;chapters;good general view;many details;techniques;deals;new york", "pdf_keywords": ""}, "46d87d4614d9353f1b7d527333073ef9109bfaea": {"ta_keywords": "user rankings;ranking;item labelings;fast algorithm;item labeling;hits algorithm;various discrete algorithms;label;likely label;relative performance;correct labels;various scalable methods;simulated datasets;superior accuracy;items;crowd;permutation;candidates;hitsndiffs;item;asymptotic improvement;consecutive ones property;consecutive ones;users;set;simple variant;consecutive ones problem;ideal case;experiments;applications", "pdf_keywords": ""}, "82ae0d4b41046ccedb435ece08a61f198cf77bb9": {"ta_keywords": "text content manipulation;basketball game report corpus;text portions;structured content;text;textual attributes;sentences;structured record;reference sentence;sentence;same writing style;wording;assists;sentiment;full content;kobe;generation;lebron;record;dataset;reference;explicit content coverage constraints;points;player;neural method;recent efforts;impressive progress;objectives;parallel data;practice", "pdf_keywords": "text generation;stylistic control;style imitation;hybrid attention;attention;style control;weakly supervised learning;content coverage constraint;content;content \ufb01delity;new content coverage constraint;copy mechanism;sentences;weak supervisions;style;neural approach;templates;generation;balanced embodiment;exemplars;stronger performance;structural nature;data records;data;results;conclusion;record;new approach;new way;experiments"}, "bc1832e8b8d4e5edf987e1562b578bd9aa5e18a9": {"ta_keywords": "mismatch condition training;data augmentation;chime3 test set;data selection;mismatched training;sequence summarizing neural network;mismatched condition;acoustic conditions;ami training;test conditions;speech;data;similarity;vectors;robustness;new approach;several configurations;network;results;different methods;efficient technique;summary;respect;paper", "pdf_keywords": ""}, "e212f788c701370af02b138d2a61e180cddfb138": {"ta_keywords": "single source language;multiple target languages t1;free grammars;translations;weak language model;strong language model;rule extraction;better translation results;multiple targets;synchronous context;models;formalism;t1;t2;pruning;scoring;specific framework;information;methods;method;motivation", "pdf_keywords": ""}, "c5dfc5fe7102fd8647edd1c9483aded82557e544": {"ta_keywords": "actionable recourse summaries;global counterfactual explanations;recourse summaries;recourse correctness;recourses;overall recourse costs;predictive models;interpretability;explanations;predictive model;novel objective;accurate summary;agnostic framework;optimality guarantees;subpopulations;analyse;such tools;algorithms;individuals;stakes decision;objective;correctness;interest;data;users;specific features;entire population;framework;real world;novel model", "pdf_keywords": "global counterfactual explanations;actionable recourse summaries;actionable recourses;individualized recourse;recourses;effective recourses;overall recourse costs;recidivism prediction;racial biases;undesirable model biases;explanations;predictive models;interpretability;decision makers;accurate summary;conclusions;accurate summaries;novel objective;interactive summaries;discrimination;individuals;black box model;trial;user studies;real world datasets;interest;effectiveness;agnostic framework;neural network;judicial bail decisions"}, "90ed32fa521b9e85f1c9efe356619814a2e79961": {"ta_keywords": "prior knowledge;explicit basis", "pdf_keywords": ""}, "a75869d69cc86f501939c237ae4711aa2885f6a6": {"ta_keywords": "neural machine translation;resource translation;resource language tasks;resource languages;diverse languages;different languages;european languages;source tasks;universal lexical representation;training examples;transfer;resource;target tasks;nmt;sl;nl;es;competitive nmt system;learning problem;finn;pt;fr;el;ro;ru;ko;fi;et;strategy;lv", "pdf_keywords": "neural machine translation;multilingual nmt;target language pairs;multilingual translation;\ufb01ve target languages;diverse languages;training examples;source tasks;meta;lowresource;nmt;transfer;target tasks;languages;european languages;target task;resource;english;sl;competitive nmt system;nl;es;europarl;ro;ko;el;russian;fr;\ufb01ve;strategy"}, "18e70ad07561cf09a2d7f0da992a0e87a5e5c0a8": {"ta_keywords": "topic tracking language model;speech recognition", "pdf_keywords": ""}, "8cebfae7cd436241eb5c3442e687a913a75a5531": {"ta_keywords": "word sense induction;sense induction;slavic language;other slavic languages;sense embeddings;russian language;disambiguation methods;group contexts;rich morphology;germanic languages;free word order;such contexts;senses;word;tasks;task;shared task;clusters;bank;river bank;participants;many features;romance;company;deposits;case;multiple teams;art baselines;competitive state;area", "pdf_keywords": "word sense induction;computational linguistics;slavic language;russian language1;russian language;disambiguation;sense inventories;contexts;novel sense;moscow;thousands sense;dialogue;datasets;task;international conference;intellectual technologies;shared task;contribution;results;proceedings;scale datasets;may;june;fold;work;conclusion;paper"}, "c6bb04f3d8000b7e800f6359082de39548c7da79": {"ta_keywords": "locality structure;locality information;contextual similarity metrics;locality features;structural locality;topical clusters;source code repositories;java source code;wikipedia text;external source;local neighborhoods;project hierarchies;examples;features;learned parameters;such models;reference;models;text;interesting differences;likelihood;improved performance;sequences;different domains;effective approach;experiments;paper;model efficacy;analysis;access", "pdf_keywords": "structural locality;capturing structural locality;locality;parametric language models;local hierarchies;programming language domain;contextual distance metrics;multiple localities;world datasets;natural language;natural language wikipedia articles;java programming language source code;datastore;noticeable lm performance gains;ubiquitous feature;lms;examples;data points;generalized formulation;similarities;external source;multiple domains;different domains;novel9 method;reference;junxian he;computer science carnegie mellon university;hellendoorn;abstract;differences"}, "97846070369f66c3080a0803be58e96963dec581": {"ta_keywords": "conspiracy theory websites;twitter;url usage;tweet text;political biases;external website usage;urls;usage patterns;fake news;clusters;main clusters;websites;misinformation;multiple views;information;data;patterns;results;terms;june;january;study", "pdf_keywords": ""}, "08f6819e66318cd49cddefd5d690a752d1098da7": {"ta_keywords": "argument mining;claims;nlp;argument;claim;deep learning systems;divergent conceptualization;such different conceptualizations;lexical level;different datasets;qualitative analysis;art feature;properties;extensive experiments;popular research area;essence;gaps;practical applications;consequences;state;central component;system configurations", "pdf_keywords": "argument mining datasets;argument mining;datasets model claims;claim identi\ufb01cation;argument;rigorous empirical assessment;nlp;claims;conceptualizations;machine learning perspective;lexical level;different machine learning systems;several computational models;datasets;available datasets;abstract;educational research;concept;conclusion;data;popular research area;different domains;computer science;features;recent deep neural networks;unknown domains;detailed analysis;obvious differences;fundamental component;analysis"}, "9f73c3f86026c21d0e5e55c70462952c6ada1175": {"ta_keywords": "deep learning;deep neural networks;backprop;backprop converges;training example;cifar10;cifar100;dnns;gradients;standard sgd;selective;modern image models;forward pass;high loss;art importance;example;examples;training;next example;svhn;evaluation;iteration;error rates;biggest losers;output;technique;parameters;paper;variety;state", "pdf_keywords": "deep learning;target accuracy;target error rates;learning rate schedule;additional learning rate schedules;backprop;selectivebackprop;cifar10;training times;training;cifar100;selective;wide resnet;art importance;modern image classi\ufb01cation models;evaluation;traditional training;art accuracies;taylor;svhn;stale;cutout;state;sensitivity analysis;selectivity;primary contributions;range;sb;wall;results"}, "dc984ea8be018a0244b40468d13f7b734ab55bac": {"ta_keywords": "neural machine translation;discrete translation lexicons;lexicon probability;lexical probabilities;encode translations;attention vector;frequency content words;translation candidate;nmt model;frequency words;source word;next word;nmt;nmt systems;sentence;model;meaning;mistakes;method;problem", "pdf_keywords": "lexical translation probabilities;discrete translation lexicons;traditional word alignment methods;probabilistic lexicons;lexicon probability;lexicon probabilities;lexical probabilities;attentional nmt models;attention vectors;encode translations;nmt probabilities;attention vector;standard nmt probability;translation candidate;nmt model;next word;source word;nmt;frequency words;nmt systems;predictive probability;handmade dictionary;training data;predictive distribution;other external parallel data resources;probability;linear interpolation;bias;additional information source;model"}, "0533ccdc4840eed0fe1769b5e78da912631be609": {"ta_keywords": "optical solitons;nonlinear fiber optics;solitons;nonlinear schr\u00e4odinger;optical soiltons;anomalous dispersion regime;modulational instability;einstein condensation;self phase modulation;bose;group velocity dispersion;governing wave equation;physics;nls;pondicherry university;existence;equation;applications;tappert;hasegawa;research interest;introduction;professor;elements;central university;overview;balance;puducherry;department;areas", "pdf_keywords": ""}, "4b73f4956c31cd10994c73b21e2c38a60a68d03e": {"ta_keywords": "conference paper assignment problem;assignment problem;sided matching problem;resource allocation;algorithms;referees;capacity constraints;indivisible goods;papers;reviewers;conference;common academic problem;averages;economics;use order;agents;voting;order;preferences;flexible class;objects;computer science;task;sides;fundamental problem;owas;other side;application;side;many areas", "pdf_keywords": "rank maximal assignment;assignment setting;allocation;egalitarian assignment;assignment;utility maximizing;algorithms;algorithm;toronto paper matching system;polynomial time;owa vectors;ef\ufb01cient package;zemel;novel notion;charlin;slider;motivation;nizer;prime example;contrast;conclusions"}, "b131cf78363993e4126b2562a156bd9d046c8bc4": {"ta_keywords": "pivot language words;pivot translation;translation models;target translation models;pivot language;syntactic matching methods;syntactic subtrees;united nations parallel corpus;pivot;syntactic roles;parallel data;intermediate language;triangulation;tree;languages;incorrect phrase combinations;language;english;phrase;target model;combinations;source;bleu;popular approach;paper;useful method;approach;method gains;experimental results", "pdf_keywords": ""}, "18e5fb8cec55a75b288a499c57d77ede541dc049": {"ta_keywords": "commonsense tasks;general semantic reasoning;neural language modeling;global knowledge graph;language models;individual knowledge graph;knowledge sources;tasks;specific tasks;commonsense question;task;external knowledge;informative questions;novel neuro;symbolic framework;different tasks;shot question;benchmarks;models;data generation strategies;training regimes;hypotheses;accuracy;recent developments;framework;addition;set;leaps;paper;structure", "pdf_keywords": ""}, "5b1bb1f6ed091dfd53adf7ebbcda2c48a3b67c2c": {"ta_keywords": "unsupervised semantic frame induction;semantic frame induction;unsupervised frame induction;context embeddings;contextualized word embeddings;syntactical features;embeddings;task;verb;role;runner;word;qasem;semeval;best performance;system;independent steps;approach;hhmm", "pdf_keywords": "unsupervised semantic frame;distributional word representations;verb clustering;context embeddings;role labelling;syntactical features;role induction;verbs;semantic labeling;verb senses;unsupervised task;embeddings;task;languages;clustering;additional features;word;runner;slots;abbreviation;arguments;type clusters;other datasets;effectiveness;combination;conclusion;hansestadt hamburg;method;moscow;mannheim"}, "384bf224d91a1691c9e6384201483121e2e7ddab": {"ta_keywords": "exact subspace clustering;subspace clustering;reliable clustering;hypergraphs;motion segmentation;subspace;community recovery;algorithmic aspect;similarities;sharp threshold;information;theoretic limit;instance;theoretic limits;problem;paper;limit;applications;literature;variety;number", "pdf_keywords": ""}, "e01aa6f8ce625469b6f161d7ab9e61a60ac33798": {"ta_keywords": "online streaming codes;streaming codes;latency streaming communication settings;live video streaming;optimal offline rate;packet loss channel;erasure codes;message sizes;online versus offline rate;size messages;future messages;burst;online;upper bounds;rate;schemes;sizes;broad parameter regimes;future;access;requirements;setting;applications;feasible goal;paper;fact;class;variable;practice", "pdf_keywords": "online streaming codes;packet loss channel;message size sequences;optimal of\ufb02ine rate;burst;rates;symbols;sequences;message;sequence;number;of\ufb02ine;exclusive conditions;size;broad parameter regimes;feasible goal;scheme;fact;paper"}, "6b7004138ee2de5ec52e500cae4e65390e961e16": {"ta_keywords": "spectral clustering meet regularization;kernel clustering;kernel clustering criteria;optimization kernel cut algorithm;kernel cuts;segmentation;data partitioning;regularization;regularization objectives;spectral bounds;new linear kernel;kernel;continuous solvers;gap;combinatorial move;joint energy;code;many applications;general methodologies;complementarity;popular methodologies;work;practical problems;integration;such terms;making;main focus;literature", "pdf_keywords": ""}, "e0236106e51984e4ea6bbbd1fb5ce57abf3e4e5e": {"ta_keywords": "face mask;masks;mask;pandemic;safety measures;new coronavirus;safe environment;global health crisis;social distance;risk;robust algorithm;guidelines;virus;training dataset;spread;techniques;approach;lockdown;disease;images;medial health practitioner;person;people;protocols;governments;malls;other such places;government;renowned scientists;sources", "pdf_keywords": ""}, "af92dd61340808f3008a84ae57803bb4aa57d03b": {"ta_keywords": "end visual pose forecasting;dyadic conversational data;attention model;avatar pose;pose;dyadic conversations;personalized avatar;adaptive attention;intrapersonal dynamics;conversation;selective attention;interpersonal dynamics;gestures;body posture;facial expressions;dyadic models;such personalized avatars;avatar;human;speech;dyadic dynamics;neural architecture;verbal messages;verbal behaviours;linguistic cues;body;dyadic residual;model;audio;dyadic", "pdf_keywords": "attention model;pose;avatar pose;dyadic conversational data;adaptive attention;selective attention;intrapersonal dynamics;interpersonal dynamics;conversation;dyadic models;neural architecture;human;avatar;body;person;dyadic dynamics;model;audio;dyadic residual;participants;specific model;dyadic;task;new model;audio signal;sequences;dynamics;dram;interlocutor;importance"}, "5b1c0152bbb12ece2a8817c727e33e6d5c503065": {"ta_keywords": "uncoded shuffling;communication bottlenecks;optimal task replication scheme;uncoded matrix multiplication;shuffling;scale computing platforms;algorithms;worker node;matrix multiplication;randomness;stragglers1;workers;runtime;codes;communication cost;machine;robustness;subtask;maintenance outages;system noise;system failures;work;data;noise;system;exponential tail;uncertainty;times;several types;number", "pdf_keywords": ""}, "c395595cf7be23f7d90cbca98d8c7861ebfd884d": {"ta_keywords": "comment toxicity task;comment toxicity;classifiers;classification metrics;machine learning tasks;social computing datasets;individual stable opinions;disagreement deconvolution;stable opinions;roc auc;annotator;performance measures;metrics;evaluation;dataset;prediction;current metrics;performance;precision;recall;human;people;misinformation;tasks;technical performance;machine;noise;many human;computer interaction;example", "pdf_keywords": "disagreement deconvolution;machine learning performance metrics;comment toxicity task;machine learning tasks;social computing datasets;comment toxicity;classifiers;machine learning;social computing design;roc auc;misinformation;metrics;machine;computing;evaluation methods;performance;tasks;human;many human;current metrics;example;computing methodologies;ccs concepts;stanford university;abstract;kayur patel;tatsunori hashimoto;kaitlyn zhou;reality;practice"}, "37074b2b9cebd89e4a92d20f41eec7360e11fe5a": {"ta_keywords": "streaming nar speech recognition system;online asr recognition;automatic speech recognition;speech processing;connectionist temporal classification;full speech utterance;maskpredict;low latency scenarios;input audio;asr;rtf;low latency conditions;nar;block;recognition inference;blockwise;more attention;completion;mask;ctc;time factor;vanilla mask;more coherent sentences;small blocks;accuracy;art attention;models;ar;novel end;blockwiseattention", "pdf_keywords": "streaming nar speech recognition system;streaming nar model;ctc streaming;emergent nar research trends;low utterance latency;context decoding;nar;maskpredict;ctc models;such online ar aed studies;ar attention;ctc;mask;connectionist temporal classi\ufb01cation;novel e2e;vanilla mask;novel end;speed;model;blockwiseattention;conclusion;competitive performance;paper;issue"}, "bd6018632a360cb567da8e50e1717ff526503845": {"ta_keywords": "conditional poisson stochastic beam search;many sequence generation tasks;sequence models;beam search;efficient estimators;nlp;consistent estimators;biased estimate;sample;stochastic process;samples;high entropy settings;conditional poisson;algorithm;diverse sets;iteration;improvements;expectations;candidates;replacement;best items;distribution;many applications;cpsbs;model;strategy;experiments;sbs;useful summary;natural alternative", "pdf_keywords": "sequence models;beam search;consistent estimators;statistical estimators;algorithms;beam;consistent estimator;algorithm;stochastic process;inclusion probabilities;diverse sets;expectations;sample;samples;cpsbs;cpsbs design;table;general framework;variance;objective;scheme;size;mainstay;solution;new method;comparison;work;simple modi\ufb01cation"}, "6494cd26511c076186673c9a636d21d1dfed8d5a": {"ta_keywords": "speech enhancement;significant asr improvements;teacher network;training data;original noisy features;asr performance;teacher learning;asr systems;teacher model;channel track;student network;better network;original noisy signals;training stage;teacher learning paradigm;enhancement techniques;asr research;features;inputs;channel;teacher;input;error reduction rate;signals;student;outputs;real dataset;multichannel scenario;conventional student;soft targets", "pdf_keywords": ""}, "c8f9313ce8416a7be079935d1cbb637705f75182": {"ta_keywords": "translation individuality;translation dictionary;translation model probabilities;gram similarity;gram statistics;language model;translation;transforming individuality;thesaurus;speech;spoken language;vocabulary;individuality;text;sentence;speaker;words;automatic construction;improvements;writer;quality;context;significant improvements;estimation;various features;meaning;experimental evaluations;target;method", "pdf_keywords": ""}, "8c7628641450203b0aa959b5a69729ff906760ff": {"ta_keywords": "external speech activity detector;speaker diarization;end neural diarization;neural diarization;decoder based attractors;encoder;speaker overlap handling;diarization;attractor calculation module;decoder;speakers;eend methods;output speakers;eend;training set;extensive evaluations;eda;iterative inference method;real datasets;end;unknown number;maximum number;approaches;terms;approach;method;paper;results;problem;contrast", "pdf_keywords": "end speaker diarization method;acoustic feature sequence;attractor calculation module;attractors;encoder;embeddings;wise embeddings;speakers;diarization results;decoder;input;dot product;eend;unknown numbers;frame;eendeda;eda;end;problem;paper;conclusion"}, "5aea95e1ae78a66474051a330ded374e199b658c": {"ta_keywords": "citation networks;networks;graph structure;graphs;aware representation;recent deep learning approaches;neighborhood aggregation procedure;representation learning;neighboring;node;knowledge;local neighborhood properties;bioinformatics;different neighborhood;architecture;random walk;better structure;models;model;representation;tasks;jk;strategy;range;spread;important properties;state;art performance;experiments;number", "pdf_keywords": "graph attention networks;graph convolutional networks;citation networks;subgraph structures;graph structure;networks;aware representations;aware representation;bioinformatics;neighborhood aggregation schemes;node;models;knowledge;better structure;neighboring;architecture;structure;real dataset;model;local neighborhood properties;different neighborhood;layers;representation;tasks;random walk;gcn;correct prediction;jk;limitations;important properties"}, "564dec6eab6115ecd604f22738ce0b47777f6e17": {"ta_keywords": "speech classification;robust speech classification;large vocabulary continuous speech recognition experiments;vbec functions;speech recognition procedures;vbec;bayesian predictive classification;spontaneous speech tasks;acoustic models;acoustic modeling;accurate acoustic models;major bayesian advantages;speech;predictive posterior distribution;total bayesian framework;posterior distributions;vb;high word accuracies;posterior distribution;maximum likelihood;gaussians;ml approach;training effects;categories;ml parameters;markov model states;appropriate model structure;advantages;mitigation;ml", "pdf_keywords": ""}, "8c5465eb110d0cab951ca6858a0d51ae759d2f9c": {"ta_keywords": "text classifiers;binary latent masks;short selections;neural network models;classifier;binary selections;l0 regularisation;reinforce;latent model;input text;gradient;words;predictions;sparsity;training;informative part;rationale;penalties;input positions;formulation;l0;model;justification;continuous behaviour;previous work;value;same time;problem", "pdf_keywords": "prespeci\ufb01ed text selection rate;gradient estimation;neural network models;gradient;reinforce;binary selections;input text;latent model;discrete selectors;training;lagrangian relaxation;rameterization;discrete behavior;speci\ufb01c rate;formulation;continuous behaviour;penalties;model;l0;value;rationale;random variable;same time;alternative;problem;use"}, "2660dbba723573266edb2a0a4929e6847ae83212": {"ta_keywords": "speaker adaptation;rnn transducers;rnn;language model fusion;prediction network vectors;recognition performance;encoder;word error rate;ts;switchboard;joint network;training recipe;general training recipe;other components;evaluation;italian test set;nist hub5;different tasks;architectural changes;model combination;hours;novel multiplicative integration;set;callhome test sets;data perturbation;techniques;applicability;effect;conjunction;mozilla commonvoice", "pdf_keywords": "prediction network embeddings;external language model fusion;speaker adaptation;hours corpus;encoder;excellent recognition performance;prediction network vectors;data augmentation;character outputs;good model complementarity;model regularization;italian test set;models;model combination;switchboard;evaluation;joint network;simple architecture;mi outperforms;rate scheduling;nist hub5;optimizer;tasks;callhome test sets;novel multiplicative integration;effective modi\ufb01cation;mozilla commonvoice;multiplicative integration;additive integration;careful choice"}, "94f22d7a8b48784b3d8975616e20d8028a08162f": {"ta_keywords": "russian academy;russian federation;mechanics;goldstein;mathematics;institute;sciences;ural branch;yekaterinburg", "pdf_keywords": ""}, "d119cc4051ed1206a0dac963cd23a84acf77fea7": {"ta_keywords": "uncalibrated forecaster;accurate decision loss prediction;forecaster;probabilistic forecasts;threshold calibration;threshold decisions;perfect forecasts;threshold decision;threshold loss function;decision loss;threshold;calibration;decision makers;downstream decision makers;regression;cutoff;loss;decisions;different decision rules;outcome;probabilities;efficient algorithm;average notion;input;stronger notion;true frequencies;procedure;practice;deployment;condition", "pdf_keywords": "threshold decision losses;threshold loss;threshold calibration minimizes;uncalibrated forecaster;accurate decision loss estimation;different threshold loss functions;threshold decision;threshold decision rules;threshold calibration;improved decision loss;threshold;forecaster;benchmark regression tasks;decision loss;reliability gap;forecaster model families;decision makers;ef\ufb01cient algorithm;baselines;datasets;iterative procedure;world settings;practical solution;input;practice;suite;conclusion;size;suf\ufb01cient condition"}, "6a9795853e5f39325deb0d916fe22d9e5a202a9f": {"ta_keywords": "clandestine printers;pamphlets;pa abstract milton;pamphlet;london printers matthew simmons;printing;milton;1640s;areopagitica;thomas paine;freedom;significant texts;history;article;gregory dexter;press;pennsylvania state university;identification;damaged type pieces;possible involvement;years;university park", "pdf_keywords": ""}, "5270b626feb66c8c363e93ba6608daae93c5003b": {"ta_keywords": "language models;knowledge modification;knowledge modifications;memorization;transformer models;stale knowledge;transformer model;factual knowledge;specific factual knowledge;transformers;transformer;models;unmodified facts;model performance;new task;key components;different training phases;specific old facts;generalization;new ones;tasks;unintended biases;many scenarios;discovery;privacy;insights;great capabilities;task;vast amount;tuning", "pdf_keywords": "transformer models;transformer model;factual knowledge;unmodi\ufb01ed factual knowledge;transformers;knowledge modi\ufb01cation;knowledge;symbolic memory module;model performance;model parameters;models;implicit knowledge;unmodi\ufb01ed facts;model;unaltered facts;modi\ufb01ed facts;new benchmark;constraint;high accuracy;tuning;better baseline methods;new task;constrained optimization problem;ability;layer;task;fae;performance;speci\ufb01c;effective way"}, "7b99c51d562e33309a46601c846abbe72a65c6a4": {"ta_keywords": "many nlp tasks;sequence tagging tasks;english classification;target tasks;question answering;language models;intermediate training;candidate datasets;intermediate task;best transfer setting;tuning approaches;best datasets;target;diverse set;large transfer gains;shot fine;tuning;efficient adapter settings;best methods;combinations;results;expense estimates;abundance;multiple choice;respective datasets;parameter;methods;different data;experiment;method", "pdf_keywords": "sequence tagging tasks;transfer learning;intermediate transfer learning;question answering;nlp;intermediate task data;target tasks;intermediate model weights;intermediate training;bene\ufb01cial intermediate tasks;english classi\ufb01cation;tuning approaches;par performance;bene\ufb01cial tasks;best datasets;transfer;ef\ufb01cient;diverse set;sequential \ufb01ne;ef\ufb01ciency aspect;shot \ufb01ne;target;approaches;expense estimates;more parameter;tuning;comprehensive comparison;data;different types;best methods"}, "c47c8c2527bf2ca8339c342f44db2218a0cbcbbd": {"ta_keywords": "knowledge graph construction;knowledge graph;knowledge graph identification;statistical relational learning framework;knowledge bases;probabilistic soft logic;knowledge base construction systems;knowledge base;many information extraction;candidate extractions;semantics;knowledge;entities;relations;incomplete information;graph identification;data;sources;web;statistics;text;labels;psl;efficient solution;key problem;millions;article;art results;order;challenge", "pdf_keywords": ""}, "4eb22b488052c430170139c492674aa05512f7bf": {"ta_keywords": "shape optimization design;preform die shape;optimization design variable;optimization;final forging;optimiztion;total objective function;near net shape;spline;multiple preform;shape;preform;control point;cost;material;coordinates;energy;force;paper;process;order", "pdf_keywords": ""}, "f394c5101d7bfc3d8055f9391a83f7e2395dec4a": {"ta_keywords": "nas parallel benchmark;parallelization;openmp parallelization directives;decision tree error reduction;decision trees;program features;runtime;dependency graph features;loop instruction counts;adaboost;sequential programs;comparable performance;vector machines;supervised learning algorithm;performance;code;npb;classification problem;relative importance;code hand;dynamic features;secondary importance;automatic method;model comparison;greatest contribution;versions;human expert;order;regions", "pdf_keywords": ""}, "f41e6c832c9e0d5360b66ee7681d3b1ffd2d9c3d": {"ta_keywords": "hierarchical tasks;hierarchical task structure;hierarchical task learning;task learning;task structures;object manipulation;task;scene navigation;depth understanding;task success rate;agent;future benchmark development;alfred benchmark;higher generalization ability;unified transformers;art system;toend architecture;human performance;ability;language instructions;evaluation;monitoring;model hitut1;hitut;explicit representation;unseen environment;unified manner;best performance;self;insight", "pdf_keywords": "hierarchical tasks;hierarchical task structure;task learning;hierarchical task;task compositions;object manipulation;task;roberta pretraining;task success rate;scene navigation;training;roberta model;hierarchical structure;higher generalization ability;human performance;alfred benchmark;transformer;roberta;role;performance;uni\ufb01ed transformers;best performance;art system;table;art performance;toend architecture;language instructions;conclusion;end;departure"}, "c54ad6e29f3e516eecf0a72bd1f95b80e8617116": {"ta_keywords": "general compressive phase retrieval problem;compressive phase retrieval;phasecode algorithm;phasecode;sparse complex vector;degree sparse;global phase uncertainty;memory complexity;linear measurements;signal components;graph code construction;complexity;algorithm;orderoptimal time;magnitudes;component;capacity;paper;variant;problem;mild assumptions", "pdf_keywords": "complexity compressive phase retrieval;compressive phase retrieval problem;layer phasecode algorithm;layer phasecode;phasecode algorithm;phasecode;compressive phase;compressive sensing layer;compressive sensing framework;compressive sensing;phase;degree sparse;graph codes;graph code construction;signal components;memory complexity;inner layer;optimal time;outer layer;retrieval;algorithm;layered approach;retrieval problem;trigonometric;modular design;feb;proposed algorithm;measurement;separation;architecture"}, "044b502e5a00b5eeff1dd078ea03f491ca2c37bf": {"ta_keywords": "continuous phoneme recognition task;automatic speech recognition;mit lecture transcription task;discriminative training techniques;wsj transcription task;language models;decoders;state transducers;recognizers;structural classification methods;speech community;classifiers;decoder arc;rich contextual information;asr performance;linguistic aspects;baseline systems;asr;frame;features;unified modeling;timit;time frame;structure;wfsts;wfst arcs;likelihood functions;computational efficiency;advantages;mpe", "pdf_keywords": ""}, "b9057dce43181a30aa3e0435c8ffc4c0b6f8f127": {"ta_keywords": "machine reasoning;inference graphs support;inference graphs;such inference graphs;defeasible inference task;defeasible reasoning;logic literature;argumentation;reasoning;related nlp task;meaningful graphs;graphs;conclusions;human evaluation;cognitive science;new evidence;task;human accuracy;cases;human;method;findings;metrics;paper;exciting new research avenues;kind;transfer;account;mode", "pdf_keywords": "inference graphs;inference graph;defeasible inference;defeasible reasoning;contextualizers;contextualizer;meaningful graphs;transfer learning;downstream defeasible task;human knowledge;machines;adapted in\ufb02uence graph;cognitive science;graphs;usability;hypotheses;discussion;mediator nodes;critical nodes;concept;situations;humans;generation;conclusion;computational model;benchmark;mediators;idea;paper;case study"}, "b143ee344fe3af4169bde8af8b682a2835dae4a4": {"ta_keywords": "expressive joint action policies;novel task furnmove;single agent;autonomous agents;agents;agent;decentralized action;training agents;tasks;gridworld;close coordination;actions;task;furnmove;successful actions;cordial sync;competitive decentralized baselines;furniture;like environments;sync;cordial;marginal policies;room;challenges;policies;abilities;rich domains;goal;difficulty;piece", "pdf_keywords": "novel task furnmove;agents;training agents;expressive joint action policies;furniture;tasks;actions;successful actions;decentralized action;gridworld;task;furnmove;dynamic neural system;close coordination;train;room;world model;furnlift;self;goal;procedures;world;validation;performance;challenges;solid lines;toussaint;piece;lines;experience"}, "c3930cb34241a42e03ed02cbc83a3c87dddd60cc": {"ta_keywords": "generated stories;story generation;reinforcement learning;reward function;stories;quality;partial evaluation metric;story;quality signals;continuation;next sentence;few sentences;task;scorer;rich feature function;systems;problem;setting", "pdf_keywords": ""}, "c9d7b1f9b13d6ea4ff45b908285cc65af959cc5b": {"ta_keywords": "word probabilities;probability measures;abstract languages;probabilistic measure;language;probability;assignment;word;second method;production;conditions;problem;turn", "pdf_keywords": ""}, "3050735eb35af3527276aa1952f79eb2483df3f0": {"ta_keywords": "large conversation corpus;spontaneous dialogue data;conversational understanding task;conversational understanding;utterance representations;resource utterance tagging;large corpus;utterance;contextualized representations;different categorical dialog;emotions;intentions;unsupervised training;human expertise;speaker;level analysis;specific aspects;labels;act;end objective;core task;high level;process;speakers;paper;limitations;new domains", "pdf_keywords": ""}, "a556914c1b32372d47a36f2826cbe143ddae95ca": {"ta_keywords": "node attachment prediction task;taxonomy expansion model;taxonomy expansion;new concept terms;taxonomy expansion problem;query terms;many taxonomies;taxonomies;taxonomy;natural supervision;important knowledge ontologies;feature representations;expansion;node attachment task;multiple views;prediction;supervision signals;self;numerous applications;public benchmarks;steam;anchor pairs;accuracy;art methods;natural self;query;mean reciprocal rank;daily basis;extensive experiments;practice", "pdf_keywords": ""}, "d85c0032d7bb0bd220eb2df8ba6d2130bc87e79e": {"ta_keywords": "relative diarization error rate reduction;neural diarization;joint speech activities;iterative pseudolabel method;unlabeled data;training method;speech;recording;speaker;eend system;eend;model adaptation;traditional clustering;callhome dataset show;data;model;seed model;end;promising performance;paper;target condition;performance;time frame;method;methods;case;experimental results;experiments", "pdf_keywords": "unlabeled data;iterative pseudolabel method;relative diarization error rate reduction;training method;model adaptation;eend model;third dihard dataset;training strategy;eend;callhome dataset show;tuning;model;seed model;target condition;\ufb01ne;performance;results;method;paper;effectiveness;experiments;approach;experimental results"}, "571b4425498549c56c0828a824dc453ff6f482fc": {"ta_keywords": "such mac protocols;hoc wireless networks;medium access control;iot;protocols;iot applications;adaptive macs;contention access;delay;throughput;qzmac;mean delays;zmac;ezmac;complete knowledge scheduler;light traffic;internet;access;mac;certain delay;node setting;node;optimality;optimality theory;heavy traffic;minimum;resource;tdma;things;available information", "pdf_keywords": ""}, "0823f2187eeed53be8fd452decf6ed9a6a6cd124": {"ta_keywords": "semantic parsing;semantic parser;semantic parsing corpus;dialog act tagging;natural language understandingcomponent;adialog act tagger;corpus;document;spacebook;spatial;operationsa knowledge;documentwill;behaviors;preliminary machine learning experiments;progress;personal adaptive communication environment;developments;creation;project;final prototype;month;large part;first phase", "pdf_keywords": ""}, "5de24203bf98ae7f4c514bc0bd2a310caa47a047": {"ta_keywords": "modern railway networks;railway network;many trains;scheduling trips;agents;many agents;traffic networks;competition setup;traffic;time scheduling;coordination;multiplayer video games;graph representations;competition;vrsp;vehicles;challenging tasks;competition models;vehicle;complexity;tree;target stations;operations research;top submissions;disruptions;observations;approaches;submissions;outstanding solutions;flatland environment", "pdf_keywords": "dynamic train;deep reinforcement learning;railway network;reinforcement learning;modern railway networks;agents;flatland competition;agent;competition setup;full system simulation;competition models;competition;rl;swiss federal railways company;vrsp;vehicle re;term planning;coordination;neurips;operations research;spatial reasoning;computational complexity;network;signi\ufb01cant challenge;flatland environment;aicrowd;e\ufb03cient coordination;framework;example;representative environment"}, "254d1b8cf247ae8b19e017f7ba758d670207ddda": {"ta_keywords": "speech enhancement;automatic speech recognition;optimal beamforming parameters;spatial filtering;neural networks;asr task;speech;aware neural networks;array signals;asr;recognition;discriminative;long processing pipeline;bf network;suboptimal performance;processing systems;network;cost functions;trainable steps;frequency domain;phase;deterministic processing steps;bf;processing steps;array geometry;tasks;task;steps;large number;chapter", "pdf_keywords": ""}, "1f5a1e959147e989e12846a5bd1d20234ef667d7": {"ta_keywords": "direct oral anticoagulants;anticoagulants;severe bleeding events;severe bleeding;prothrombin complex concentrates;bleeding;plasma concentration;rivaroxaban;creatinine clearance;prospective cohort study;dabigatran;patients;conclusions;registry;outcomes;ml;ng;min;use;cases;june;role;results;background;november;management strategies;management;aim;methods", "pdf_keywords": ""}, "148f055083666c72945eea79833a19494f5f57c0": {"ta_keywords": "synonymy dictionaries;sparsity", "pdf_keywords": ""}, "924ce584acc148be29ef905c228fda7fe552c0c2": {"ta_keywords": "probabilistic logics;many probabilistic logics;large knowledge bases;markov logic networks;large knowledge base;probabilistic language;efficient inference;personalized pagerank;kb inference;pagerank;propositional representation;interrelated predicates;queries;logic;grounding;proof space;entities;clauses;database size;correct approximate grounding scheme;imperfect information;proofs;local groundings;proppr;bottleneck;joint learning;kbs;kb;orders;computation", "pdf_keywords": "markov logic networks;stochastic logic programs;statistical relational learning solution;kb inference;learning scheme;joint learning;learning;potential bottleneck;inference;approximate grounding scheme;interrelated predicates;weights;single grounding g\u02c6qk;multiple threads;logic;short derivations;slp;kb;contention;entities;largest tasks;pagerank;noisy kb;gradient;personalized pagerank;ppr;clauses;mutual recursion;proppr;improvements"}, "8c4d1e81c277f71cd9e3c9a0af356203c7948dca": {"ta_keywords": "novice transcription correction task;endangered language documentation;transcriber shortage;effective human transcribers;novice transcribers;transcription bottlenecks;hidden markov model asr systems;transcription bottleneck;end asr system;end asr;asr systems;asr community;linguistic resources;el documentation;documentation;language;empirical study;combinatory methodology;yol\u00f3xochitl mixtec;shortage;el;main challenges;end;effectiveness;suggestion;way;data settings;method", "pdf_keywords": "end asr efforts;novice transcription correction task;novice transcription correction;novice transcribers;end asr;transcriber shortage;end asr system;hidden markov model asr systems;el documentation;asr systems;transcription bottleneck;asr community;linguistic resources;asr;language;ym;combinatory methodology;ymc;end;whole process;espnet;potential task;community;western mexico;suggestion;recipe;way;work;effectiveness;material"}, "c5ed3d1a2ce418610a6fc9b5520a4f845279969a": {"ta_keywords": "parity queries;parity models;parity model;parity query;parm;neural network inference;erasure coding;decoder;storage;neural network;localization tasks;prediction;decodes approximations;unavailable predictions;erasure;queries;efficient resilience;median latency;predictions;speech recognition;resilience;resource;data unavailability;image classification;class;multiple queries;many serving workloads;functions;same median;inference", "pdf_keywords": ""}, "657329c633709dd1ac34a30d57341b186b1a47c2": {"ta_keywords": "sparse attention;dynamic sparse attention patterns;comparable sparse attention models;attention layers;attention;efficient content;memory;attention suffers;sequence modeling problems;sequence length;memory requirements;image generation;content;overall complexity;language;routing transformers;complexity;interest;routing transformer;fewer self;bits;module;self;perplexity;small set;computation;wide range;model;query;windows", "pdf_keywords": "comparable sparse attention models;layer routing transformer model;large long sequence benchmarks;attention layers;routing transformer;transformer models;attention;language modeling;overall complexity;sequence length;tensor\ufb02ow;language;image generation;test perplexity;perplexity;regressive generative models;bits;unconditional image generation;module;model;sequences;length;fewer self;code;auto;sequential data;source;dim;selfattention;art"}, "ba4a34680e09e77984624c95f5245d91b54373f6": {"ta_keywords": "multilingual encoders xtreme benchmark;multilingual models;multilingual representations;sentence retrieval tasks;nlp;languages;benchmark;benchmarks;many tasks;machine learning models;english;tasks;xtreme;comprehensive evaluation;coverage benchmarks;performance;models;human performance;recent progress;diverse range;wide variety;such methods;interest;end;sizable gap;applications", "pdf_keywords": "multilingual encoders;multilingual representations;multilingual representation;diverse languages;transfer learning;languages;translation;linguistic knowledge;natural language inference;benchmark;english test;language families;benchmark1;xtreme;transfer;tasks;mbert;performance;syntax;diagnostics;dataset;pseudo test sets;table;purpose;addition;end;different levels;approaches;research;representative set"}, "927ff874d3ed9307356d256c31b79a0624b3c9d5": {"ta_keywords": "speech activity detection;automatic speech recognition;acoustic model training data;source separation;plda score fusion;reverberation;different acoustic model architectures;asr systems;posterior fusion;diarization;speakers;tracks;asr;overlap assignment;recognition;prediction error;variational bayes;pipeline;word error rate;markov model;wpe;stage;evaluation set;everyday home environments;lattice combination;jhu team;other techniques;vb;dereverberation;hmm", "pdf_keywords": "speech processing;speech recognition;speech activity detection;automatic speech recognition;acoustic model training data;different acoustic model architectures;asr systems;source separation;reverberation;plda score fusion;speakers;human language technology center;posterior fusion;sixth chime challenge;asr;diarization;overlap assignment;recognition;prediction error;variational bayes;markov model;word error rate;tracks;wpe;stage;pipeline;evaluation set;eess;lattice combination;shinji watanabe"}, "c4efaeccd7f0d900b1df95dadf51bad74264f613": {"ta_keywords": "nash equilibrium profiles;pure nash equilibrium;nash equilibrium;probabilistic serial rule;ps rule;utility functions;allocation;computational complexity;preference profiles;utility;manipulability;agents;goods;agent;strategic aspects;computation;linear time;different combinations;frequency;experiments;objects;different types;best responses;existence;number", "pdf_keywords": "sequential allocation;ps algorithm;indivisible houses;pure nash equilibrium;utility functions;nash equilibrium pro\ufb01les;best response algorithm;utility;ps rule;manipulability;agents;computation;objects;di\ufb00erent combinations;experiments;frequency;chandrasekaran;best response;number;section;existence;kohler"}, "605bae6c397e4829dde7ff7b8ddb84782ec6e607": {"ta_keywords": "influenza viruses;influenza;virus interaction network;virus replication cycle;comprehensive pathway map;flumap;viral infection;influential host response mechanisms;common infectious disease;host cells;virus;conclusionthe flumap;potential drug targets;host responses;host factors;computational network;functional interactions;life cycle;mechanisms;comprehensive map;host;available webtools;backgroundinfluenza;manual curation approach;systematic understanding;targets;base;literature;knowledge;reliable representation", "pdf_keywords": ""}, "a18b49fae647ae08711c2384611b3537485e8408": {"ta_keywords": "automatic speech translation systems;machine translation system;speech translation system;translation data;translators;simultaneous interpreters;simultaneous interpreter;translation studies;translations;simultaneous interpretation data;automatic evaluation metrics;performance;learning process;computerized version;content;important content;small chunks;experience;system;fair amount;field;work;possibilities;tricks;number;time;year;fact;previous work;majority", "pdf_keywords": ""}, "417259d40d0d8b3ca7ebdcf811aa9f7814d5c0c5": {"ta_keywords": "saxophone model;saxophone model couples;saxophone;reed model parameters;reed parameters;reed stiffness;reed;sample recordings;several possible frequency response pairs;spectral envelope;tone hole configuration;synthesized sound;filter frequency responses;estimation;different spectral envelopes;convex optimization;parameters;several different pitches;control parameters;cost function;mouthpiece;fingering;recording;minimization problem;sound;vocal tract shape;pitch;timbre;possible fingerings;input pressure", "pdf_keywords": ""}, "4302e981e3ec118b68e0b3fcf1820b3f6ecfa988": {"ta_keywords": "argumentation quality assessment;argumentation quality;argumentation theory;arguments;quality;absolute quality ratings;practical assessment approaches;theory;relative comparisons;fact;most observations;paper studies;practice;views;extent", "pdf_keywords": ""}, "15251fa3a3bcf695bf153d0856886cab9a3145ea": {"ta_keywords": "text summarization;cnn;reranking;summaries combination;dailymail dataset;further performance improvements;comprehensive evaluation;datasets;refactor model;new framework refactor;performance improvement;recent works;other researchers;insight;effectiveness;researchers;unified view;few works;base systems;art results;several limitations;limitations;previous methods;shelf tool;techniques;system;new state;other areas;art systems;light", "pdf_keywords": "refactoring neural summarization;text summarization;text summarization systems;modern text summarization systems;summaries combination;refsum;refactor model;cnn;new framework refactor;dailymail dataset;recent works;better model architectures;performance improvement;previous methods;few works;abstract;complementarity;yixin liu;insight;future directions;performance;problem formulations;new direction;yi dou;art results;effectiveness;zi;apr;several limitations;stage learning problem"}, "f9e3b7c6ca7d534694148bd0c7c37c1ef896a784": {"ta_keywords": "multilingual multispeaker asr;several multilingual asr systems;automatic speech recognition;multiple languages;utterances;monolithic neural network architecture;languagedependent modules;acoustic features;languages;word label sequence;asr;end system;speakers;end framework;hybrid systems;end;whole system;model;sequence;modeling;direct estimation;systems;direct optimization;character;internal linkage;expressive power;challenging task;mixtures;scope;capabilities", "pdf_keywords": ""}, "400e083a18ab94bbf45b0820693fb5035684dd7c": {"ta_keywords": "stochastic parsing;spoken utterances;hybrid semantic analysis system;linguistic research;sentence;computer algorithm;recognition;meaning description;computation;goal;article;experiments;problem;area", "pdf_keywords": ""}, "71a85e735a3686bef8cce3725ae5ba82e2cabb1b": {"ta_keywords": "practical ml pipelines;training domain performance;training domain;ml pipeline;modern machine learning;underspecified pipelines;clinical risk prediction;ml models;such predictors;many predictors;predictors;credibility;poor model behavior;medical genomics;training;electronic health records;examples;world domains;underspecification;natural language processing;challenges;computer vision;instability;performance;deployment domains;medical imaging;distinct failure mode;ambiguity;practice;equivalent", "pdf_keywords": "early adverse event prediction;clinical risk prediction;medical genomics setting;modern ml models;deep learning;genomic features;shallow random feature model;predictors;optimal predictors;such models;electronic health records;powerful prediction abilities;demographic features;continuous risk models;speci\ufb01c regularization schemes;underspeci\ufb01ed models;domain expertise;di\ufb00erent models;natural language processing;demographics;epidemic;linear regression models;di\ufb00erent generalization behavior;inductive biases;iop;encode di\ufb00erent;medical imaging;wide limit;computer vision;british training set"}, "dd961bb9e2a70f3819a13b13402fe585ae384226": {"ta_keywords": "pure nash equilibrium;pure nash equilibria;nash deviations;probabilistic serial rule;equilibria;social welfare;truthful profile;agents;ps rule;cycles;time algorithm;quality;profile;vast majority;experiments;np;same assignment;possibilities", "pdf_keywords": "pure nash equilibrium;pure nash equilibria;nash equilibrium;nash deviations;probabilistic serial;equilibria;extensive form game;agents;hardness results;ps rule;social welfare;perfect information;cycles;truthful pro\ufb01le;preference relation;houses;quality;existence;assignment problem;time algorithm;challenging problem;experiments;vast majority;rule;paper;ps;possibilities;number;same assignment;pro\ufb01le"}, "86d55c5a098689438ceb1d52bdd768da3b47f55f": {"ta_keywords": "optimal dynamic sensor subset selection;active sensor selection;dynamic sensor activation;sensor networks;stochastic approximation;efficient tracking mechanisms;active sensors;stochastic process;tracking;global optimality;cyberphysical systems;energy efficiency;algorithms;learning;local optima;internet;energy;infinite horizon;gibbs;squared error;process;high performance;time;constraint;key theoretical results;fidelity;things;mean number;key ingredients;methods", "pdf_keywords": "optimal dynamic sensor subset selection;decentralized tracking;sensor subset selection;sensor networks;dynamic sensor activation;stochastic process;markov chain;tracking;cyberphysical systems;centralized scheme;decentralized scheme;probability transition matrix;optima;iid process;benchmark;algorithm;process;internet;parametric distribution;urbashi mitra;\ufb01nal generalization;arpan chattopadhyay;time;things;numerical results;\ufb01rst extension;nov;problem;fundamental problem"}, "2c0ebf5479db7f76c1e15512676c16b9032343fb": {"ta_keywords": "gear shift control method;automatic automotive transmission", "pdf_keywords": ""}, "0d360a1256ccdfca58cf98d12243df8407fd442d": {"ta_keywords": "pretrained models;weight poisoning attacks;backdoors;vulnerabilities;security threat;attacks;weights;such attacks;attacker;large datasets;weight poisoning;regularization method;models;arbitrary keyword;nlp;dataset;model prediction;limited knowledge;tuning;tuning procedure;users;initialization procedure;question;task;ripple;tune;usage;surge;surgery;paper", "pdf_keywords": "untrusted software;security threat;vulnerabilities;malware;weight poisoning attacks;backdoors;attacks;weights;spam detection;computer security research;such attacks;attacker;weight poisoning;fundamental computer literacy;regularization method;serious threat;arbitrary keyword;attack;nlp;models;computer systems;graham neubig language technologies institute carnegie mellon university;toxicity detection;limited knowledge;dataset;model prediction;\ufb01netuning procedure;trend;initialization procedure;widespread adoption"}, "c14254fd285706e549d0dcc57ae74680164c9afc": {"ta_keywords": "sensitive inverse reinforcement learning;inverse reinforcement learning;reinforcement learning framework;markov decision processes;risk;passengers;behavioral economics;mdp;decisions;behavioral psychology;agent;ride;gradient methods;models;neuroscience;canonical grid world example;sensitivity;human;examples;sharing;use;performance;technique;origins;problem;second", "pdf_keywords": "inverse reinforcement learning;inverse reinforcement learning algorithm;inverse risk;sensitive reinforcement learning algorithm;sensitive reinforcement learning;markov decision processes;markov decision process;convex risk metrics;risk;passengers;rewards;loss function;transition probabilities;behavioral economics;pricing;ride;sensitive agent;agent;travel time data;gradient;decisions;convergence guarantees;models;observed behavior;price changes;canonical grid world example;eric mazumdar;examples;company;theoretical underpinning"}, "e10dba1d4a56a81429d6ec4c9b7bdc15ea75474b": {"ta_keywords": "malicious sensor observations;secure estimation;attack detection;false data injection attack;unknown sensor subset;sensor observations;estimation scheme;remote estimation;injection attack;multiple sensors;gaussian process;optimal filter;other sensor measurements;novel filtering;linear time;novel detector;cyber;observations;algorithms;physical systems;algorithm;numerical results;time;efficacy;order;paper", "pdf_keywords": ""}, "5403fd71810d098e572d9bd0f9ec10e96d6b6336": {"ta_keywords": "graph signal processing;graph symmetrization methods;point network transmission control problem;markov decision process;linear programming;probability transition graph;classical dynamic programming techniques;gsp approach;other mdp problems;mdp;networks;undirected graphs;optimal policy;subspace construction;standard algorithms;policy iteration;typical wireless system;gsp theory;computational complexity;large state space;more general construction methods;gsp;optimization problem;system information;subspace;proper subspace;structural information;function approximation;policy error;faster runtime", "pdf_keywords": ""}, "967b2d10b8b378f1da43fd4d9107826e540e1112": {"ta_keywords": "natural language grounded pose forecasting;pose;joint embedding;joint language;virtual human animation;accurate animations;animations;language2pose;movie script visualization;multimodal problem;natural language sentences;language;3d;neural architecture;available corpus;sentences;human judgment evaluation;human;robot motion planning;curriculum;humans;model;jl2p;data;objective metrics;easier sequences;other data;space;end;approaches", "pdf_keywords": "natural language grounded pose forecasting;joint multimodal space;pose;joint language;joint embedding;language2pose;parallel corpus;animation;available corpus;multimodal problem;3d;language;sentences;human;prediction accuracy;neural architecture;chaitanya ahuja language technologies institute;figure;philippe morency language technologies institute;model;input sentence;human judgment;data;jl2p;topose;objective metrics;user study;end training paradigm;space;paper"}, "0bdf1f3b79f4df5d5e11af1ea00379e1461e22fa": {"ta_keywords": "pdp generalization;automated dependency plots;machine learning;specific pdps;partial dependence plots;interesting pdps;raw feature spaces;pdps;datasets;features;models;various qualitative properties;pdp;generative model;single features;feature;example;sample behavior;instance;ice plots;selection;model;usefulness;model response;undesirable changes;class;visual way;multiple use;practical applications;standard metrics", "pdf_keywords": ""}, "d95973f0f0d86b758154e9a5f3d7434430d7856c": {"ta_keywords": "free optimization methods;accelerated gradient;norm;free method;convergence;method;low noise;estimates;rate;calculation;function value", "pdf_keywords": ""}, "194c5644c49e9e1b87990439fae05c98ba8b4fbb": {"ta_keywords": "materials science procedural text corpus;annotating materials synthesis procedures;synthesis extraction models;scientific information extraction systems;materials science literature;unstructured natural language text;scientific text;materials synthesis procedures;materials synthesis;corpus;synthesis sentences;shallow semantic structures;shallow semantic structure;synthesis procedures;synthesis planning;semantics;deeper scientific understanding;new resource;dataset;domain experts;graphs;further research;development;evaluation;training;millions;detail;specific challenges;community;scale analysis", "pdf_keywords": "synthesis extraction models;shallow semantic structures;shallow semantic structure;semantic structure;scienti\ufb01c information extraction systems;synthesis sentences;robust supervised entity tagging models;semantic representation;automatic extraction;corpus;semantics;scienti\ufb01c text;synthesis procedures;synthesis;materials science;materials;domain experts;text;dataset;machine learning models;new dataset;directed acyclic graph;structured frame;new resource;models;graphs;training;steps;step;dag"}, "03b68259f9e70d2007d40e5331c9ff31f2bb46b9": {"ta_keywords": "activity modeling;activity recognition method;activity models;training sensor data;unlabeled acceleration sensor data;appropriate training data;training data selection;activities;physical characteristics data;unlabeled sensor data;recognition performance;acceleration;physical characteristics;recognition method;end user;information;height;other users;gender;user;methods;effort;need;method;paper;advance", "pdf_keywords": ""}, "e11d6a031d5f85f372b0fda3ab62ca4ce2d89f2c": {"ta_keywords": "rule generation module;expert system;combinational logic;knowledge base;socrates;transformation rules;timing constraints;implementation;rules;rule;design;equivalent gate configurations;system;large design space;designer;substitutions;circuit;specific target technology;speed;library;minutes;users;matter;overall area", "pdf_keywords": ""}, "90fbeb4c871d3916c2b428645a1e1482f05826e1": {"ta_keywords": "reviewer module;caption generation;review;decoder learning framework;encoder;decoder;decoder model;review step;review steps;attention mechanism;decode;input;novel module;fact vectors;fact vector;number;states", "pdf_keywords": "source code captioning;sequence learning;image captioning;recurrent neural networks;rnns;machine translation;encoder;art encoder;text sequences;encoders;decoder;text sequence;decoders;cnns;conventional encoder;decoder framework;decoder systems;encoding;language;other language;representation;sequence;tasks;different tasks;input;transformation;output;context;related work;consistent improvement"}, "ddd74358d7e11535ee77e2c323dd662d115a0f20": {"ta_keywords": "natural language robot instruction following;robot policy;shot language;natural language instructions;shot object grounding;augmented reality data;objects;new objects;object;mapping;map representation;training;shot grounding output;exemplars;encodes;prior state;mentions;prior approach;art;instructions;presence;locations;method;reason;use;approach;problem", "pdf_keywords": "natural language object mentions;object mentions;shot language;shot segmentation model;augmented reality data;objects;instance segmentation mask;object;instruction;groundings;shot method;physical quadcopter;map;language;exemplars;observations;task;language modalities;mentions;continuous control;raw observations;instructions;policy design;world;effectiveness;process;centric;method;database"}, "97943a5dee3c6e36d01a6099acb9ec360ad0ee19": {"ta_keywords": "portmanteau generation;additional phonetic information;neural sequence;portmanteau creation;word formation phenomenon;portmanteaus;unsupervised word lists;language independent;words;new word;sequence;s2s;models;character;charmanteau;style model;target model;channel;end;standard source;level;performance;task;incorporation;methods", "pdf_keywords": "word formation phenomenon;language model;neural s2s model;input words;portmanteau generation;root words;portmanteau creation;portmanteaus;words;additional phonetic information;language independent;neural sequence;new word;vocabulary;s2s model;noisy channel model;output character;eric nyberg language technologies institute;s2s;models;character;neural system;features;model;style modelling;channel;candidates;charmanteau;tosequence;major contributions"}, "30f86d38f0660af5ea2e16d996434c72eee8c5ee": {"ta_keywords": "end speech processing;speech recognition;automatic speech recognition;other open source asr toolkits;dynamic neural network toolkits;main deep learning engine;major asr benchmarks;kaldi asr toolkit style;espnet;asr;new open source platform;software platform;feature extraction;pytorch;data processing;other speech;chainer;end;format;complete setup;recipes;several important functionalities;major architecture;paper;experimental results;experiments", "pdf_keywords": "end speech processing toolkit;other speech processing;toend speech processing;dynamic neural network toolkits;end asr techniques;speech recognition;multilingual asr experiments;end asr;neural end;end platform;whole asr pipeline;new open source toolkit;espnet;recurrent neural network language model;multihead decoder;main deep learning engine;dynamical neural network;rnnlm;data augmentation;asr;open source software;new open source platform;6preferred networks;jahn heymann8;multichannel;attention methods;nanxin chen1;end;3ntt communication science laboratories;babel"}, "36bca9d41de386fce5dce06999a45a802a7c4f41": {"ta_keywords": "conditional preference networks;modeling preferences;net algorithms;dependency graph;acyclic cp;nets;cp;arbitrary bounds;equiprobable manner;domains;compact formalism;novel algorithm;properties;indegree;method;performance", "pdf_keywords": ""}, "0c5bfa2d4bb351a479073cb358c3ae6f7ecf0476": {"ta_keywords": "corpora annotations;nlp applications;annotation modules;natural language processing;shelf nlp tools;corpus;nlp community;annotators;nlp;text representation;popular corpora;syntactic tasks;library cogcompnlp;python interface;feature extraction;extensive suite;datasets;sister project cogcompnlpy;reader module;language;search;language constructs;features;text;training machine;memory statistics;modules;considerable engineering effort;module;data", "pdf_keywords": ""}, "a2aa642db090b3aa28a44ccbc3c51fdb0be8335b": {"ta_keywords": "neural constituency parsers;neural parsers;domain treebanks;benchmark treebanks;structured output prediction;rich input representations;output trees;corpus;domain corpora;stronger generalization;encoder representations;constituency;trees;generalization;domains;larger text spans;other domains;higher exact match accuracy;larger relative improvement;training;shot setting;results;performance;degree;art results;state", "pdf_keywords": "neural constituency parsers;neural parsers;benchmark treebanks;english web treebanks;parser;structured tree decoder;order parser;chinese corpora;corpus;art parsing results;domain corpora;bert encoder;ofdomain generalization;generalization;shot generalization properties;neural models;constituency;trees;english;berkeley;brown;other domains;liu;klein;abstract;questions;results;novel integration;kitaev;zhang"}, "de5834305ea419c25b17f0c8d27bad6a5feb311a": {"ta_keywords": "scale chess commentary;natural language generation;natural language descriptions;commentary;chess games;truth commentary texts;chess game;chess move;direct move descriptions;trainable neural model;pragmatic context;multiple pragmatic aspects;individual moves;predictions;game state;various baselines;models;fluency;data;correctness;task;styles;outputs;end;subset;terms;large variety;human study;methods;paper", "pdf_keywords": ""}, "47234fca1b14666d72bc5df0e2d911ff7cdea688": {"ta_keywords": "hypergraph spectral clustering;edge weights;nodes;algorithms;spectral clustering;binary edge weight case;hypergraph;hyperedges;random hypergraph model;polytime algorithms;hsclr;hidden partition;weighted stochastic block model;hsc;computational barrier;hsc outputs;weights;partition;optimal results;sum;stochastic block model;inline;formula;math;paper;performance analysis;multiway measures;analysis;local refinement;random guess", "pdf_keywords": "hypergraph spectral clustering;spectral clustering;binary edge weight case;edge weights;weighted stochastic block model;pairwise similarity information;nodes;algorithms;hidden partition;wise optimal results;new algorithm;partition;computational barrier;celebrated algorithm;sketching algorithm;hsclr;local re\ufb01nement;hsc;relevant model;information;random guess;sum;ones;work;model;may;hsc outputs;st;changho suh;kangwook lee"}, "9a41111cf881b052555985bd8cf304ef9fc4f6d5": {"ta_keywords": "large corpus;corpus;corpora;coupling constraints;coupling;potential instance labels;document structure;distant ie;such sections;sections;same label;task;list;items;example;same section;second example;analysis;noise;performance;f1;way", "pdf_keywords": "target corpus;structured corpus;test corpus;potential instance labels;training data svm classifier;diebolds pipeline;training data;distant ie;diebolds;conjunctive list;many nps;example;coupling constraints;list;bootstrapping;document structure;graph mrw;nps;sections;same category;coupling schemes;many types;coupling;edges;ie;section;pseudo;noise;association;way"}, "c8a95217cde1bc893b230297250918818aa01dd7": {"ta_keywords": "backpack mobile mapping system;systematic mapping framework;degenerate environments", "pdf_keywords": ""}, "71cdf94d13cc6c497dcc2dcb20893fe64cfaf62e": {"ta_keywords": "text generation model;text generation;current interactive writing assistants;controllable language generation;word clusters;language models;topics;upcoming topics;candidate topics;plausible continuations;text;topically;generation;possible continuations;human authors;transformers;framework;centers;large transformer;authors;components;subset;topical directions;limitation;multiple candidate;method;set;user;mind;output adheres", "pdf_keywords": "text generation model;text generation;interactive writing framework;candidate topics;many topics;userchosen topics;topics;topic options;upcoming topics;word clusters;generation;prompt;input prompt;topic;sentences;elections;election;human evaluation;evaluation;multiple candidate;democratic election;possible continuations;book;books;novel model;framework;novels;new book;components;component"}, "edb49aa423afc210facec998277923c4b75e4648": {"ta_keywords": "antiferromagnetic phase transitions;antiferromagnetic phase transition temperature;zncr2se4;structural phase transition;neutron diffraction;cr3;magnetostriction;magnetic interaction;structural properties;orthorhombic symmetry;se2;ions;temperature;correlation;chains;tc;function;tn;cooperative displacements;means", "pdf_keywords": ""}, "4e749b2e0728044af44d50a708fc99d49359ea0b": {"ta_keywords": "languages;unsupervised character;sequence models;linguistic knowledge;level transduction problems;language;level transduction;explored unsupervised learning scenario;unsupervised tasks;kannada;attention;comparative error analysis;native script;state models;neural;russian;arabic;text;different error classes;character;finite;errors;testbeds;sequence;different types;recent approaches;model classes side;distributions;underlying process;flexibility", "pdf_keywords": "many natural language sequence transduction tasks;transliteration;informal romanization decipherment;language translation;related language translation;informal romanization;languages;sequence models;language;phoneme conversion;linguistic knowledge;level transduction tasks;kannada;seq2seq approaches;different alphabets;seq2seq models;simpler decodingtime model combinations;native script;comparative error analysis;decipherment;unsupervised character;grapheme;arabic;russian;generative process;sequence;unsupervised tasks;different error classes;text;level tasks"}, "9700940262cd5e797ab81eee464c3b3a16295cba": {"ta_keywords": "speech enhancement;speech recognizer;speech recognizers;automatic speech recognition;speech dereverberation;dynamic variance adaptation;dereverberated speech;adaptive training scheme;variance adaptation;static adaptation scheme;model adaptation;relative error rate reduction;reverberation;clean speech;novel parametric variance model;efficient interconnection;noise;robustness;dynamic capabilities;preprocessing;recognition;model;dynamic components;dynamic component;evaluation;final error rate;parameters;presence;method;paper", "pdf_keywords": ""}, "0d2a1c0724743de0cb74463466b075598ba36c45": {"ta_keywords": "alarms;alarm;medical devices;medical equipment;labour sciences research grants;health;study;purpose;present status", "pdf_keywords": ""}, "f01f4808263ecfa221f856c34d3420166dbf5930": {"ta_keywords": "driver confusion status detector;driver confusion status detection;car navigation system;road driving;recurrent neural networks;recurrent neural network;classifiers;classifier;driver;multimodal sensor data;neural network;car;term memory;confusion level;navigation system;traffic;confusion status;traffic conditions;multiple features;corpus;sensors;data;logistic regression;forward;behavior;different types;feed;paper;method;variety", "pdf_keywords": ""}, "ff7b5379641875be7357766af0b1e2bd55c74cc8": {"ta_keywords": "information retrieval;differentiable search index;text model;whole retrieval process;dual encoder models;corpus;relevant docids;documents;corpus sizes;text;identifiers;models;information;variations;other words;dsi model answers;strong baselines;single transformer;model;parameters;maps string;dsi;paper;training procedures;new paradigm;interplay;experiments;appropriate design choices;end", "pdf_keywords": "document retrieval task;information retrieval;retrieval tasks;search system;retrieval;next generation search;whole retrieval process;novel indexing;document representation;indexing;di\ufb00erentiable search index;text model;generative indexing;documents;docids;relevant docids;model training strategies;di\ufb00erent model architectures;sequence;seq2seq;transformer model;terms;text;query;dsi model answers;alternative architecture;training strategies;other words;knowledge;maps string"}, "3cd4ae1cac866f853bb3276d215cff18df371b67": {"ta_keywords": "noisy speech recognition;robust speech recognition;microphone speech recognition task;augmented discriminative feature transformation;discriminative feature transform;discriminative training;discriminative language modeling;chime challenge benchmark;simple noise suppression methods;second chime challenge;discriminative methods;feature transformation;various feature transformations;deep neural networks;art asr techniques;asr;noisy signals;arbitrary features;noise;clean signal;mbr;dlm;efficient combination method;binary;minimum bayes risk;source;addition;arrival;separation community;combination", "pdf_keywords": ""}, "ceef266c59698999c9283a0cda852d8bc1ce27ea": {"ta_keywords": "language models;isotropy enhancements;isotropy;isotropy enhancement methods;performance improvements;space changes;essential linguistic knowledge;space;cwrs;tuning;downstream tasks;desirable geometrical property;geometry;extent;contrast;gap;experiments;paper;affect;dramatic growth;case study;directions;fine;number", "pdf_keywords": "language models;essential linguistic knowledge;isotropy;space changes;tuning;isotropy enhancement methods;performance improvements;space;bert;improved performance;cwrs;downstream tasks;extent;\ufb01ne;contrast;experiments;lms;gap;base versions;roberta;abstract;geometry;paper;in\ufb02uence;technology;affect;advanced studies;experimental setup;tehran institute;khatam university"}, "b719fc66b173f8e9e0624317bb00abf10a4d5606": {"ta_keywords": "basketball game video;video image;video data;image frames;video shot;temporal segmentation algorithm;temporal segmentation;basketball games;basketball game;long segmentation time;video shots;edge detection;histogram;continuous frame difference;histogram statistics;deep learning model;rgb space;deep learning;video;hsv space;boundary detection;multimedia research;frame difference;detection rate;quantization level;window frame difference;dimensional feature vector;optimization algorithm;processing;adaptive window", "pdf_keywords": ""}, "18ef33a6e040b49ba475e586202932cecbafba0d": {"ta_keywords": "event influence generation;question answering;language models;event influences;reasoning chain;relevance;generations;human judgments;questions;strong baselines;influence;context;background knowledge;eigen;reference;evaluation metrics;wiqa;benchmark;closeness;distance;nature;rouge points;terms;paper;performance;method", "pdf_keywords": "event in\ufb02uence generation;language models;background reasoning;events;reasoning chain;event in\ufb02uences;event;generation;downstream tasks;relevance;reasoning;human judgments;generations;understanding processes;large corpus;context;strong baselines;reference;evaluation metrics;eigen;evaluation;language technologies institute;challenges;terms;yiming yang;summary;wiqa;relationship;research;in\ufb02uences"}, "e5acad5bba23a8c3a9f7cd24f7694ab10357ebc7": {"ta_keywords": "speech recognition;decent speech dereverberation;voice activity detection;speaker reverberant condition;singlechannel;spatialized wsj1;separation performance;beamforming;2mix corpus show;end dereverberation;multichannel conditions;advanced frontend subnetworks;sdr;asr criterion;recognition;advanced frontend;improved numerical stability;end approach;relative reduction;end;masks;numerical stability;system;previous framework;work;experiments", "pdf_keywords": "decent speech enhancement performance;speech recognition;speaker reverberant condition;decent speech dereverberation;speechlab;reverberant conditions;separation performance;spatialized wsj1;speaker condition;voice activity detection;beamforming;singlechannel;multichannel conditions;2mix corpus show;good asr results;improved numerical stability;recognition;severe performance degradation;noisy scenarios;numerical stability;large performance gap;asr criterion;end system;shinji watanabe3;separation;denoising;end dereverberation;relative reduction;end training;dereverberation"}, "4b9b7240ef9b6bc442044684ed5646ef02897d87": {"ta_keywords": "planning domain;planning competition domain;mdp;academic;domains;domain;domain variables;real world applications;concurrent actions;research;challenges;true stochasticity;previous contests;success;paper;limits;characteristics;order", "pdf_keywords": ""}, "c3aa698b562e91f78a042b938ffce1877b6e859c": {"ta_keywords": "awful german language;natural language processing;nominal compounds;semantics;germanet;committees;program", "pdf_keywords": ""}, "728a6850882a0d8ef5551949cc2baee1e1667cd8": {"ta_keywords": "optimal bribery schemes;bribery problem;voting over combinatorial domains;bribery;computational complexity;candidate set;cartesian product;most cases;agents;nets;variables;domains;cp;preferences;set", "pdf_keywords": ""}, "df8ae2068d17d969db6ab2d27108776e99413975": {"ta_keywords": "natural language inference;many natural language processing;harness external knowledge;nlp;textual information;external knowledge;semantic search;science questions domain;nli problem;learning;nli;text;datasets;models;premise entails;hypothesis;large scale;methods;contradicts;results;significant attention;techniques;present approaches;graph;question;implications;problem;applications;order;performance", "pdf_keywords": "external knowledge source;dbpedia;wordnet;conceptnet;harness external knowledge;external knowledge;entailment relationships;background knowledge;knowledge;external sources;text features;other sources;nli;nli problem;features;hypotheses;models;text;science questions domain;hypothesis;scitail science questions;graph;results;premise;distinct approaches;premises;techniques;model;framework;implications"}, "a7abd783de8d21d640e41d31ec89f2c1caec4e42": {"ta_keywords": "interpretable word sense disambiguation;word sense disambiguation;interpretable word sense inventories;word disambiguation;disambiguation results;sense predictions;sense representations;word senses;interpretability;hypernyms;predictive model;knowledge;art wsd models;wsd;texts;web interface;predictions;tool;free counterparts;free;correctness;trust;access;usage examples;users;powerful feature;system;systems;wealth;images", "pdf_keywords": "word sense disambiguation;interpretable wsd;wsd models;interpretable word sense inventories;wsd web interface;word sense induction;hypernyms extraction;sense representations;restful wsd api;words disambiguation;word disambiguation;single word disambiguation;disambiguation results;wsd system;sense usage examples;text corpus;super sense induction building sense representations labeling senses;disambiguation;wsd model index postgresql;labeling senses;sense predictions;web interface;interactive web;distributional thesaurus;lexemes;texts;restful api;user interface;human users;embeddings"}, "58961f0ea3291ddab697fbe5be999a0793b0efaf": {"ta_keywords": "muc codes;access sets;randomized construction;decodability;update cost;storage;codes;nodes;certain subsets;significant savings;practical importance;design;existence;paper;metrics;function;analysis;results", "pdf_keywords": ""}, "f75e691daae9133941c9a083e319b39bd837d456": {"ta_keywords": "joint knowledge embeddings;entity alignment;knowledge graph completion performance;joint semantic space;entities;dimensional semantic space;semantic distance;wikipedia links;alignment performance;relations;realworld datasets;alignment;baselines;external information;small seed;various kgs;costly manual feature construction;parameter sharing method;novel approach;favor;significant improvements;paper;process;method;methods;experiment results", "pdf_keywords": ""}, "80a085a79ac6cee94f21d21ab8ca302458c4e131": {"ta_keywords": "cloud;dnn inference;shredder;partial dnn inference;cloud service;information degradation;dnn;noisy data;world dnns;privacy;network;trainable parameters;privileged data;remote servers;inference accuracy;high accuracy;loss functions;service provider;edge;data;additive noise;accuracy;inference;noise;additive noise distribution;tensor;mutual information;input;weights;information content", "pdf_keywords": "inference privacy;learning noise distributions;heavy inference;deep neural applications;cloud;privacy;shredder;additive noise distributions;edge device;inference accuracy;noise tensor;information degradation;noise;offline learning phase;noise injection;inference;offline learning process;network;laplace distributions;loss function;data;life dnns;learning process;alternative computing technologies;distribution;weights;paper;samples;end framework;key idea"}, "464b47a6a395fa1338e230254965cf5f669e715c": {"ta_keywords": "neural machine translation techniques;resource machine translation;polysynthetic languages;character trigrams;random babbling baseline;standard phrase;resource scenarios;model;range;systems;runs;end;bad fit;ii;spite;theory", "pdf_keywords": ""}, "ca57443fcb87f03267fccee162a4924c56062c6f": {"ta_keywords": "training\u306b\u3088\u308b\u975e\u8a00\u8a9e\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3\u30b9\u30ad\u30eb\u306e\u6539\u5584\u306b\u95a2\u3059\u308b\u691c\u8a0e;computer", "pdf_keywords": ""}, "d3304b926cfcd91110bd5ba01db21d26ce5fca2d": {"ta_keywords": "paraphrastic sentence embeddings;neural machine translation;neural machine translation output;sentential paraphrases;english paraphrase pairs;paraphrase pairs;bilingual sentence pairs;sentences;translation;translated bitext;many languages;large training sets;training data;rare words;data quality;bitext;repetition;par;wieting et al;human;clear differences;back;prior work;amount;length;purpose;ability;advantage;domains;use", "pdf_keywords": "paraphrastic embeddings;paraphrastic sentence embeddings;generated paraphrase corpus;paraphrase datasets;pretrained word embeddings;paraphrase pairs;neural machine translation output;effective paraphrase;humanwritten sentences;sentences;embeddings;language pairs;attention;several language pairs;translating;training data;repetition;human;par;generation technique;data sources;ppdb;\ufb01ltering;data;nmt systems;training bitext;clear differences;less work;paper;techniques"}, "305a1251a68fb16835876d8c99de498472c0cd8f": {"ta_keywords": "coded computation;computational locality;locality;computation scheme;reed muller code;locality properties;computation;code;computing;multivariate polynomial functions;codes;robustness;function;scheme;unavailable workers;new notion;scale;lens;new approach;viewpoint;paradigm;theory;principles", "pdf_keywords": ""}, "3332dc72fbe3907e45e8a500c6a1202ad5092c0f": {"ta_keywords": "deep clustering;speaker mixtures;source separation;spectral clustering;spectrogram;channel mixtures;deep network;target spectrogram;input mixtures;deep learning framework;speaker;multiple speakers;mixtures;separation;speakers;previous deep network approaches;embeddings;clustering step;segmentation labels;wise affinity matrix;ideal affinity matrix;speech;cocktail;distinct signal class;segmentation implicit;signal quality;party;decodes;noise;vectors", "pdf_keywords": "channel speech separation methods;speech separation experiments;speech separation task;acoustic source separation;speech separation;various auditory scene analysis;deep clustering;spectrogram;speech signal;separation;frequency regions;target speaker;speaker;audio domain;deep learning framework;segmentation;discriminative embeddings;speech;multiple speakers;spectral envelope;speakers;generative models;complex features;mixture;regions;frequency elements;pitch;model;classi\ufb01ers;onset"}, "6e7cfed8815cce163efac9d17b1109849c050c6b": {"ta_keywords": "learning page;web pages;independent heuristics;data", "pdf_keywords": ""}, "7038b181f776e9cd587d4d61cb68692fdac8ec26": {"ta_keywords": "signalized traffic systems;traffic signal control parameters;signalized traffic;traffic signal control status;traffic flow data;traffic flow networks;koopman operator applications;congestion;koopman operator theory;koopman operator;dynamical mode decomposition;queue lengths;oscillatory modes;unstable queue growth;phase timing;complex oscillatory dynamics;intersection;measured data;dmd;control;analysis;related algorithm;free approach;knowledge;early identification;application;method;paper;several problems;potential", "pdf_keywords": "signalized traf\ufb01c systems;koopman operator applications;traf\ufb01c signal control parameters;koopman operator theory;koopman operator;dynamical mode decomposition;traf\ufb01c signal control status;oscillatory modes;queue lengths;unstable queue growth;congestion;traf\ufb01c \ufb02ow data;complex oscillatory dynamics;phase timing;networks;network;control;ieee;dmd;traf\ufb01c;measured data;interactions;related algorithm;analysis;ds;intersections;structure;early identi\ufb01cation;intersection;esther ling"}, "1e58c9d1153d2f25d94b3a12b785bd7abe43bd1c": {"ta_keywords": "human activity recognition datasets;deep learning;change point detection methods;autoencoder;improved representations;classification;sequential sensor data;change points;large datasets;neural network;sequences;likely class changes;representations;sequence;dissimilar sequences;data;examples;extensive synthetic simulations;unsupervised manner;points;quality labels;recent years;improved results;speech;such contexts;impressive performance gains;dissimilar pairs;novel framework;world;domains", "pdf_keywords": "change point detection;change point detection algorithms;change point detection methods;human activity recognition datasets;change points;semisupervised context;autoencoder;improved representations;likely class changes;neural network;unlabeled sequence;unsupervised manner;classi\ufb01cation;representations;sequences;sequence;data;points;dissimilar sequences;examples;extensive synthetic simulations;improved results;electrical;school;useful approach;computer engineering;dissimilar pairs;paper;novel framework;technology"}, "5bad092098ba7400e19468a06cb8b238c43b7637": {"ta_keywords": "individual freedom;state", "pdf_keywords": ""}, "c81bb5ff79e8c7f65a3e28b7ba52d90deaa32fde": {"ta_keywords": "wikipedia editor success;arabic wikipedia;other languages;collaborative editing;language choice;social influence;code;switching;online community;social motivations;technical language;social effect;syntactic constraints;pages;topics;case code;regions;work;predictor;addition;task", "pdf_keywords": ""}, "f26f17ec49f2593bcc926051394871480a80c0c2": {"ta_keywords": "difficult language pairs;bilingual word;gaussian mixture model;word pairs;languages;density matching;densities;normalizing flow;probability densities;generalization;mappings;spaces;vectors;linear transformations;formulation;robustness;paper;recent approaches;sets;respect;attractive properties;approach;method", "pdf_keywords": "bilingual lexicon induction;word embeddings;bilingual word;bilingual mapping;semantic similarity;different languages;gaussian mixture model;languages;density matching;densities;graham neubig language technologies institute carnegie mellon university;probability densities;words;unsupervised method;single vector space;benchmark data;spaces;mappings;vectors;vector;computational models;space;components;di wang;linear transformations;paper;dema;chunting zhou;xuezhe ma;sets"}, "28028458d75bf9281200389a880741eb6d06a3a4": {"ta_keywords": "inductive logic programming methods;inductive logic programming;abstract datalog specifications;specification recovery;database software;software specifications;test suite;recall;world software system;grendel2;examples;case study;techniques;modules;candidate hypotheses;precision;extensions;lines;certain type;operation;specifications;task;shelf;determinations;performance;high rates;third;set", "pdf_keywords": ""}, "436380dd75d8ff3f2debb29913bd2fe8dde0b684": {"ta_keywords": "source separation results;complex matrix factorization approach;source separation;complex matrix factorization problem;conventional nmf methods;speech mixtures;effective separation;separation process;spectral phase;spectral magnitudes;nmf problem;grid corpus;decomposition process;objective quality evaluations;matrix;phase;joint modeling;magnitude;simple transformations;methods;improvement;paper;results", "pdf_keywords": "multi channel source separation;single channel source separation;complex matrix factorization approach;channel source separation;complex factorization method;complex matrix factorization;generalized nmf method;conventional nmf methods;source separation;channel separation domain;speech enhancement;spectral magnitude;spectral magnitudes;music transcription;phase spectrum;decomposition stage;matrix;phase;karan nathwani;joint modeling;magnitude;cmf;nathwani;new method;method;algorithm;chaitanya ahuja;chahuja;indian institute;kanpur email"}, "6992f54509c139455c3cffa9b0e4ae5c19ebff82": {"ta_keywords": "multilingual asr system;multilingual conversations;medical domain;network", "pdf_keywords": ""}, "30c6be4c7f549a2ec7328d24ecc0a54fbf90d41c": {"ta_keywords": "optimal control policies;optimal policies;policy iteration;markov decision processes;policy structure;wireless communication networks;wireless networks;faster convergence rate;large scale networks;value iteration;moderate complexity manner;complexity challenges;many systems;classical methods;negligible loss;new approach;alternative approach;good models;performance;properties;numerical results;goal herein;dimension;solutions;herein", "pdf_keywords": ""}, "4da018847a0f44378e6a1ded93fee672a3c7c370": {"ta_keywords": "automatic speech recognition;encoder network architecture;connectionist temporal classification;fast inference speed;end asr system;different asr tasks;fast inference;recognition performance;asr;ctc achieves;predict;ctc;mask;standard ctc model;tokens;new training;partial target sequence;conformer;computational resources;model;insert tokens;inference;end;architecture;wsj;auxiliary objective;length;performance;ar;system", "pdf_keywords": "end speech translation;encoder network architecture;different asr tasks;inference speed;standard ctc model;nar models;ctc;mask;partial target sequence;autoregressive models;improved mask;new training;model;eval92;lm;auxiliary objective;inference;performance;insert tokens;dlp;conformer;wsj;c3;architecture;art model;degradation;length;approaches;potential application;competitive performance"}, "abaf39dc9d1b156ddf387230611f5102378d052c": {"ta_keywords": "unsupervised ocr correction;textual variants;large corpora;texts;corpora;human annotation;word error rates;unsupervised techniques;unsupervised training;correction model;supervised methods;historical newspapers;books;novel approach;uniform error model;noisy target outputs;single inputs;evidence;training;source;character;half;ways;addition", "pdf_keywords": "unsupervised ocr correction;onebest ocr transcripts;unsupervised ocr;best ocr output;ocr output;texts;australian national library;text collection;rdd newspaper dataset;newspapers;large corpora;multiple candidate texts;human annotation;single input text sequences;textual variants;many corpora;chronicling america collection;duplicate documents;library;books;domain books;data collection;daily dispatch;unsupervised training;sources;correction model;input sequences;computer information;evidence;trove"}, "63bfe58735f44b0af24da3c2cb6b1651b001b83c": {"ta_keywords": "secret sharing;communication complexity;secure multiparty;several cryptographic protocols;secure network;eavesdropping;low communication cost;complexity;secret;general network;protocols;communication;direct communication links;network;networks;dealer;dealer condition;shares;computation;algorithm;threshold;shamir;worst case;nodal;deterministic solution;participants;paper;solutions;case;participant", "pdf_keywords": ""}, "5d69380565aa258bfa54005c9ba05e30675be227": {"ta_keywords": "such exploratory learning methods;hierarchical classification tasks;exploratory learning;semantic drift;flat classification task;clueweb09 corpus;seeded classes;naive extension;exploratory em method;html table datasets;ontology;such unanticipated classes;seed class f1;optdac;dac;text;terms;exploreem;paper;previous work;method;subsets;nell;dalvi et al;presence;problem", "pdf_keywords": ""}, "62d6ccd01c2e022a385add5e689b4561b0fbfd88": {"ta_keywords": "speaker diarization;novel speaker diarization method;speech segment proposals;speaker embeddings;many speech applications;region proposal network;standard diarization systems;speech;neural network;rpnsd;modules;problem;paper;method;various scenarios;same time;satisfactory results", "pdf_keywords": "speech segment proposals;novel speaker diarization system rpnsd;speaker diarization;novel speaker diarization method;speaker embeddings;diarization datasets;object detection;region proposal network;cnn;audio;segment boundaries;neural network;vector baseline;rpnsd;remarkable improvements;input;model;state;method;frameworks;paper;conclusion;same time;experimental results"}, "9ba545841b837fa077579290e252eb00351ebeb0": {"ta_keywords": "federated learning;novel communication compression strategy;biased gradient estimator;communication complexity;local loss functions;learning;compression;marina;efficient method;gradient differences;heterogeneous datasets;new communication;clients;diana method;order methods;expectation form;feature;diana;finite sum;variants;practical performance;strategy;second method;first method;partial participation;pp;case;vr;key;mishchenko et al", "pdf_keywords": "federated learning;local loss functions;deep learning models;novel communication compression strategy;new ef\ufb01cient methods;compression;clients;gradient differences;training;marina;feature;diana method;partial participation;strategy;\ufb01rst method;expectation form;second method;case;\ufb01nite sum;modi\ufb01cation;mishchenko et al;sun;ment"}, "ea1f61270480a8dec54ec571c0e6ce116d096241": {"ta_keywords": "polyphonic sound event detection;polyphonic sound event detection method;speech recognition;sound event;hidden markov model;hmm state output probability;term memory recurrent neural network;markov model hybrid system;convolutional bidirectional long short;term memory;neural networks;multiple frames;duration change;sequential data;detection results;hybrid system;wise detection methods;frame;cblstm;hmm;state;segment;smoothing process;art approach;method;study", "pdf_keywords": ""}, "598321d9c3eb5c035b449e19e539b6fa04b3802a": {"ta_keywords": "available general web crawl;large web corpus;tokens;commoncrawl;creativecommons license family;urls;languages;date", "pdf_keywords": ""}, "8f1f43408baf1ccb0ec3e7985592326c83ee276d": {"ta_keywords": "dialog system;statistical machine translation;twitter scripts;semantic similarity retrieval;semantic similarity;cosine similarity evaluation metrics;cosine similarity retrieval;human subjective evaluation;chat;response generation;objective metrics;tf;idf;phrase;smt;ebdm;movie;approaches;example;performance;advantages;disadvantages;best performance;system;techniques;method;experimental results;paper;experiments", "pdf_keywords": ""}, "07a9f47885cae97efb7b4aa109392128532433da": {"ta_keywords": "high translation quality;cross attention;attention variant;cross attention head;encoder;attention;bleu;bleu scores;attention heads;decoder;bleu drop;transformer;different language pairs;self;importance;agnostic gaussian distributions;parameters;direction;recent work", "pdf_keywords": "multiheaded attention;high translation quality;neural machine translation;translation quality;attention head;gaussian attention;attention;attention mechanisms;decoder self;encoder;transformer architecture;transformer;decoder;linguistic properties;different language pairs;baseline transformer;token representations;better model;importance;distance subject;vaswani et al;information;speedup;direction;ef\ufb01ciency improvements;recent research;mha;verb agreement;outputs;standard normal distribution"}, "8afbc4188be9e9452ce1fe868ebe217179d36793": {"ta_keywords": "noisy speech spectra;sparse representation;clean speech exemplars;sparsest possible linear combination;noisy spectra;noise exemplars;clean spectrum;individual speech;spectrum;recognition;observed spectrum;compositional models;linear transforms;noise sources;maximum likelihood linear regression;new acoustic condition;basis atoms;mllr;model parameters;linear;nmf;observed signal;dictionary;techniques;methods;example;collection;recent prominence;parts;reconstruction", "pdf_keywords": ""}, "3426fadf73a5ce418486e640b26b3d2470d932b5": {"ta_keywords": "multilingual adversarial speech recognition;end speech recognition models;multilingual end;phonetics;languages;phonology;language family;adaptation;similarity;geographical location;relative importance;target;dimensions;findings;light", "pdf_keywords": "multilingual asr model training;multilingual asr models;multilingual speech dataset;target language;multilingual seed model;phonetic inventory;multilingual end;languages;auxiliary phoneme;language family;phonology;language;proximal languages;adaptation data;end asr framework;speech;target speakers;other seed models;models;target;cmu wilderness;context;speakers;model;similarity;knowledge;relative importance;orthography;geographic location;objectives"}, "8de431e0e62653711136836642af38179731c2f0": {"ta_keywords": "theoretically secure erasure codes;distributed storage;storage systems;storage;passive eavesdroppers;erasure;security;high availability;repair operations;possible security levels;codes;active adversaries;repair;demand security;data movement;reliability;malicious acts;data;schemes;bandwidth requirements;lower bounds;information;algorithms;network;risk;system;system parameters;paper;additional appealing feature;constructions", "pdf_keywords": "secure erasure codes;distributed storage;storage systems;storage;passive eavesdroppers;explicit codes;high availability;security;repair algorithms;codes;reliability requirements;repair operations;reliability;active adversaries;demand security;repair;data;lower bounds;ef\ufb01ciency;malicious acts;mbr;ieee;information;network;algorithms;msr;system parameters;paper;system;additional appealing feature"}, "fdf1aec2da3597010c31138159574b1016019f73": {"ta_keywords": "computational social choice;preference reasoning areas;preference reasoning;group decision making;computer scientists toolkit;algorithms;voting;computer science;resource allocation;system building;research;human interaction;data;equal importance;complexity analysis;tools;development;others;topics;theoretical results;results;impacts;empirical part;application;areas;new avenues;work;tremendous progress;techniques;last decades", "pdf_keywords": ""}, "538deb39d57bef62833c492a56c796a2bafa340f": {"ta_keywords": "active learning;support vector machines;entity recognition;shallow parsing;radial basis function kernels;labels;multiclass task;dataset;class;majority class;instances;binary task;criterion;linear;thesis;use;distribution;cases;experiments", "pdf_keywords": ""}, "63e7e3b16e03da62a2c535ac9cfccfa3ae48b292": {"ta_keywords": "accurate ai team;ai team;ai recommendation;ai accuracy;ai;ai systems;team utility;ai practitioners;human expert;team performance;predictable performance;human overseer;best teammate;stakes datasets;datasets;task;human;utility;final decisions;decision making;accurate system;improvements;criminal justice;example;stakes domains;actions;slight sacrifice;system;experiments;finance", "pdf_keywords": "ai teaming;ai teams;ai collaboration;most accuracy ai;ai optimization problems;ai recommendation;ai systems;team utility;automation accuracy;human skill;team performance;teamwork;human overseer;traditional model optimization;team;task;machines;highest team performance;training;individual accuracies;human;people;stakes datasets;decision making;datasets;utility;loss functions;current optimization approaches;cost;log"}, "b2baf9e053c32abfb3c8658b9bc6d6790ae671cb": {"ta_keywords": "unknown word detection;novel eye movement features;eye gaze;support vector machines;gaze duration;natural reading;svm;random forests;word rarity features;svms;tracking features;eye;unknown words;detection;detection performance;learning;machine;previous approach;method;non;paper;rf;previous work", "pdf_keywords": ""}, "15931520cce546bbf19b4cebeb4161c4debeabe7": {"ta_keywords": "mechanical turk;multiple winners;voting;voting rules;ballot;votes;board elections;many candidates;collective decisions;voters;heuristics;winners;agent;agents;uncertain situations;behavioral data;winner;human cognitive constraints;many real world situations;better outcome;most approvals;many scenarios;scenarios;behavior;approvals;uncertainty;committee;manipulation;world behaviors;additional effort", "pdf_keywords": "heuristics model realworld decision;utility heuristic;mechanical turk;heuristics;approval voting;human cognitive constraints;best predictive power;attainability;threshold;uncertainty;accuracy;winner;behavioral data;scenarios;behavior;world behaviors;models;effectiveness;paper;model;account;size;novel model;degrees"}, "931cbd9d689e9fd6bd91f4e8e1dbdd7fbb6df9de": {"ta_keywords": "single channel target speech recognition;target speech recognition system;speech separation mechanism;speech separation;promising target speech recognition results;automatic speech recognition;speech mixtures;speech enhancement;speech features;end speakerbeam;speakerbeam;e2e separation systems;speaker;single neural network;e2e asr system;neural network;speakers;diarization ability;e2e training;recognition results;mixtures;mixture;e2e;attention;asr;pipelines;sequence;characters;system;such systems", "pdf_keywords": ""}, "a445adf335aa5212f929f67c1ca56a62c221b43a": {"ta_keywords": "predictive models;unknown unknowns;predictive model;discovery;training data;guided exploration;systematic biases;agnostic methodology;model incompleteness;explore;high confidence;feature similarity;confidence scores;exploit strategy;data;instances;real world;open world;partitions;feedback;oracle;cases;test time;multiple partitions;representations;policies;incorrect labels;mismatch;such errors;phase approach", "pdf_keywords": "discovery;unknown unknowns;predictive model;similar feature values;oracle;feature similarity;algorithmic framework;exploit strategy;partitions;queries;instances;test data;multiple partitions;modelagnostic methodology;explore;data;wild;constituent components;\ufb01xed budget;framework;optimization problem;feedback;step approach;true labels;results;evidence;con\ufb01dence scores;labels;\ufb01rst;method"}, "947750c717a5fbd17fc52758322d1ca201c4c6bc": {"ta_keywords": "tweet classification;nlp researchers;entity recognition;safety information mining;word segmentation;twitter;unorganized information source;disaster;safety;relief efforts;east japan earthquake;mine information;people;collaborative effort;large scale;efforts;effective systems;system;paper;area", "pdf_keywords": ""}, "c45a23e7c565169c5a55898683aceac458c116bb": {"ta_keywords": "3rd chime speech separation;speech recognition systems;front speech enhancement;lstm;scale rnn language models;recurrent neural networks;acoustic models;rnns;deep neural network;high recognition accuracy;term memory;adaptive training;language modeling;recognition challenge;features;speaker;feature systems;data augmentation;frequency cepstral coefficients;mel;dnn;enhancement network;test time model combination;model;word error rate;sri system;mfcc;training methodology;channel;real test data", "pdf_keywords": ""}, "2b0aa68ef2c1773642ca91627a4fc03f536cc5fc": {"ta_keywords": "statelens", "pdf_keywords": ""}, "f762ce106b37728df1126375981a02a589e0497c": {"ta_keywords": "stochastic gradients;gradient descent;coordinate descent;proximal stochastic;variance reduction;importance sampling;quantization;batch sampling;convergence analyses;quasi convexity;loss function;methods;unified analysis;tricks;method;iterates;variance;variants;linear convergence result;first unified theory;theorem;key;complexity result;special case;various communities;single theorem;different intuitions;approach;paper;product", "pdf_keywords": "sgd methods;gradient descent;variance reduction;coordinate descent;proximal stochastic;sgd;quantization;convergence analyses;variance;methods;variants;sampling;rcd;uni\ufb01ed theory;mipt;\ufb01rst uni\ufb01ed theory;uni\ufb01ed analysis;kaust;may;eduard gorbunov mipt;various communities;peter richt\u00e1rik kaust;different intuitions;different applications;saudi arabia;russia;product;paper;oc;math"}, "ec084dac14a069da2e924ff7f3d5d2fb75b9b39a": {"ta_keywords": "multinomial inverse regression;sentiment information;multinomial logistic regression;dimensional document representations;lasso;dimensional logistic regression;nonconcave likelihood penalization;sentiment;text data;document annotations;logistic regression;sufficient dimension reduction;effective estimation;multinomial distribution;phrase;independent laplace priors;dimensional response;regression;predictor sets;novel estimation technique;literature;prior scale;speeches;gamma;other document forms;general tool;guidelines;prior specification;marketing;variables", "pdf_keywords": "multinomial inverse regression;multinomial logistic regression;sentiment information;low dimension document representations;text analysis;multinomial distribution;text data;dimension response;logistic regression;independent laplace priors;document annotations;novel estimation technique;phrase;predictor sets;speeches;regression coef\ufb01cient;prior scale;literature;prior speci\ufb01cation;marketing;business;variables;economics;perspective;estimator properties;other document forms;general tool;maximization;joint posterior;modeling"}, "bc251481aa5566b1e86a8dbd0417cdf858205e3b": {"ta_keywords": "fake news detection;fake news posts;fake news;model preference learning;veracity;fact;facts;external sources;patterns;pattern;model preferences;texts;claim;models;convolutional network;joint learning;world datasets;post;respective preference maps;heterogeneous dynamic graph;paper;final prediction;preference differences;pref;researchers;methods;respective preferred parts;fend;various methods;experiments", "pdf_keywords": "aware fake news detection framework;fake news detection;model preference learning;fake news;fact;facts;patternand fact;patterns;models;heterogeneous dynamic graph;realworld datasets;respective preference maps;convolutional network;joint learning;model preferences;texts;respective preferred parts;paper;xueyao zhang;final prediction;preference differences;post;preference;qiang sheng;chinese academy;sep;joint detection;pref;abstract;computing technology"}, "dc2f6f092fa04e334dfe2e8592b6d597e00b97ca": {"ta_keywords": "aware semantic classes;hypernymy extraction;semantic classes;distributional semantics;noisy hypernymy relations;semantic class;hypernyms;domain taxonomy induction task;scale crowdsourcing study;recall;benchmarking dataset;similar senses;sense;terms;extraction;wrong extractions;processing;art results;utility;global structure;method;precision;first time;hand;denoising;quality;state;approach;paper", "pdf_keywords": "aware semantic classes;domain taxonomy induction;distributional semantics;semantic classes;noisy hypernymy relations;domain taxonomy induction task;noisy hypernymy databases;semantic class;taxonomy induction;hypernyms;graph clustering;unsupervised method;sense;induction;text;denoising;method;utility;art results;methods;paper;conclusion;state;post"}, "02a83a01d6236149e4ead01e202b2453f9590e9e": {"ta_keywords": "group fairness incompatibilities;group fairness notions;group fairness;fairness objectives;group fairness trade;fairness notions;fairness;different groups;attributes;predictive performance;confusion tensor;individuals;confusion matrix split;attribute values;majority;several optimization problems;tensor;loss;accuracy;class;model;offs;necessary cost;systematic characterization;multiple trade;general perspective;general diagnostic;elements;trade;diagnostic", "pdf_keywords": ""}, "c263507db2c15a8b2e3c955bda7b3c29a1ebd106": {"ta_keywords": "intent detection systems;intent detection;chatbots;intent;nlu platforms;bert;training data;datasets;real user queries;classifier;training process;test sets;unintended patterns;performance saturates;hint3;wild;real world;unwanted correlations;unintended correlations;inadequate levels;domain;complexities;systems;bar;perception;specific aberrations", "pdf_keywords": "intent detection systems;intent detection;intents;intent;live chat bots;nlu platforms;bert;dialog\ufb02ow1;rasa nlu3;language understanding;manas chaturvedi jio haptik;training data;spurious patterns;new datasets;ofscope queries;unintended patterns;datasets;training dataset;luis2;accuracy;gaurav arora jio haptik;unsatisfactory levels;hint3;platforms;performance saturates;performance;scope;krupal modi jio haptik;test sets;abstract"}, "9bd170248355047067f05349d57110cc8e4de5cf": {"ta_keywords": "available general web crawl;large web corpus;tokens;commoncrawl;creativecommons license family;urls;languages;date", "pdf_keywords": ""}, "9952fe8cbd09e4fc89dc7d76595d138e36c7d7b5": {"ta_keywords": "high annotation costs;annotated queries;english datasets;bert;shot transfer;training data;shot evaluation mode;large dataset;transferability;dataset;shot;results;systematic evaluation;bm25 scorer;source datasets licences;training;transfer;queries;models;better model;collections;best use;modest number;subsequent fine;human;tuning;small number;reliability;important research direction;substantial number", "pdf_keywords": "ranking models;transfer learning;bertbased;ranking;bert;retrieval models;high annotation costs;transferability;english datasets;humancreated training data;bm25 scoring function;labeling;transfer;systematic evaluation;artificial intelligence pittsburgh;models;hse university moscow;pavel braslavski;pseudo;training;ir;leonid;best use;ural federal university yekaterinburg;ccs concepts;abstract;important research direction;bosch center;russia;information systems"}, "1f76ee8472ec3a41511540f62e4676317df14ea5": {"ta_keywords": "statistical voice conversion;singing voice timbre;voice conversion;novel voice timbre control technique;singing voice;voice timbre;arbitrary target singer;arbitrary source singer;voices;singers;perceptual age control;singer;perceptual age;prosody;regression approaches;song;listener;age;svc;technique;limitation;varieties;physical constraints;perceptions;paper;notable characteristics;use;previous work", "pdf_keywords": ""}, "5a5fb155b5fc518389a7fe67b55271e143ad695d": {"ta_keywords": "hypergraphs;generalized censored block model;community recovery;graphs;hyperedge;hyperedges;data clustering;nodes;social network applications;image segmentation;complex detection;shape matching;bernoulli noise;observations;paper;protein;science;information;theoretic limit;sum;core problem;problem;cbm;engineering;size;popular approach;values;wide applicability;literature;many fields", "pdf_keywords": "network clustering;hypergraphs;community recovery;communities;clustering;block models;complex detection;parity measurement;channel coding;homogeneity measurement;motion segmentation;machine learning;models;same community;gcbm;central problem;paper;measurements;problem;protein;sep;types;wide variety;sum;changho suh;applications;conclusion;fundamental limits;abstract;number"}, "17c7c92db1f4ace842f9db6b44bfce264308b628": {"ta_keywords": "unsupervised labeled parsing;outside recursive autoencoders;latent code learning;phrase vectors;speech tags;additional human annotations;labeling accuracy;deep inside;bert;noun phrases;meaningful constituent spans;verb phrases;text;labels;elmo;relative error reduction;diora;wall street journal;training procedure;ground;dataset;wsj;truth part;model;previous state;prior work;versions;types;art system;absolute f1 points", "pdf_keywords": ""}, "753fd6952c9f06f3bbd46e37129acc3f7a984896": {"ta_keywords": "many text generation systems;textual knowledge corpus;generation tasks;informative utterances;generator underperform;many varied passages;retriever;passages;conversations;generator;additional context;wikipedia;target output;relevant passages;additional guide;guide;input;standard retriever;training;output;evidence;hindsight;expectation;elbo;preference;methods", "pdf_keywords": "retrieval;generation tasks;generation task;informative conversations;retriever;gold utterance;best matching generation;wikipedia;generator;end performance;passages;relative improvement;granular evaluation;rare words;hindsight;supervision;ended generation;performance;passage depths;marco nlgen;passage;input;training;additional guide;form qa;individual models;target output;guide;end;ability"}, "7fa3a5318ac45b2fd93a0130f0ceba9995ffa3c0": {"ta_keywords": "machine translation applications;languages;similarities;similar terms;computational social science;slang;social media;entities;mining;tasks;baseline methods;effective approach;novel tasks;research;framework;problem;number;paper;experimental results", "pdf_keywords": ""}, "8306e4a566e2b1279d5d67b40facc8e1e345c4e3": {"ta_keywords": "contractive compression operators;communication compression strategies;markov compressor;bidirectional compression;gradient descent;contractive compressor;stochastic approximation;pessimistic convergence rates;smooth nonconvex regime;new error feedback mechanism;optimization methods;strong convergence theory;bounded gradients;ef21;modern error feedback;ef;convergence;practical algorithmic extensions;error feedback;gradient;full gradients;variance reduction;strong assumptions;rate;momentum;heuristic;practical extensions;construction;whistles;popular mechanism", "pdf_keywords": "ef21;pessimistic convergence rates;ef;gradient descent;smooth nonconvex regime;modern error feedback;full gradients;bounded gradients;practical algorithmic extensions;strong assumptions;peter richt\u00e1rik kaust saudi arabia;rate;igor sokolov kaust saudi arabia;theory;eduard gorbunov mipt;same regime;seide et al;first;whistles;bells;yandex russia;oct;abstract"}, "bad5d2d6d1f3282ebbcb602a6f3a5dd9488fd713": {"ta_keywords": "phone recognition datasets;phoneme recognition;multilingual recognition;phonetic annotation;endangered tangkhulic language;phonetic representations;burman language variety;luhya language cluster;phonemes;phonological knowledge;luhya language varieties;shot recognition;utterances;datasets;language;dataset;phone error rates;allosaurus;western kenya;universal narrow phone;eastern uganda;dependent allophone layer;tibeto;saamia;fine tuning;india;significant improvements;tuning;shot;world scenario", "pdf_keywords": "phoneme recognition;phone recognition datasets;multilingual recognition;phonetic annotation;reasonable phone recognition;universal phone representations;endangered tangkhulic language;burman language variety;phonological knowledge;phonemes;bantu languages;luhya language cluster;new language;phone;utterances;language;allosaurus;uganda;acoustic model;kenya;universal narrow phone;western kenya;zeroshot recognition;datasets;dataset;eastern uganda;dependent allophone layer;tibeto;saamia;\ufb01rst datasets"}, "c64843e51f24773c895511ba9befa8a9bc4924a9": {"ta_keywords": "singing voices;statistical voice conversion processing;voice conversion;singing voice;vocal timbre;prosodic features;acoustic features;voices;perceptual age;speech analysis;singers;prosody;singer;spectral features;subjective evaluations;age;synthesis processing;actual age;perception;listener;factors;physical constraints;larger effect;experimental results;varieties;adverse effects;part;first step;index terms;paper", "pdf_keywords": ""}, "8ef0ca924ae88ac2bb2803c49589722b52efc5b4": {"ta_keywords": "affective interaction corpus;real emotion occurrences;affective interactions;natural conversations;social interactions;various television talk shows;affective aspects;emotion;corpus;corpora;human communication;rich corpora;indonesian;interaction;english;analysis;interest;dynamic experience;construction;terms;structure;paper;vital role;increase;lack;aforementioned observation", "pdf_keywords": ""}, "192fc995631e3443bb7f291a971089bd06e61017": {"ta_keywords": "annotating science questions;ai2 reasoning challenge;human annotation;reasoning types;questions;new questions;reasoning;challenge set;complex science questions;arc;knowledge;answer pairs;respective knowledge;interface;classification;novel interface;types;easy set;analysis;paper;science question;open domain;respect;order;work;recent work", "pdf_keywords": ""}, "39ffb5e9f2f36df42ef8ea010499e484c913e79e": {"ta_keywords": "spelling normalization;normalization methods;historical wordforms;different normalization algorithms;modern language;historical german;modern pos taggers;texts;training data;modern ones;common approach;restricted evaluation;diverse set;evaluation;acceptable results;data;adesam et al;tools;jurish;bollmann;paper;approach;small amounts", "pdf_keywords": ""}, "26f427d2b27828f2893e95344342570699e9c589": {"ta_keywords": "code conversions;code conversion;code pairs;mds decodability constraint;convertible codes;traditional codes;decodability properties;code rate;code;size constructions;explicit construction;optimal mds;high field size;broad range;merge regime;mds;lesser resources;new framework;nodes;tight bounds;important parameter regime;achievability result;resource;efficient manner;data;parameter values;default approach;parameters;distance;notion", "pdf_keywords": ""}, "5c333f11431d1f0d04ced62b712c8d05ebac0891": {"ta_keywords": "speech enhancement;novel speech enhancement algorithm;noisy speech signal;conditional diffusion probabilistic model;generative models;speech signal;conditional diffusion;noise characteristics;probabilistic models;probabilistic model;diffusion;models;generalization capability;generalized formulation;other datasets;training;reverse processes;recent advances;strong performance;reverse process;experiments;characteristics;approach;work", "pdf_keywords": "other generative speech enhancement approaches;speech enhancement;world speech enhancement problems;audio synthesis;generative models;generative model;image generation;noise characteristics;speech signal;conditional diffusion;probabilistic models;deep learning;probabilistic model;original diffusion;diffusion;noisy input signal;models;generalization capability;generalized formulation;model;outstanding performance;cdiffuse;strong performance;art results;strict generalization;training;other datasets;reverse process;class;state"}, "c82854b8d4c715da141d34c73bf9bda67adf307c": {"ta_keywords": "sentiment polarity prediction;polarizing topics;political blogs posts;sentiment polarity;semisupervised latent variable model;news topics;latent variable models;community responses;blog content;different political communities;topics;comment sections;comment volume;polarity;polarization;same news events;specific communities;different political beliefs;communities;different communities;comments;topic;mcr;lda;responses;multitarget;joint modeling;same news;interest;view", "pdf_keywords": ""}, "30a30781c66c758e8e59cdb00c368f3add99768b": {"ta_keywords": "unsupervised speaker representations;unsupervised speaker recognition;voices datasets;utterance embeddings;adversarial training;speaker information;adversarial training strategy;augmentation;contrastive learning;acoustic characteristics;voxceleb;channel information;models;self;significant improvements;network;supervision;previous works;extensive experiments;performance;end;humans", "pdf_keywords": "adversarial training;robust speaker recognition models;speaker recognition;adversarial training strategy;data augmentation;popular augmentation methods;speaker information;augmentation;speaker labels;speech processing;contrastive learning framework;utterance;batch formation;training;acoustic characteristics;additive noise;channel information;channel environment;joon son chung2;self;jingu kang2;jaesung;network;hee soo heo2;south korea 3johns hopkins university;sd;end;shinji watanabe3;oxford;1visual geometry group"}, "84370f2fa3ac21ed3c6a30144fbdb377157b8853": {"ta_keywords": "key preference reasoning tasks;conditional preferences;probabilistic uncertainty;qualitative preferences;dominance queries;agents;preferences;pcp;optimal outcome;nets;cp;group;collection;paper", "pdf_keywords": ""}, "d66110a315f5f216b42d99cfafec31e8e30a03ea": {"ta_keywords": "neural uncertainty estimation;target speaker extraction;rnn transducer;investigation", "pdf_keywords": ""}, "05d1e21f5f0c8209cc125f2e9ccd3a62d6479114": {"ta_keywords": "document similarity metrics;document retrieval;similarity metrics;information retrieval;similarity;record linkage;bibliography records;documents;text classification;database records;different source databases;same entity;same publication;journal name;summarization;insurance information;different hospitals;paper title;pairs;many tasks;methods;study;list;patient;yc1994;authors;same person;address;example;instance", "pdf_keywords": ""}, "f9409302c4d8201481fe65675bc6f0fa32e01df7": {"ta_keywords": "protection;individual", "pdf_keywords": ""}, "59d3f6a14e20efdf54216188e227e58a351237e5": {"ta_keywords": "gan fingerprint disentangling network;disentangle gan fingerprint;gan fingerprint;superior fake image attribution performance;fake image attribution;gan architecture;binary fake image detection;gan;fingerprint;generative models;visual forensics;digital copyright infringement;unseen generators;images;malicious personation;irrelevant feature extraction;gfd;net;irrelevant representation;significant generalization ability;discriminability;content;new threats;world testing;works;clues;experiments;world;constraints;method", "pdf_keywords": "gan fingerprint disentangling network;gan \ufb01ngerprints;gan \ufb01ngerprint;different gans;gan architecture;gan;fake image attribution;same gan;binary fake image detection;learned \ufb01ngerprint;unseen generators;images;\ufb01ngerprint;net;gfd;content;signi\ufb01cant generalization ability;irrelevant representation;1b;work;paper;contributions;clues;method;factors;properties;comprehensive analysis"}, "207c64b36fbd6accf7067366a251d071e8dd03a7": {"ta_keywords": "mt vardoussia;vascular flora;flora;floristic affinity;hemicryptophytes;neighbouring mountains;mountainous character;erimanthos;timfristos;taxa;saerensen coefficient;killini;predominance;examination;iti;first time;paper", "pdf_keywords": ""}, "4f6d64eec6eaa38177ae45ad6315cf25d1535294": {"ta_keywords": "encode conversation history;dialog act prediction;essential conversation task;conversation history;text representation;bert;positional history answer;position information;prediction;aspects;history;mtl;novel solution;convqa;current question;advantage;major challenges;addition;uniform model architecture;different weights;method;work;natural way;powerful technique", "pdf_keywords": "dialog act prediction;encode conversation history;answer span prediction;conversation histories;essential conversation task;conversation history;history attention mechanism;bert;positional history answer;text representation;position information;prediction;soft selection;history;ham;aspects;current question;novel solution;advantage;uniform model architecture;mtl;addition;different weights;convqa;work;method;natural way;powerful technique"}, "e8135016ff3bd33ace936e50247fd650fcc58a7a": {"ta_keywords": "attentional neural machine translation;neural machine translation;discrete translation lexicons;english translation track;asian translation;minimum risk training;nmt;standard nmt model;lexicons;nara institute;probability estimates;bleu score;models;naist;cmu;improvements;workshop;mt system;addition;technology;wat2016;submission;number;science;use;year", "pdf_keywords": "neural translation model;baseline neural machine translation model;baseline translation model;translation accuracy;discrete translation lexicons;english scienti\ufb01c paper translation task;asian translation;attentional model;minimum risk training;risk training;nmt systems;models;lamtram toolkit;probability estimates;model;paper;workshop;wat;results;bahdanau et al;neubig;parameters;combination"}, "7847419becbc04596b79f804f844cf9719e875ea": {"ta_keywords": "natural language commands;unannotated demonstrations;level subtask descriptions;level actions;action sequences;level subtasks;level instruction sequences;sparse natural language annotations;planning;demonstrations;many tasks;instruction;skill induction;skills;latent language;reusable skills;action;training;hierarchical policies;language;agents;autonomous decision;truth plans;descriptions;generative model;ground;seed annotations;goals;sequences;making", "pdf_keywords": "natural language plan speci\ufb01cations;natural language commands;sparse natural language annotations;unannotated demonstrations;level subtask descriptions;natural language annotations;level actions;action sequences;planning;hierarchical policy;natural language;level subtasks;skill induction;latent language;hierarchical policies;demonstrations;autonomous agents;language;level instruction sequences;action;highlevel reasoning;plans;reusable skills;skills;autonomous decision;descriptions;agents;task completion rates;training;plan"}, "ad734a3f530a6c338af6bf2bf678e5af05477c1a": {"ta_keywords": "secret sharing;several cryptographic protocols;secure multiparty;communication complexity;general network;protocols;byzantine agreement;efficient generalization;secret;complexity;dealer;networks;general networks;network;dealer condition;direct communication links;shares;communication;algorithm;threshold;computation;lower bounds;shamir;key management;large class;information;participants;worst case;paper;theoretic", "pdf_keywords": ""}, "11154216ca898590e7b2f0339587e3378c2c646c": {"ta_keywords": "connected vehicle environment;connected vehicle technology;expressway work zone;warning information;confidence;complex traffic environment;average vehicle;expressway;drivers;psychological characteristics;traffic efficiency;accident rates;behavior data;different indicators;psychology;gas pedal angle;work zone;simulation technology;machine interface;information;objective weighting method;degree;characteristics;important impact;zone scene;study;spatiotemporal diagram;method;results;average degree", "pdf_keywords": ""}, "87951cea6573eed827986371a35025e478d3c184": {"ta_keywords": "stochastic extragradient;stochastic gradients;variational inequalities problems;variational inequalities;convergence guarantees;samples seg;sample seg;various machine learning tasks;seg;bounded variance;art convergence guarantees;variants;several variants;sampling;new variants;popular algorithms;lipschitzness;convergence properties;monotonicity;restrictive assumptions;vip;sum;method;others;novel theoretical framework;literature;approach;paper;unified manner;questions", "pdf_keywords": "variational inequalities;convergence guarantees;stochastic gradients;seg;art convergence guarantees;convergence properties;monotone \ufb01nite;sampling;restrictive assumptions;new variants;sum;rates;others;several important questions;current state"}, "dfa7bdea128b899d348ed32a84a7ccb1da4340e4": {"ta_keywords": "long short term memory;robust dialog systems;dialog system;dialog response;response generation;lstm decoder;response retrieval;dialog baselines;lstm;lstm encoder;recursive autoencoders;probable word sequence;neural networks;retrieval tasks;utterance;sentences;neural network;user inputs;new statistical model;generation;database;arbitrary length;key words;space representation;subjective metrics;data sources;model;standard example;dynamic pooling;user", "pdf_keywords": ""}, "3675958405f3ad1633d565efa36b4eb3004bcf59": {"ta_keywords": "social live video streaming;traditional live streaming;live streams;social live streams;higher quality video;live stream;low latency video;video upload;time quality;youtube;twitch;viewers;viewing;available bandwidth;upload solution;lower quality;different delays;upload;facebook;mobile environments;encoding schedules;significant delay penalty;live;diverse time;selective quality;overall quality;content;presence;platforms;time frames", "pdf_keywords": ""}, "0ca2a7465fe88f1f4912b8dd7b4b0db69a268b0b": {"ta_keywords": "neural lattice language models;multiple language modeling tasks;language model;new language modeling paradigm;linguistic intuitions;polysemous embeddings;lexical items;polysemy;multiword;chinese model;multiple granularities;lattice;models;sequence probabilities;perplexity;prediction;english;information flow;sentence;word;character;possible paths;level baseline;optimize parameters;ability;work;approach;experiments;moderation;existence", "pdf_keywords": "neural lattice language models;neural lattice languages models;neural lattice language model;standard lstm language modeling framework;neural lattice lms;language modeling;new language modeling paradigm;billion word corpus;lstm;chinese gigaword corpus;word phrases;linguistic intuitions;polysemy;language;multiple embeddings;instantiations;multiple granularities;words;graham neubig language technologies institute;model;latent segmentations;novel modi\ufb01cation;prediction;human intuition;features;abstract;usage;information;baseline;section"}, "4786e10003655be97feee21b9d9894a88a62885f": {"ta_keywords": "multilingual transfer nlp models;entity recognition;target language;unsupervised truth inference;many source languages;resource target language;unsupervised method rivals oracle selection;distant languages;languages;strong baselines;transfer;many such models;poor transfer;standard ensembling;single model;limited supervision;prior work;techniques;small handful;contrast;critical problem", "pdf_keywords": "new multilingual transfer models;multilingual transfer;supervised transfer;target language;unsupervised transfer;multilingual transfer setting;several unreliable annotators;noisy annotations;truth inference;best labelling;single best transfer model;supervised baseline;training data;multiple source models;language;transfer;single source;unsupervised method;transfer model;resource;sourcing;dataset;ground truth;several competitive baselines;data;speci\ufb01c transfer errors;bayesian graphical model;reasoning;crowd;dawid"}, "4a06bfa86cbccdf5e55dcec3505cdc97b8edb288": {"ta_keywords": "combinatory categorial grammars;grammatical type;generalized composition;normal form;type;raising;extension;degree;form;modification;eisner", "pdf_keywords": ""}, "622f980030f766e5eb3989f36eea4459ccc948bf": {"ta_keywords": "incremental adaptation;incremental adaptation techniques;novel incremental adaptation framework;direct adaptation approaches;adaptation approaches;indirect adaptation;speech recognition;acoustic models;stable adaptation characteristics;variant acoustic characteristics;acoustic model parameters;macroscopic time evolution system;temporal changes;speaker;transformation parameters;posterior distributions;variant characteristics;noise source;combinatorial approaches;time;unified interpretation;major conventional approaches;style;proposal;paper", "pdf_keywords": ""}, "ae06bc1e8e67c27b89329ebcfe61b71625d853f6": {"ta_keywords": "diverse explainability techniques;explainability techniques;downstream text classification tasks;text classification;explanations;human annotations;saliency scores;salient input regions;machine learning;neural network;architectural complexity;model architectures;model architecture;models;tasks;gradient;human ones;human performance;performance;definitive guide;list;further insights;particular application task;model;properties;rationales;recent developments;diagnostic study;drawbacks;relations", "pdf_keywords": "explainability techniques;explainability methods;diverse explainability techniques;human annotations;downstream text classi\ufb01cation tasks;saliency scores;text classi\ufb01cation;machine learning models;salient input regions;neural network architectures;machine learning;architectural complexity;salient regions;attributions;diagnostic properties;models;evaluation;human performance;performance;conclusion;different perspectives;human ones;model;comprehensive list;abstract;comparative study;list;rationales;humans;diagnostic study"}, "43896ea7d488100d135645fbb4be6e7eb2e7f4e2": {"ta_keywords": "feature vectors;vector representation;feature vector;nominal features size;features;representation;text categorization problems;most learning systems examples;feature color;feature;infinite attribute;possible set elements;traditional feature;order representations;strings;nominal values;world learning problems;example;black dog;length;value;set;components;instance;blum;extension;size;real numbers;species;familiaris", "pdf_keywords": ""}, "adb80a4190fdb6a019d57f18ae072ca93f494b7e": {"ta_keywords": "rank deep neural network acoustic models;noisy speech recognition;sequence discriminative training;discriminative training;speech recognition task;low rank approximation;discriminative criterion;acoustic models;deep neural network;dnn model size;singular value decomposition;conventional gaussian mixture model;rank model;rank approximation;rank approximations;weight matrices;svd method;model reduction;rank;svd;dnn;base model;low;frame;number;evaluation;sequence;order;performance;gmm", "pdf_keywords": ""}, "f3762141fd64bee8d09e55ad4c83057cd4e002d4": {"ta_keywords": "coalition utility learning;coalition utility learning method;correlation utility;own estimated utility function;correlation utility function;coalition;utility functions;generalized least squares;form coalitions;correlations;agents;estimators;correlation;noise estimation;constrained feasible;training data;utilities;agent;online framework;game;players;weighted sum;weights;initial training phase;schemes;performance;approaches;method;more complex schemes;parameters", "pdf_keywords": ""}, "388d41b99c9c0867301f345c65877a2796225ead": {"ta_keywords": "speaker asr baseline;interference speaker asr accuracy;transcribes target speaker;novel auxiliary loss function;automatic speech recognition;auxiliary loss function attempts;multiple speakers speech;target speaker;secondary asr;speaker;interference speakers;normal asr;speech;utterances;auxiliary output branch;asr;word error rate;accuracy improvement;loss;free maximum mutual information;monaural mixture;short sample;wer;target;strong target;training;strong baseline;baseline;addition;art lattice", "pdf_keywords": "speaker speech recognition;transcribes target speaker;speaker asr baseline;automatic speech recognition;auxiliary interference speaker loss;target speaker;multiple speakers speech;novel auxiliary loss function;speaker;utterances;naoyuki kanda1;normal asr;auxiliary output branch;asr;kenji nagamatsu1;target;mmi;strong target;short sample;loss;ryoichi takashima1;shinji watanabe2;monaural mixture;shota horiguchi1;yusuke fujita1;wer;jun;free maximum mutual information;japan 2johns hopkins university;model architectures"}, "7a8f8109e65ed9a6048859681a825eb5655e5dd2": {"ta_keywords": "sentence embeddings;much modern sentence embeddings;word embeddings;sentence representations;sentence classification;random encoders;random parameterizations;random methods;appropriate baselines;training;training required;field;various methods;aim;nothing;solid footing", "pdf_keywords": "sentence embeddings;sentence representations;word embeddings;sentence classification;recurrent networks;sentence classi\ufb01cation evaluation;random encoders;encoder;random parameterizations;echo state networks;models;dimensional space;lowdimensional space;douwe kiela facebook ai research;space;iclr;complex pattern;training;types;classi\ufb01cation problem;training required;future research;cover;projections;machine;paper;takeaway recommendations;important observations;recommendations;several important observations"}, "03058f9a39d37a8bee635969eed227d59bbc8152": {"ta_keywords": "stochastic differential equations;stochastic differential equation;stochastic dynamics;adaptive solvers;dimensional motion capture;neural networks;adjoint sensitivity method;gradient;gradients;memory computation;memory;ordinary differential equations;noise;efficient algorithm;numerical solutions;time;competitive performance;solutions;order;solution;method;conditions", "pdf_keywords": "gradientbased stochastic variational inference scheme;backward stratonovich sde;latent sde models;latent sde;stochastic adjoint framework;latent sdes;variational inference;sde models;sdes;stochastic dynamics;tractable approximate posterior;adjoint method;adjoint approach;arbitrary di\ufb00erentiable likelihoods;necessary gradient;motion capture dataset;marginal log;neural networks;likelihood;dynamics;parameters;approaches;section;functions;competitive performance;work;problem"}, "4eb62ee328ceac9976c72bca65570d73ca0e8b64": {"ta_keywords": "behavioral stable marriage problems", "pdf_keywords": ""}, "30a6a5614727017e7d7981f87df57d17713501a0": {"ta_keywords": "combinatorial bandits;greedy matching paradigm;bandits;incentives;incentivizing agents;demand;dynamic preferences;regret;markov chains;bike;algorithm;theoretical bounds;upper confidence;supply;ideas;sharing platform;preferences;times;time;resource;performance;users;ucb;examples;priori;ii;theory;iii;distinct domains;environment", "pdf_keywords": "combinatorial bandits;bandit algorithm;bandits;greedy matching paradigm;greedy matching;incentives;incentivizing agents;dynamic preferences;favorable convergence rates;markov chains;user engagement;markov chain;approaches;recommendations;computational ef\ufb01ciency;resource;algorithm;ideas;large data sets;time;preferences;users;times;digital platform providers;ucb;ii;liyuan zheng;priori;iii;work"}, "357ff26120dd220d7132f8083697d54b007ef260": {"ta_keywords": "speech processing tasks;lightweight prediction heads;universal performance benchmark;ssl representations;natural language processing;learning;speech;nlp;task;superb tasks;minimal adaptation;sota;performance;representation;leaderboard;ssl;various tasks;self;minimal architecture changes;cv;computer vision;model;unlabeled data;accessibility;competitive generalizability;wide range;data;framework;simple framework;large volumes", "pdf_keywords": ""}, "9f24b8f93ed00a1592e02fdb0edf5ebf0d8752ff": {"ta_keywords": "conference peer review;various assignment algorithms;assignment algorithm;review quality;fairness objective;reviewers;review process;peerreview;peer;statistical accuracy objective;sharp minimax analysis;objective comparison;algorithm;disadvantaged paper;score model;review;assignment;statistical accuracy;fairness;deterministic approximation guarantees;incremental max;papers;total quality;accuracy;flow procedure;experiments;objective;paper;inherent difficulty;novel experiment", "pdf_keywords": ""}, "6a4deeb40aed8a4d56c8d9401c94b6c7a769e8c3": {"ta_keywords": "information retrieval task;query documents;relevance scores;high annotation agreement;input query document;rhetorical structure elements;search query;scientific papers;annotation guideline;faceted query;computer science research articles;relevant documents;large collection;document;computational linguistics;scientific paper;test collection;data collection;machine learning venues;depth;task;trec;query;example;csfcube;diverse set;models;expert;aspect;finer", "pdf_keywords": "faceted qbe task;faceted query;faceted qbe;information retrieval task;faceted qbe problem;annotated test collection;search query;computer science research articles;strong baseline approaches;test collection;large collection;scienti\ufb01c articles;relevant documents;document;dataset;query;challenging aspects;models;evaluation;performance;task;ir;expert;csfcube;example;case;paper;improvement;mccallum;nov"}, "356ea9b29101ec6974a7a97b62266b0e7e58d6bf": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "9e0d3161b13481418b7e85e3a691d23d67cf1e68": {"ta_keywords": "dynamic regionaware graph convolutional network;privacy leakage;convolutional network;privacy;image detection;images;social media;drag;input image;graph;crucial regions;textures;correlation;regions;art;attention mechanism;largest dataset;objects;self;accuracy;limitations;state;percentage points;interaction;issue;other important elements;severe issue;daily practice;goal;further case study", "pdf_keywords": "dynamic regionaware graph convolutional network;aware gcn;leaking image detection;convolutional network;object detectors;privacy leakage;gcn;visual features;crucial regions;privacy;drag;dynamic region;regions;graph;images;social media;input image;aware method;channels;xirong li3;region;gyang;china;qiang;shengqiang18z;correlation;intelligent information processing;chinese academy;jintao;data engineering"}, "a3c9d1c5e403f35e5694778b86832f0f9a7d87e6": {"ta_keywords": "utterance gmm search tasks;large speech data;speech models;speech model;fast similarity search;gaussian mixture model;neighborhood graph indexing;leibler divergence;query model;novel graph;gmm;low computational cost;conventional pruning techniques;model space;dissimilarity;kld;metric space;kullback;large set;paper;triangle inequality;method;approach;set;problem;experimental evaluations", "pdf_keywords": ""}, "77910e51a40d17157fc798325d06edfa6cff18d6": {"ta_keywords": "domain code generation;code generation;programming language api documentation;purpose programming language;natural language;code pairs;code;online programming qa forum stackoverflow;external knowledge;python;developers;data augmentation;retrieval;web;resources;nl;intents;sources;evaluations;absolute bleu score;effectiveness;intuition;conala;varieties;art;current state", "pdf_keywords": "code generation models;code generation;programming language api documentation;domain code generation;code snippets;natural language;api documentation;purpose programming language;nl intents;intents;python;external knowledge resources;code pairs;code;art syntax;external knowledge;common software libraries;online programming qa forum stackover\ufb02ow;additional hypothesis reranking;nl;data augmentation;retrieval;abstract;developers;resources;web;evaluations;sources;cl;facts"}, "948b68677c4f3bcbb1bae7f1d4e1fd5a103f03d4": {"ta_keywords": "speech enhancement quality;speech enhancement;speech enhancement systems;end speech recognition objectives;automatic speech recognition;speech distortion factor;end asr training objectives;signal reconstruction objectives;asr error minimization criteria;noisy data;asr word error rate;various signal level metrics;asr objective;beamforming subnetwork;different signal level metrics;linear prediction;asr;dereverberation sub network;me2e;wer metric;learning;estimation;distorted signals;reinforcement learning;addition;maximum likelihood;wer;filter order;square error;metric", "pdf_keywords": ""}, "5edaab1fa078a5c468e3fb26d267ca49be32e70e": {"ta_keywords": "preference elicitation;effective elicitation questions;luce model;aggregation;fewer queries;information criteria;budget constraint;budget;better group decision;information gain;various information criteria;features;plackett;questions;effective framework;prediction accuracy;cost;agents;order;framework;experiments;question;correct answer", "pdf_keywords": "effective preference elicitation framework;effective preference elicitation;preference elicitation;amazon mechanical turk;elicitation questions;aggregation framework;voting rules;luce model;aggregation;preference;information criteria;features;information gain;prediction accuracy;group decision;various information criteria;plackett;junming wang rpi troy;single agent;jul;models;effective framework;cost;contributions;experiments;\ufb02exible cost;troy;question;different types;hui su"}, "98caf4eb79208cf4bbfe20bde37bc1b6ded6d6de": {"ta_keywords": "resource named entity recognition;entity recognition models;entity recognition;english knowledge bases;soft gazetteers;english data;entities;gazetteers;modern neural network models;wikipedia;lists;features;available information;strong performance;recent work;performance;utility;low;method;problem;such hand", "pdf_keywords": "soft gazetteer features;soft gazetteer methods;entity recognition models;entity recognition;soft gazetteers;english knowledge bases;natural language processing tasks;lowresource languages;linguistic features;resource languages;different candidate retrieval methods;ner dataset;syntactic knowledge;lowresource ner;wikipedia;features;tir;tigrinya;ner;kinyarwanda;orm;neural networks;available information;sinhala;kin;oromo;performance;points;baseline;effectiveness"}, "55b61befce42280c3d57331121c7d349dd8be4cf": {"ta_keywords": "speech translation results;simultaneous speech translation;speech translation;user evaluations;speech;delay;evaluation;translation;evaluation measure;explicit sentence boundaries;accuracy;speed;text;various speeds;results;accuracies;human judgements;study;data;relative importance;technology;higher relative importance;end;users;systems;different levels;certainty;previous work;factors;parameters", "pdf_keywords": ""}, "a949ba38194ad43c86925acec6705b434d5a920f": {"ta_keywords": "fake news detection;entity bias;future", "pdf_keywords": ""}, "22b6e88a2f234fc5646f6239f9040a776e841a97": {"ta_keywords": "bilingual lexical entries;bilingual lexicon;bilingual lexicons;corpora;corpus;phonemic transcriptions;english translations;sentence;high precision;performance improvements;additional models;models;induction;small quantities;report;purpose", "pdf_keywords": ""}, "9abd13caa32b1a90e32462a884a512f8666e80cc": {"ta_keywords": "independent semantic parsing;dependent semantic parsing;dependent natural language;parser;contextual information;query analysis;followup dataset show;follow;context;multifarious follow;split;star;task;novel approach;recombine approach;advances;scenarios;large margin;art baseline;state;experiments;phase process;different domains", "pdf_keywords": "sqa dataset;recombination process;phase process;phases;star;annotations;different annotations;novel approach;extensibility;experiments;promising results;method;methodology;extension;overview;approach;section;turn;answers;idea;task"}, "3c8853d4ae3ad2633c47e840a48951d62b64a5b4": {"ta_keywords": "sparse graph;graph sparsification;adaptive label propagation;label propagation;latent factor extraction;graphs;independent data representations;view;latent factors;many data mining paradigms;benchmark datasets;mvgl;unified framework;efficient optimization algorithm;model;remarkable improvements;paper;baselines;approach;essential role;experimental results", "pdf_keywords": ""}, "df29486c04eafd004f2f0816e84c798783802cdf": {"ta_keywords": "transliteration;transfer language data;international phonetic alphabet;phoneme conversion;related languages;several diverse language pairs;latin alphabet;languages;grapheme;accuracy improvements;improvements;data;cross;use;space;percentage points;most cases;order;methods;target one;issue", "pdf_keywords": ""}, "298a68153859303ee70b3ef1525ee9c7031e32f5": {"ta_keywords": "chat dialogue systems;dialogue generation;mutual persona perception;persona;human evaluations;chat;p\u02c62 bot;like responses;automatic metrics;aim;interlocutors;chit;engagingness;receiver;understanding;large public dataset;aspects;transmitter;effectiveness;approach;consistency;experiments;framework;efforts;considerable boost;art baselines;majority;state;current work", "pdf_keywords": "chat dialogue systems;chatbots;dialogue generation;personalized dialogue generation;mutual persona perception;conversations;p2 bot;domain dialogue;persona;chat;like responses;interlocutors;human evaluations;aim;arti\ufb01cial intelligence;chit;neural models;receiver;engagingness;understanding;accessibility;computer science;transmitter;automatic metrics;dongmei;advance;aspects;abstract;introduction;framework"}, "251a80dd4126fed3d6ae64f00dc24479f0ba5662": {"ta_keywords": "tutorials;style tutorials;web conference;hands;report", "pdf_keywords": ""}, "46dab5eb9c11bd49893e2dafa7d1b720a0aa2b3d": {"ta_keywords": "comprehension tasks;social media tag prediction;scalar weighting;paragraphs;gating;level tasks;level representations;comprehension;gating mechanism;book test;words;concatenation;character;level;improved results;word;questions;children;idea;datasets;performance;interaction;generality;experiments;previous work;art results;properties;approach;new state", "pdf_keywords": ""}, "e92677eb974a2814d57de54e2c3733cbd92e2c00": {"ta_keywords": "distributed computing;hierarchical coding;hierarchical computational structure;latency computation;computation time;computing systems;computing supports;worker model;workers;simple master;architectures;computing time;most existing works;work;cost;burden;groups;world;scheme;schemes;need;many practical scenarios;model", "pdf_keywords": "hierarchical coding;outer mds code;mds code;like hierarchical structure;ef\ufb01cient parallel;computation time;computing system;tree;schemes;groups;scheme;framework;cost;costs;computing time;orders;fig;work;model;k2;many practical scenarios;contribution;magnitude"}, "0e9e334e2647307f8fa7f9937d93f3ca9095e351": {"ta_keywords": "monotone variational inequalities;optimistic gradient method;variational inequalities problems;hamiltonian gradient method;extragradient method;lipschitz vip;lipschitzness;lipschitz;iterate convergence;update operators;convergence rate;cocoercivity;monotone;original operator;operator;saddle point;popular methods;jacobian;additional assumptions;vip;type;eg;korpelevich;several results;such questions;connections;paper;result", "pdf_keywords": "extragradient method;variational inequalities problems;monotone variational inequalities;saddle point;iterate convergence;cocoercivity;popular methods;vip;eduard gorbunov mipt;nicolas loizou johns hopkins university;korpelevich;canada canada cifar ai chair;udem;eg;baltimore;oc;feb;gauthier gidel mila;connections;mila;canada;abstract;math;usa;russia"}, "75ba422d90c488b1388345865e0525208331bb3d": {"ta_keywords": "private learning;privacy regime;stricter privacy guarantees;privacy;different privacy;modern neural models;gradient descent;differentiallyprivate stochastic;nlp tasks;sgd;downstream datasets;complexity;model performance;strategies;short paper;pattern;thorough analysis;special treatment;task;dp;adequate performance;size", "pdf_keywords": "private learning;differential privacy;preserving privacy;privacy regime;privacy;different privacy;stricter privacy guarantees;modern nlp models;private training;many nlp tasks;down stream nlp datasets;private ner;nlp tasks;modern neural models;ivan habernal trustworthy human language technologies department;nlp community;downstream datasets;datasets;skewed class distribution;dataset;sgd;complexity;gradient descent;differentiallyprivate stochastic;model performance;speci\ufb01c behavior;abstract;deeper understanding;task;tasks"}, "9d3e33875ec39001e72313fb919f66242ee97880": {"ta_keywords": "orthographic transcriptions;linguistic units;orthography;raw speech;subwords;discovery;language;words;text;images;accomplishments;replacement;scientific issues", "pdf_keywords": "speech summarization;speech2image;speech2translation;speech synthesis;raw speech;machine translation;unsupervised unit discovery;orthographic transcriptions;linguistic units;unit discovery;linguistic knowledge;resource language;translations;subwords;language;image retrieval;orthography;video information;unwritten languages;words;discovery;tasks;text;workshop;symbolic units;explicit symbolic units;asr system;index terms;rosetta;end tasks"}, "7d7469e059c6890c24d42931c697df835329f26a": {"ta_keywords": "noise mixture model;noise model estimation;noise suppression;noise model;robust estimation method;mmse estimation;noise;neous optimization;word error rate;observed signal model;single gaussian distribution;squared error;minimum mean;mmse;vts;vector taylor series;estimate;maximum improvement;method;simulta;approach;way;problems", "pdf_keywords": ""}, "f7f6160d4e9e3bf7f36bacbc9f15e916a6f226de": {"ta_keywords": "multichannel speech enhancement;speech enhancement objectives;speech enhancement;speech enhancement work;end speech recognition architecture;adequate speech enhancement ability;speech enhancement component;clean speech data;speech quality;speech recognition;speech recognition component;stage speech recognition component;automatic speech recognition;noise suppression;novel multichannel;sum beamformer;multichannel;end asr objectives;end asr;end architecture;wsj corpus;additional training;perceptual evaluation;asr;channel;ability;end;signal;level measures;delay", "pdf_keywords": ""}, "99c87e16c56b8a113124779734951f11bd662d5d": {"ta_keywords": "utility maximizers;nash equilibrium concept;continuous game;social game;occupant voting data;occupants;efficient behavior;overall energy consumption;utility functions;game;convex optimization problem;energy;lottery;lighting level;play;vote;occupant behavior;win points;points;building;tradeoff;actual behavior;maximum setting;comfort level;good predictor;model;aim;parameters", "pdf_keywords": "continuous game;utility maximizers;social game;utility learning;overall energy consumption;nash equilibrium concept;utility functions;energy;building energy e\ufb03ciency;game;occupants;occupant voting data;play;building;lighting level;simulation;lottery;actual behavior;occupant behavior;e\ufb03cient behavior;vote;points;win points;model;convex optimization problem;comfort level;maximum setting;good predictor;aim;math"}, "4697ef43450f173e12b1e22b77e976dc56fdf5fe": {"ta_keywords": "compressive sampling matching pursuit;compressive sensing;novel compressive sensing;basis pursuit;white box attacks;adaptive defence;norm attack;defence schemes;attack;adversarial perturbations;various recovery schemes;various attack types;cad algorithm;spectral domain;cad;excellent classification accuracy;frequency domain;exponential weight algorithm;novel constraint;lower computation;mnist;exploitation;distortion;algorithm;low frequency perturbations;exploration;cosamp;time domain;high frequency components;coefficients", "pdf_keywords": "gradient attacks;adversarial videos;white box gradient attacks;adversarial image classi\ufb01cation;compressive sampling matching pursuit;bandit techniques;norm attacks;adaptive defence;adaptive defense;compressive sensing;novel compressive sensing;standard basis pursuit;attack type;attacks;modi\ufb01ed basis pursuit;gradient;recovery algorithms;popular exponential weight algorithm;exploitation decision;excellent classi\ufb01cation accuracy;novel constraints;appropriate recovery method;scheme;low computational complexity;l0;lower computational complexity;algorithm;exploration;low memory requirement;l2"}, "ce3d6673b7eebdd0198940316d18e383e9597c9a": {"ta_keywords": "contextual bandits;optimal regret;minimax regret;loss predictors;rounds;predictor;total error;several surprising results;study;remedy;logarithmic dependence;sharp contrast;help;linear dependence;hint;standard;main question", "pdf_keywords": "contextual bandit learning;contextual bandits;optimal regret;loss predictors;learning theory;stochastic setting;estimators;robust mean estimator;stochastic;key action;action remapping;algorithms;multiple predictors;several novel algorithmic techniques;underestimator;complete pseudocode;catoni;independent interest;bins;upper bounds;scheme;algorithm;technique;erm oracle;self;ef\ufb01cient implementation;size;hint;histogram;33rd annual conference"}, "29b3a609f2b5cb10cffb80a6aaf96413a4a9998e": {"ta_keywords": "efficient lossless compression;lossless compression;efficient compression;neural compression;invertible flow transformations;modular scale transform;high compression ratios;compression ratio;uniform base conversion system;normalizing flows;uniform coder;art compression ratios;traditional codecs;distribution codec;deep generative models;invertible flows;transmission;iflow;data storage;performance schemes;59zb;numerically;recent advances;great capacity;data;ubcs;mst;enormous costs;algorithms;paper", "pdf_keywords": "neural compression codec;lossless compression;ef\ufb01cient compression;modular scale transform;invertible \ufb02ow transformations;uniform base conversion system;invertible class;distribution codec;bijections;iflow;algorithms;\ufb02ows;discrete space;speed;\ufb02exible family;broad class;ubcs;paper;mst;time;techniques;gap;novel family"}, "24ee54c8d5a01197e015d40be4277cfbb727394f": {"ta_keywords": "bus routes;bus route;bike lanes;city transportation systems;sharingbikes;travel flow coverage;bikes;road segment;planners;heuristic approach;passengers;best coverage;new york city;sharing;data;areas;area;scale datasets;design;consideration;flows;extensive evaluation;paper;solid foundation;system;function;current system;baselines", "pdf_keywords": ""}, "ea5cfce90444b17b36da07840b2f0cafb54ab0a7": {"ta_keywords": "automatic deception detection;deceptive conversational partner;deception;potential liar;dialogue systems;telltale signs;humans;questions;actions;signs;second action;features;more salient;results;goal;paper;significant prior work;other hand;initial analysis", "pdf_keywords": ""}, "e3a1b2a19356dc685d78630ae2a8852ad6c86200": {"ta_keywords": "relevance features;indexing close word pairs;aware ranking functions;enterprise search engine;retrieval system;indexing;proximity information;spam scores;close word pairs;proximity;relevance;classic proximity;index;word pairs;pruning;occurrences;aware function;words;functions;logistic function;waterloo;experiments;university;modification;lessons;method;goal;linear combination", "pdf_keywords": ""}, "5e24aa9fdf5466e96d314dfcde973fccec02995d": {"ta_keywords": "online feature selection;batch feature selection methods;feature selection;online learning methods;new modified margin balanced winnow algorithm;massive data streams;online learning;features;batch techniques;line learning;art batch learners;learning methods;line learner;same training data;winnow;practice multiple passes;pass;perceptron;real time;limited memory;chi;accuracy;data;processing;information gain;fly;performance;inference;techniques;single passover", "pdf_keywords": ""}, "e2854bf66ed86a5dc74183bae5fde18e65699833": {"ta_keywords": "polyphonic sound event detection;speech recognition;acoustic scenes;polyphonic tasks;term memory hidden markov model hybrid system;such copying;detection;partial copies;classification;copyright notice;events;neural network;event;rnn;dcase2016 task;explicit duration model;acknowledgment;dataset;blstm;bidirectional long short;dcase;output labels;evaluation;extension;workshop;standard blstm;straightforward application;nmf;applicable portions;segment", "pdf_keywords": ""}, "21c9c624bc328686cef4bb1f80a786a5027d8886": {"ta_keywords": "scientific information extraction;different scientific information extraction tasks;raw scientific text;scientific documents;citation graph;end information extraction;literature search;citationie;extraction;level entity clusters;scientific progress;document;scientists;broader literature;sciie;key information;content;individual paper;prior work;paper;tasks;importance;task;structure;future work;relations;sizable improvement;significant gains;language;methods", "pdf_keywords": "citation graph information;different scienti\ufb01c information extraction tasks;relation extraction;citation graph;language scienti\ufb01c documents;salient entity classi\ufb01cation;textual content;key entities;machine learning domain;mention identi\ufb01cation;document text;concrete example;speech recognition system;long document;content;late fusion models;information;single dataset;early fusion;sciie;example;strong baseline;network structure;concept;strong improvements;structure;task;detailed comparison;model;paper"}, "50c651e9f94f9d4927a726af0ef44818179d87da": {"ta_keywords": "semantic parsing;semantic parsing evaluations;semantic parser;straightforward machine translation task;machine translation;structured meaning representation;standard machine translation components;machine translation methods;natural language utterance;informative baseline;results;use;research;advances;problem", "pdf_keywords": ""}, "cd0702deabaa8b7ccfba077f89dcc24e48ae1d47": {"ta_keywords": "subtopic retrieval;subtopic retrieval problem;query likelihood relevance ranking;most traditional retrieval methods;baseline relevance;intrinsic topic difficulty;query topic;ranking;independent relevance;maximal marginal relevance;many different subtopics;statistical language models;trec;documents;document;other documents;interactive track;redundancy;metrics;mmr;traditional precision;mixture model;data;utility;several methods;strategy;framework;problem;assumption", "pdf_keywords": ""}, "c1d0e73ec3aaf7ffdcbe41835d649d638cbc2f2d": {"ta_keywords": "consistent accelerated inference;confident adaptive transformers;natural language processing;additional prediction heads;meta consistency classifier;nlp;computational efficiency;computational effort;expensive multilayer transformers;approximate computational methods;unpredictable performance costs;inference;high confidence;efficiency;consistency;novel approach;intermediate layers;cats;input;method;original model;specifiable degree;top;work", "pdf_keywords": "con\ufb01dent adaptive transformers;consistent accelerated inference;new conformal prediction approach;intermediate transformer representation;meta predictors;prediction;transformer;computational ef\ufb01ciency;cat model;conformal calibration process;meta classi\ufb01er;expensive multilayer transformers;dcal;early classi\ufb01er;inference;retrospective analysis;reliable margin;python;dtest;novel approach;ef\ufb01cient marginal guarantees;arti\ufb01cial intelligence laboratory massachusetts institute;natural language processing;framework leverages;nlp;multiple tasks;con\ufb01dence;generality;tal;signi\ufb01cant gains"}, "77cd3ae8a0b9ef6865d5324a4d62280e6f7a1053": {"ta_keywords": "data augmentation;augmentation methods;label augmentation;e2e asr robust;automatic speech recognition;augmentation;augmentation method;chime challenge datasets;augmentations;generative adversarial network;e2e asr;e2e asr models;gan;asr module;noisy recordings;spontaneous speech;clean speech;speech;accuracy;different audio characteristics;further improvements;specaugment;wer;conventional specaugment;label distributions;text;robustness;great performance;cycleconsistent;data", "pdf_keywords": "data augmentation methods;augmentation methods;data augmentation;label augmentation;augmentation method;augmentation;augmentations;generative adversarial network;chime challenge datasets;gan;noisy recordings;specaugment;spontaneous speech;clean speech;speech;accuracy;conventional specaugment;asr module;further improvements;different audio characteristics;e2e asr;e2e asr models;real tasks;label distributions;text;wer;talk scenarios;cycleconsistent;tts;thier combinations"}, "3b3a5a9c7352b74e8377ce3182ea646b0bed5b4c": {"ta_keywords": "neural semantic parsing;neural semantic parser;semantic parsers;natural language;executable meaning representations;nl;neural network;machine;best list;features;impressive improvements;baseline models;cursory;task;results;coherence;problems;obvious problems;performance;adequacy;mrs;previous methods;lack;simple approach;paper;manual inspection", "pdf_keywords": ""}, "89d15c9de3608157ff746af7368556149b50e037": {"ta_keywords": "language modeling;language models;headline generation;atomic semantic units;language model;most language modeling methods;minimum semantic units;level semantics;atomic language units;tune language models;implicit semantics;distinct semantic expert;human languages;words;word;corresponding word;sememes;sdlm;probable senses;hownet;sememe;interpretability;sequential patterns;robustness;experts;paper;powerful tools;level manipulation;way;significant effectiveness", "pdf_keywords": "language modeling;language model;most language modeling methods;chinese language modeling dataset;word generation process;sequence learning;minimum semantic units;several sememes;implicit semantics;human languages;novel sememesense;language;syntactic information;sequential patterns;arti\ufb01cial intelligence state key lab;next word;words;sememes;sememe experts;sparse product;generic chinese word;chinese headline generation experiment;sememe;intelligent technology;sequence;level decoder;cst;task;context;systems"}, "9dbd86f089c2132dc46d316750d9786d60d5d720": {"ta_keywords": "annotation tool;manual annotation;annotation process;token boundaries;web;primary data;cora", "pdf_keywords": ""}, "6f1ca0249eafa36a5762ac53f6ba2a4ee2133456": {"ta_keywords": "transcribed audio;speech recognition training;quality transcription;domain asr corpus;high transcription quality;audio;supervised training;segmentation pipeline;professional human transcribers;sentence segments;unsupervised training;total audio;audiobooks;podcasts;hour xl training subset;word error rate;gigaspeech;other smaller training subsets;test evaluation sets;validation stage;youtube;segments;dev;hours;high quality;alignment;topics;arts;paper;styles", "pdf_keywords": "popular speech recognition toolkits;speech recognition training;quality transcription;convolutional neural networks;segmentation pipeline;sentence segments;espnet baseline;espnet;convolution;baseline systems;alignment;segments;system training;augmented transformer;kaldi;transformers;conformer;gigaspeech;pika;architecture;athena;section;range interactions;different sizes;local sensitivies;\ufb01ve subsets;experimental results;experiments"}, "22b7a7c9faa8f340520ae1418c9cf8d960aaeec0": {"ta_keywords": "symbolic reasoning systems;symbolic knowledge bases;emulate symbolic logics;symbolic reasoning;symbolic knowledge;dataflow query language;reasoning system;neuro;order logics;symbolic methods;neural networks;computational intractability;language questions;formal results;set;task;present results;gap;choice;chapter;claim;delicate balance", "pdf_keywords": ""}, "eeec05fc11b2e0b40b3b0800bc50930e240cafeb": {"ta_keywords": "textual information sources;textual features;corpus;corpora;wikipedia;online technical material;semantic impact;prerequisite structure;technical publications;truth labels;knowledge;individual reader;complex technical material;classifier;documents;pages;labels;statistical methods;features;various sorts;readers;crowd;task;production;principle;ground;domain;signals;pairs;access", "pdf_keywords": ""}, "525b7f73744f5650391be4678d6d51ddaf23ed72": {"ta_keywords": "semiparametric estimation;nonlinear structural errors;nonlinear errors;econometrics;consistent estimation;parametric estimation;invariables models;variables models;variables model;statistics;annals;wang;southern california;taupin;paper;hsiao;university;journal;li", "pdf_keywords": ""}, "d338bcd1e34a8259e123465203b05c5bf21aa12a": {"ta_keywords": "individual japanese speakers;speech synthesis;japanese speaker;english acoustic model;erj voices;speaker individuality;acoustic model;model adaptation techniques;speaker;natural english speech;dependent acoustic characteristics;native english speaker;prosodic differences;pronunciation errors;voices;english speech;prosody;language system;erj;english;hmm;duration;framework;read;naturalness;differences;power;technique", "pdf_keywords": ""}, "095bc69eddbf73fabf58a929d2be9a99c1b533a6": {"ta_keywords": "recommendation systems;computational social choice;preferences;preference;library;high quality data;preflib;delimited data formats;community;kidney exchanges;online resource;survey;facets;repository;interest;centralized repository;awareness;emergence;challenges;applicability;initial release;areas;techniques;growth", "pdf_keywords": ""}, "85099e075880a4844f3de77006a80c73daf99a4c": {"ta_keywords": "syntax;simplenlg;word order phenomena;grammatical coverage;surface realisation engine;german;implementation;examples;several features;current framework;system;gatt;reiter;special focus;means;paper", "pdf_keywords": ""}, "f7ce4c7ec30c846cc122393deee98f1eacd24049": {"ta_keywords": "dialogue state tracking;dialogue state tracker;long short term memory neural networks;dialogue state;long short term memory;lstm;lstm network;dialogue participants;utterances;input utterances;current utterance;neural networks;embeddings;words;input;vectors;orders;sparsity problems", "pdf_keywords": ""}, "bd24b47165407a8b2d32016645ca71f7c9213636": {"ta_keywords": "email speech;text classification;speech acts;email;classification learning methods;intent;messages;sender;ontology;text;class;certain categories;categorization problem;reasonable recall;information;verbnoun pair;meeting;high precision;fashion;experimental results", "pdf_keywords": ""}, "b54d49cdf57abf7f7e7bcc0e946f450fd807f829": {"ta_keywords": "inverse reinforcement learning;maximum entropy irl framework;markov decision processes;maximum likelihood constraint inference;simple reward;expert agent;nominal reward function;reward function;control task;feature constraints;agent;hard constraints;constraints;knowledge;cumulative rewards;mdp;irl;mdps;likelihood;action;policy;nominal model;demonstrations;behavior;environment;such behavior;state;set;approach;setting", "pdf_keywords": "inverse reinforcement learning;maximum likelihood constraint inference;maximum entropy irl framework;markov decision processes;simple reward;nominal reward function;maximum likelihood constraint;maximum entropy approach;reward function;constraints;hard constraints;feature constraints;observed behavior;control task;expert agent;agent;obstacle;knowledge;policy;action;mdp;behavior;likelihood;mdps;environment;irl;nominal model;demonstrations;algorithm;iclr"}, "1a2410823486613e327892f05b38d3070f2d712c": {"ta_keywords": "networks", "pdf_keywords": ""}, "3bb1e24eb3429f807397833105d1e137d9927767": {"ta_keywords": "current active sequence labeling methods;active sequence labeling;entity recognition;standard active sequence labeling method;human annotations;event detection tasks;sequence mixup;label efficiency;effective data augmentation method;seqmix;sequences;level labels;discriminator;samples;challenge;terms;iteration;mixup;experiments;inefficient way;method", "pdf_keywords": "active sequence labeling framework;sequence labeling task;standard active sequence labeling method;entity recognition;standard active sequence;new framework seqmix;candidate sequences;seqmix;data augmentation;event detection tasks;sequences;more data diversity;data augmentation method;perplexity sequences;labels;baselines;perplexity scores;samples;discriminator;model generalization;terms;plausible ones;different data usage percentiles;plausible pseudo;iteration;f1 scores;mixup;study;experiments"}, "17c9a0f1a287c08bb2c1c1df47fa51ce1e428c4e": {"ta_keywords": "advanced dnn;robust feature extraction;rnn backend", "pdf_keywords": ""}, "a064010cf6fe594b2506a8fecd16dc0040211daa": {"ta_keywords": "neural machine translation;multilingual encoding method soft decoupled encoding;multilingual data;resource language;resource languages;nmt decoder;target language;translation;different languages;gram;nmt models;efficient character;parallel data;english;nmt;lrl;lrls;decsde;performance;bleu;hrl;consistent gains;effective strategy;ones;purpose;experiments", "pdf_keywords": "multilingual neural machine translation;multilingual encoding method soft decoupled encoding;multilingual transfer;neural machine translation;side lexical transfer;multilingual nmt;resource language;resource languages;target words;target word;corresponding vocabulary;graham neubig language technologies institute;nmt decoder;similar representations;nmt decoders;languages;different representations;gram;vocabulary overlap;ef\ufb01cient character;lrl;similar words;parallel data;lrls;target;target side;ef\ufb01cient adaptation;hrl;luyu gao;sde"}, "2fbb75d7947808698f1554e4d400ec5ecb5ef998": {"ta_keywords": "multiple choice reading comprehension;challenging reading comprehension;answer selection task;answer selection;multiple choice readingcomprehension;span prediction models;span prediction model;long summaries;weighted global normalization;task baseline performance;attention;long documents;narrativeqa;model performance;recent evidence;method;fragility", "pdf_keywords": "reading comprehension model;answer selection aids performance;answer selection task;answer selection model;current reading comprehension;challenging reading comprehension;comprehension models;answer selection;long summaries;span prediction model;entire summaries;task baseline performance;task baseline;weighted global normalization method;long documents;scores;predictions;global normalization;narrativeqa;document;documents;portions;length portions;performance;model performance;context;novel method;models;parallel;choice setting"}, "c7c93601b52b1bcc68ec1f8b2c77c54f1b358ab9": {"ta_keywords": "pairwise comparison models;pairwise comparison data;sample complexity;comparison data;comparisons;crowdsourcing;lower bounds;sample testing;complementary information;sample test;minimax sense;samples;information;ratings;modeling assumptions;assumptions;people;results;theoretic;thurstone;mst;range;distributions;sets;parameter;question;sst;btl;paper;wst", "pdf_keywords": ""}, "e59adee86b666ad76164b3446cfee5068a15e5c9": {"ta_keywords": "efficient abft scheme;nn layers;abft;nn inference;nns;nn layer;many nns;abft schemes;layers compute;neural networks;gpus;memory;high compute;spacecraft;soft errors;intensity;adaptive approach;wide range;bandwidth ratios;time overhead;others memory;current approaches;arithmetic intensities;deployment scenarios;safety;execution;critical domains;untapped opportunities;environments;scenarios", "pdf_keywords": "gpus;gpu hardware;nn inference;impart fault tolerance;future nns;many nns;nns;fault tolerance;nn design;neural network inference;efficient redundant execution;arithmetic intensity;matrix multiplications;abft;matrix;intensity;arithmetic;algorithm;promise;efficient approach;adaptive approach;time overhead;execution;section;deployment scenarios;mo;usa;mix;november;size"}, "e6fa88f4af68aa7be4ae91940892eee52571997c": {"ta_keywords": "shot object detection task;shot object detection;rare objects;new benchmarks;detectors;current benchmarks;benchmarks;rare classes;simple few;coco;accuracy;datasets;stable comparisons;prior methods;few examples;examples;tuning approach;points;new state;pascal voc;lvis;art;last layer;methods;simple approach;evaluation protocols;multiple groups;problem", "pdf_keywords": "siamese neural networks;new benchmarks;early lexical learning;recognition;shot image;machine learning;datasets;feature reweighting;object detection;models;stable comparisons;rare classes;coco;shape;liu;examples;lvis;arts;points;importance;large margin;koch;ap;conference;pascal voc;evaluation protocols;wang;kang;jones;new states"}, "db0a3ce9f315f650fe5220101c5677778de39fee": {"ta_keywords": "discriminative parser;machine translation;parallel text;parser;parse tree;derivation tree;margin training;latent variable;accuracy;model;paper;measures;method", "pdf_keywords": ""}, "06f4de06fc37576e1e381cd76e375d57852047b9": {"ta_keywords": "neural machine translation;task french;english dataset;clean text;task;text;nmt;bleu score;wmt;typos;robustness;domain text;baseline vanilla transformer;grammatical errors;remarkable performance;performance;bleu points;model;submission;noise;other varieties;method", "pdf_keywords": ""}, "cd3595f65519e4af6bcd073790ac32acdafadf55": {"ta_keywords": "shot image generation;adaptation;human faces;few available training examples;diversity;source domain;weights;related source domain;appearance;examples;target domain;target;few observations;emojis;model;more data;few examples;source;domain;additional parameters;changes;performance;dissimilarity;distribution;respect;information;method;important factors;order;number", "pdf_keywords": "shot image generation;generative model;real faces;adaptation;weights;continuous learning framework;source domain;tuning process;examples;quality results;target;more data;source;important parameters;target domain;different target domains;few examples;performance;data;lot;algorithm;information;parameter;preservation;importance;changes;respect;method;dissimilarity;important factors"}, "6887537de3655a25c75bf4d0833f51e72331bdad": {"ta_keywords": "enhanced audio signal;extended audio signal;noisy audio signal;noisy signal;extension network;phase estimate;network parameters;common size mask;method;process;environment", "pdf_keywords": ""}, "a8fc183c089bd596ccc48b3d666f8814e1b41e55": {"ta_keywords": "first large generative code model;program synthesis;standard program synthesis benchmarks;code infilling;comment generation;unified generative model;generative model;code files;synthesis;editing;code;type inference;large corpus;right generation;bidirectional context;incoder;file;only models;challenging tasks;performance;right;tasks;model;arbitrary regions;shot setting;comparison;end;regions;ability;similar scale", "pdf_keywords": "interactive code editing;code editing;program synthesis;comment generation;editing;tag generation;shot code in\ufb01lling tasks;editing tasks;metadata conditioning;bidirectional translation;generative model;uni\ufb01ed generative model;practical code in\ufb01lling;technical jargon;causal masking objective;generation;nautral language descriptions;right contexts;code;english;class attribute inference;type prediction;qualitative examples;right generation;chinese;in\ufb01lling;training;shot performance;shot;occurrences"}, "9a43dda4b01dde5d513c431564098e4d8794a7a5": {"ta_keywords": "large sentiment datasets;word cluster features;level sentiment analysis;english movie reviews;semantic spaces;product reviews;supervised state;feature;unlabeled data;words;clusters;art classification approach;czech movie;document;article;current state;art;method", "pdf_keywords": ""}, "2f201c77e7ccdf1f37115e16accac3486a65c03d": {"ta_keywords": "adversarial defense;robust adversarial defense;adversarial examples;stochastic activation pruning;adversary;attacks;deep learning systems;neural networks;misclassification;sum game;game theory;real images;mixed strategy;accuracy;wild;model;perturbations;calibration;experiments;humans;reliability;inspiration;problem;sap;light", "pdf_keywords": "adversarial defense;robust adversarial defense;adversarial training yields;adversarial setting;adversarial examples;ensemble adversarial training method;stochastic activation pruning;neural networks;activation functions;activations;image classi\ufb01ers;accuracy;training;ensemble;models;networks;sap;aran khanna1;model;additive bene\ufb01ts;iclr;mixed strategy;abstract;nayebi;reinforcement learning;1amazon ai;method;anima;calibration;kamyar azizzadenesheli3"}, "136235d2a3dc4f1c995eaf977aec9c42114da850": {"ta_keywords": "morphological reinflection;morphosyntactic features;crosslingual variation;generalization across languages;language families;languages;hebrew;classical syriac;typological diversity;arabic;turkish;sigmorphon shared task;multiword lemmas;sigmorphon;unimorph;kurdish;extensive error analysis;indonesian;egyptian;polish;karelian;predictions;systems;misspelled forms;models;task;v\u00f5ro;eibela;evenki;ash\u00e1ninka", "pdf_keywords": ""}, "8a09c90f6e9a3f6c3b172e5059c7af47f528f66b": {"ta_keywords": "artistic typography;semantic reinforcement;thematic reinforcement;text;boring input word;input word;google doodles;visual cues;creative context;letters;individual letters;word;theme;latent space;meaningful baselines;unsupervised approach;cliparts;compute similarities;context;education;participants;treats;human studies;approach;computational approach;outputs;trick;use;treat;message", "pdf_keywords": "artistic typography;semantic reinforcement;thematic reinforcement;word typography;text;google doodles;word;visual cues;doodles;doodle;theme;task;context;ramprs;replacement;exam;technology;computational approach;abstract;approach;introduction;treats;work;education;treat;conclusion;use;message;figure;trick"}, "1022696090666eab5c82ebc07d63c0de2fca2521": {"ta_keywords": "soft joins;inductive classification tasks;text classification;classification tasks;relational databases;mature inductive classification systems;textual identifiers;more general similarity;world wide web;similarity;reasoning tasks;whirl;tables;unlabeled items;extension;equivalence;data;high confidence;atomic values;large pool;paper;number;traditional operation", "pdf_keywords": ""}, "71124b00b873e85aa55b07100cd5b492e5b1d73d": {"ta_keywords": "integrity protection scheme;integrity protection;quantum key distribution network;data integrity certification;data integrity;secret sharing;message authentication code;integrity check;universal2 hash function;qkd network;time pad encryption;tokyo qkd network;powerful security tools;key distribution;storage system;term secure;qkd;party verification;verification;quantum;data owner;storage;party verifier;stamp;mac tag generation;spss system;vernam;scheme;mac tags;shares", "pdf_keywords": "verifiable secret sharing scheme;secret sharing protocol;secure data transmission;theoretical security;data integrity;authentication;qkd network;tokyo qkd network;data storage system;storage system;qkd;key distribution;storage;simple share renewal function;party verification;quantum;spss system;promising solution;real metropolitan area network;data backup system;metropolitan area network;server;scheme;hardness;hiding;discrete logarithm problem;key player;best knowledge;attack scenarios;system"}, "eb7a64195ef4a268f79fa6740f128387f2696c65": {"ta_keywords": "inverse reinforcement learning;environment reward;reinforcement learning;contextual bandit;contextual bandit orchestrator;ai agents ethical values;environmental rewards;constrained policy;reward;policy orchestration;agent;agents;environment;pac;policies;constraints;algorithms;demonstrations;constraint;implicit constraints;unspecified constraints;orchestrator;best actions;novel approach;complex ways;values;novel ways;set;society;techniques", "pdf_keywords": ""}, "6cddfbed35c46937588bd9d6b846ca2855953cea": {"ta_keywords": "speech translation lattices;neural lattice;attentional encoder;word lattices;neural sequence;latticelstm;sequence models;lattice;attention mechanism;sequence model;decoder model;posterior scores;encoder;treelstm;alternative sequences;posterior probabilities;uncertain inputs;inputs;consistent improvements;input;bias term;gates;architecture;baselines;uncertainty;sum;stream system;child;best hypothesis;compact form", "pdf_keywords": "speech translation lattices;lattice encoder;attentional encoder;sequential encoder;high lattice scores;lattice scores;better training convergence;decoder model;lattice;sequential asr outputs;sequential data;parallel sequential data;attention mechanism;sum treelstm;source embeddings;posterior scores;consistent improvements;large corpora;inference;hidden units;predecessor;predecessors;baselines;only minor improvements;training;more focus;baseline;strict generalization;units;model"}, "58a2e825884bc86e650fffafb86a2833117852c5": {"ta_keywords": "novel bayesian tuning;ptm selection;tuning pre;target ptm;ptm;ptms;exploiting model hubs;heterogeneous ptms;ptm hubs;multiple ptms;tuning algorithm;tuning;homogeneous ptms;model hub;ranking;models;target task;model hubs;tuning part;rest ptms;features;model;tune;label evidence;logme;machine;high cost;tasks;specialized methods;sufficient exploitation", "pdf_keywords": "exploiting model hubs;ranking;ptm hub;ptm hubs;model hub;multiple ptms tuning;tuning pre;model hubs;ptms;models;features;tuning;label evidence;logme;software;jianmin wang1;tasks;ziyang zhang2;new algorithm;beijing;maximum value;new paradigm;\ufb01ne;paper;conference paper;tsinghua university;school;various types;china;novel theoretical analyses"}, "e6cec3044688f1701b4b72b4b2189f215abc3759": {"ta_keywords": "massively crowdsourced evaluation tasks;new reward mechanisms;output agreement mechanisms;evaluation tasks;truthful behavior;verifiability;truthful responses;truth serums;assignments;agents;extraneous elicitation;knowledge;labeling images;effort;underlying generating model;mechanisms;beliefs;major challenge;abilities;heterogeneity;minimal assumptions;online courses;paper;intuitive structure;practice;structure;such settings;many types;absence", "pdf_keywords": ""}, "549df5fc83c382cbdf633dc782fa67bf2f983f2c": {"ta_keywords": "stochastic gradient descent;random mixtures;deep neural networks;sgdrm;linear activations;data breach threats;data;optimal point;simple way;converges", "pdf_keywords": ""}, "f61886d138497431cbeaa7bb73051bfb7a745026": {"ta_keywords": "linguistic supervision;scene graph generation;crowdsourced triplets;visual scene graph generation;categorical supervision;multimodal data;captions;level supervision;sequential context;linguistic structures;weak supervision;supervision;context;objects;subjects;images;prior methods;predicates;nouns;human;information;diverse sources;web;relations;blog posts;triplets;techniques;phrasal;individual triplets;image", "pdf_keywords": "captions;multimodal data;instructional videos;imagecaption pairs;youtube video descriptions;global context;level supervision;images;prior methods;sequential context;social media posts;supervision;web;techniques;text;image;diverse sources;blogs;objects;subjects;extensive experimental comparisons;localization;phrasal;method;internet;impact;approach;road"}, "275aaa20ba853c40a461f224eefbf06730bf03a9": {"ta_keywords": "robust hessian power method;gradient descent methods;nonconvex optimization;simple gradient;only gradients;polynomial speedup;saddle points;negative curvature;algorithm;stationary point;iterations;art algorithms;stochastic setting;order;paper;idea;previous state;terms;main contribution;jin et al;complexities;central research topic", "pdf_keywords": "nonconvex loss functions;gradient descent methods;nonconvex optimization;robust hessian power method;saddle points;optimization theory;simple gradient;only gradients;modern machine learning problems;deep neural networks;tensor decomposition;polynomial speedup;negative curvature;models;principal component analysis;descent;stationary point;algorithm;computing studies;iterations;computer science;paper;frontiers;introduction;nov;peking university;school;order;theoretical physics;idea"}, "e6924d247b56980260e4c68dbc51b947409e4764": {"ta_keywords": "local sgd;new efficient methods;unified theory;kaust baseline research grant;russian federation;science;goszadaniye;higher education;research;rfbr;ministry;project number;work", "pdf_keywords": "local sgd methods;local sgd;supervised machine learning models;convex regimes;new e\ufb03cient methods;training;kaust;uni\ufb01ed framework;uni\ufb01ed theory;saudi arabia;yandex;nov;russia;sirius;abstract;eduard gorbunov mipt"}, "a1fc0041ef89ed5371317c8e2cc5effa8f38ae48": {"ta_keywords": "bayesian network structure;reliable causal discovery;large graphs;nodes;local clusters;exact search methods;improved exact search;exact search;local search strategy;superstructure;search space;linear gaussian setting;neighbors;inverse covariance matrix;score functions;methods;scalability;hops;several strategies;assumption;assumptions;high accuracy;exact score;research;hundreds;weaker assumptions;work;procedure;support;faithfulness", "pdf_keywords": "causal discovery;reliable causal discovery procedure;linear structural equation model;linear gaussian setting;inverse covariance matrix;exact search;local search strategy;search space;sscf assumption;common assumptions;assumptions;methods;scalability;sem;exact score;constraint;main contributions;several strategies;data distribution;method;faithfulness;support;section;work;rise"}, "0a227a21172f7344ad911aeefc40ae4ec82d7cac": {"ta_keywords": "metaphor identification;figurative language;annotated corpora;metaphor;linguistic creativity;nlp methods;computational lexical semantics;new annotated materials;nlp techniques;semantic tasks;lexical acquisition techniques;datasets;dunn;creation;new features;interpretation;workshop;computational approaches;naacl;recognition;workshops;machine;modelling;robust tools;approaches;identification;domain;tsvetkov et al;many new avenues;recent related events", "pdf_keywords": ""}, "178f424d0f156cbf5b35eb241fc00b27a0a3808b": {"ta_keywords": "robust speech recognition;speech recognition;speech enhancement;lstm networks;lstm;robust asr tasks;sequence training;term memory;best word error rate;neural network;speech;asr;estimation architecture;noise;recognition;se;several integration architectures;pipeline architecture;integration;long short;performance;consistent integration;combination;earlier work;options;paper;objective criteria;work;kind", "pdf_keywords": ""}, "317ed59456d76b500a7eb63b181df9e8b795976b": {"ta_keywords": "urban parking;parking;queues;nash solution;parallel queues;queue length;utility maximizers;optimal welfare;games;urban centers;nash;game framework;occupancy;game;welfare;other performance metrics;simulation;society;complex scenario;network;drivers;theoretic structure;time;collection;usual result;set", "pdf_keywords": "congestion;overall traf\ufb01c congestion;parking resources;queues;parallel queues;congestion relationship;nash equilibrium;parking;social optimal;optimal welfare;optimal equilibria;utilization;limited game;utilization factor;different nash;simulations;network topology;nash;game;occupancy;network;welfare;through simulation;complex scenario;drivers;drivers1;simulation tool;system;information;time"}, "56823e326f2515f73662b176054fbee0895e0c44": {"ta_keywords": "web forms;www system;update request;particular update request;requests;forms;assistant;familiar tasks;more complex tasks;sap;expertise;navigation problem;request;users;right form;personal tool bars;large system;user;correct form;specialist;relations;thousands;stream;standard installation;sea;problem;various aids;paper;former case", "pdf_keywords": ""}, "7891ec1d8ba2abf238326dc6e8862cc4431a6f5c": {"ta_keywords": "optimal sequential placement policies;relay placement;optimal impromptu deployment;convex hop costs;random lattice path;link scheduling;relay;multihop wireless network;relays;impromptu deployment;optimal policy;markov evolution;measurement traffic;deployment operative steps;heuristic;end cost metric;path;base station;distance;sensor;various probabilities;east;north;step;simple link;performance;certain threshold;variation;parameters;same direction", "pdf_keywords": ""}, "cdf5eb63e9c2434073e811aba50ae80ede9d15f6": {"ta_keywords": "focused retrieval;passage retrieval;document corpus;question answering systems;clueweb12 collection;crowdsourcing;relevance;collection;documents;new collection announcement;web;new web;rank method;effective learning;query;intermediate step;own right", "pdf_keywords": ""}, "1afe82d34c182d43cbcc365d26e704058aa32351": {"ta_keywords": "voice conversion;gaussian mixture model;speaker model;parameter generation algorithm;parallel corpus;joint density model;model optimization approach;probabilistic integration;dynamic features;mivc;model;model structure;other vc methods;perceptual quality;parameter trajectory;gmm;vc;information criterion;integration;paper;requirement;degradation;first problem;difficulty;second problem;discontinuity;problems;mutual influences", "pdf_keywords": ""}, "2c871df72c52b58f05447fcb3afc838168d94505": {"ta_keywords": "knowledge neurons;such knowledge neurons;factual knowledge;bert;language models;knowledge attribution method;training corpus;pretrained transformers;relational fact;blank cloze task;neurons;facts;fact;transformers;activation;concept;fill;paper;expression;preliminary studies;scale", "pdf_keywords": "knowledge neurons;such knowledge neurons;knowledge expression;factual knowledge;knowledge;language models;pretrained transformers;knowledge attribution method;training corpus;neurons;computational linguistics;relational fact;forward networks;transformers;facts;activation;bert;fact;feed;addition;abstract;expression;paper;implicit way;\ufb01ll;key lab;baobao;blank cloze task;scale;cl"}, "26c2aad87810418b09e0f5b80352dd4d2536afe3": {"ta_keywords": "human social skills;user speech;dialogue system;social communication skills;social skills training;social interaction;human interaction;social skills;social skills trainer;social skill;speech language features;speech;training system;virtual avatar;training systems;interaction;language features;skill;avatar;sst;agent interaction;user survey;human anxiety;training;unfamiliar person;computer;language information;ability;experimental evaluation;participants", "pdf_keywords": ""}, "07cedc7899497f2f4ee6f4736e03b78accb47b74": {"ta_keywords": "relational neighbor classifier;harmonic functions classifier;training data;network data;many recent graph;unlabeled instances;few labels;authoritative instances;random graph walk;several benchmark datasets;same classification accuracy;data;instances;large margin;training seeds;ssl;macskassy;ssl methods;wvrn;vote;methods;effective baseline;field;provost;zhu et al;goal;amount", "pdf_keywords": ""}, "d4d26ccbf1e64e725b5bffc08ab28a72e271facb": {"ta_keywords": "pragmatic chinese dataset;coherent question sequences;easy sql queries;sql;question sequences;sql queries;dependent text;databases;xdts;datasets;questions;context;considerable attention;independent questions;major challenges;challenging problems;exact match accuracy;biases;extent;chase;recent years;high proportion;wide range;potential applications;problem;best approach;scale;work", "pdf_keywords": ""}, "26d5c7ad2778c77a1b8734dceb34fe38a1179e2f": {"ta_keywords": "novel malicious application detection model rt;malicious app space;malicious apps space;time malicious application detection;various malicious applications;possible malicious applications;malwares detection;malwares;app;android;normal apps;android devices;normal app space;normal application modeling;normal apps space;hidden markov model;application testing samples;devices;mobile platform;negative selection;time api monitor tool;real;api data;rt;rrns;likelihood vectors;safety;model;mad;time series data", "pdf_keywords": ""}, "9045bf2a9c1e2b9621c69c57f991d10880e91f18": {"ta_keywords": "computational hardness;sparse pca;polynomial time algorithms;submatrix detection;computational efficiency;clique problem;interesting computational phenomena;other statistical problems;statistical problems;different statistical problems;br13a;host;existence;variant;question;context", "pdf_keywords": "computational hardness;submatrix detection;sparse pca;polynomial time algorithms;secret leakage planted clique;interesting computational phenomena;clique problem;computational e\ufb03ciency;other statistical problems;logspace reducibility;statistical problems;examples;techniques;notion;ability;abstract;ideas;host;br13a;existence;july;jay;results;variant;question;space e\ufb03ciency;jul;di\ufb00erent;context"}, "24a2f68cf81ba3ee55e7a87d0770374ab8e99858": {"ta_keywords": "free recursive logic programs;recursive logic programs;recursive programs;learnability;eecient learnability;polynomial predictability;equivalence queries;boolean functions;certain cryptographic encoding schemes;disjunctive normal form;learning algorithm;examples;models;restricted class;pac;language;function;rst portion;problems;novel method;identiication;boundaries;paper;ultimate goal", "pdf_keywords": ""}, "5ed4b17a4b7932619f0969e1f5acae76e90f7bdd": {"ta_keywords": "neural semantic parsers;novel recursive semantic parsing framework;recursive semantic parsing framework;sql query layer;sql query generation problem;novel question decomposer module;complicated utterances;recparser;sql queries;sql task;utterance;large search space;text;layer;different components;different layers;paper", "pdf_keywords": ""}, "feb403bb5a064ab68b2db655b80a7417f7cfc9f3": {"ta_keywords": "novel relational learning approach;relational learning method;relation tree;markov networks;relational mns;relational data;efficient hidden variable detection algorithm;contrastive variable induction;similar prediction quality;prediction qualities;treermns;treermn;real datasets;long range dependencies;complex features;features;rmn;training;cvi algorithm;cvi;rmns;training speed;variables;mns;challenge;state;pairwise;complex model;restricted class;empirical results", "pdf_keywords": ""}, "2fb44f1317bc51a1e011a5a44d817ad9104e29e8": {"ta_keywords": "differential privacy;differential privacy applications;tight privacy guarantees;privacy;private mechanism;private auto;encoder;nlp;utterances;formal guarantees;small encoder;formal analysis;text;peer;authors;formal approach;detailed scrutiny;individuals;true sensitivity;entire dataset;results;optimistic case;krishna et al;experimental results;adept;least factor;intention;proof;downstream tasks;contribution", "pdf_keywords": "differential privacy;input utterances;natural language processing;latent space;nlp;empirical methods;feasible search space;lm;atis;emnlp;laplace mechanism;detailed proof;dp;neighborhood;detail;sec;camera;key concepts;devil;conference;ivan habernal;force attack;article;ready version;publication"}, "b3848d32f7294ec708627897833c4097eb4d8778": {"ta_keywords": "neural language models;language models;annotated data;model safety;public dialog data;factual grounding;helpfulness;safety;dialog;dialog applications;filtering candidate responses;crowdworker;external knowledge sources;classifier fine;human values;content recommendations;web text;model;data;key challenges;role consistency;quality;education;metric;significant improvements;lamda;tuning;less improvements;use;illustrative set", "pdf_keywords": "dialog modeling;speci\ufb01c helpfulness;candidate responses;helpfulness;dialog examples;information retrieval;agent utterances;annotated data;public dialog data;crowdworker;dialog;neural language models;content recommendations;worker interaction;agent role;role consistency;external knowledge sources;model safety;web text;new safety metric;lamda classi\ufb01er \ufb01ne;lamda models;correct responses;human values;key metrics;data;lamda;safety;model;education"}, "17c5e16d16585a01fbfd90ff39f6799952675b21": {"ta_keywords": "bilingual speech recognition;conversational bilingual speech;final bilingual output;monolingual asr;monolingual information;monolingual types;conditional factorization;utterances;joint modeling framework;frame synchronization;code;joint modeling;type;label;general framework;likelihoods;types;work", "pdf_keywords": "bilingual speech recognition;bilingual mandarin;bilingual asr problem;bilingual task;monolingual asr;monolingual label;english speech recognition;conditional factorization;sentence generation;corpora;joint framework;differentiable neural network;cs asr;generative adversarial networks;end framework;data augmentation;code;joint model;toframe;general framework;ef\ufb01cacy;model;lee;end;\ufb01nal output;conclusion;formulation;cs;likelihoods;arxiv"}, "c204d40384d39c59cd7249bde4cd8615972acaac": {"ta_keywords": "machine translation robustness;current machine translation systems;machine translation;language pairs;domain diversity;robustness;shared task;mt models;challenges;shot variants;task;wmt;social media;japanese;test sets;content;shot;mt;findings;real world;second edition;user;ability", "pdf_keywords": ""}, "024aa0b78e2a29d07533ee1c6e3b2e875ae45618": {"ta_keywords": "conversation data;conversations;general word distribution;word use;speaker;own earlier word use;trust;probabilistic model;multiple people;people;previous speakers;japanese;influences;english;behavior;speakers;meeting data sets;companions;effectiveness;model;method;experiments;level", "pdf_keywords": ""}, "ffc211476f2e40e79466ffc198c919a97da3bb76": {"ta_keywords": "policy learning;agent values;agents;global state information;centralised learning;decentralised policies;micromanagement tasks;tractable maximisation;qmix;best strategy;starcraft ii;action value;extra state information;decentralised way;joint action;monotonic value function factorisation;communication constraints;values;value;world settings;consistency;challenging set;behaviour;team;laboratory setting;centralised fashion;same time;attractive way", "pdf_keywords": "policy learning;agent values;agent action;rich joint actionvalue function;micromanagement tasks;decentralised policies;qmix;starcraft ii show;end learning;starcraft ii;tractable maximisation;action value;learning;joint action;extra state information;value function factorisation;value functions;tractable decompositions;centralised setting;value;sophisticated joint state;other value;novel value;centralised end;consistency;end;challenging set;unit;\ufb01nal performance;solution"}, "a6b431df3b3d40c98d8d623cab559a9cddd41662": {"ta_keywords": "schema attention model;dialog systems;star corpus;dialog research;dialog;unseen tasks;schema representations;neural models;specific dialog policies;shot generalizability;task;shot settings;training data;prior work;major challenge;results;significant improvement;ablation experiments;sam;mechanisms;efficacy;domains;feasibility", "pdf_keywords": "schema attention model;natural language responses;dialog systems;shot dialog;dialog research;dialog;response generation;schema representations;dialog policy;unseen tasks;next action prediction model;star corpus;schema representation;schema;schema graphs;shot transfer;system actions;response templates;primary challenge;model;major challenge;maxine eskenazi language technologies institute;reservation;paradigm;mapping;abstract;zero;collection;sam;paper"}, "62763dbdd47f144c73663b6c6b5d95caeb318e43": {"ta_keywords": "noisy matrix completion;low rank matrix;rank matrices;rank models;classical low rank assumptions;noisy completion;underdetermined inverse problem;rank model;low rank;structured matrix;underlying matrix;rank;richer permutation;matrix;estimation;low permutation;richer model;information;estimator;entries;noise;lower bounds;standard approaches;permutation;paper;structural properties;restrictions;logarithmic factors;problem;goal", "pdf_keywords": "permutation rank setting;permutationrank setting;rank polytope;rank decomposition;richer permutation;valuethresholding algorithm;rank;rank model;rank setting;constituent permutation;algorithms;computable algorithms;permutation;intuitive algorithms;matrices;convex approximations;uniqueness;restrictions;various structural results;e\ufb03cient singular;time;consistent estimator;practice;appendix;section"}, "bd49e66af9755e6138967eba6aeb37d8190d2b4f": {"ta_keywords": "relation extraction tasks;natural language explanations;bert baseline;bert;inductive biases;inductive bias;couples;spouses;text;explanations;honeymoons;input sentence;model developers;representations;multinli;baseline;explanation;task;pairs;data;types;input;respect;paper;method;same amount", "pdf_keywords": "natural language explanations;natural language inference datasets;several relation extraction tasks;new explanation groups;semantic parsing;model representations;explanations;modern neural representations;model developers;inductive biases;models;features;explanation pair;input sentence;ngram matching;fact;building models;prior knowledge;ofconcept;various explanatory factors;proof;broad coverage;prospect;types;richer set;performance;multinli;paper;ability;table"}, "5e51edfcef2b28594c63cce97c08752dfd438af0": {"ta_keywords": "structured soft margin confidence;discriminative models;phoneme conversion;structured learning;soft margin support vector machines;phoneme error rate;regularization;phoneme;learning;overfitting;grapheme;g2p conversion task;conversion task;improved robustness;multiclass cw;second order statistics;margin error;g2p;novel method;parameters;best hypotheses;method;methods;paper;terms;ways;update;other approaches;recent years;evaluation experiment", "pdf_keywords": ""}, "eebfece29b7a5c2202f1ec53ef49d6fdb75ce0ea": {"ta_keywords": "neuronal computations;neural computations;teacher neuron;fire neuron;presynaptic neurons;synaptic weights;synaptic connectivity;simulated neural networks;sparse feedback signals;intrinsic electrophysiological properties;backpropagation;learning mechanism;unsigned sparse feedback signals;online learning;complex temporal functions;target spike times;inputs;gradient;output functions;specific input;teacher;intrinsic parameters;cellular properties;fire;parameter updates;time;most computational approaches;student paradigm;event;updates", "pdf_keywords": "neural computation;neuron;neural computations;synaptic weights;sparse temporal feedback;arti\ufb01cial neuron;synaptic connectivity;arti\ufb01cial neurons;backpropagation;complex temporal dynamics;online learning rule;sparse feedback signals;complex temporal functions;feedback signals;gradients;gradient;local gradient;target spike times;postsynaptic potentials;potential dynamics;update rule;computational properties;intrinsic parameters;target input;student paradigm;teacher;membrane;intrinsic properties;time;threshold"}, "e31efa7295e5d6681607ed8ef9c45300d64227aa": {"ta_keywords": "board elections;voting rules;heuristics;multiple winners;votes;optimal manipulation;most votes;agents;many candidates;agent;vote;manipulation;winners;committee;better outcome;uncertain situations;partial information;additional effort;simulations;true preferences;behavior;complete information;situations;scenarios;effectiveness;paper;people;access;way;av", "pdf_keywords": "heuristics;collective decisions;voting;optimal manipulation;vote;agents;better outcome;many real world situations;alternative strategies;simulations;behavior;effectiveness;partial information;situations;scenarios;complete information;jaelle scheuerman;paper;people;louisiana state state university nicholas mattei;experimental study;access;tulane university;ihmc;may;use"}, "99c4007b1f6cb905788479db7fc886168f05e57c": {"ta_keywords": "recurrent dnn architecture;recurrent deep neural networks;dnn systems;recurrent dnns;robust automatic speech recognition;chime challenge data;conventional feedforward dnn;new backpropagation;2nd chime challenge;minibatch stochastic gradient descent;deep representations;full recurrent connections;adaptive training;relative wer improvements;dnns;asr;sgd;speaker;bptt;certain hidden layer;temporal dependency;model;passes;system;state;time;algorithm;hybrid setup;art performance;work", "pdf_keywords": ""}, "c783e1fb3ce8514f981925ee590c00884660ee4e": {"ta_keywords": "causal masked multimodal model;generative models;languageimage models;multimodal outputs;full generative modeling;image tokens;modal tasks;large corpus;hypertext markup;text;gan;language models;document contexts;hyperlinks;bidirectional context;original html source;long token spans;casual masking object;image;common causal;wikipedia articles;document;tokens;spans;cm3 models;cm3;internet;type;end;string", "pdf_keywords": "causal masked multimodal model;generative models;full generative modeling;multimodal tasks;luke zettlemoyer facebook ai research;generative mask in\ufb01lling;large corpus;bidirectional context control;language models;bidirectional context;image tokens;shot summarization;causal;text;cm3;armen aghajanyan;entity disambiguation;internet;strong transfer;art;supervision levels;objective;abstract;mike lewis;new sequence;naman goyal;jan;gargi ghosh;hybrid;mandar joshi"}, "80b92f762e116d4513da27792822897ca3915247": {"ta_keywords": "strong privacy guar021 antees;differential privacy;private gradient;privacy leaks;privacy;baseline privacy;preserving graph convolutional networks;sensitive personal information;social networks;nlp datasets;representation learn002 ing;text classification;random graph splits;convolutional networks;gcns;graphs;documents;relation006 ships;profiles;graph;tical challenges;training specifics;edges;challenges;optimizers;lan016 guages;model;training;scores;competitive f1", "pdf_keywords": "private gradient;strong privacy guarantees;citation networks;preserving graph convolutional networks;private stochastic;strict privacy guarantees;privacy;reddit datasets;\ufb01ve nlp datasets;social networks;gradient descent;sensitive information;nlp tasks;13th language resources;sgd;reddit post classi\ufb01cation;gcns;neural network;mnist;languages;text classi\ufb01cation;\ufb01ve datasets;slovak;models;user interest classi\ufb01cation;forward;lrec;dropout;simple feed;english"}, "3d5b51fc30ffacdcc8424618555accb36756ccc9": {"ta_keywords": "random search direction;unconstrained minimization problem;free algorithm;several stepsize selection schemes;iteration complexity;objective function;stochastic;method stp;iteration;finite differences;stepsize parameter;sphere;stp;positive spanning set;function evaluations;halfspace;points;method;smooth function;current iterate;distributions;uniform distribution;instance;paper;measure;assumptions;probability law;laws;novel;setting", "pdf_keywords": "nonconvex functions;unconstrained minimization problem;free algorithm;coordinate search method;several stepsize selection schemes;numerical performances;function evaluations performance pro\ufb01les;iteration complexity;smooth function;stochastic;random directions;method stp;function evaluations;dds method;method;coordinate directions;stp;points;dds;approach;improvement;\ufb01nite di\ufb00erences;e\ufb03ciency;rgf;paper;problems;rn;setting;terms;large set"}, "845aad7b99f48526fe003c775836091521624471": {"ta_keywords": "such collaborative lexicography projects;crowdsourcing phenomena;wiktionary;russian wiktionary;wikipedia;week articles;knowledge bases;word;binary classification task;traditional semantic resources;words;general public crowd;week;expert;fuzzy nature;strong competitors;data;worth attention;challenging problem;study;good quality;problem", "pdf_keywords": ""}, "a3cd9c4f8fa52c5e23885c2f82931d7e0f7d4b45": {"ta_keywords": "dimensional barcode symbology;dimensional barcode symbols;linear barcode;barcode;drug name;powder drugs;automatic dispenying checking system;new checking system;data;dispensing;label;necessary item data;2d;usual prescribing limits;database files;usual dosage;generic name;system;kilobyte;high capacity;capability;high density", "pdf_keywords": ""}, "697e6eecb0e77ba56c685bb99b221d959739d13b": {"ta_keywords": "automatic image geotagging;tagging;latent dirichlet allocation;tag model;detailed 3d location models;tags;flickr;textual tags;automatic geo;query photo;separate lda models;geo;lda;classification accuracies;visual data;city location;images;various likelihood metrics;model user;cities;location;city;precise location;approaches;many applications;internet;user;first approach;approach;estimate", "pdf_keywords": ""}, "e42b3ead5ff04adfa95c87e0180561f0c3ba4af4": {"ta_keywords": "reinforcement learning policies;learned policy;policy network architecture;vertex networks;action constraints;reinforcement learning;control policies;safety constraints;convex combination weights;hard constraints;convex combination;constraint satisfaction;control systems;safety;convex set;vertices;weights;actions;state variables;exploration;guarantees;hard state;action;output action;points;geometric property;construction;projection step;vns;algorithm", "pdf_keywords": "novel vertex policy network;vertex policy network framework;vertex networks;policy network architecture;safety constraints;control policies;safe layer;neural network architecture design;convex combination weights;convex combination;network architecture;safety;constraints;vertices;safety region;vertex calculation;convex set;weights;vn;vns;guarantees;action;geometry;exploration;algorithm \ufb01rst;challenges;points;geometric property;end way;next section"}, "e54a4e49917eb3da18c2f239be70a68fbd3274c3": {"ta_keywords": "review packages;package authors;reviewers;documentation debt;packages;scientific software;documentation;review process;peer;package;editors;reviews;organizations;review;data science;several community;taxonomy;debt;findings;authors;types;ropensci;td studies;analysis;other roles;study;different types;results;popularity;effort", "pdf_keywords": "oo programming;scienti\ufb01c software;technical debt;data science;documentation;taxonomy;td studies;ropensci case study;review documentation;proposals;code;different td types;peer;study;ropensci;statistical applications;popularity;objective;td;paper;recent years;review;different perspectives;zadia codabux university;context;momentum;oo;saskatchewan;metaphor;mar"}, "59d225fcb08ce66935e0285a9936ee158c4fdb97": {"ta_keywords": "entailment trees;entailment steps;entailmentbank;multistep entailments;textual evidence;systematic explanations;strong language model;explanations;textual question;reasoning;answers;relevant sentences;intermediate conclusions;tasks;qa;generalization;trees;tree;context;hypothesis;facts;input;goal;interest;baselines;answer;model;rationale;dataset;approach", "pdf_keywords": "entailment tree explanations;entailment tree;entailment trees;multistep entailment trees;entailmentbank;explanations;intermediate conclusion leaf node;explanatory worksheet;such trees;answers;\ufb01rst large dataset;similar ideas;qa;\ufb01rst dataset;question explanation;web;explanation;model;relevant facts;science questions;tool;ways;root node;end;novel formulation;skill;pool;baseline results;controls;multistep"}, "deedb9b61a01d686b28e6034770fccc142e77fab": {"ta_keywords": "nlp experiment;different nlp tasks;nlp model;nlp;natural language processing;meaningful predictions;plausible predictions;plausible judgments;unseen languages;representative experiments;reasonable baselines;predictors;languages;possible experimental setting;models;human experts;predictor;regression models;experimental setting;tasks;experimental settings;evaluation score;other experimental settings;model;possibility;different modeling architectures;complexity;input;research;combinations", "pdf_keywords": "nlp experiment;nlp;natural language processing;nlperf;plausible predictions;feature;predictor;representative experiments;new models;models;languages;human experts;regression models;tasks;experimental records;single feature;experiments;task;performance;grid search;multiple baselines;evaluation score;effectiveness;robustness;scoring function;input;experimental settings;vast \ufb01eld;process;introduction"}, "4cfbd97a5b42695697f70a9f28ee29711f6ca433": {"ta_keywords": "aware novelty detection;network saliency;adversarial attacks;trustworthy prediction;saliency map;deep learning;similar driving dataset;indoor driving environment;novel inputs;novelty;learning architecture;novel image;training dataset;autonomous systems;critical autonomous systems;cars;similar features;safety;visual;datasets;scenarios;new input;images;knowledge;task;model;self;input;situations;environment", "pdf_keywords": ""}, "10e88416035a8a3cbef0e65f8967df650abd0a00": {"ta_keywords": "unsupervised word sense disambiguation system;word sense disambiguation;different lexical semantic resources;semantic similarity;similar word sense;russian;resourced languages;target word;sparse one;input word;synset;unsupervised system;traditional vector space model;rand index;sense;context;datasets;relevant sense;sparse mode;watasense;sentence;evaluation;system;dense mode;present system;architecture;respect;paper", "pdf_keywords": "unsupervised word sense disambiguation system;word sense disambiguation system;word sense disambiguation;word sense inventory;semantic similarity;resourced languages;different sense inventories;target word;sparse;unsupervised system;language technology group;input word;web science group;datasets;sense;synset;watasense;russian;informatics;open source;relevant sense;department;apr;data;sentence;evaluation;system;mannheim;cl;performance"}, "4fffa5245d3972077c83614c2a08a47cb578631e": {"ta_keywords": "speech representation learning;unit bert;masked prediction;like prediction loss;prediction loss;input utterance;bert;cluster labels;language model;multiple sound units;sound units;unsupervised clustering step;hidden units;explicit segmentation;target labels;continuous inputs;hidden;input;self;lexicon;model;regions;intrinsic quality;step;key ingredient;unique problems;consistency;variable lengths;hubert;approaches", "pdf_keywords": "speech representation learning;hidden unit bert;speech representation learning approach;speech sequences;unit bert;continuous speech features;masked prediction;deepcluster method;hidden units;bert;bert model consumes;iterative pseudo labeling;like prediction loss;prediction loss;sound units;input utterance;predetermined cluster assignments;multiple sound units;explicit segmentation;hidden;target labels;means cluster assignments;visual learning;self;input;training;segments;sequential structure;yao;of\ufb02ine"}, "520e82c0f35a14ecf78b93de3673bb8b2a3212fc": {"ta_keywords": "timeline extraction;timelines;timeline;distant supervision;temporal expressions;events;joint inference;supervised approach;noisy training data;entities;target entity;predictions;documents;goal;models;state;score points;work;experiments;testing;art performance", "pdf_keywords": ""}, "0115d5d37f7cdc7b8d2147c0bb348e714432e899": {"ta_keywords": "channel speech enhancement;speech enhancement step;noisy speech;telephone speech;language recognition evaluation;telephone audio domain;unaltered noisy speech phase;noisy spectrogram;language identification;domain adaptation;deep neural network;magnitude spectrogram;telephone conversation;noisy audio;mel noisy features;spectral mask;noisy audios;term memory;neural network;identification performance;frequency bin;blstm;video domain;videos;adaptation;significant improvement;mask;lre17;time domain;addition", "pdf_keywords": ""}, "cc2c3df6b09166c54e670d347bfe26dae236ac73": {"ta_keywords": "many automatic knowledge base construction;single abstract problem;incomplete class hierarchy;tasks;instances;akbc problems;akbc;paper", "pdf_keywords": ""}, "f7979c6690562c5f8bf700e3fd184c4d1df0a54c": {"ta_keywords": "bilingual lexical resources;target languages;resource languages;source language;languages;entity mention;universal phonological representations;language;structured knowledge base;entity;neural transfer;total of54 languages;resources;baseline systems;target;pivot;source;accuracy;entry;average accuracy;gap;different scripts;previous work;use;maps;framework;experiments", "pdf_keywords": "entity linking;neural entity;bilingual lexicon;resource language pairs;entity mention;resource languages;source lowresource language;structured knowledge base;lexical data;resource transfer language;entity;entities;information retrieval;languages;language;event coreference;universal phonological representations;document understanding;candidate retrieval;lowresource test language;wikipedia;phonological input representation;english kb;english;text mining;shot transfer;pivot;neural model;hrl;freebase"}, "3b0a1a10d8f7496226635c5c3b8475fcd10d890d": {"ta_keywords": "redundant requests;latency performance;optimal average latency;latency;redundancy;storage systems;more servers;servers;service times;faster execution;requests;multiple copies;complete service;additional copies;memoryless;high loads;such systems;request;many systems;load;data;policies;jobs;system;several recent works;mechanism;scenarios;removal;paper;diverse settings", "pdf_keywords": ""}, "f826381aea632791b6007e427a9587c11b239b6a": {"ta_keywords": "dialog policy learning;dialogue tasks;boltzmann exploration;dialogue systems;thompson sampling;replay buffer spiking;replay buffer;efficient exploration;learning;monte carlo samples;exploration technique;primary reward signal;rewards;action spaces;backprop;neural network;task;successful completion;successful episodes;bayes;promising applications;experiences;improvement;appropriate actions;complex sequence;common approaches;problems;small number", "pdf_keywords": ""}, "f07a326e21395f025a87b2d77cac7e8ca502f002": {"ta_keywords": "textual inference;domain knowledge;question entailment;medical domain;specialized medical domain;art language understanding models;specialized domains;medicine;bionlp;data augmentation;acl;task;challenges;results;prior work liu et al;submissions;system;paper;quad;work;different strategies;state;powerful strategy", "pdf_keywords": "natural language inference dataset;natural language understanding model mt;textual inference;question entailment;domain knowledge;medical domain;specialized medical domain;contextualized representations;art language understanding models;new dataset mednli;specialized domains;medicine;nli;data augmentation;bionlp;speci\ufb01c resources;task;domain;challenges;acl;rqe models;mtl;abstract;ashwin;results;vbkumar;teruko;dnn;importance;vinayshekhar bannihatti kumar"}, "d95aafa571e9cb6795cc28ecf257ead123664e3c": {"ta_keywords": "mrf segmentation energies;standard pairwise clustering criteria;common regularization energies;regularization models;common pairwise clustering criteria;normalized cut;regularization functionals;standard clustering applications;new segmentation model;order mrf constraints;optimization;machine learning;markov random field;mrf;computer vision;continuous solvers;common pairwise;kernel;many common applications;formulations;graph;potentials;linear;average association;inclusion;techniques;nc;move;order nc term;aa", "pdf_keywords": "new segmentation model;image segmentation;biomedical image analysis;potent segmentation results;common regularization energies;object recognition;optimization algorithms;computer vision;clustering;dimensional features;new energy model;energy;rgbm;standard mrf methods;early vision;model \ufb01tting;rgbd;video editing;basic formulations;photo;many useful applications;feature;rgbxy;area;registration;restoration;main contributions;motion;ef\ufb01cient;problems"}, "250e4a8f5155f1f9f60b2dee3e8da8024338db4d": {"ta_keywords": "sentiment labels;english movie review datasets;level sentiment analysis;sentiment target;maximum entropy classifier;dirichlet distribution;words;global context;czech;document;local information;extension;measure;movie;product;significant improvement;consistency;art;current approaches;current state;better performance", "pdf_keywords": ""}, "8eda71ecad19cdef6092e76276eba48312ec7063": {"ta_keywords": "level topic representations;dense retrieval;discrete representations;query encoders;embeddings output;representations;input tokens;level topics;dr models;stage retrieval;document;input;attention;interpretation study;different aspects;art results;results;mixture;attribution;dr;mechanisms;work;success;state", "pdf_keywords": "embeddings;embeddings output;dr models;level representations;attribution techniques;query encoders;representations;level topics;topics;repmot;attention;document;different aspects;qualitative analysis;mixture;input;analysis results;finding"}, "e0c66240239263f16159eef166a391d3939ae2d5": {"ta_keywords": "much reading;comprehension require;cnn;many popular benchmarks;popular benchmarks;accurate prediction;leaderboard dominance;corresponding answers;sentence passages;sensible baselines;questions;models;datasets;cbt;information;squad;passages;topic;babi;hundreds;model;basic questions;papers;difficulty;intense interest;critical investigation;passage;paper", "pdf_keywords": "many popular benchmarks;popular benchmarks;divyansh kaushik language technologies institute;comprehension;corresponding answers;questions;several popular rc datasets;tasks;performance;tuples;leaderboard dominance;passages;information;examples;models;papers;topic;many recent papers address;basic questions;level;hundreds;business carnegie mellon university;cl;passage;answer;model;critical investigation;intense interest;question;aug"}, "3105b5863d4597058bf51aeda40db53394075784": {"ta_keywords": "bribery;tournaments;complexity;uncertain information;manipulation", "pdf_keywords": ""}, "446efa0bcf3528b51332a12495cb56784dd8bad3": {"ta_keywords": "transferable representations;modern deep transfer;generic latent relational graphs;different embeddings;word embeddings;relational graphs;generic feature vectors;glove embeddings;convolutional features;elmo embeddings;graphs;downstream tasks;specific rnn;unlabeled data;other tasks;free units;task;dependencies;pixels;image;data units;language;vision;words;unit;pairs;scale;possibility;work;glomo", "pdf_keywords": "unsupervised relational graph learning;unsupervised latent graph learning;latent relational graph learning;hierarchical graph representations;latent graphs;graph structures;deep transfer;graphs;traditional feature transfer learning framework;successful generic graphs;unsupervised learning objectives;unlabeled data;downstream tasks;neural network;sequence prediction;level unit modeling;novel transfer;features;feature;network;data;training;unit;such structures;versatile structures;paper;novel framework;glomo;scale;level objectives"}, "549dae68d04eefad88885c64a4d946205e524b79": {"ta_keywords": "word embeddings help document classification;document clustering;document representations;sentiment classification;text data analysis;traditional nlp tasks;classification;topology;document;sentiment;algebraic topology;idf;metric space;vectors;datasets;invariant mappings;geometry;methods;topic;basis;simple techniques;tf;pertinence;fact;utility;performance;work;enough variability;respect;development", "pdf_keywords": "document representations;word embeddings help document classi\ufb01cation;sentiment classi\ufb01cation tasks;such embeddings;sentiment classi\ufb01cation;document clustering;text representation;traditional nlp tasks;persistent homology;persistence diagrams;model mapping words;movie review datasets;text classi\ufb01cation tasks;topology;topological signatures;document;cornell sentence polarity;dimensional vectors;algebraic topology;metric space;vectors;invariant mappings;tool;geometry;methods;\ufb01nite subset;introduction;conclusion;work;utility"}, "35c710f5fdacc71a675832f6beaa2dbfe301d0ce": {"ta_keywords": "dialog systems;system utterances;dialog;random selection;random selection strategy;human annotators;inputs;system responses;specific task;evaluation;evaluation results;simulation;uncertainty;example;significant human effort;complexity;performance;domains;example bases;good alternatives;popular option;strategies;domain;different domains;construction", "pdf_keywords": ""}, "25efc17ba82ba4af29f2e03868de74e1ea66d025": {"ta_keywords": "new multilingual instructional video dataset;contextual multilingual multimodal embeddings;multilingual multimodal;multilingual annotations;multilingual text;video search;language models;image search;additional annotations;video model;recent baselines;shot setting;vtt show;shot;vatex;vtt;transformer;performance;vision;zero;model;large margin;method;problem", "pdf_keywords": "multilingual multimodal pretraining;new multilingual instructional video dataset;contextual multilingual multimodal representations;multilingual multimodal embeddings;multilingual multimodal;tovideo search;multilingual text;language models;video model;text;shot setting;vision;shot;performance;transformer;strategy;model;mmp;conclusion;problem"}, "e60b88313fad52c1ef8dd02b482785651d09ad66": {"ta_keywords": "depth separation;size depth;depth;networks;neural networks;many functions;weights;separation;low degree polynomial;above form;uniform distribution;function;form;simple proof", "pdf_keywords": "depth;deep networks;neural networks;networks;expressive power;separation;functions;years;main result;many aspects;introduction;basic setting"}, "a1c5af2a531c64f1c06e806d7986cd878ec3c33a": {"ta_keywords": "new explainable ai;model explanations;fraud analysts;interpretability;explanations;explainers;world fraud detection task;ml model score;ml model score variant;model score;highest decision accuracy;xai test;ml model;evaluation methodology;xai;conclusion highlights;robustness;information;assessment;accuracy;slowest decision time;real data;lower accuracy;methods;data;fact;shap;several research works;study;fidelity", "pdf_keywords": "fraud analysts;world fraud detection task;xai test;highest decision accuracy;explanations;different xai methods;explainers;user study;ml model score variant;ml model score;evaluation methodology;real data;slowest decision time;ml model;model score;information;accuracy;data;ml production model;statistical tests;lower accuracy;conclusion highlights;performance;application;world data;study;shap;transaction data;utility;metrics"}, "4fa4e39ade763085a75146392b997b7d4da49725": {"ta_keywords": "contextualized weak supervision;contextualized corpus;seed word information;seed words;text classification;weak supervision;corpus;word occurrences;classifier;class labels;same word;novel framework conwea;much attention;multiple interpretations;world datasets;few user;extensive experiments;iterative manner;representations;necessity;researchers;paper;case studies;significant advantages", "pdf_keywords": "contextualized seed words;seed word information;userprovided seed words;indicative keywords;text classi\ufb01cation;weak supervision;text classi\ufb01er;group word occurrences;corpus;word occurrences;principled comparative ranking method;userprovided seed information;words;label;unsupervised method;interpretations;multiple interpretations;same word;novel framework conwea;representations;mechanism;adaptive number;paper"}, "462e36e5e296900c80dcd36173340f9c29e36c80": {"ta_keywords": "appropriate phonetic decision tree structure;independent word recognition;bayesian model selection criterion;variational bayesian approach;speaker;practical bayesian framework;bayesian criterion;higher recognition performance;conventional mdl criterion;mdl criterion;sst;hmms;hmm;criterion;data set;method;case;data;paper;order;effectiveness;small amounts;insufficient amounts;experiments;second experiment", "pdf_keywords": ""}, "f05741b65a1d644f2fae4c654dae315a7451ee85": {"ta_keywords": "text network exploration;such heterogeneous topic web;heterogeneous topic web;text networks;academic citation networks;text network;new text network;topicatlas;topics;hyperlinked webpages;heterogeneous web;text document;document level;probabilistic generative model;text;word level;documents;links;edges;vertex;paper;task;data type;general sense;people;different relationships;relationship;demand;proliferation;system", "pdf_keywords": "text network exploration;such heterogeneous topic web;heterogeneous topic web;text network;topicatlas;topics;heterogeneous web;document level;word level;probabilistic generative model;text;citeseerx collection;convenient navigation;links;exploration;paper;task;aan;users;prototype system;people;experiment;prototype demo system;system;different relationships;problem"}, "fe54832083f65eade8e2847627d330a24df22488": {"ta_keywords": "background noise removal;multiple signals;probabilistic generative model;noise;time fourier transform;covariance matrices;erps;observed signal;stft;frequency bins;frequencies;event;potentials;trial event;frequency domain;different spatial spread;time;main contribution;paper;coefficients;method;new method", "pdf_keywords": ""}, "d7a7ebd1565c3795bc2bcdec4334d42a65ad17c5": {"ta_keywords": "text generation;neural generation models;language models;text;deep learning;plms;different input data;core content;tuning strategies;paper;field;preliminaries;resurgence;topic;overview;general task definition;paradigm;survey;mainstream architectures;special properties;major advances", "pdf_keywords": "text generation;different text generation tasks;plms;synthesis;tuning strategies;formulations;general task de\ufb01nition;overview;paper;pointer;survey;topic;tion;preliminaries;research;section;mainstream architectures;several important \ufb01ne;brie\ufb02y;major advances"}, "a2221b03211408ac2db0559b9a54c1d72b5f560c": {"ta_keywords": "acoustic representation learning approach;music genre classification;massive unlabeled music;acoustic data;continuous acoustic frame domain;annotated training data;musicoder;contiguous frames masking;contiguous channels masking;music;learning models;attention;adversarial attacks;bert;art models;learning approach;tagging tasks;new self;cfm;reconstruction tasks;auto;self;data;specific downstream tasks;model;transformer;bidirectional transformers;machine;ccm;architecture", "pdf_keywords": "musicoder model;music genre classi\ufb01cation;music genres;level music features;musicoder;music;universal music;jamendo dataset;acoustic encoder;theme recognition;art models;jamendo;gtzan dataset;mediaeval;emotion;theart model;transformers;rich statistics;mtg;haining;prevoious work;youku;challenge;intelligent lab;urbana;abstract;hangzhou;eess;alibaba group;china"}, "74e9053d6f44f4507bd40bbea999ee65f0cbefb2": {"ta_keywords": "neural model predictions;adversarial examples;nlp;neural models;interpretation methods;words;model confidence;prediction;important input features;high entropy outputs;high confidence;word;examples;example;heatmap visualization;models;importance;same predictions;confidence calibration;information;input sentence;gradient;human experiments;pathological behaviors;input perturbation;counterintuitive results;label;deficiencies;ones;maximum likelihood", "pdf_keywords": "neural models make interpretations dif\ufb01cult;neural model predictions;neural models;comprehension;important input features;interpretation;textual entailment;adversarial examples;fundamental dif\ufb01culties;visual question;words;input sentence;tasks;arti\ufb01cial intelligence;heatmap visualization;example;input reduction;results;counterintuitive examples;beam search;snli;squad;overcon\ufb01dence;consequence;observed pathologies;abstract;section;aug;way;graber1 1university"}, "01a21d74fb7414404851872f23cdca42243ab6a8": {"ta_keywords": "progressive transfer learning;reid datasets;convolutional cell;dataset;reid model;feature;batch;feature extraction model;transfer;reid;cuhk03;model;cell;model fine;cells;global information;bconv;dukemtmc;tuning;perspective;tuning process;occlusion;novel network structure;target scenario;performance;different camera viewpoint;ptl;aggregation;latent state;utilization", "pdf_keywords": "batchrelated convolutional cell;progressive transfer learning;novel cnn building block;convolutional cell;reid datasets;batch;feature;dataset;cell;feature extraction model;transfer;cells;reid model;bconv;model;novel network structure;cuhk03;dong shen;dukemtmc;member;model \ufb01ne;tuning;tuning process;global information;reid;zhongming jin;ptl;\ufb01ne;contributions;xian"}, "c2dd1c332f65fea3a66f4a982428f31ce1a9dc70": {"ta_keywords": "information retrieval;ranked retrieval methods;deductive databases;search engines;common database representation;like queries;conventional databases;diierent information sources;information sources;many information sources;queries;structured collections;database;ir similarity metrics;structured collection;web;information system;information systems;novel logic;complex site;information;text fragments;inference;logic;whirl;object identiiers;altavista;multiple web sites;models;text", "pdf_keywords": ""}, "eca07d2b351d81719b33c913a87c63d6930ee7f5": {"ta_keywords": "debating technologies;existing resources", "pdf_keywords": ""}, "3a95fab610d5ff49fbdb7a4d8760b02c51df0013": {"ta_keywords": "sensitive information;differential privacy;sensitive data;word embeddings;anonymization technique;privacy;private health information;privacy technique;clinical texts;natural language processing classification tasks;downstream natural language processing tasks;clinical notes;neighboring word vectors;original data;random replacement;readability trade;security;dataset;high recall;readability;search;family history;results;removal;low cost;perturbations;end machine;abstract objective;space;current techniques", "pdf_keywords": "word embeddings;human annotated word;nlp classification tasks;novel anonymization technique;downstream natural language processing tasks;sensitive information;specialized corpus;anonymization technique;binary sentiment classification;embeddings;word similarity;downstream clinical nlp tasks;semantic relevance;semantic properties;more traditional machine learning;text data;movie reviews;diagnostic code classification;intrinsic tests;text;results;perfect recall;dataset;classi\ufb01cation tasks;security;neural networks;extrinsic tests;literature;end machine;claim"}, "76b95833fd0e242896d231abdea8dc01a167c7a6": {"ta_keywords": "approximate gaussian process inference;drift functions;stochastic differential equations;drift function;gaussian process;approximate em algorithm;latent dynamics;drift;incomplete observations;nonparametric approach;state vector;observations;systems;function", "pdf_keywords": "approximate gaussian process inference;sparse gaussian process regression;variational em approximation;gaussian process;approximate em algorithm;drift functions;sparse observations;stochastic differential equations;maximum posterior gp prediction;sparse gp;latent dynamics;drift;map estimation;nonparametric approach;state vector;leibler divergence;ornstein;observations;step;free energy;andreas ruttor computer science;process;manfred opper computer science;true processes;states;kullback;uhlenbeck type;continuum;philipp batz computer science;systems"}, "a660429b77e932af1c1d7d3f0554f4b17c044082": {"ta_keywords": "jihadist groups;terrorist groups;latent clusters;terrorist attacks;complex networks approach;cluster formation;terrorist actions;similarity;groups;islamist;von neumann entropy;tactics;dynamic entropy;extreme heterogeneity;novel algorithm;common behaviors;opposite ideologies;targets;behaviors;information;main statistical results;idea;others;characteristics;peculiar behavioral characteristics;weapons;relevant information;knowledge;active regions;gower", "pdf_keywords": "terror groups;terror group;terrorist groups;latent clusters;cluster formation;novel clustering architecture;cluster assignment;cluster assignments;pure groups ideology;groups;complex networks approach;terrorist actions;similarity;patterns;von neumann entropy;hidden similarities;entropy;ideology;tactics;novel algorithm;new entropy;new algorithm;heuristic approach;targets;di\ufb00erent contexts;similar results;extreme heterogeneity;weak heuristic approach;regions;data"}, "8512718bafa447f9b433da9e809215dfc28b6b28": {"ta_keywords": "reliable nlp performance prediction;performance prediction;performance prediction methods;performance predictors;nlp tasks;performance measures;performance;accuracy;reliability analysis;tasks;task;languages;examples;models;holistic measures;future;analysis;types;individual classes;different datasets;feasibility;system;f1;experimental burden;experiments;bleu;combinatorial explosion;necessity;more fine", "pdf_keywords": "performance prediction models;performance prediction methods;performance prediction;performance prediction model;typical nlp tasks;nlp tasks;different performance prediction models;reliability analysis;reliability;nlppp;performance;reliable;features;machine;future;algorithm;\ufb01ne;feasibility;code;analysis;calibration;paper;methods;system;types;neulab;p2;ef\ufb01cacy;con\ufb01dence intervals;\ufb01negrained settings"}, "84702b091af8842b6bbe457e5435c343a9824693": {"ta_keywords": "energy disaggregation;utility learning;behavior modification", "pdf_keywords": ""}, "54e7209e692ca4f5c85f0e68df34040b3cfa8bad": {"ta_keywords": "coded computation;encoded matrix;new encoding scheme;larger sparsity;mds matrix;dot scheme;sparsity;sparsity level;matrix;processors;schemes;maximum distance separable;mds;information;short;new tradeoff;work;number;goal;observation;fundamental limits;theoretic", "pdf_keywords": ""}, "1acbfc7d3e245bd3146e9e24eae7550aa2d03482": {"ta_keywords": "standard neural network architectures;deep networks;activation matrices;neural network;normalization;networks;batch;markov chain perspective;bn exhibit rank collapse;optimization speed;markov chain theory;bn;training;higher rank;training process;poor training performance;rank;good predictor;datasets;unstabilities;empirical evidence;theoretical understanding;extensive set;latter quantity;tools;direct effect;experiments", "pdf_keywords": "rank robustness generalizes;deep linear networks;relu nets;rank stability;cheap rank preservation operator;deep neural architectures;deep networks;convolutional neural nets;meaningful lower rank;random matrices;rank;hidden matrices;bn layers;\ufb01nal training accuracy;full rank;random initialization;network;scaling;depth;spectral instabilities;forward;markov chain theory;crucial condition;world data sets;data;bn;su\ufb03cient modes;tools;connection;variation"}, "796f29cee975603c7a1469df1eb21ed5142ecff5": {"ta_keywords": "literary evidence retrieval;literary quotations;literary claims;literary analysis;semantic similarity matching;literature;quotations;humanities scholars;retrieval task;quotation;excerpt;passage;novel;linguistic phenomena;passages;novel task;deep understanding;evidence;critical analysis;claims;relic;work;scale dataset;models;methods;set;form", "pdf_keywords": "literary evidence retrieval;dense passage retrieval;scholarly excerpts;literary claims;scholarly claims;literary quotations;literary analysis;challenging literary domain;english texts;scale retrieval dataset;excerpt;quotations;passages;compute candidate quotation;passage;dataset;evidence;novel task;relic retriever;book;recent research;text;quotation;sentence;future research;learning;relic;models;pretrained roberta networks;scale dataset"}, "d10e410765699a75628a1437b93f0d0fc3dc0aa6": {"ta_keywords": "new pagerank;unlabeled instances;supervised algorithms;graph data;accurate classification results;labels;seed instances;training data;link structure;graph;world datasets;content;algorithms;instances;simple content;accurate semi;most machine;baselines;style method;art;method;state;small number", "pdf_keywords": ""}, "48aa33ad92566cb60ef348ffa438e4712f618b03": {"ta_keywords": "reflectance depth measurements;interproximal lesion penetration depth;occlusal transillumination images;swir occlusal transillumination;clinical probe;occlusal surface;microct measurements;reflectance;occlusal transillumination;measured depth;occlusal surfaces;higher depths;depths;swir images;depth;imaging system;tooth;natural interproximal lesions;depth deviates;multispectral short wavelength;lesions;dual probe;microct;swir;3d;diagnosis;broadband light sources;ingaas camera;significant correlation;r2", "pdf_keywords": ""}, "3fb78bee6cb39588a1a4cbb4e0abce5e362aa130": {"ta_keywords": "adversarial bandits;improved regret bounds;regret bounds;optimal regret;optimistic mirror descent framework;easier loss sequences;loss sequence;dependent bounds;regularization function;careful choices;classical algorithms;work explores algorithms;horizon;primary algorithmic method;actions;easy data;exp3;other words;variants;terms;data;main results;methods;number;question;parameters;recent work;scribe note;time;overview", "pdf_keywords": ""}, "e6ffeb4b9d808d6c9b8d388a7cbb431ac96bf194": {"ta_keywords": "thrombotic outcomes;aspirin dosing;hvad;patients;impact", "pdf_keywords": ""}, "99053e3a708fc27709c9dab33110dc98b187c158": {"ta_keywords": "finance knowledge;financial data;financial experts;financial documents;financial reports;financials;financial statements;finance domain;large corpus;deep questions;finqa;complex numerical reasoning;numerical reasoning;dataset;knowledge;answering pairs;heterogeneous representations;expert humans;models;understanding;business;scale dataset;general domain;new community research;analysis;sheer volume;tasks;humans;question;analytical progress", "pdf_keywords": "gold reasoning programs;deep questions;complex numerical reasoning;answering pairs;financial reports;large corpus;heterogeneous representations;\ufb01nancial experts;knowledge;\ufb01nancial data;finqa;expert humans;\ufb01nancial documents;understanding;\ufb01nance knowledge;models;dataset;new community research;tasks;full explainability;baselines;general domain;\ufb01rst;analytical progress;question;work;results;complex application domains;\ufb01nance domain;analysis"}, "0acbdcac9edf74cc2c1e98bd59e301c9300977d0": {"ta_keywords": "crowd annotation framework;crowd annotations;sequence tagging;data annotation framework;rapid tagging;sequence labeling tasks;active intelligent recommendation;annotations;new annotations;automatic crowd consolidation;multiple annotators;active learning;entity recognition;active learned model;informative unlabeled instances;sequence;auto;ner;models;alpacatag;inconsistent labels;tasks;source web;recommendations;users;comprehensive solution;consolidation;time model deployment;end;time", "pdf_keywords": ""}, "ee2e171d6a897ee5d0b0bde2d5f2548b52d3a840": {"ta_keywords": "effective tutoring;cognitive skills;cognitive help;teachable agent;online learning environment;classroom study;teaching;problems students;simstudent;students;algebraic equations;better problem selection;ninth grade students;aplus;results;data;version", "pdf_keywords": ""}, "9633928f72cda45d102fb6740291d47137d0a5ca": {"ta_keywords": "federated learning;federated learning system;backdoor attacks;pruning;malicious data;backdoor samples;malicious clients;attacks;pruning influence;pruning method;attackers;redundant neurons;attack success rate;training phase;learning systems;training;validation dataset;average attack success rate;mnist;test accuracy;defenders;network;aggregation stage;server;new method;experiments;method;tune;model;side", "pdf_keywords": "federated learning;backdoor attacks;malicious data;malicious clients;collaborative model training;backdoor samples;new training method;learning systems;neuron pruning process;pruning methods;pruning process;training phase;pruning sequence;pruning method;sencun zhu computer science;datasets;inputs;neurons;chen wu computer science;server;original data;new method;clients;access;prasenjit mitra information sciences;different clients;network;model;jan;engineering"}, "7731e3dec97c48498b585408d44615346ade144a": {"ta_keywords": "language variation;sociolinguistic theories;language deviates;different sense clusters;reddit communities;unique word types;community behavior;social groups;social group;community;variation;groups;words;english comments;senses;trends;bert;specificity;norm;glossaries;type;types;metrics;user;cases;internet;months;much previous work;study", "pdf_keywords": "language variation;reddit communities;sociolinguistics literature;sociolinguistic theories;community behavior;online english varieties;distinctive language;communities;community size;unsupervised sense groupings;sense variation;community;language;evaluation metrics;user loyalty;words;different occurrences;english comments;metrics;variation;attributes;network density;distinctiveness;glossaries;user activity;trends;common wsi benchmarks;attribute;sized groups;semeval"}, "b116e5044fe047fc48307795af1f3e11b3a9401c": {"ta_keywords": "statistical machine translation;moses machine translation system;word alignments;variational bayes;em algorithm;bayesian approaches;such bayesian technique;overfitting;model parameters;prior probabilities;software;bleu score;overall performance;performance;piece;terms;amount", "pdf_keywords": ""}, "4b18303edf701e41a288da36f8f1ba129da67eb7": {"ta_keywords": "shot learning;shot learning approach;domain adaptation methods;learning;standard real datasets;attributes;classes;standard datasets;linear layers network;features;weights;general framework;code;top layer;improvement;simple approach;generalisation error;art approaches;kind;approaches;relationships;environment;art;approach;state;line;paper;experiments;ratio", "pdf_keywords": "shot learning;shot learning approach;zsl datasets;learning;standard datasets;domain adaptation methods;attributes;zsl;classes;features;linear layers network;new concepts;shot;general framework;ef\ufb01cient implementation;approaches;standard collection;engineering science;description;simple approach;weights;code;regularizers;art approaches;top layer;framework;generalisation error;zero;abstract;approach"}, "b29dd2c50da0dc4589eafac58007f6be7e13c501": {"ta_keywords": "room layout estimation;indoor scene understanding;indoor environments;room;camera model;generative statistical model;mcmc sampling approach;3d geometry;specific objects;doors;cabinets;beds;objects;relative dimensions;couches;recognition;frames;geometry;bed;object category;locations;tables;pictures;location;box;center;discrete changes;art performance;parameters;windows", "pdf_keywords": ""}, "873b83326ad1f98549beb85bdb130a40a61e1f9b": {"ta_keywords": "multiple choice tasks;domain conditional pointwise mutual information;large language models;alternative scoring function;string probability;multiple choice options;conditioning;specific task;highest probability;surface form competition;priori likelihood;other strings;probability;competition;valid answers;example;different surface forms;probability mass;same underlying concept;context;option;computer;answer;shot settings;promising results;question;correct answer;pc", "pdf_keywords": "pmidc scoring;probability scoring methods;generative models;previous scoring functions;selection tasks;pmidc;multiple choice datasets;normalizing log probabilities;raw probabilities;depressed performance;datasets;results;multiple choice;shot experiments;model;avg;lm;extensive experiments;dozen datasets;surface form competition;different possible prompts;other methods;primary cause;broad use;shot;comparison;discussion;hypothesis;wide variety"}, "9fe579e54712ba82c4f1c93e46409613f592df16": {"ta_keywords": "matrix formulas;vector", "pdf_keywords": ""}, "178d51c35c03e3ccaae2409c32a3c2001cefe7eb": {"ta_keywords": "incremental estimation algorithm;new incremental model adaptation approach;kalman filter algorithm;posterior refinement;conventional bayesian approaches;posterior distributions;time evolution system;discrete stochastic process;model parameters;macroscopic time scale;propagation mechanism;evolutions;transition;algorithm;utterance set;input;process;paper;general solution", "pdf_keywords": ""}, "415d4231cab5ddee73e2ed536d033d5c31f24b4a": {"ta_keywords": "bootstrapping biomedical ontologies;open information extraction system;entity recognition;biomedical text;biomedical entities;learned lexicon;biomedical categories;initial ontology;scientific text;larger corpus;ontology category;web text;extraction;original bootstrapping algorithm;text;seeds;ending language learner;new facts;terms;web;data;seed quality;resources;significant improvements;tasks;types;task;system;nell;previous applications", "pdf_keywords": ""}, "8163c4010fc103343518d49db5974577593972f6": {"ta_keywords": "deception detection;deceptive conversational partner;deception;dialogue systems;potential liar;dialogue;telltale signs;questions;humans;actions;second action;goal;results;more salient;features;analysis;paper;initial analysis;other hand", "pdf_keywords": ""}, "fa5c7406d09af3f06a3a7ead49975e3ee90ed584": {"ta_keywords": "humanrobot language;autonomy;robotic agents;robot;human domain knowledge;plan efficiency;cognitive load trade;human;task;extra knowledge;efficiency;satisfaction;preferences;offs humans;instructions;lens;user;gains;paper", "pdf_keywords": "humanrobot language;robotic manipulation capabilities;robot;robots;robot butler;task complexity;manipulation objects;task ordering;language balance;autonomy;language communication perspective;language;object destination;cognitive loads;linguistic comprehension;task;interaction;cognitive load trade;human;constraints;humans;knowledge;offs humans;robustness;problem size;user studies;lens;simple table;instructions;work"}, "9527352b925f9fa36c40966ed755afd22301b0aa": {"ta_keywords": "ethical principles;specific ethical principles;subjective preferences;net formalism;appropriate ethical theory;model preferences;decision context;constraints;feasibility constraints;decision makers;decision maker;decisions;bad decisions;principles;priorities;ai systems;optimization criteria;various laws;norms;safety regulations;preferences;other properties;cp;systems;expressive way;decision;outcomes;information;conflict;combinatorial structure", "pdf_keywords": ""}, "74c80622b91894efbe4ae9ce1428e4d699b05516": {"ta_keywords": "dual stochastic gradient oracle methods;dual stochastic oracle;convex optimization problems;optimal point;duality gap;large deviations;networks;batch size;convergence;iteration sequence;new technique;distance;probability;rate;new analysis method;solution;starting point;analysis;terms;proper choice", "pdf_keywords": ""}, "c00e4564ea054c14c83cb564af6c37e47c8ab367": {"ta_keywords": "active sensor subset;sensor activation rate constraint;sensor usage;complete sensor observation;uniform sensor sampling;remote estimation;centralized active tracking;finite state markov chain;more sensors;markov chain;sensors;slower timescale stochastic approximation;unknown transition probability matrix;expectation maximization;reliable estimation;lagrangian relaxation;mse minimization;observations;unknown tpm;discrete time;bandwidth consumption;tpm;more observations;better error performance;lagrange multiplier;comparable error performance;unknown dynamics;gibbs;energy;selection", "pdf_keywords": "state estimation;state markov chain;active sensor selection algorithm;centralized active tracking;like state estimation;optimal sensor subset;active sensor subset;markov chain;unknown transition probability matrix;centralized tracking;kalman;discrete time;lowcomplexity algorithm;computational complexity;reliable estimation;unknown dynamics;sensors;algorithm;complexity;observations;gibbs;estimate;bandwidth usage;tpm;selection;ojal kumar;telecom technology;management;energy;bharti school"}, "98ef0db84e62aef969629264c9de1f4d0013f3b9": {"ta_keywords": "diverse nlu tasks;transfer learning;multiple tasks;dataset balancing;knowledge composition;catastrophic forgetting;adapterfusion;knowledge extraction stage;knowledge extraction;task;knowledge;adapters;classifier;representations;shortcomings;different layers;model;specific information;sequential fine;tuning;stages;various types;stage;methods;difficulties;specific parameters;algorithm", "pdf_keywords": "diverse nlu tasks;knowledge composition;separate knowledge composition step;multiple tasks;catastrophic forgetting;fusion;different tasks;knowledge;knowledge extraction;adapterfusion;representations;adapters;balancing;different layers;model;stages;performance;classi\ufb01er;stage;mt;st;algorithm;\ufb01nd;various types;issues"}, "43953a051b6518f32fc37734cfc49942baeac5a1": {"ta_keywords": "statistical voice conversion technologies;speech sample;prosodic change;input speech;spectral conversion;utterances;speech;spectral parameter variation;spectral variation;prosody;spectral parameters;target speaker;speaker;spectral parameter;cepstral distortion;same speaker;training metrics;mel;cepstrum;evaluation;ideal sample;prediction;distance measures;distance;parameters;current evaluation;same sentence;report;case", "pdf_keywords": ""}, "4077c1986f32817801b3082ce8dde514424f71a1": {"ta_keywords": "crowdsourcing;thesaurus;russian thesaurus;synset cleansing;synset quality;common sense reasoning;many natural language processing;synsets;expert assessment;novel workflow;agreement;crucial resource;artificial intelligence problems;remove;confirm;present workflow;special effort;high quality;high level;add;paper", "pdf_keywords": ""}, "2344cca985dd4e2e2519838b2353b5c295e73036": {"ta_keywords": "ai2 reasoning challenge;reasoning types;naive information retrieval methods;arc dataset;questions;arc;challenge sets;reasoning;corpus;knowledge;systematic classification;complex science questions;information;sentences;types;text;context;comprehensive set;query;labels;clark et al;definitions;clear definitions;analysis;open domain;paper;respect;recent work;quality", "pdf_keywords": "reasoning type labels;novel annotation interface;annotations;annotators;reasoning type categories;annotation;reasoning types;question analysis;de\ufb01ne annotation instructions;questions;novel labeling interface;arc challenge set;arc dataset;knowledge;reasoning;existing qa systems;respective questions;ai2;types;standardized tests;dataset;statistics;results;people;conclusion;ef\ufb01cacy;comprehensive set;set;institutions;paper"}, "05fb1eea6381ccd21bde53495c7707546aa234c7": {"ta_keywords": "entity recognition;comprehensive word representations;term memory;social media messages;traditional bidirectional long short;channel bilstm;text;conditional random fields;entity;social media;bilstm;crf;crf model;emnlp;neural network;gazetteers;craft features;task;additional hand;noisy user;nut;novel approach;paper;workshop;novel", "pdf_keywords": ""}, "3132a18a441ab6067066e4d4d85608b058c9ed33": {"ta_keywords": "change point detection;autoencoders;false detection alarms;abrupt property changes;change points;deep learning techniques;high false alarm rate;change point score;autocorrelation statistics;time domain;time series data;subtle changes;recent cpd methods;novel loss function;cpd;signal;invariant representation;filter;time;frequency domain;user;use;issues;ability;flexible method;issue;result;potential;postprocessing procedure;methodology", "pdf_keywords": "change point detection;autoencoders;multiview learning;new autoencoder;deep learning techniques;abrupt property changes;false detection alarms;autocorrelation statistics;time series data;signal processing;high false alarm rate;change point score;recent cpd methods;invariant representation;signal;subtle changes;frequencydomain information;dynamical systems;data analytics;cpd;mathematics;life benchmark data sets;cpd method;domain;time;baseline methods;department;feb;electrical engineering;development"}, "91e605a125f64207a242693d0dc1c862080f6c27": {"ta_keywords": "manual phonemic transcription;automatic phoneme recognition;useful bilingual lexical entries;automatic transcription;translation model;phoneme error rate improvements;phoneme lattices;translations;prior lexicon;such translations;lexicon;word level;speech;orthography;model;baselines;ability;method;absence;experiments", "pdf_keywords": ""}, "b953a582cc79c33054b295c20c1201e8d5bd8243": {"ta_keywords": "intelligent tutoring systems;tutoring systems;automaticallygenerated problem content features;student models;student behavior patterns;student model;good student model;knowledge engineering effort;clustering algorithm;previous automated approach;instructional decisions;important instructional implications;task difficulty;models;better instruction;such models;problem content;content;model;related problems;useful information;approach;paper;system;key factors;transfer;distinctions;experimental results;traditional ways;quality", "pdf_keywords": ""}, "d9d0d908e3f652ee350f4919d4c2ab972ada1ca4": {"ta_keywords": "new coreference dataset;coreference dataset;coreference data;coreferences;coreference;annotation framework;core nlp problem;quiz bowl community;denser references;text data;quiz bowl questions;entities;newswire data;primary source;challenges computers;new domain;humans;entertains humans;training wheels;richness", "pdf_keywords": ""}, "f18ec4e0bce2e4d847954c9692959d88ba8a9b66": {"ta_keywords": "secure remote estimation;cooperative intelligent transport system;packet drop attacks;v2x networks;secure estimates;malicious observations;garbage packet injection;individual vehicles;vehicles;security;adaptive filtering algorithm;traffic efficiency applications;vehicle;estimation;traffic safety;estimation error;v2x;communications;gauss;central fusion center;fdi;systems;wireless links;system;goal;markov process;anything;injection;components;set", "pdf_keywords": ""}, "5e27712db641bc8f16c510292f7fd5440acd563d": {"ta_keywords": "collective classification;graphical learning;base learner;relational datasets;classification;other related instances;classes;instance;instances;inference;class;group;dependencies;inference procedure;predictions;features;many iterations;scheme;kind", "pdf_keywords": ""}, "73e868f74376814a4c08eca6ce043fe7c7aefeed": {"ta_keywords": "pagerank similarity vectors;personalized pagerank measure;graphical models graph walks;pagerank;graph walks;graphwalks;graph nodes;similarity measure;graphical models;variable pairwise mrfs;similarity;markov;random fields;marginal probabilities;tree;graph;mrfs;inference;vertices;paper;formal connection;discrete;computation;limited postprocessing stage;connection;small set", "pdf_keywords": ""}, "f6160c3196288b9e435dc6f86024f56e6b5ab722": {"ta_keywords": "computing fair utilitarian allocations;fair allocations;maximal allocations;tractable fairness concepts;indivisible goods;allocations;utilitarian social welfare;utilitarian welfare;computational complexity;computational problems;envy;utilities;freeness;proportionality;agents;item;prop1;sum;ef1;number;problem;np", "pdf_keywords": ""}, "579095d50eab27ace24a1ea0e97af2f70191dc7c": {"ta_keywords": "subcellular location image finder;stacked graphical model;images;labels;graphical model;text;image;journal articles;figures;biology;sentences;slif;information;system;combination;particular aspect", "pdf_keywords": ""}, "0c61265a4325df4b97389f92e5e4f5df412f8e97": {"ta_keywords": "electrical joint localization method;partial discharge location;power transformers;ultrasonic signal;power transformer;dimensional nonlinear localization equations;partial discharge;convex optimization equations;localization accuracy;order cone program;localization process;matrix inequality transformation;accurate localization;acoustic;paramount importance;reflection;diffraction;refraction;order;pd;slow convergence;socp;safe operation;computational complexity;significant computational complexity;relaxation;full consideration;solution;paper;set", "pdf_keywords": ""}, "46a2960e409c39901c1efd07a6adfc5f26e22ee8": {"ta_keywords": "email leaks;popular email client;information leaks;mozilla thunderbird;unintended recipient;such data mining techniques;data mining techniques;costly misunderstandings;clients;recipient;client;costly mistake;intended collaborator;users;widespread problem;case study;large corporations;suggestions;permanent additions;corporations;recommendations;message;costs;few lessons;everyday lives;type;communication delays;techniques;individuals;real cases", "pdf_keywords": ""}, "d6a7d2e9f2caf3e8eb615580f4ee8329ff9a271d": {"ta_keywords": "available parking space;finite capacity queues;curbside parking;interdependent queues;adjacent queue;parking;parking transaction data;queue;exponential service time distributions;traffic measurement data;occupancy;markovian relaxation;available space;service times representative;mean rate solutions;seattle;wa;simulation;neighborhood;networks;drivers;rate;network;proportion;percentage;belltown;model;methods;problem;exogenous source", "pdf_keywords": ""}, "4d01d6b445077ad0f1c9d85af93f9ed9239f3c33": {"ta_keywords": "tagging accuracy;ofspeech tagging;modern german corpora;spelling normalization;pos tagger;different corpora;texts;historical data;15th century;manuscript;training data;century;tokens;paper;method;part", "pdf_keywords": ""}, "189e6bb7523733c4e524214b9e6ae92d4ed50dac": {"ta_keywords": "neural sequence taggers;several different sequence tagging tasks;sequence tagging;deep hierarchical recurrent networks;hierarchical recurrent networks;transfer learning;pos tagging;penn treebank;fewer available annotations;plentiful annotations;source task;microblogs;target task;neural networks;tasks;transfer;languages;improvements;recent papers;current state;paper;significant improvement;domains;performance;state;applications;effects;art performance;art;problem", "pdf_keywords": "neural sequence taggers;sequence tagging;deep hierarchical recurrent neural network;source task;deep neural networks;fewer available annotations;plentiful annotations;target task;pos tagging;penn treebank;microblogs;neural network;transfer;few labels;iclr;previous work;1code;sentation;paper;hidden feature;part;conference paper;generality;model parameters;performance;experimental results;problem;approach;conclusion;settings"}, "58b628792d3eb22a034a871ed3cf373afe591928": {"ta_keywords": "hadoop hdfs;hdfs implementation;storage systems;hdfs module;erasure codes;high storage efficiency;large storage;solomon codes;more storage;replication;large clusters;high reliability;high repair cost;higher reliability;new codes;locality;reliability;repair network traffic;reed;systems;standard design choice;novel family;unavoidable price;disadvantage;reduction;scheme;overhead;information", "pdf_keywords": "hadoop hdfs;novel erasure codes;new erasure codes;erasure codes;storage systems;hdfs module;data reliability;solomon codes;reedsolomon codes;replication;large clusters;big data;higher reliability;explicit codes;reliability;codes;new codes;locality;reed;megasthenis asteris;information;theoretic bounds;optimality;theorem;main challenges;variant;rlnc;southern california;bound;facebook"}, "58174f5bb9f9815b52a99fa03ec42f2b44f2d550": {"ta_keywords": "automatic set instance extraction;semantic lexicons;semantic class;large corpus;dependent hyponym patterns;instances;automatic set instance acquirer;car makers;japanese;language;set;english;toyota;chinese;noisy set;asia;ford;web;additional benchmark problems;seeds;initial seeds;art language;dozen;independence;brief;expansion;seed;expansion system;production;system", "pdf_keywords": ""}, "2bafaffe45ba66685c87e2d0a598222a9a68ae13": {"ta_keywords": "russian linguistic resources;russian language processing;linguistic resources;survey nlpub;representation approaches;specialized catalogue;data gathering;resources;catalogue;tools;merotomy;information;research;coordination;progress;community;analogs;whole field;practical applications;significant problem;one;problem;lack", "pdf_keywords": ""}, "108ec3512cdf2e89ba3067f5b10eaa4a96df9347": {"ta_keywords": "speaker adaptation experiments;conventional transfer vector adaptation;large vocabulary continuous speech recognition;accurate transfer vectors;transfer vectors;transfer vector;acoustic modeling;adaptation scheme;directional statistics;unit direction vectors;gaussian class;unit direction vector;posterior distributions;maximum likelihood;cft parameters;estimation;free parameters;von mises distribution;representative distribution;bayesian approach;cft;fine training;bayesian;efficient coarse;maximization algorithms;fine class;coarse class;basis;scaling factor;posteriori", "pdf_keywords": ""}, "b575d272036740e03fcf67d64db969557843f629": {"ta_keywords": "tweet2vec;whole tweets;hashtags;traditional nlp approaches;character composition model;character sequences;unusual character sequences;informal language;social media;large vocabulary size;text;space representations;abbreviations;special characters;vocabulary words;posts;word;spelling errors;challenges;input;vector;model;user;level approaches;level baseline;set", "pdf_keywords": "tweet representations;traditional neural network language models;tweet2vec;distributed representations;directional gated recurrent unit;tweet;social media posts;associated hashtags;representations;character level encoder;constituent characters;traditional nlp approaches;social media;neural network;text;word type;character;nnlms;language;special character;words;vocabulary words;gru;basic units;sequences;\ufb01nal gru states;bi;model;independent vectors;bhuwan dhingra1"}, "d34712c217046ccf8063efe083fbb1e6cbfc0340": {"ta_keywords": "content delivery networks;cdn architecture;large cdns;ef\ufb01cient content delivery;replication;cdns;cdn;servers;parity chunks;clusters;cluster;lower byte miss ratio;multiple servers;write load;server;video content;redundancy;c2dn;write load imbalance;erasure;miss ratio spikes;miss ratio spike;harness erasure codes;internet;web;server unavailability;core;performance;edge;source production software", "pdf_keywords": ""}, "f8e580fcf34ee6da50989bbde685634018cbe224": {"ta_keywords": "5th dialog state tracking challenge;advanced dialog state tracking system;human dialog;dialog state;dialog;utterance;input word sequence;tracker;trackers;attention;semantic labels;attention mechanism;decoder architecture;challenge;main task;english;score;encoder;chinese;slot;dstc5;system;frame;test;set;paper;full history;rule;results;development set", "pdf_keywords": ""}, "8a6d2e134b3b2df6291af8e36e126ae55d50649c": {"ta_keywords": "paraphrastic sentence embeddings;gated recurrent averaging network;lstm recurrent networks;recurrent networks;new recurrent architecture;lstms;speech;dependency relations;models;word;wieting et al;particular parts;purpose;preferences;evidence;opposite conclusion;setting;several developments;problem", "pdf_keywords": "recurrent averaging network;promising new recurrent architecture;paraphrastic sentence embeddings;recurrent methods;lstm;natural language semantics;sentential compositionality;lstms;semantic modeling;novel recurrent;neural network architecture;speech;dependency relations;gran outperforms averaging;supervised settings;models;averaging;composition;avg;particular parts;fundamental aspect;transfer;strong performance;gran;performance;preferences;evidence;settings;different errors;introduction"}, "3911b13a61a3a57674cc8c70c760f545de8aeea2": {"ta_keywords": "reward;strong incentive properties;new reward mechanism;truth serum;verifiability;evaluation matches;intuitive output agreement structure;scale evaluations;online platforms;agents;service reviews;peer;agent;honest responses;labeling images;online courses;major challenge;product;response;mechanism;wide variety;such settings;absence", "pdf_keywords": ""}, "f335e2256b31d9458c10c61e60bb8bed9dcaf1d9": {"ta_keywords": "language navigation;natural language instructions;visual environment;vision;learn;novel training paradigm;greedy agent;multiple instructions;room;language ambiguity;base agent;recent room;different views;benchmark dataset;r2r;generalization;challenging task;spl;same trajectory;path length;leo;everyone;paper;success rate", "pdf_keywords": "instruction variants;multiple instruction;single instruction;language navigation;novel training paradigm;new training paradigm;multiple instructions;limited training data;greedy agent1;r2r benchmark;language ambiguity;room;benchmark dataset;generalization;vision;unseen environments;r2r;testing;techniques;models;recent room;instructions;spl;leo;mutual agreement;same trajectory;path length;different views;approach;everyone"}, "5f23482a8c06ca1ae3e4577e3fdd9213884dac85": {"ta_keywords": "probabilistic lobbying;complexity", "pdf_keywords": ""}, "1e638d235a512cc76d00713639259540342c6fbe": {"ta_keywords": "relation classification task;semantic relation extraction;relation extraction task;end relation extraction model;concept candidate embeddings;subtask;scientific papers;classification;task;attention mechanism;semeval;model;end;miwa;character;level;scenario;bansal;paper;official submission;senerio;submission;several enhancements", "pdf_keywords": ""}, "c07fdc95bbf533f8709f8e39c069c1e22b73a7dc": {"ta_keywords": "perfluorinated polyelectrolyte;batteries;safe", "pdf_keywords": ""}, "26c65dad79da20aa67df21a6c10e509a964f0841": {"ta_keywords": "tac kbp english entity linking;entity linking system;reference knowledge base;cluster entity mentions;entailment formulation;slot filler validation system;illinois wikifier;slot filler validation;source document;entries;additional functionality;evidence;submission;candidate answer;sfv;ui ccg;tasks;improved version;paper;separate systems;el;university;illinois", "pdf_keywords": ""}, "d4d25eaa373087ac80810d79afff863ef1bae3c3": {"ta_keywords": "seat activity tracker;seat movement scores;wheelchair cushion;seat activity;wheelchair users;wheelchair in;seat movements;seat movement;weight shift precision;weight shifts;wisat algorithms;wisat;sensor mat;sensors;sufficient accuracy;dataset;readings;real world usage;scores;system;resolution interface pressure mat;mean absolute error;methods;results;study;purpose;terms;conclusion;objective", "pdf_keywords": ""}, "a4cd428d196bf041c22592216f15246b98b91915": {"ta_keywords": "bayesian matching equilibrium;public good economy;uniqueness;existence", "pdf_keywords": ""}, "8a94106364576f0aa79dccfb30f0536514408249": {"ta_keywords": "robust rank learning;linear baseline ranker;rank;pairwise preference framework;art baseline rankers;pairwise preferences;document pairs;eective feature;search engines;recent algorithms;outlying pairs;eects;learning approach;documents;datasets;undesirable eects;meta;algorithm;second optimization step;significant performance gains;learning process;fundamental task;optimization step;input;instances;paper;research;dierent;functions;experiments", "pdf_keywords": ""}, "abcaec70b463ed925c29180437ed581c971952cf": {"ta_keywords": "dialogue example databases;dialogue modeling;plural appropriate response candidates;spoken dialogue systems;response utterances;dialogue quality;multiple response candidates;plural responses;adaptive response selection method;dialogue;user satisfaction improvement;user satisfaction;single response;system response;appropriate responses;plural;appropriate response;adaptive selection;user preference;ebdm;example;users;examples;effective methods;system;framework;experimental results;keys;important factors;paper", "pdf_keywords": ""}, "f46a3a5dc70a70292175e6c7ad505b8206cb070c": {"ta_keywords": "automatic speech recognition;speech separation;microphone;asr systems;stationary talker;reverberation;challenge tracks;chime;recognition challenge;challenge systems;asr;everyday environments;vocabulary;challenge;tasks;datasets;domestic environment;baseline systems;multiple background sources;systems;performance;challenging goal;overview;initiative;world;summary;paper reports;paper;results;outcomes", "pdf_keywords": ""}, "1756376bf7cf0d0a7bec881d663b57907a361ecf": {"ta_keywords": "incremental editing;novel edit encoder;abstract syntax trees;structural edits;incremental tree transformations;entire editing process;source code edit datasets;edit encoder;editor;editing processes;edited data;single editing pass;neural generative models;edited program;structured data;subtree;tree;edits;iterative building;refinement;sequential data;imitation;models;computer programs;human creative process;data;previous approaches;generic model;pass;single pass", "pdf_keywords": "incremental editing;novel edit encoder;tree editor;improved program editing accuracy;source code edit datasets;structural edits;new edit encoder;editor;edit encoder;incremental tree transformations;edited program;structured data;edits;tree;neural generative models;iterative building;imitation;iclr;tab;previous approaches;daggersampling;accuracy;generic model;abstract;unique bene\ufb01ts;outputs;huan sun;paper;pass;conference paper"}, "5eba3e525056cac6112cf0b13b62d86ba66661d9": {"ta_keywords": "active learning;annotation cost;representative training instances;useful training samples;diverse languages;aforementioned languages;output tags;al heuristics;other al strategies;current heuristics;oracle scenario;al strategy;data selection algorithm;predictions;examples;empirical study;auxiliary results;models;oracle data distribution;instances;strategy;al;extensive experimentation;true uncertainty;persian;galician;ukrainian;surprising result;north sami;large number", "pdf_keywords": "speech tagging;diverse languages;related languages;resource pos tagging;novel active learning method;active learning;output tags;annotation cost;al methods;graham neubig1 1language technologies institute;confusionreducing strategy;useful training samples;oracle;new al method;higher accuracy;persian;al method;accuracy improvement;al;ukrainian;models;galician;methods;shortcomings;simulation experiments;north sami;computer science;data selection algorithm;confusion;abstract"}, "84bc74d875e748aa0f11ac0c5e3000b16484b053": {"ta_keywords": "adversarial evaluation;simple adversarial attacks;natural language inference task;deep neural networks;fact extraction;robust fact;fever;classification accuracy;language;first fever;wikipedia;task;evidence;joint information retrieval;claims;recent investigations;submissions;attacks;verification;datasets;assessment;models;truthfulness;resilience;literature;participants;such models;absolute losses;instances;discussion", "pdf_keywords": "adversarial evaluation;adversarial attacks;simple adversarial attacks;decomposable attention model;neural semantic matching network;\ufb01rst fever;elmo embeddings;task;natural language inference;fact extraction;esim model;model;instances;resilience;idf information retrieval;abstract;tf;scoring system;systems;nli component;number;art models;veri\ufb01cation;james thorne university;baseline architecture;athene;collection;paper;state;andreas vlachos university"}, "ecab8208e5182d4b3b0d6183928e816301d2366d": {"ta_keywords": "efficient elastic net regularization;stochastic gradient descent;elastic net reg ularization;learning rates;logistic regression classifier;sparse linear models;stochastic updates;proper elastic net update;dense updates;sgd;nonzero features;backward splitting;features;bag;dynamic programming algorithm;words;algorithm;ing weights;update;time subproblem computation;fobos;example;previous work;identical implementation;times;method", "pdf_keywords": "elastic net regularization;ef\ufb01cient elastic net regularization;elastic net regularizers;sparse linear models;learning rate;elastic net update;fast training;ef\ufb01cient training;weights;biomedical articles;biomedical literature;dynamic programming algorithms;linear models;logistic regression;representative dataset;sparsity;algorithms;charles elkan;constant time;popular squared norm \u211322;dynamic programming algorithm;time computation;updating;update;algorithm;medline;may 27th;zlipton;straightforward experimental implementation;speed"}, "02cc92287c6614b6a2aa982007471f16b3450013": {"ta_keywords": "natural language;natural language utterances;grounded language acquisition;action sequences;planning policies;actions;language;solution sequences data;plans;learning;large corpus;solution sequences;human computer communication;dataset;meaningful steps;example;context;generation;mappings;problem formulation;open problems;goals;understanding;physical world;empirical approach;mechanisms;relation;problem;paper;bidirectional connection", "pdf_keywords": ""}, "ddc502b6c0d08fefe5b77639e4737cd8c7bce25c": {"ta_keywords": "html documents;textual similarity;web pages;web page changes format;structure;information retrieval community;wrapper;page;extraction program;recognition methods;certain types;appropriate background information;whirl;purpose methods;methods;examples;logic;experimental evaluation;method;earlier method;notion;time;hand;value", "pdf_keywords": ""}, "ab42ad9698386cc15a30a8c7885fa82b260f537b": {"ta_keywords": "parking demand data;similar parking demand;curbside parking demand;gaussian mixture models;parking;gaussian mixture model;pricing policies;congestion;transportation;spatial autocorrelation;pricing schemes;zones;data;drivers;traditional policies;seattle department;temporal properties;factors;search;understanding;attention;performance;methods;aforementioned decision;straightforward modifications;significant amount;technique", "pdf_keywords": ""}, "3abcd0ffc54c3a16c9dc5e5d3ea59eaa43070127": {"ta_keywords": "machine learning algorithms;machine learning algorithms simplifies;standard machine learning approaches;machine learning;algorithm design;algorithms;intelligent machines;algorithm;pattern recognition tools;computer scientist;algorithm design framework shifts;machine;harmful behavior;simple data analysis;designer;general framework;undesirable behavior;flexible framework;framework;various tasks;superhuman performance;responsible application;science;burden;complex systems;user;thomas et al", "pdf_keywords": ""}, "37241cdc693b9c2daf49557f18c1ad6a15247239": {"ta_keywords": "degraded color document image binarization;document binarization scheme;thresholding method;degraded color document images;art binarization solutions;segmentation;shift algorithm;contrast;image;popular niblack;different scales;art;proposed solution;range;version;par;performance;solution;state;use", "pdf_keywords": ""}, "f66a17836380c0c79c1b42a9219cf8fde6524287": {"ta_keywords": "modern question answering;unstructured text corpora;rnn language model;knowledge bases;corpus;cloze;software questions;posts;such specialized qa;style software questions;text;strong baselines;entity;qa;stack overflow;answers;occurrence model;documents;sources;dataset;quasar;kbs;paper;large accuracy gains;systems;fill;hybrid;case;form", "pdf_keywords": ""}, "a817785f0100f3fadc5c1203974d151d5b093310": {"ta_keywords": "parallel programs;parallel virtual machines;parallel virtual machine;java;common application programming interface;javapvm;independent computers;traditional pvm libraries;computer architectures;java code;traditional pvm library;pvm;communication performance;multiple computers;message passing interface;fortran;tradition pvm;jpvm;programs;architecture;single computation;such libraries;libraries;mpi;api;performance;di erent computer;computations;machines;machine", "pdf_keywords": ""}, "9336a2ff833d0b4bc914e2282ad04e19d27bc2be": {"ta_keywords": "grounding grid parameters;copper grounding grid;220kv substation;intelligent substation;ground;potential difference;grid;galvanized flat steel;potential rise;short circuit fault current;impedance;copper;secondary equipment;cdegs software;flat steel;shell;comparison;points;normal operation;paper", "pdf_keywords": ""}, "4d5f9a0aba65ba6294c543ba5e6108e6d690f133": {"ta_keywords": "annotated data;protein mentions;unlabeled captions;source domain data;distinct source domains;target domain data;such full text articles;abstracts;academic publications;unlabeled full text;target domain;domains;researchers;robust features;biology;examples;documents;data;conditional distributions;knowledge;classes;changes;field;implicit common structure;different subsections;large amounts;access;internet;gap;work", "pdf_keywords": ""}, "c69da8266e2f3f67febf22b8f2bf91623346d283": {"ta_keywords": "tweets;twitter;health information;vaccine;vaccination;dissemination;health promotion efforts;pandemic;content;data mining;common communication strategy;inauthentic propagation strategies;websites;misinformation;data analysis methods;methods;agenda;topic;links;future studies;temporal patterns;conclusions;screening;challenges;days;february;theory;triangulation;pattern;study", "pdf_keywords": ""}, "cd9bfa6266cab4bf4b04c82746a5b650f83b57e4": {"ta_keywords": "optimal stochastic;global minimizer;other optimization problems;gradient schemes;optimization algorithms;minimization;theoretical convergence guarantees;deep neural networks;global performance guarantees;global minimum;convergence rates;local minimum;recent theoretical results;general theoretical analysis;order methods;lojasiewicz condition;general classes;functions;reasonable time;classical arguments;stationary point;polyak;list;overview;goal;problems;structure;setting;problem;interest", "pdf_keywords": ""}, "d385d8563192569b229bde762fcd4d57ce2b3ee2": {"ta_keywords": "software entities;ontological category information;language model;technical domain;technical terms;definitions;definition generation;large corpus;language;specific terms;domain;text;user forum stack overflow;knowledge;architectures;additional domain;additional challenges;task;specific information;model;comings;person;way;experiments", "pdf_keywords": ""}, "63d7e40da7f0d37308b8e97fca4a14a26a6b52ea": {"ta_keywords": "data excellence;data quality;data practices;data cascades;ai;ai models;ai practitioners;data issues;data work;stakes ai;empirical evidence;conventional ai;ml practices;health;stakes domains;wildlife poaching;heightened downstream impact;elevated significance;hci opportunities;conservation;more robust systems;west african countries;predictions;model work;downstream effects;events;loan allocations;interviews;usa;class citizen", "pdf_keywords": "data practices;data excellence;ai practitioners;ai;data work;ai models;stakes ai;hci opportunities;wildlife conservation;data cascades;qualitative study;conservation;health;challenges;road safety;stakes domains;environment;more robust systems;model work;west african countries;credit;food systems;interviews;cutting;abstract;class citizen;edge;india;paper;mountain view"}, "7707af52b3e19bfd3fc07c2be5aed044e5d7953a": {"ta_keywords": "persistent homology;road networks;homology;deep networks;microscopy scans;connectivity;topology;neuronal processes;loss yield reconstructions;medical images;thresholding;3d shapes;aerial images;2d;persistent;novel filtration function;data sets;filtration;fusion;height functions;originals;techniques;ph;essence;effective way;method;comparison", "pdf_keywords": "persistent homology;improved locality information;homology;microscopy scans;dimensional images;more effective delineation;deep networks;thresholding;dimensional image stacks;medical images;connectivity;road networks;novel \ufb01ltration function;topology;persistent;aerial images;neuronal processes;3d shapes;doruk oner epfl;data sets;loss yield reconstructions;cvlab;ic;2d;height functions;\ufb01ltration;curvilinear structures;ski epfl;kathryn hess epfl;fusion"}, "f74ccbc8988b7f0b847c480d4e8bea3082f4f931": {"ta_keywords": "generative adversarial tree search;efficient deep reinforcement learning;monte carlo tree search;conditional gan;generative model;atari game pong;reward predictor;planning;tree search;finite depth mcts;parameterized policy;dqn;bias;search;mcts;sample complexity;practice;leaves;gats;sample;best policy;variance trade;rl;typical drl algorithms;state transitions;environment;data;algorithm;drl;interaction", "pdf_keywords": ""}, "3f5b7fcb6fc50ba80318ab959f3d63253cd0ef6b": {"ta_keywords": "acoustic event detection;neural network baseline system;multiple binary classifiers;classifier chains;new classifier;recording dataset;classification;convolutional recurrent;events;event;probabilistic chain rule;aed;conditional independence;superior aed performance;linear layer;conventional aed methods;sigmoid function;next output;activity;method;interdependence;paper;assumption;iteration;experiments", "pdf_keywords": "acoustic event detection;iterative binary detection;convolutional recurrent;multiple binary classi\ufb01ers;recording dataset;events;event;aed;recurrent unit;superior aed performance;new classi\ufb01er;neural network baseline system;classi\ufb01er chains;classi\ufb01cation;conventional aed methods;probabilistic chain rule;conditional independence;linear layer;sigmoid function;japan 4human dataware lab;eess;shinji watanabe2;tatsuya komatsu1;japan;japan 2carnegie mellon university;method;interdependence;tomoki;feb;usa"}, "e6beab7c192d7fb04c8bfb0886464fd719cd3421": {"ta_keywords": "target domain accuracy;accuracy;model confidence;average thresholded confidence;unlabeled target data;dataset reproduction;datasets;confidence;optimal predictor;imagenet;threshold;unlabeled examples;training;distribution shifts;world machine;source data;model;shift;breeds;performance drops;synthetic corruptions;mnist;target;several model architectures;wilds;novel subpopulations;source;assumptions;cifar;mismatches", "pdf_keywords": ""}, "d25c4bf23b4b951f2417e4a8a44574c99608e9d7": {"ta_keywords": "general linear chirplet transform;wavelets;linear chirplet transform;robust seismic time;continuous wavelet transform;seismic signals;frequency analysis;seismic data;short time fourier transform;frequency analysis method;frequency representation;frequency feature;chirplet atom;frequency spectrum;instantaneous spectral variations;robust time;frequency point;sinusoidal wave;broadband time;geologic spatial distribution;glct method;local time;cwt;glct;hydrocarbon reservoir anomalies;time;lct;base function;stft;best atom", "pdf_keywords": ""}, "4a160efbe80c38cd5eb2f92c7c095b49b113397d": {"ta_keywords": "code retrieval;code retrieval functionality;better code generation models;retrieval developer assistants;code generation;python programming tasks;developer productivity;developer experience;code edits;pycharm ide;software development;developers;developer;developer workflow;software;natural language queries;code;development;programs;future machine learning;retrieval accuracy;retrieval;future empirical studies;keystrokes;machine learning methods;machine learning;virtual environments;effectiveness;challenges;plugin", "pdf_keywords": "ide developer assistants;ide code generation;code generation;pycharm ide;python programming tasks;code retrieval functionality;software development;developer productivity;developer experience;programs;natural language;nl2code;nl2code assistance;virtual environments;generation;challenges;human study;se;technology;participants;study;retrieval;plugin;many user events;carnegie mellon university bogdan vasilescu;procedures;carnegie mellon university;use;carnegie mellon university graham neubig;logic"}, "e7ce1b01d2928514710bba044ac2af758c975d99": {"ta_keywords": "selfish routing game;network costs;favorable network conditions;equilibrium quality;congestion costs;uncertainty;estimates;multicommodity;optimism;users;user;multiplicative constant;user type;perception;different level;many types;face;results;new model", "pdf_keywords": "urban transportation networks;realistic urban network topologies;favorable network conditions;congestion;dynamic pricing policies;sli networks;parking users;network topology;networks;network;parking;seriesparallel networks;equilibrium quality;equilibrium;social cost;uncertainty;equilibria;prices;edges;uncertainty level;independent topology;policy;equilibrium solution;traf\ufb01c;perception;ef\ufb01cacy;users;identical system;application;multiple types"}, "caf40157a7a1d72ae3a6946169c992d8c973b743": {"ta_keywords": "free gingival graft;gingival inflammation;attached gingiva;gingival recession;periodontics;periodontium;root coverage;flap;surgical procedure;acceptable esthetics;clinicians;mucogingival problem;coronally;current practice;therapy;areas;absence;challenge;narrow band;step;functional problems;presence;introduction", "pdf_keywords": ""}, "1b57ffe73ae95f339015c174ec574b59f99ea553": {"ta_keywords": "mutual information;sifted representations;cloud;cloak;target prediction task;perturbation maximization method;optimizations;features;service provider;input feature space;prediction model;services;provider;utility;adversaries;gradient;normal service;only negligible reduction;data;input;functionality;fact;ability;box access;model;machine;collaboration;addition;mi;scenarios", "pdf_keywords": ""}, "c6048cd0b1368be0e62633ef723f9d691323102c": {"ta_keywords": "gaussian mixture model;phoneme contexts;robust sampling method;mixture;speech;speaker;iterative conditional modes;novel sampling method;gmms;mogmms;gmm;noisy data;speakers;hierarchical structure;icm;gibbs;model;blocked gibbs;singularity solution;difference;component;attributes;problem;existence", "pdf_keywords": ""}, "40e292d16168fcb8ac87c20682b827ad17a999dd": {"ta_keywords": "temporal app usage representation;personalized mobile apps;aware spatio;graph convolutional network;user experience improvement;recent years;need;rapid proliferation", "pdf_keywords": ""}, "6332d5bb0e6af89471ffc6157e3816c029b3ae83": {"ta_keywords": "pemfc;dynamic load cycle;durability;operating parameters;experimental study;influence", "pdf_keywords": ""}, "8b3c0dd95167d4d63161038493a691ee5cdc76b3": {"ta_keywords": "text simplification;available parallel corpora;model similarity;sentences;monolingual sentence;convolutional neural network structure;knowledge;adaptation;output;model;high performance;system;performance;experiments;limitation;method", "pdf_keywords": "convolutional latent semantic model;word embeddings;latent semantic vector representations;semantic vector representation;unsupervised neural language model;structural semantic similarity scores;word vectors;automatic aligned sentence pairs;wordnet;deep learning architecture;text simpli\ufb01cation task;simple cnn;sentences;cnn;information retrieval;convolutional neural network;convolutional neural network structure;sentence classi\ufb01cation;semantic information;level embedding;length sentence;sentence;trigram clsm;deep strucure;model similarity;layer;higher layer;convolution;\ufb01ne;clsm"}, "e4de1009eb7b3524bf7d19bdcebced80035a47cf": {"ta_keywords": "asynchronous neighbor discovery protocol;noncoherent neighbor discovery;active neighbors1;graph codes;iot;level synchronization;efficient energy;complexity;network;codeword length;log;scheme;internet;paper;things;frame;assumption;set;solution", "pdf_keywords": ""}, "dbb159b288930c6be32c2d5b91373ca1e341e633": {"ta_keywords": "speech feature enhancement;alternative noisy speech feature representation;middle vocabulary noisy speech recognition task;feature enhancement;dictionary learning;2nd chime speech separation;sparse weight vectors;gaussian mixture;stereo;recognition challenge;wsj;posterior values;other methods;effectiveness;variants;paper;approach", "pdf_keywords": ""}, "2f3ec666ba50c6a9ce74abad6a5127ea38a05bca": {"ta_keywords": "efficient erasure codes;erasure codes;traditional erasure codes;erasure code;node repair;erasure;data replication;storage;error detection;node failures;storage space;decoding;constituent codes;repair;fewer disk;nodes;node;codes;helper nodes;entire file;data need;resilience;data;low complexity;schemes;simultaneous minimization;network;framework;feature;types", "pdf_keywords": "erasure codes;erasure code;replacement node;distributed storage;enabling node repair;node failures;data replication;erasure performance;decoding;nodes;erasure;node;constituent codes c0;constituent codes;network re\ufb02ect features;codes;repair;network;prone network;code framework;algorithms;reconstruction;ieee;complexity;twin;resilience;data;c1;specialization;collector"}, "8f2182846d5d4cfbc216b5e4c00411e021dc4776": {"ta_keywords": "recurrent neural networks;lstm;rnns;lstms;sequence data;electronic health record;term memory;multilayer perceptron;diagnoses;multivariate time series;raw time series;data;multilabel classification;sensor data;models;patient visit;features;long short;patterns;effective training strategy;several strong baselines;clinical measurements;irregular sampling;patient;insights;popular models;model;episode;sequence step;units", "pdf_keywords": "lstm recurrent neural networks;lstms;clinical medical data;clinical data;simple lstm network;intensive care unit;diagnoses;multivariate time series;multilayer perceptron;raw time series;clinical measurements;diagnose;patterns;hospital los angeles los angeles;models;icu;several strong baselines;features;observations;iclr;multilabel classi\ufb01cation;effective training strategy;department;model;\ufb01rst study;computer science;consist;sequence step;engineering university;charles elkan department"}, "bcffee102a99f726ddfe765906babb01b8226269": {"ta_keywords": "tcr therapy;ras mutation", "pdf_keywords": ""}, "322ef476e90a487c8f9797bece7799b69af9e5c1": {"ta_keywords": "dimensional coded matrix multiplication;large matrix multiplication;matrix multiplication;single compute node;matrices;computation scheme;ldpc;slower nodes;computation;backup nodes;parity;codes;complexity;redundancy;mds;product atb;check;time performance;stragglers;systems;scheme;density;case;size;solutions;framework;time;novel application;maximum distance;product", "pdf_keywords": ""}, "822395760906f4940df68aa33925b6bf9123bac2": {"ta_keywords": "data science community;competitions;nips;data science problem;open source platforms;data;codalab;new research directions;popular tool;companies;skills;anything;people;kaggle;hard problems;art;rich ecosystem;question;state", "pdf_keywords": ""}, "24d28783f6061bd1e91fb60417ac8b3646305a49": {"ta_keywords": "scale information extraction systems;many learned components;infrastructure components;weight blackboard system;components;declarative control system;architecture;feature computation;such systems;appropriate architecture;level tasks;classification;component;extraction;systems;information;actions;communication;paper;experience", "pdf_keywords": ""}, "c8648d04f52e49167d1a4443a4830709cf3331ff": {"ta_keywords": "computing optimal stackelberg strategies;security resource allocation games;optimal stackelberg strategies;algorithms;stackelberg model;mixed strategy;world security applications;complexity;polynomial time;security personnel;defender;such games;checkpoints;game;cases;placement;los angeles international airport;others;theoretic solutions;canine units;paper;np", "pdf_keywords": "optimal stackelberg strategies;optimal stackelberg strategy;stackelberg games;large strategy spaces;nash equilibrium strategy;polynomial time;nash equilibrium;linear programs;allocations;security games;complexity;pure strategies;polynomialtime constraint generation technique;polynomial size;computational perspective;such games;player games;cases;game;exponential size;von neumann theorem;birkhoff;defender;resources;cumbersome concept;daskalakis;ppad;case;others;time algorithm results"}, "651468a69da74dab716cebbd179a5cbb8e672c14": {"ta_keywords": "imitation learning;suboptimal demonstrations;reinforcement learning;sophisticated exploration;demonstrations;sparse rewards;replay buffer;agent;training;hyperparameters;additional hyperparameters;challenging task;self;recent rl algorithm;meticulous tuning;modern lfd algorithms;silfd;environments;rl;lfd setup;paper;sil;past good experience;schedules;numerous breakthroughs;approach hinge;realistic scenarios;influence;quality;benefits", "pdf_keywords": "imitation learning;noisy demonstrations;expert demonstrations;suboptimal demonstrations;demonstrations;sparse environments;art lfd algorithms;lfd algorithms;of\ufb02ine rl algorithms;training;silfd;useful demonstrated behaviour;additional hyperparameters;modern lfd;\ufb01nd silfd;scheduling;sil;crucial properties;schedules;expert;need;self;art performance;paper;ability;methods;experimental results;il;properties;section"}, "1cb7015c0a8015c65844876459809ecac917ec02": {"ta_keywords": "talker speech recognition;tal speech enhancement;acoustic modeling;channel am;channel;training pipeline;input;model;module;hitachi;complemen;competition period;se architecture;se;method;paper;power;best result;paper details;foundation;various investigation results", "pdf_keywords": ""}, "899055ad2f0863cf1931c41f04da8b1dd7382607": {"ta_keywords": "lipid variability;density lipoprotein cholesterol;lipid profiles;total cholesterol;elective percutaneous coronary intervention;cardiovascular disease;variability;retrospective cohort study;hba1c level;lipids;hemoglobin a1c levels affect visit;risk factors;hba1c;standard deviation;potential risk factor;ldl;cvd;variation;elective pci;retrospective study;cv;subgroup analyses;conclusionhba1c;baseline;pci;several subgroups;mean values;backgroundboth hemoglobin a1c;sd;tg", "pdf_keywords": ""}, "173c73077a421680f12576524e85dff4b890c17e": {"ta_keywords": "kernel projected wasserstein distance;wasserstein distance;empirical estimates;distributions;distance;distance function;same distribution;data space;machine learning;statistics;nonlinear mapping;kernel;samples;sample test;practical algorithms;method;sets;essential building block", "pdf_keywords": "wasserstein distance;reproducing kernel hilbert space;kernel projected;nonlinear dimensionality reduction;wasserstein;dimensional data;kernel trick;highdimensional setting;probability distance;distributions;distance;kernel;projection;test power;data space;nonlinear projector;tests;statistics;same distribution;rkhs;nonlinear mapping;theoretical results;machine learning;sample test statistic;linear projector;optimal design;samples;kpw;sample test;numerical examples"}, "4ae15dbb068cc962b39dca07d87b22fe5dcd5f6a": {"ta_keywords": "privacy tradeoff;smart grid;smart grid operations;consumer privacy;privacy metric;privacy;private parameter;adversary;strong adversary model;smart meters;electrical grid;utility;better load control;load control example;consumers;monitoring;tradeoff;data;loads;algorithm;simulation results;many advantages;performance;frequency;paper;ability;results;modernization;installation", "pdf_keywords": "inferential privacy;privacy;energy consumption patterns;smart grid operations;new privacy;different sampling policies;predictive control;energy consumption;load control example;generative model;dlc model;realistic dlc;device models;demand;model;sampling rate;unexpected demand;mpc;likelihood;uncertainty;data;loads;simulation results;user;human behavior;certain bounds;tradeoff;ideas;performance;formal de\ufb01nition"}, "513552a56668279d6cd0857a4399fe8a63d92145": {"ta_keywords": "\u6587\u8108\u3092\u8003\u616e\u3057\u305f\u78ba\u7387\u7684\u30e2\u30c7\u30eb\u306b\u3088\u308b\u8a71\u3057\u8a00\u8449\u306e\u6574\u5f62", "pdf_keywords": ""}, "8113f05360c6483e52b3e261fc9efce671e0aaa6": {"ta_keywords": "speech separation;speaker diarization;meeting transcription;automatic speech recognition;unsegmented recordings;automatic subtitle generation;separation module;speech;diarization;recognition;asr;downstream wer;stage;sdr;diverse applications;pipelines;system description;pipeline;reasonable error rates;task;systems;analysis;specific metrics;der;different state;technical advances;integration;results;problem;comparison", "pdf_keywords": "recognition components;speaker;recognition;single speaker;diarization;libricss meeting data;modular pipeline;libricss evaluation set;downstream wer;art asr model;pipeline;separation;sdr;permutation wer;wer;dataset;modular system;best system;stage;css pipeline;task;speci\ufb01c metrics;best available cpwer;end;overview;different state;cpwer;order;state;novel end"}, "29437d98b9e6f45bef7029f3ce1237b8b284464f": {"ta_keywords": "text generation;stylistic control;writing style;hybrid attention;content fidelity;sentence structures;recent neural approaches;sentences;quality templates;soft templates;style control;weak supervisions;exemplar sentence;neural approach;new content coverage constraint;styles;content record;exemplars;explicit control;template;stronger performance;copy mechanism;word choices;automatic construction;hard constraints;model;automatic adaptions;record;records;results", "pdf_keywords": ""}, "d63edef60d674408819bb015b64b7f42470e151b": {"ta_keywords": "de novo molecule design;molecular generative model;protein binding sites;protein environment information;3d structural information;novel generative model;ligand;normal rnn model;protein;crnn models;molecules;like molecules;pocket descriptor deeplytough;dimensional information;conditional rnn;model;3d information;compounds;egcm method;drug;higher similarity;pocket;atoms;crnn;egcm;grain strategy;coulomb matrix;composition;generation;scores", "pdf_keywords": "de novo molecule design;abstract de novo molecule design;molecular generative model;protein environment information;normal rnn model;novel generative model;3d structural information;protein;molecules;conditional rnn;ligand;like molecules;model;egcm descriptor;compounds;3d information;pocket;drug;threedimensional information;grain strategy;atoms;guangzhou regenerative medicine;chen1;crnn;egcm;1bioland laboratory;descriptor;coulomb matrix;higher similarity;attention"}, "1ddf9d306ae27113f55ea3d4eee12c8441235656": {"ta_keywords": "scientific paper translation subtasks;translation results;asian translation;automatic evaluation server;mixed domain subtasks;3rd workshop;tasks;submissions;results;overview;wat2016;paper", "pdf_keywords": ""}, "b03feec6f5b898484fdfdc3cd12f084afbe77036": {"ta_keywords": "pairwise preference framework;pairwise preference;linear baseline ranker;noisy relevance judgment;rank;pairwise preferences;document pairs;feature;outlying pairs;outliers;single document;documents;algorithms;algorithm;learning process;second optimization step;input;paper;disadvantage;instances;mis;functions;large number;isolation;undesirable effects;process;effects", "pdf_keywords": ""}, "f388c2be45e4415fcb59cf43a3b29463cf7e7940": {"ta_keywords": "natural language processing tasks;statements fact;journalists;statements;public figures;fact;truthfulness;claims;ordinary citizens;claim;available dataset;task;assessment;construction;paper;further research;relates;volume", "pdf_keywords": ""}, "9352dfd127dcfce8013eb350e0229cc72b9bd203": {"ta_keywords": "convolutional block attention module;attention weights;layer feature maps;convolutional network;attention;wise feature representation;encoder;decoder network;detail enhancement;decoder subnet;traditional attention mechanism;abundant spatial information;hidden features;earth observation;resolution;sr images;network;maps;scale view field;images;multiple features;edge details;panchromatic;channel;lr inputs;cbam;details;skip;sensor limitation;wgan", "pdf_keywords": ""}, "4104d632d1cff0c9314cde344e2b1da06e662c5b": {"ta_keywords": "unpaired speech;automatic speech recognition;sequence asr;text data;speech;text modalities;text;asr;sequence;librispeech corpora;data;models;such models;derive training procedures;tts;data quantity;extensive results;losses;high performance;wsj;interest;terms;such techniques;large quantities;techniques;impact;recent surge;consistent gains;method;reason", "pdf_keywords": ""}, "7e43dad7fbae3a7db47adc6b89c76acbd2fb225f": {"ta_keywords": "hierarchical knowledge;such hierarchical knowledge;instructional articles;hierarchies;procedures;complex procedures;videos;wikihow;child relation;parent;steps;complex procedure;camera;website;base;shallow structures;details;domain;turn;kb;work;budget", "pdf_keywords": "hierarchical knowledge;rerank algorithm;instructional articles;instructional videos;hierarchies;automatic evaluation;accomplish tasks;wikihow article;wikihow;search;steps;several strong baselines;topics;step;resource;effective algorithm;similar goals;other articles;downstream tasks;understudied task;procedures;base;procedure;nlp;complex procedures;camera;method;conclusion;website;complex procedure"}, "15a6c3d32ae1daefba3c4b40146de8efdf16ec8d": {"ta_keywords": "bayesian speech;language processing;introduction", "pdf_keywords": ""}, "950c2c041db52c416e49fb0945078f6463c501b8": {"ta_keywords": "utility learning;energy disaggregation;energy consumption patterns;aggregate consumption data;incentive design;demand response programs;consumption data;utility function;incentives;iterative control;disaggregation;consumers;utility company;consumer;iterative algorithm;many motivations;revenue;estimation;design;examples;process", "pdf_keywords": "utility learning;incentive design;design incentives;utility function;utility functions;incentives;consumer behavior;energy consumption;power consumption signals;consumers;utility companies;reverse stackelberg game;utility company;consumer interaction;iterative control;consumer;satisfaction function;behavior modi\ufb01cation;iterative algorithm;estimation;model;agent;disaggregation;algorithm;examples;process;change;section"}, "f637d061704579531a8b8e03ef6e8331ba117490": {"ta_keywords": "adaptive estimators;oracle estimator;strong stochastic transitivity;efficient estimator;adaptivity index;pairwise comparisons;risk;oracle;future comparisons;estimator;flexible model;randomize;pairwise comparison data;least squares;step estimator;case risk;specific difficulty;tex;ground truth;clique hypothesis;outcome probabilities;instance;methods;bern;extent;bernoulli probabilities;count;formula;collection;addition", "pdf_keywords": ""}, "7626f73c3b013b5b7bf293c1cc22d2835b6579b3": {"ta_keywords": "speech synthesis;rich context models;improvements;hmm", "pdf_keywords": ""}, "bf0b66e0e328df1df42b075422c8fecdd95736c0": {"ta_keywords": "teachable peer learner;tutor learning;cognitive tutor;artificial peer learning environment;teaching;students;student;linear algebra equations;agent;first classroom study;simstudent;initial classroom baseline study comparing;local public high schools;aplus;prior knowledge;line game;insufficient training;paper;application;problem;target problems;machine;effectiveness;results;environment;benefits;strong influence", "pdf_keywords": ""}, "4ffca5d623950e2396089e7fc1621b4a477436cb": {"ta_keywords": "text generation;stylistic control;writing style;hybrid attention;content fidelity;recent neural approaches;sentence structures;quality templates;sentences;style control;weak supervisions;exemplar sentence;neural approach;styles;templates;new content coverage constraint;explicit control;exemplars;stronger performance;template;copy mechanism;word choices;automatic construction;hard constraints;model;record;records;results;automatic adaptions;comparison methods", "pdf_keywords": ""}, "97e033d79b6aebab1927ab9232afa8268e198481": {"ta_keywords": "cache communication aspects;cache content placement;cache;scalable vod system;network codes;vod;codes;dress codes;allocation;users topology selection;desirable tradeoffs;optimization;scale video;users rate;combinatorial problem;video;algorithm;design;demand;demand system;system;user;berkeley;role;problem;specific class;tractable one", "pdf_keywords": ""}, "f5ca46585818771e64ee9449c930748fbee35cba": {"ta_keywords": "explainable nlp models;structured explanations;natural language feedback;reasoning tasks;explanation structures;defeasible reasoning;natural language;explanations;reasoning task;human feedback;mercuriean interactive system;neural model performance;accuracy;points;structures;form;output;errors;decisions;class;gain", "pdf_keywords": "defeasible inference;defeasible reasoning;reasoning task;natural language;explanation structure;reasoning;explanations;schema;interactive system;human evaluators;human feedback;task;feedback;input;pipeline system;new evidence;graphs;literals;speci\ufb01c instructions;speci\ufb01c;output;components;450k graphs;dataset;generalizability;defeasible query;answer;mercurie;section;approaches"}, "97db55b196cf0c768644a392a7e6c79d1c65207e": {"ta_keywords": "online neural speech enhancement;reverberant speech enhancement task;online speech enhancement;online speech enhancement systems;frame prediction;frame prediction technique;enhancement models;deep learning;deep neural network;several past frames;inverse stft;overlapped;add algorithm;overlap;stft;current frame;frame;algorithmic latency;dnn;future contextual information;time fourier transform;window size;add;information;effectiveness;evaluations;domain;algorithms;length;use", "pdf_keywords": "online neural speech enhancement;online speech enhancement;online speech enhancement systems;frame prediction technique;frame prediction;improving frame;deep learning;several past frames;inverse stft;overlapped;deep neural network;addition;add algorithm;stft;frame;overlap;current frame;algorithmic latency;dnn;add;time fourier transform;oracle target signals;zhong;window size;novel loss function;qiu wang;sd;information;domain;scale difference"}, "45ce9fce4a4eea9f72688885182aee0c84786fab": {"ta_keywords": "musical domains;musical transcriptions;musical instruments;music;genres;diverse training dataset;independent encoder;encoder;domains;waveforms;training;domain;latent space;supervision;samples;large net capacity;styles;end;form;method", "pdf_keywords": "universal music translation network;wavenet;sequence recurrent networks;instrumental music;audio style transfer;musical instruments;genres;music;universal encoder;encoder;adam polyak;audio;orchestra;mozart symphony;embeddings;professional musicians;pianist;decoder;separate reconstructing decoder;target spectrograms;nsynth;target pathways memorization;supervised learning domain;waveforms;convincing translations;beethoven;dataset;untrained humans;yaniv taigman facebook ai research;augmentation"}, "782a50a48ba5d32839631254285d989bfadfd193": {"ta_keywords": "interpretable entity representations;entity representations;natural language processing;entity types;entities;entity;embeddings;domain knowledge;representations;text;scale typing;corresponding type;dense vector spaces;models;tasks;downstream models;high performance;task fine;posterior probabilities;vectors;data;model;performance;choi et al;small number;confidence;box;end;tuning;way", "pdf_keywords": "interpretable entity representations;entity representations;entity typing models;entities;entity;natural language processing;embeddings;supervised entity;interpretability;wikipedia categories;domain knowledge;downstream errors;distantlysupervised dataset;models;dataset;dense vector spaces;benchmark tasks;text;onoe;tasks;scale typing;box models;durrett;challenge;transformer;concept;abstract;greg durrett department;machine;high performance"}, "d26683135c70d7b2a61ce5f70fb49b4fa22cf9c4": {"ta_keywords": "arbitrary ranking distributions;ordinal rankings;arbitrary pairwise comparisons;pairwise comparison data;pairwise evidence;approximate samplers;inference methods;conditional mallows models;insertion model;alternatives;mallows models;likelihood;algorithms;data;evidence;world data sets;mallows model;mallows mixtures;first algorithms;learning;restrictive assumptions;user preferences;effectiveness;provable bounds;new algorithm;grim;mixtures;restrictions;experiments;log", "pdf_keywords": "approximate samplers;arbitrary pairwise comparison data;sampling algorithms;pairwise evidence;preference data;pairwise comparison data;mallows mixtures;mallows mixture;mallows models;machine learning research;incomplete preferences;mallows model;e\ufb00ective sampling;learning;algorithms;pairwise;em algorithm;mixtures;approximate;statistical properties;important special cases;many important special cases;likelihood;\ufb01rst algorithms;direct sampler amp;world data sets;tyler lu craig boutilier department;provable bounds;computer science university;section"}, "205d67dfe0112df846bc4b221fa2665b0434d441": {"ta_keywords": "asian translation;2nd workshop;wat2015;proceedings", "pdf_keywords": ""}, "7df95dceaba3f4fb45e2b9de29caf7fbce20e25c": {"ta_keywords": "", "pdf_keywords": ""}, "83a2582b94aeaaa97b2f52af8d827d28dc4690bf": {"ta_keywords": "fluency;stuttered speech recognition;silent pauses;speech;communication;means clustering algorithm;pauses;dysfluency;effectiveness;mfcc;basic means;mel;presence;repetitions;algorithm;person;prolongations;frequency coefficients;characteristics;removal;humans;interjections;information;aspects;thoughts;feelings;optimal solution;ideas", "pdf_keywords": ""}, "930445d9cda71d6ff857e69aa5bb4b1bef7d31e5": {"ta_keywords": "low dynamic regret bounds;dynamic regret bounds;reinforcement learning;bandit;reward functions;state transition distributions;algorithms;confidence;free manner;sliding window upper;widening;state;algorithm;time;cw;parameter;art;various cases;framework;main contributions", "pdf_keywords": "conventional optimistic exploration techniques;low dynamic regret;reinforcement learning;stationary mdps;conventional optimism;uncertainty;exogeneity;endogeneity;rl;algorithms;algorithmic frameworks;principle;unique challenge;unprecedented challenge;jaksch et al;piecewise;interplay;ofu;face;related works;settings;section"}, "d3231772937a2182b2377d028417245c49868dd1": {"ta_keywords": "neural machine translation;neural sequence models;minimum translation length;shorter translations;empty translations;empty translation;neural models;german test set;global best model scores;entire wmt15;transformer base model;sentences;global best score;exact search;beam search;nmt;search errors;exact inference procedure;model errors;search;model;depth;first search;massive failure;large beam size;inherent bias;most cases;adequacy;root;fact", "pdf_keywords": "neural sequence models;nmt scores;global best model scores;nmt search errors;model scores;nmt;german test set;beam search;exact search;exact inference procedure;transformer base model;entire wmt15;bleu scores;model;empty translation;search errors;model errors;large beams;conditional log;alternative dfs algorithm;algorithm;tongue;consistency;eq;practice;probabilities;reduction;failure;cat;evidence"}, "6b2b5d3d9a2ca4bc4fbd81551a62370be2fbff1b": {"ta_keywords": "scaling behavior;scaling regimes;related scaling regimes;large random feature;model size;neural networks;models;resolution;datasets;dataset;predictions;theoretical framework;theory;setting;range;standard architectures;variance;laws;regimes;regime;respect;number;work;total", "pdf_keywords": "deep network representations;deep networks;deep models;dataset scaling exponent;scaling behavior;unsupervised learning;large random feature;scaling regimes;neural networks;superclassing;scaling exponent;datasets;scaling regions;standard datasets;model size;models;dataset;di\ufb00erent downstream tasks;versatility;standard architectures;resolution;invariance;data;predictions;empirical support;architecture;properties;changes;input data;setting"}, "4e1b16fd719354b0a9e92075be66c85d4b95082c": {"ta_keywords": "neural representations;task relevant information;similarity;density", "pdf_keywords": ""}, "713844009469478141671c53a3b73cd12caf9df0": {"ta_keywords": "\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "810420af4fa5f3ed932724aea5f7b66d3bd592b2": {"ta_keywords": "www search engine;world wide web;new online weight allocation algorithm;web;learning methods;resource;experts prediction algorithm;www;queries;resource directory;augmented www browser;label documents;ripper rule;documents;batch system;unknown concept;links;list;machine;query;specific topic;examples;rule;methods;appropriate form;definition;system;human intervention;positive examples;series", "pdf_keywords": ""}, "e5e74d312679eae8f2a2943e16f2efebcb5cc50f": {"ta_keywords": "surface wind speed changes;other reanalysis products;china", "pdf_keywords": ""}, "e35357ac461a669fe7e4b877ee1fad0dfda26303": {"ta_keywords": "style transfer;controllable style transfer;sentiment transfer;style extraction;shot style transfer;formality annotations;several attribute transfer tasks;corpus;corpora;sentence pairs;paraphrases;indic languages;resource multilingual settings;gender neutralization;target style;sentences;stylistic difference;languages;text anonymization;style;content;shot;inference;large style;qualitative results;sentence;art;future research;task;resource setting", "pdf_keywords": "several attribute transfer tasks;natural language generation task;sentiment transfer;controllable style transfer;formality annotations;style transfer;gender neutralization;input sentences;style examples;indic languages;sentence pairs;resource multilingual settings;semantics;shot style transfer systems;many languages;target style;content;qualitative results;datasets;\ufb01nd model evaluation;task;inference;text anonymization;sentence;future research;data;resource settings;recipe;abstract;bidishasamanta"}, "e97c5b206c1f308b821917bc2f584b5f1faad547": {"ta_keywords": "ranking;cardinal scores;possible estimators;crowdsourcing community;estimators;miscalibration;miscalibrations;scores;linear biases;simplistic models;popular approach;assumptions;only useful information;variety;people;absence;concept;approach;plug;applications;proof;issue", "pdf_keywords": "ranking;relative ordering;ordinal data;cardinal data;possible estimators;canonical estimator;canonical estimator \u03c0coaunr;estimators;algorithms;superiority;compelling feature;variety;items;theorem;assumptions;pair;miscalibration;simple extensions;section;proof;probability;plug;concept;applications"}, "2d3fcbaf28e650471b942f221c5fa3c178b1b72a": {"ta_keywords": "accelerated directional search method;accelerated directional search;unconstraint optimization problem;free methods;convex;nesterov;linear coupling;norm;mirr;method;advance;structure;point;simplicity;allen;step;derivative;solution;orecchia;paper;basic idea;case;zhu", "pdf_keywords": ""}, "b345057638e60eee581fea6c7110a98e3b9ebe61": {"ta_keywords": "semantic scan;business trend detection task;anomalous text patterns;better event detection;massive text streams;disease surveillance task;topics;text streams;contrastive topic;text emergency department;world text data;early detection;labeled lda;keywords;rapid detection;new documents;anomaly;online lda;spatial scanning;regional business trends;events;online document assignment;training data;cluster;public health interventions;yelp reviews;unexpected patterns;shortcomings;paper;single new document", "pdf_keywords": "novel contrastive topic model;spatial event detection;spatiotemporal free text data;semantic scan;topics;contrastive topic;robust online document assignment;text streams;spatial scanning;detection;online document assignment;events;anomalous patterns;event;keywords;free text data;labeled lda;detection power;online lda;pattern detection laboratory;world tasks;unexpected patterns;paper;comprehensive evaluation;signi\ufb01cant improvements;likelihood ratio;novel framework;state;characterization;art methods"}, "2038086c604f1f8841d086cd5cc6052e546ffc24": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "9850d2b41c6c5be039649d6422306121b760169d": {"ta_keywords": "oblivious update algorithms;optimal oblivious updates;oblivious updates;distributed storage networks;protocols;stale node;updates;explicit codes;nodes;several system operations;lower bounds;computer systems;codes;communication;generic settings;bounds;mds;distanceseparable;modifications;previous versions;optimality;system;interim;data symbols;central control;data;contents;additional information;log;settings", "pdf_keywords": ""}, "71bcdfe5b6be3a0d08ce4bde45acdfd0f738e2f7": {"ta_keywords": "inverse reinforcement learning;inverse reinforcement learning algorithm;reinforcement learning framework;markov decision processes;risk;passengers;human decision;mdp;loss function;ride;agent;decisions;behavioral psychology;models;observed behavior;economics;gradient;canonical grid world example;sensitivity;sharing;examples;use;origins;problem;performance;second;making;technique", "pdf_keywords": ""}, "1843c91e9692484b574ef40961f1d0443a56ddf4": {"ta_keywords": "incentivizing objective feedback;simple incentive mechanism;truthful equilibrium;nash equilibrium;informative feedback;objective feedback;online platforms;verifiability;symmetric equilibrium;truthful behavior;agents;strict bayes;evaluations;higher expected payoff;such platforms;products;root agreement rule;game;services;sra;major challenge;square;number;mild condition;regime;absence", "pdf_keywords": ""}, "4c0a915b9389e6489753a968085ee12833131d0a": {"ta_keywords": "peer review;peer review process;scholarly research;incompetent review;researchers;research;academic practice;important open problems;unfairness;academia;specific paper;systemic challenges;behooves research;key challenges;bias;grant;paper;improvements;topic;grant application;outcome;author;kdd;matthew effect;community;problems;principled approaches;consequences;ultimate failure;importance", "pdf_keywords": ""}, "df53aabeca68a8c0076f7e110f2cc7df7d010e7a": {"ta_keywords": "source splitting;deep learning;effectiveness", "pdf_keywords": "single speech source input;speech recognition;localization task;audio mixture;deep neural networks;localization method;doa estimation;end training approach;speakers;directional asr;multi task;doa;loss function;standalone task;doas;arrival;mover distance;explicit supervision;joint optimization;direction;model;alternative modeling approach;pseudo;soft earth;frontend;end;high resolution;semd;future work;method"}, "b03c7ff961822183bab66b2e594415e585d3fd09": {"ta_keywords": "attention heads;multiple attention mechanisms;attention;neural models;memory efficiency;art nlp models;bert;multiple heads;greedy algorithms;models;head;accuracy improvements;particular salient pieces;training dynamics;performance;mt models;parallel;model;predictions;simple weighted average;test time;transformer;weighted average;sophisticated functions;input;different parts;large percentage;parts;gains;results", "pdf_keywords": "decoder attention layers;attention layers;machine translation models;neural networks decomposes;memory ef\ufb01ciency;encoder;training progresses;transformer models;training dynamics;compression;head;models;multiple heads;several heads;test performance;mutual information;training;empirical risk minimization;layers;greedy algorithms;model;intermediate representations;relative importance;accuracy improvements;ziv;early stages;phases;labels;unimporant heads;signi\ufb01cant degradation"}, "315432474166ff7abbc6351e8ff07fcccbd68458": {"ta_keywords": "low quality misinformation websites;low quality misinformation sources;high quality health information network;high quality health information websites;low quality misinformation network;news information network;low quality urls;news sources;twitter;tweets;central brokerage role news sources;low quality sites;traditional news sources;high quality health sources;information ecosystem;misinformation;urls;community;clear community structure;source types;web;information;health;article;findings;users;combined network;connections;prevalence;higher rate", "pdf_keywords": "low quality information sources;low quality information sites;twitter;low quality urls;high quality health information;low quality information;news sources;low quality sites;sharing;computational social science;information sources;high quality health sources;central role news sources;traditional news sources;low quality information subnetwork;high quality information subnetwork;url links;high quality sources;clear community structure;research article;links;misinformation;coronavirus disease;networks;prevalence;article;users;webpages;situation report;journal"}, "92acaf505a9c738e56ed70759e8d0062f3c520d6": {"ta_keywords": "audio segmentation;practical automatic speech recognition;long recording;connectionist temporal classification;audio;neural end;single neural network;asr model;low rtf asr;asr;baseline autoregressive transformer;segmentation;high accuracy;english dataset;rtf;latency;models;end;input;accuracy;e2e;new architecture;addition;systems;time factor;system;promising technique;method;important issue;reasonable trade", "pdf_keywords": "audio segmentation;audio recognition;nonautoregressive asr;single neural network;low rtf asr;baseline autoregressive transformer;connectionist temporal classi\ufb01cation;asr;streaming;segmentation;high accuracy;rtf;english dataset;ctc;baseline ar transformer;models;accuracy;cer;model;insertion;addition;new architecture;combination;system;good balance;conclusion;method;reasonable trade;paper;experimental results"}, "f75d05e759447c2aedb7097728f29f9a520d9bc1": {"ta_keywords": "range language models;range transformer language models;language models;sequence lm benchmark dataset;longer sequences;truncated input sequences;attention;range context;input sequences;level prediction tasks;long;distant context;models;discourse;tokens;sentence;predictions;routing transformer;level information;recent efforts;results;efficiency;ability;small set;paper;past;state;self;analysis;art perplexity", "pdf_keywords": "longrange transformer language models;range language models;range transformer language models;subword clusters;distant context;range context;random document replacement;tokens;long;input sequences;models;level prediction tasks;books;sequence;ligible impact;simpler baseline model;sentence;routing transformer;different document types;improvements;textbooks;perplexity;word;art routing transformer;results;paper;magazines;various perturbations;aggregate;particular types"}, "1dfa71ecab0c25c5fdd6b2df83a41e944ffa5d58": {"ta_keywords": "multinomial distribution;classification tasks;statistical models;occurrence;binomial distributions;text;words;poisson;more classes;models;higher frequencies;analytic tractability;simplicity;negative;desirable properties;paper;wide range;sensible manner", "pdf_keywords": ""}, "0c47eb31b2dd76d8dc986173a1d3f00da1c9c74d": {"ta_keywords": "nearest neighbors language model;adaptation datasets;inference speed;nlms;retrieval;training datapoints;comparable performance;models;text;example;external datastore;predictive distributions;inference;test time;domain;efficiency;various dimensions;paper;methods;practical applications;6x speed;experiments;deployment", "pdf_keywords": "ef\ufb01cient nearest neighbor language models;nearest neighbors language model;adaptive retrieval;unnecessary retrieval operations;datastore pruning;inference speed;simple dimension reduction techniques;adaptation datasets;comparable performance;greedy merging;demonstrate speed improvements;comparable perplexity;knn;training datapoints;indexing method;adaptation;importance;nlms;speed;lightweight network;performance;external datastore;\ufb01ltering;index;junxianh;domain;example;various dimensions;training;6x speed"}, "83cbe142d445a521aefa11acbd184e176085e7c7": {"ta_keywords": "trusting voters;trusting voter;suspicious voters;biased sources;biased communications;suspicious voter;unbiased sources;motivated reasoning;prior positive opinion;partisan goals;negative information;trusting;political decision;voters;information sources;candidate;candidate strengthens;anomalous updates;rational models;information source;anomalous behavior;evidence;decision making;behavior;weakens;audience;model;new data;effect;part", "pdf_keywords": "suspicious voters;bayesian networks;prior positive opinion;biased communications;negative information;political science;biased sources;positive information;multiple agents;voters;candidate strengthens;candidate;multiagent in\ufb02uence diagrams;trusting;unbiased sources;political decision;arti\ufb01cial intelligence community;machine learning;information sources;distinct goals;model;new information;weakens;concluding remarks;formalism;anomalous behavior;douglas pierce rutgers university department;support;part;november"}, "6a79ff7465d8249d9c8a50fa5f2e0a3e308b436d": {"ta_keywords": "domain adaptation method generative pseudo labeling;domain adaptation;unsupervised domain adaptation;generative pseudo labeling;dense retrieval approaches;dense retrieval approach;dense retrieval;query generator;retrieval tasks;representative domain;target domain;improved results;pseudo;search results;datasets;tsdae;training;tasks;gpl;data;lexical gap;\ufb01nd;average improvement;previous methods;best approach;paper;role;box state;art;scenario", "pdf_keywords": "domain adaptation method generative pseudo labeling;unsupervised domain adaptation;unsupervised domain adaptation technique;generative pseudo labeling;domain adaptation method;dense retrieval approaches;dense retrieval approach;dense retrieval models;dense retrieval;query generator;ubiquitous knowledge processing lab;pseudo;search results;datasets;nils reimers3;kexin wang1;lexical gap;gpl;theart;technical university;abstract;iryna gurevych1;\ufb01nd;hugging face;university;paper;apr;darmstadt;box state;waterloo"}, "3e3f55cb25b919c4e8158195fd3ce2f23cfa7723": {"ta_keywords": "novel counterfactual inference framework;counterfactual inference framework;language bias;counterfactual vqa;balanced vqa v2 dataset;direct language effect;bias;recent debiasing methods;vqa models;inference;language;vqa;sensitive vqa;various vqa backbones;direct causal effect;causal effects;total causal effect;fusion strategies;cp dataset;answers;questions;data;effect;vision;competitive performance;shortcut;experiments;cause;paper", "pdf_keywords": "counterfactual inference framework;novel counterfactual inference framework;novel counterfactual inference framework cf;language bias;counterfactual vqa;counterfactual reasoning;direct language effect;bias;direct causal effect;balanced vqa v2 dataset;causal effects;total causal effect;language;vqa models;sensitive vqa;data;cp dataset;vqa;effect;experiments;big data management;ji;competitive performance;questions;arti\ufb01cial intelligence;conclusion;various vqa backbones;fusion strategies;sheng;answers"}, "7b29f45df975ed1e4c3864b6ab4483f11086aa76": {"ta_keywords": "neural machine translation;word embeddings;such embeddings;scale parallel corpora;natural language analysis tasks;performance;nmt;bleu points;resource scenarios;data;cases;paucity;favorable setting;systems;gains", "pdf_keywords": "word embeddings;bilingual systems;neural machine translation;target languages;multilingual systems;other linguistic features;embeddings;such embeddings;language families;nlp tasks;neural network models;sequence tagging;nmt;text classi\ufb01cation;similarity;spaces;q1;source;questions;experiments;\ufb01ve sets;ef\ufb01cacy;q4;following questions;q5;gains;bleu points;cases;paper;q3"}, "7a684045afae2ccf40338ff07b8fa429bad93a57": {"ta_keywords": "large web corpora;pages web corpus;full commoncrawl corpus;available general web crawl;size corpus;multilingual web;scalable hadoop;many nlp tasks;full documents;amazon elastic map;commoncrawl;creativecommons license family;tokens;free license;languages;urls;cpu cluster;permissive licenses;framework;infrastructure;c4corpus;article;construction;date", "pdf_keywords": ""}, "fc5d79301a0876201c95954a764ec374b8eb236e": {"ta_keywords": "domain adaptation;neural machine translation;domain target sentences;domain corpus;domain lexicon;translation baselines;domain nmt model;lexicon induction;parallel sentences;pairwise adaptation settings;unsupervised adaptation method;translation;word back;unadapted models;domains;consistent improvements;domain;pseudo;word;bleu;model architectures;fine;tunes;method;problem", "pdf_keywords": "domain parallel corpus;domain source corpus;domain target corpus;domain unaligned corpus;domain corpus;domain target sentences;pseudoparallel corpus;domain lexicon;domain adaptation;monolingual target sentences;unsupervised seed lexicon;lexicon induction;monolingual data;source sentences;unsupervised adaptation;translation;unsupervised adaptation method;\ufb01nd translations;forword back;word back;gan;unseen words;word;new domains;source side;unknown words;pseudo;domain;domain nmt model;task"}, "75abecb4568366d89e89c3c9d39574b9c1c028a5": {"ta_keywords": "certain nlp tasks;named entity recognition;natural language processing;navigational utility;biomedical text;nlp;text;paperbrowser;flybase curators;navigational efficiency;highlighting events;curators;first nlp;resultspaperbrowser;navigational functionalities;computer interaction;navigational mechanism;anaphora resolution;database curation;tasks;task;results;interface;curation;art performance;study;evaluation criteria;article;human;interactions", "pdf_keywords": ""}, "ec9367ab933a142124eecd3232fe2d933d93a144": {"ta_keywords": "efficient navigation;stochastic sampling", "pdf_keywords": ""}, "51c2321244b0a489970e1b52c59b049fdcc5cd46": {"ta_keywords": "automatic translation evaluation metrics;machine translation evaluation metrics;machine translations;translation results;qa accuracy;knowledge bases;clqa accuracy;qa systems;language;clqa;metric;information source;qa;manual analysis;few major languages;questions;systems;data;topics;data set;words;result;investigation;variety;question;factors;paper;frequency;relationship", "pdf_keywords": ""}, "bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d": {"ta_keywords": "natural language processing;language processing models;utterances;contextual information;language;large text corpora;successful linguistic communication;contextual foundations;text;new representational theories;representation;social interaction;representations;social interactions;grounding;tasks;experience;social nature;data collection paradigms;brief history;diverse field;techniques;field;physical world;research;approaches;parallel tradition;eye;work;world", "pdf_keywords": "multimodal comprehension;language learning;corpora;cooking recipes;language;multimodal phenomenon;text;representation;recipeqa;communication;challenge dataset;deeper questions;social context;parallel tradition;processing;evolution;approaches;research;implications;present success"}, "6b98bef930182a848c027dece1bfb58ca706449d": {"ta_keywords": "end speech recognition systems model text;pronunciation information;character sequence frequencies;erroneous speech recognition output;pronunciation;pair encoding methods;characters;byte;word;baseline;character;most end;sequence;pasm;current approaches;times;method;experiments", "pdf_keywords": "end speech recognition systems model text;end speech recognition;speech processing;separate pronunciation;word modeling;language models;pronunciation information;erroneous speech recognition output;pronunciation;character sequence frequencies;most end;characters;end system;word;byte;pair encoding methods;language;end;sub;shinji watanabe;shuoyang ding;pasm;sequence;hybrid;baseline;hainan xu;systems;current approaches;feb;network"}, "8d7db1b1290e5d6f802e9f1075ef197cb55d754f": {"ta_keywords": "english speech recognition system;janus recognition toolkit;iwslt ted task;evaluation campaign;iwslt;asr track;interact project;system;kit;multipass system combination framework;nara institute;naist;single system;karlsruhe institute;collaboration;stage;technology;paper;teams;science", "pdf_keywords": ""}, "acbf4f9a4457cf2884e6018e4653519beef2833a": {"ta_keywords": "gpcmv infection;gpcmv pentamer components;guinea pig cytomegalovirus homologue;potent vaccine antigen;human cmv infection;epithelial cell infection;congenital cytomegalovirus;glycoproteins;effective vaccines;pentameric complex;pentameric complex component ul130;infection;epithelial cells;macrophage;macrophages;cmv;pentamer;gp131;mutations;alanine alteration;amino acid;cell types;cell type;several mutants;developmental abnormalities;differences;public health;children;development;effects", "pdf_keywords": ""}, "790d3503fa95ec32f04c280bd9a52fef6bf1e874": {"ta_keywords": "certain finite differencing methods;finite differencing schemes;various finite difference schemes;traffic flow;macroscopic models;differencing;friedrichs methods;simulated data;microscopic models;parameter estimation;models;least squares approximation;backward euler;statistical assessment;lax;parameters;basic method;statistical value;data;consistency;verification;paper;researchers;authors;result;work", "pdf_keywords": ""}, "0fcfa0ef253a81c103854e1dc123d90e7310a0e1": {"ta_keywords": "private deep learning;differential privacy;deep learning models;sgd;sgd algorithm;fairness;model utility;model accuracy;dp;less disparate impact;pate;disparate impact;ties;population;minori;ones;high drop;application;terms;mechanism;work", "pdf_keywords": "private deep learning;differential privacy;better fairness;privacy;fairness implications;privacy trade;fairness;deep learning models;private aggregation;deep neural networks;sensitive data;sgd;disjoint training sets;sgd algorithm;teacher ensembles;model accuracy;less disparate impact;disparate impact;teacher classi\ufb01er;pate;dp;model utility;dp mechanism;minorities;performance;recent advances;insights;levels;abstract;mar"}, "634bbe75c34b82e664f1e9f083314b5bdb6ba187": {"ta_keywords": "electroencephalogram;eeg data;eeg;ocular artifact removal;contaminated signals;clean erp data;ocular artifacts;observed signal;eye movements;eye blinks;probabilistic generative model;multiple signals;event signal;target erp component;erp;data contamination;signal;prior information;eye;physical events;event;contamination;model parameters;data;evaluation;potential;model;method;major barrier;sum", "pdf_keywords": ""}, "79a6f290cfe8652575e7bb65cfed519bca8f3bd3": {"ta_keywords": "information extraction;world wide web", "pdf_keywords": ""}, "9cda754187545c3cc8f9e9f134c08707269d0fae": {"ta_keywords": "speechstew asr tasks;speech translation;unifying speech;unsupervised language pre;unlabeled speech;language modeling;unified encoder;speech;bert objective;single encoder;text;normalization;bert;sota performance;additional supervised signals;text data;learned representations;unlabeled text;modality;slam;librispeech;models;single model;equivalent text;universality;glue tasks;degraded performance;extensive empirical analysis;bleu;downstream quality", "pdf_keywords": "speech encoder;speech understanding;language modeling;joint speech;multimodal encoder;language model;unified encoder;speech;text joint pre;text encoder;slam;art speech;single encoder model;text;learning objectives;preprint;training;models;downstream tasks;bert;arti\ufb01cial intelligence laboratory 3center;representations;model;data science;self;model architecture;jason riesa1;challenges;discussion;melvin johnson1"}, "b50d03ecd9f2055b32451e3c04138a0da07b0f69": {"ta_keywords": "time meeting recognition;time meeting analyzer;ongoing group meeting;individual speaker;distant microphones;meeting assistance;conversations;meeting table;meeting;speech recognition;microphone array;speech signal;speaker;advanced audio processing operations;utterances;participant;online manner;activity;someone;poses;channels;omni;latency real;transcripts;topic;browser;directional camera;system;components;casualness", "pdf_keywords": ""}, "2bd54adb3b5588281396a4b5dae7db09496b2c61": {"ta_keywords": "stanford squad;russian language;experimental results;large scale analog;thorough analysis;scientific community;description;gap;valuable resource", "pdf_keywords": "russian reading comprehension dataset sberquad;russian reading comprehension dataset;russian language;russia 2sberbank;abstract sberquad;multilingual qa;pavel;moscow;qa;sberbank1;high lexical overlap;saint petersburg;leonid boytsov;questions;1saint petersburg state university;russia;sentences;substantial monetary prizes;answers;challenge;valuable resource;study;andrey chertok2;scienti\ufb01c community;research;conclusions;thorough analysis;yekaterinburg;data science department;important contribution"}, "5e657bc8097c12649d027ca3c16ff7d37df1354d": {"ta_keywords": "multilingual neural machine translation;multilingual machine translation;multiple languages;more training data;test languages;weight training data;languages;heuristic baselines;training sets;data scorer;training;performance;models;mt;others;average performance;mt settings;sets;flexible control;experiments;method;paper;terms", "pdf_keywords": "multilingual model training;multilingual neural machine translation;multilingual machine translation;multilingual training preliminaries;multilingual models;language scorer;more training data;multiple languages;different training examples;languages;model performance;training sets;training;models;weighting;standard nmt model;general machine;differentiable data selection;optimal strategy;optimization objectives;data;others;multidds;mt;variety;abstract;method;usage;carnegie mellon university;dds"}, "302ae0d991d62dee82b63530b487a50469810af4": {"ta_keywords": "interpretable spatial operations;rich natural language descriptions;complex spatial actions;complex 3d spatial operations;natural language instructions;new neural architecture;language;3d blocks world;mapping;2d environment;new world configurations;pragmatic interpretations;new dataset;dataset;tokens;twisting;simulation environment;addition;original dataset;figure;bisk;competitive results;inventory;paper;marcu;yuret;size;problem", "pdf_keywords": "complex spatial language;interpretable spatial operations;complex 3d spatial operations;complex spatial actions;spatial operations;rich natural language descriptions;learning interpretable operators;interpretable neural model;action understanding;3d blocks world;rich 3d blocks world;natural language instructions;rotation;new neural architecture;movements;pragmatic interpretations;actions;subtle movements;mapping;grid assumptions;language;twisting;new concepts;interactions;complexity;new corpus;abstract;new dataset;addition;washington 2university"}, "a73d83e50b5687455336a2adce32a069c77ba163": {"ta_keywords": "nict", "pdf_keywords": ""}, "13608821aa3b369526221182dfbd3a8842549652": {"ta_keywords": "wireless relay placement;optimal power allocation;relay nodes;total cost markov decision process;relays;optimal sequential decision approach;placement policy;cost function;network;placement;deployment;nodes;exponential path;theoretic achievable rate formulas;numerical exploration;loss model;hops;value function;information;performance;length;line;structure;problem;insights;results", "pdf_keywords": "optimal relay placement;wireless relay placement;relay placement;relay nodes;impromptu wireless networks;relays;packet forwarding model;optimal sequential decision approach;network;placement policy;total cost markov decision process;allocation;mac layer;communication;ieee;deployment;theoretic achievable rate formulas;placement;information;transmission powers;theoretic achievable rate;numerical exploration;total cost mdp;index terms;physical layer;number;different conditions;arpan chattopadhyay;performance;lagrange"}, "81e684d01bbfb1f4143bb2ffea36cc4791f0530c": {"ta_keywords": "reverberation time estimation;multiple asr systems;single asr system;acoustic models;various acoustic environments;art asr techniques;discriminative training;discriminative training technique;gaussian mixture model;deep neural networks;subspace gaussian mixture model;reverb challenge;reverb;multichannel;channel dereverberation method;direct sound;various feature transformation techniques;mismatch environments;sound;discriminative criteria;different features;system combination;system combination approach;better generalization;mismatch problem;preprocessing;different model types;combination;different error patterns;specific environment", "pdf_keywords": ""}, "14dddd1d8cb2e8c5f4e9998fef84e715cb321ac9": {"ta_keywords": "formalizing trust;trustworthiness;interpersonal trust;human trust;trustworthy ai;trust;contractual trust;sociologists;ai;ai model;artificial intelligence;sociology;formalization;technology;intrinsic reasoning;interaction;cognitive mechanism;notion;extrinsic behavior;disuse;misuse;model;decisions;concepts;vulnerability;explicit contract;people;ability;causes;key properties", "pdf_keywords": "formalizing trust;trustworthiness;trust;human trust;contractual trust;distrust;formalization;ai;ai model;artificial intelligence;artificial intelligence university;commitment;notion;technology;computing;information systems;xai;explicit contract;abstract;misuse;concepts;sociology;disuse;interaction;allen institute;cases;connection;university;prerequisites;people"}, "941e42ee75fc2bf07078bcfbd14bdf9ca7fe99ff": {"ta_keywords": "monolingual language models;textual training data;language models;bilingual lexicons;documentary linguistics;textual data;speech recognition;natural language processing;languages;lexicons;such lexicons;threatened language;text data;sentences;yongning na;challenges;resource environments;fundamental task;use;application;results;cases;preliminary step;number;approach;method", "pdf_keywords": ""}, "981152cb3f1e11c9cee6af2275b57ef79c621934": {"ta_keywords": "outperform beam search;text generation;improved diversity;inverse probability weighting;human text;high probability words;repetitive candidates;diversity;samples;nucleus;distribution;inverse probability;high probability;repetition loops;surprising candidates;algorithm;higher probability;close resemblance;lower probability;controllable variation;probability;results;head;part;tail;method;methods;interquartile range;rationality;issue", "pdf_keywords": "neural text generation;inverse probability weighting;music arti\ufb01cial intelligence;language model;human text;repetition;diversity;music information technology;algorithm;inverse probability;music;reasonable permutation;text degeneration issue;distribution;intelligent technology;arti\ufb01cial intelligence;beijing;close resemblance;computer science;samples;xiaobing;jiafeng liu1;xinran zhang1;china state key lab;head;results;interquartile range;china 2department;china;systems"}, "1ea337ac24503d9da8dd9bbf98aac0bfd5920834": {"ta_keywords": "clean transcripts;monotonic statistical machine translation;faithful transcripts;speech recognition results;human stenographers;lecture speech;common corrections;corrections;style transformation;asr results;other transformations;punctuation;insertions;colloquial expressions;insertion;correction;sst;evaluation;words;effectiveness;disfluencies;types;detailed analysis;human consumption;deletion;model;paper;method;wide variety;framework", "pdf_keywords": ""}, "b8b5b95a0471e0553a0e6cd5086f384cf0f4d4d8": {"ta_keywords": "target language emphasis sequence;emphasis translation module;emphasis levels;speech tags;emphasis sequence;emphasis information;emphasis value;paralinguistic information;speech synthesis module synthesizes;translation model;utterance;transcription;speech;target language;emphasis;acoustic features;linguistic meaning;audio;words;hsmms;conventional s2st systems;lr;word;objective evaluation;conditional random field model;human subjects;emotion;regression;features;other features", "pdf_keywords": ""}, "0f2ea810c16275dc74e880296e20dbd83b1bae1c": {"ta_keywords": "recurrent neural network document reader;attention;novel attention mechanism;accurate answer selection;reader;ga reader;specific representations;document;tokens;daily mail news stories;documents;query;task;compositional operators;gated;paper;model;style questions;art results;ablation study;multiplicative interactions;benchmarks;intermediate states;multiplicative interaction;effectiveness;ga;problem;state", "pdf_keywords": "recurrent neural network document reader;ga reader;gated attention;attention;wise attention visualization;novel attention mechanism;semantic representation;reader1;multiplicative gating;novel multiplicative gating mechanism;ga;scale benchmark datasets;gru;information \ufb01lters;theart performance;gated;layer;model;components;query;intermediate states;wdw;signi\ufb01cant improvements;multiplicative interactions;contrast;competitive baselines;ablation study;strict;model design;state"}, "e58edbeb41f3d2d24832e6e3abb94baac754e3f7": {"ta_keywords": "text summarization;most summarization papers;evaluation metrics;manual evaluation;automatic metrics;standard evaluation;evaluation;scoring system outputs;evaluation method;summary;generation tasks;standard metrics;text;level evaluation settings;reliability;popular datasets;field;system;development;years rouge;paper;essential part;attempt;level;stand", "pdf_keywords": "summarization metrics;summarization community;abstractive summarization systems;text summarization;machine translation;wmt3 metrics task;evaluation metrics;automatic metrics;summary level;manual evaluation;summary;scoring system outputs;large benchmark;evaluation;generation tasks;systematic metaevaluation;text;evaluation method;scoring;dailymail dataset;cnn;task;level evaluation settings;popular datasets;datasets;reliability;abstract;end;systems;graham neubig carnegie mellon university"}, "0180c56bfbfb21243f8605e4c6f6aab2779d3ef0": {"ta_keywords": "natural language explanations;natural language argumentation interface;explanation generation;explanation system;salient explanations;markov decision processes;markov decision process;explanation logic;policy presents;reward;mdp;mdp policy;trust;additional effort;policy;optimal action;model builders;incremental upgrades;end user;knowledge engineers;action;real time;system;applications;user;psychology;time;state;novel system;robust system", "pdf_keywords": ""}, "197fcdfe05d0892ee7b4a98ef6fa74dfbcd14b48": {"ta_keywords": "crowdsourcing;convex inference;human computation;support vector machines;convex optimization;machine learning;reasonable objective functions;spammers;inference;joint inference;svms;axioms;rigorous guarantees;convexity;convex function;objective function;convexity issue;answers;data likelihood;axiomatic approach;performance algorithms;worker;inference problem;instance;statistics;natural assumptions;requirement;assumed underlying model;truth;ground", "pdf_keywords": "crowdsourcing satisfy;convex inference;human computation;axioms;spammers;inference;axiomatic approach;mild axioms;reasonable objective functions;convexity;models;inference problem;natural assumptions;objective function;explicit modelling;objective;requirement;absence;paper;set;problem;other hand"}, "18c00a9b1e6fde799ec5100cf0b1f37c306d061f": {"ta_keywords": "web search;traditional information retrieval system;web queries;interoperable multimedia catalog system;statistical learning methods;queries;electronic commerce;topics;information;data;pages;relevant information;topic;case studies;multiple sources;products;robust methods;importance;entertainment;approach;tool;common theme;discussion;current events;large fraction;reality;need;small number", "pdf_keywords": ""}, "5c283474bbb4838160410e24d33ce89ebaf32c07": {"ta_keywords": "speaker clustering;clustering accuracy;speech processing;variational bayesian method;bayesian models;speaker;effective optimization methods;markov chain monte carlo;optimization methods;mcmc;large scale data;samples;accuracy;methods;method;parametric;data;small amount;study;purpose;impact;terms;difference;experiment", "pdf_keywords": ""}, "2acc25a01a7ab7cd6b1a75d534ad29ea7d26f92d": {"ta_keywords": "subtopic retrieval;query likelihood relevance ranking;most traditional retrieval methods;subtopic retrieval problem;baseline relevance;ranking;intrinsic topic difficulty;independent relevance;query topic;maximal marginal relevance;statistical language models;many different subtopics;trec;interactive track;documents;document;other documents;metrics;redundancy;mmr;traditional precision;mixture model;data;utility;several methods;strategy;framework;problem;assumption", "pdf_keywords": ""}, "0d3baef146655c5727452ccc0dd680d21d92ae4e": {"ta_keywords": "hierarchical gaussian process approach;hierarchical gaussian process method;consumer behaviors;gaussian process;marketing variables;flexible models;orange juice category;similar demographic features;prior distributions;store;level scanner data;hierarchical structure;regression;behaviors;chicago super market;simple parametric forms;people;different individuals;class probability functions;information;similarities;income;paper;relationship;gender;lot;second problem;such flexibility;challenges;effectiveness", "pdf_keywords": ""}, "0735fb79bf34698c1df4461a05ed51c232c412e4": {"ta_keywords": "recurrent neural networks;restricted access sequence processing language;programming language;transformers;encoder;attention heads;attention;transformer;rasp program;finite state machines;forward computation;rasp;tasks;layers;simple primitives;rasp solution;task;architecture variants;models;computational model;basic components;heads;model;feed;such familiar parallel;form;difficulty;direct parallels;terms;paper", "pdf_keywords": "neural transformer;rasp language;transformer;transformer architecture;rasp program;encoder;programming language;restricted access sequence processing language;several transformers;simple language;rasp;transformer heads;rasp solution;attention;forward computation;programs;gradient descent;simple primitives;tasks;operations;layers;task;several examples;basic components;computational model;introduction;feed;form;solutions;paper"}, "6fea118a29d78340ae26c465ff06e80e55efbe3b": {"ta_keywords": "question answering;incremental reading;unidirectional language models;docqa;models reason;text;best answer;far answer;context;model;entire passage;naive approaches;question;accuracy;current state;paper;extensions;loss;restriction;issues;art question", "pdf_keywords": "incremental reading;question answering;text comprehension;incremental models;new incremental model;answering;language comprehension;rnn;text;qa;docqa;models reason;slicing;entire passage;context;model;question;primary goal;current state;conclusion;paper;extensions;accuracy;humans;loss;use;problem;art question"}, "92731a953ad063eab1bc90dc541fb956f147a6ba": {"ta_keywords": "food preferences;preference handling;restaurant software;preference representation;preference;dining;preferences;restaurants;menus;personal preference;seating;mpref community;reasoning;software;presentation;commercial potential;examples;experience;research;technology;seminal papers;art;significant further innovation;work;problem;serious application;states;current use", "pdf_keywords": ""}, "0791fe161d947d1e4d3af279b261155b88bc9ddf": {"ta_keywords": "several clinical prediction tasks;benchmark mortality prediction task;clinical time series data;efficient data augmentation technique;temporal clustering;multiresolution ensemble;predictive accuracy;deep neural networks;predictions;fine temporal detail;inputs sequences;models;data;sequences;electronic records;blood tests;multiple visits;model;different timestamp;mre;events;rapid succession;multivariate;map;intuition;series;single visit;invariance;place;others", "pdf_keywords": "irregular healthcare time series;several clinical prediction tasks;clinical time series data;temporal clustering;irregular time series;multiresolution ensemble;predictive accuracy;deep neural networks;clustering invariance;e\ufb03cient data augmentation technique;temporal detail;temporal;inputs sequences;predictions;models;sequences;timestamps;data;blood tests;series;multiple visits;data points;events;downsample;model;di\ufb00erent timestamp;electronic records;mre;rapid succession;invariance"}, "8d35230fec724398bed3f5939e9fa6a94f55a785": {"ta_keywords": "differential privacy;private datasets;private algorithms;privacy;patient privacy;public data;private machine;machine learning;data release mechanisms;data;loss functions;learning;algorithms;information;theoretical results;utility;open questions;useful information;example;medical research;samples;machine;survey;number;cost;objective;important application;upper bounds;review;interplay", "pdf_keywords": "private datasets;private algorithms;privacy;di\ufb00erential privacy;public data;private machine;machine learning algorithms;machine learning;fundamental machine learning tasks;learning models;data release mechanisms;dimensionality reduction;algorithms;learning;data;clustering;loss functions;regression;classi\ufb01cation;theoretical results;useful information;open questions;\ufb01nd clusters;utility;similar samples;machine;objective;samples;paper;cost"}, "6eae6230ae277b6915706ec05241c8db6b9fab86": {"ta_keywords": "new similarity search library;distance computations;realistic benchmarks;cheaper distance function;parallelization;algorithms;various performance aspects;computation;performance;competitive baselines;performance issues;modern hardware;library;realistic measurements;other costs;best method;future work;design;engineering;high degree;methods;goal;number;position;attention;oftentimes;original one;development;end;variety", "pdf_keywords": ""}, "8872e32284467fcbeadd1edd2f11aff077de4ccf": {"ta_keywords": "rule learning systems;algorithm ripperk;large noisy datasets;benchmark problems;algorithm;rule;error rates;large samples;diverse collection;modiications;more eecient;irep;eecient;paper;respect;number", "pdf_keywords": ""}, "47442ea4c28d631a9d46a9c23454684b834e49ea": {"ta_keywords": "coreference;unsupervised event coreference;essential distributional semantics;biomedical language processing;corpus;original corpus vocabulary;trigger word;abstract words;clauses;new dataset;novel approach", "pdf_keywords": ""}, "df873bde0b44e543634d109a7a8b1ba7dfaa8187": {"ta_keywords": "latent semantic relationships;knowledge bases;topic models;latent ontological structure;latent concept hierarchy;learned ontology;corpus;ontology;mixed membership stochastic block models;web documents;unsupervised model;freebase;input corpus;learned structure;hierarchy;categories;entities;structure;facts;text;various components;relations;software domain;model;data;kb;kbs;case study;system;yago", "pdf_keywords": ""}, "22dd93fe1a0b8e9cb83eaff6e2ecca0cd6693294": {"ta_keywords": "voice activity detection;automatic speech recognition integrated;automatic speech recognition;online speech interface;speech segments;long audio recordings;synchronous label prediction;simple thresholding;attention;conventional vad hyperparameters;ctc;threshold value;vad;unsegmented data;cue;greedy search;vad methods;conventional energy;rtf;end;input;labels;function;length;network;baseline methods;paper;architecture;experimental results;method", "pdf_keywords": "conventional voice activity detectors;voice activity detection;online speech recognition;speech recognition;online speech interface;automatic speech recognition;long audio recordings;attention architectures;streaming;connectionist temporal classi\ufb01cation;ctc;inference algorithms;end manner;end;extension;takenori yoshimura1;vad;greedy search;shinji watanabe2;tomoki hayashi1;kazuya takeda1;types;japan 2johns hopkins university;eess;index terms;conclusion;1nagoya university;paper;function;of\ufb02ine"}, "9d332ad27bfce66ee725b413aa07bd93c355efdf": {"ta_keywords": "natural language augmentation framework;sensitive natural language augmentation;natural language tasks;data augmentation;natural language processing;augmenter;popular natural language models;nlp;robustness evaluation;robustness;modifications;nl;filters;models;task;transformations;specific features;data splits;data;important component;tranformations;diversity;framework;creation;paper;variety;efficacy;initial set", "pdf_keywords": "natural language augmentation framework;data augmentation;natural language tasks;natural language processing;popular natural language models;augmenter;nlp;synthetic data;robustness evaluation;training data;data splits;nl;robustness;new datapoints;models;tranformations;modi\ufb01cations;data;transformations;speci\ufb01c features;creation;\ufb01lters;diversity;important component;variety;introduction;framework;paper;copies;act"}, "8057a5e7bcb0be7059a6e632124bc861b533c794": {"ta_keywords": "original recurrent neural network language model;term memory recurrent;speech data;sequential discriminative training;lstm;covariance matrix adaptation evolution strategy;language model;training data;rnn;channel track task;acoustic model;word error rate;neural network;training;4th chime challenge;baseline wer;chime4;best rescoring;channels;lms;cma;dnn;official baseline system;lm;baseline system;evolution experiments;wer;long short;real test data;objective function", "pdf_keywords": ""}, "88167f36dced91c279162d68af7225f2b4e2091c": {"ta_keywords": "language models;several corpora;downstream tasks;structured data;natural language;unstructured data;downstream performance;models;glue benchmarks;certain features;pre;model;results;ability;intrinsic nature;tune;paper;end;scratch", "pdf_keywords": "downstream natural language tasks;language model;human language;downstream tasks;natural language;nonenglish language;downstream performance;models;structured data;amino acid sequences;dataset;mlm;unstructured data;hierarchical structure;token embeddings;miscellaneous disciplines;lms;pre;arti\ufb01cial data;model;simple arti\ufb01cial dataset;performance;complex living organisms;intrinsic nature;abstract;ability;results;cheng;many different transformer;yi lee national taiwan university"}, "f752bf6f8c1502b8cb58aa1483ef598f9fc0d44c": {"ta_keywords": "nodes;nets;arbitrary cp;net;rank;cp;algorithms;partial orders;samples;number;trivial task;subset;method", "pdf_keywords": ""}, "5ebe542ee1a7eab7aad8e36ed53dbdd7ebd98c8d": {"ta_keywords": "scene understanding;semantic segmentation;capsule networks;convolutional neural networks;deep neural network architectures;encoders;encapsulation;core computer vision problem;scene;objects;context;large margin;knowledge;concept;accuracy;auto;relations;problems;number;applications;importance;fact;problem statement;other approaches;efficient alternative;terms", "pdf_keywords": ""}, "73484141ca58d9714ac592e3667de416322b51eb": {"ta_keywords": "wavelet transform;wavelet transform domain;signal reconstruction;multiresolution analysis;reconstructed image;signal processing;original signal;iterative linear operations;actual image;conventional method;dimensional case;clear physical interpretation;representation;practical method;method;lower computional complexity;good approximation;form;additional information;paper;authors;convergence;theoretical guarantee", "pdf_keywords": ""}, "29263fa3632951be0ca617988d7c9ce651e74393": {"ta_keywords": "multilingual translation models;multilingual training;bilingual models;machine translation model;multilingual training con;machine translation;different multilingual settings;resource languages;related languages;many learning;encoder;encoders;decoder;decoders;training;mt model;training settings;performance;lrls;different data distributions;mt;systems;tial ingredient;different effects;different varieties;light;components;paper;tribute;methods", "pdf_keywords": "multilingual translation models;multilingual models;multilingual machine translation;multilingual training;bilingual models;multilingual training contribute;machine translation;different multilingual settings;resource languages;related languages;highresource languages;many learning;many training paradigms;many models;decoders;encoders;ting;models;pei chen2 yi;training;mt model;ting yeh1 graham neubig1 1carnegie mellon university;rui chiang1 yi;lrl;2the university;performance;different varieties;lrls;different effects;mt"}, "8b1be80cc1fabcd9ccea76d9a8830e2b07e71f0c": {"ta_keywords": "raspberries;imitation game;fruit;vegetable beer;recurrent neural network;beer;words;deep learning;review;intelligence tool;computer program;passage;english syntax;software;rules;guy;reason;overpowering bouquet", "pdf_keywords": ""}, "76b36a059c0d8d66a1bf910de32b34dba19482fa": {"ta_keywords": "synchronous decoding;decoder asr;endpoint prediction;encoder;encoder features;decoder;automatic speech recognition;various asr tasks;endpoint;latency reduction;latency;continuous block synchronization;high recognition accuracy;asr;back stitch search;running stitch;ctc posterior;end;novel blockwise;tokens;novel block;style inference;evaluations;librispeech test;ms;run;algorithm;expectation;current blocks;expectation value", "pdf_keywords": "synchronous decoding;decoder asr;streaming encoder;encoder;decoder;encoder features;automatic speech recognition;dec asr;endpoint prediction;asr;endpoint postdetermination;endpoint;endpoints;back stitch search;continuous block synchronization;rabs search;enc;latency;running stitch;back stitch;search;backward jump;novel blockwise;end;ctc posterior;tokens;novel block;rabs;style inference;algorithm"}, "caabc3d0c5ece9d44fb2216a347362d4609934c1": {"ta_keywords": "large language models;various programming languages;programming languages;natural language modeling;natural language descriptions;source models;art code lms;polycoder;codeparrot;code;gpt;source model;codex;models;lms;neo;new model;neox20b;model;systematic evaluation;source;close results;many questions;blanks;current state;single machine;data design decisions;tremendous promise;piece;form", "pdf_keywords": "large language models;source language model;popular programming languages;programming languages;different programming languages;polycoder;natural language descriptions;code;gpt;source model;art code lms;software engineering domains;larger model;github data;neo;computer science carnegie mellon university;github repositories;systematic evaluation;codex;stack exchange dumps;new model;workshop paper;model;text;dl4c;pile dataset;many questions;lms;performance;future research"}, "3a8129e6fe3ad9bc3a51e44da32424e38612e4cc": {"ta_keywords": "probabilistic deductive database;tensorlog;large knowledge bases;belief propagation;logical theory;learning systems;predicates;inference;knowledge;proof depth;factor graph;multiple interrelated clauses;reasoning;gradient;steps;many tasks;database size;clause;theory size;type;certain type;query;differentiable process;compilation;functions;bp;sort;kbs;message;function", "pdf_keywords": "probabilistic deductive database;differentiable deductive database;prior probabilistic logic programming models;stochastic logic programs;tensorlog;large knowledge bases;learning systems;knowledge;inference;machine learning;gradient;many tasks;differentiable process;prddb;predicates;reasoning;several variants;slps;others;kbs;multiple interrelated clauses;system;functions;carnegie mellon university pittsburgh;sort;jul;pa;problem"}, "891fd2690a21f29b2ab54ee2249261d93c8cbc5c": {"ta_keywords": "crowdsourcing;downstream machine learning tasks;answers;modern machine learning methods;crowd;reference answer;workers;labels;questions;worker;data;mathematical guarantees;self;silly mistakes;inadvertent errors;many errors;correction;large amounts;performance;goal;first stage;mechanism;quality;stages;stage setting;significant amounts;mechanisms;oops;popular means;error", "pdf_keywords": ""}, "0ce6db2fb8c691ff8a89bd01f379ce92b1d248d0": {"ta_keywords": "topical retrieval;frequent terms;informative words;probabilistic models;occurrence;bayesian methods;classification tasks;classification;clustering;contagion;text;statistical learning tools;sentiment;words;multinomial;poisson;simplicity;latent variables;statistic;classes;binomial distributions;models;negative;analytic tractability;paper;desirable properties;comprehensive set;author;higher frequencies;sensible manner", "pdf_keywords": ""}, "6994b9860248aea10f8b8bac74e87afd3fcdc842": {"ta_keywords": "google sets;named entities;set expansion;benchmark sets;sets;entities;independent set expansion;partial set;complete set;languages;mean average precision;language;web;terms;objects;experimental results;system;novel method;paper", "pdf_keywords": ""}, "49f9afa4d0405019d01b55529ce4167380acc103": {"ta_keywords": "controllable speech modification;speech production mapping;speech modification system;synthetic speech;vocoderbased waveform generation framework;articulatory inversion mapping;direct waveform modification;input speech;vocoderbased excitation signal generation;gaussian mixture models;gaussian mixture model;unobserved articulatory movements;articulatory;modified spectral envelop parameters;speech;spectral differential parameters;spectrum differential;modeling;quality degradation;conversion errors;time sequence;system;previous work;methods;order;biggest issues", "pdf_keywords": ""}, "e1bb329621de73d08c47beae9b5439a1c244eb1a": {"ta_keywords": "novelty detection;various novelty detection scenarios;contrastive learning;conventional contrastive learning methods;visual representations;various image benchmark datasets;reliable machine learning;training distribution;instances;other instances;class;training scheme;augmentations;representation;sample;csi;many attempts;such representation;recent success;superiority;experiments;addition;method;score;effective method;end;paper", "pdf_keywords": "novelty detection;various novelty detection scenarios;new detection score;contrastive learning scheme;contrastive learning;proper detection score;various image benchmark datasets;training distribution;reliable machine learning;discriminative representation;distributionally shifted instances;new training method;ood samples;new training scheme;class;training scheme;oods;other instances;ai;sample;novel additional components;kaist;electrical engineering;csi;score function;representation;augmentations;experiments;school;superiority"}, "931a103258c96a1230dc5c7e38a1cd0b095b9d62": {"ta_keywords": "gram language model;language model;lexical acquisition techniques;language model construction;vocabulary speech;phoneme lattice;asr phoneme error rate;prior linguistic knowledge;acoustic model scores;continuous speech;lattice processing;bayesian techniques;text;learning;word boundaries;noisy input;novel sampling technique;test data;techniques;paper;new approach;improvement;separate set;important factors", "pdf_keywords": ""}, "a5690b0a514a7cbc913871e41e54c9ad4f6362db": {"ta_keywords": "automatic evaluation;translations;language pairs;noisy comments;english;blind test;challenges;submissions;robustness;task;compare;human judgment;large improvements;japanese;salient differences;reddit;best improvement;occasional disagreement;french;additional insights;new task;noisy input;mt models;baselines;bleu;national labs;qualitative analysis;models;high correlations;systems", "pdf_keywords": "machine translation robustness;machine translation;translations;translation directions;noisy social media texts;language pairs;robustness;mt models;mtnt dataset;english;challenges;french;noisy comments;models;first shared task;hassan sajjad4 1facebook ai;task;yonatan belinkov3;eng;mt;japanese;xian li1;new task;blind test;noisy input;national labs;neubig;submissions;reddit1;5google ai"}, "6aecc93c2d61da073b70dec19795172ca1ff3405": {"ta_keywords": "counterfactual invariant predictors;counterfactual invariance;counterfactual examples;spurious correlations;spurious correlation;underlying causal structure;true underlying causal structure;stress tests;implications;sentiment predictor;machine learning;model predictions;stress test;features;models;dependence;domain model performance;data;different domain shift guarantees;aspect;label;subject;model;irrelevant parts;gender;analyst;input;character;formalization;sentence", "pdf_keywords": "counterfactual invariant predictors;counterfactual invariance;counterfactual examples;causal inference;stress testing;stress tests;perturbative stress tests;robust prediction;spurious correlations;model predictions;spurious correlation;synthetic confound;domain model performance;model;certain domain shifts;formalization;dependence;tools;aspect;discussion;input;1google research 2university;distributional signature;analyst;aim;paper;irrelevant parts;abstract;relationship;victor"}, "dfd4beb1ecf70b07eb4a52e6ae58f3357e66f478": {"ta_keywords": "speech recognition;representations;training example;training iteration;learning;representation;noisy counterpart;librispeech dataset;character error rates;same representation;domain noise settings;clean example;training;inputs;current models;noise;same class;performance;art model;counterparts;test sets;superficial perturbations;layer;irl;cer;penalty term;state;rapid advances;paper;benefits", "pdf_keywords": "invariantrepresentation learners;generic data augmentation models;data augmentation;irl algorithm outperform wellknown regularization tactics;regularization terms;noisy data;multicondition training;hidden representations;domain noise;invariant representations;challenging dataset;noisy counterparts;model accuracy;models;asr task;domain noise conditions;higher word error rate;irl models;representation space;inductive bias;same representations;clean inputs;ofdomain noise;noise;data;generalization error;convergence speed;activations;same point;baselines"}, "a427334e296b6be27c3a9c7d6b942d6468e487b8": {"ta_keywords": "radio propagation;connected wireless relay networks;optimal sequential deployment;efficient deployment algorithms;wireless sensor networks;wireless relay network;relay locations;optimal deployment policy;wireless sensors;relay;relays;deployment;deployment agent;forest trail;connectivity;network;sensor;neighbouring node;forestlike environment;link quality measurements;sink node;location;base station;objective;measurement;node;potential locations;multihop;computation;measurements", "pdf_keywords": ""}, "823956ee7b994735f3605f426a71e7f85d86f1d4": {"ta_keywords": "unsupervised semantic frame induction;scale corpus;framenet;verb class;triclustering;triframes;dependency triples;dataset;web;par;graph;task;state;replicable benchmarks;competitive methods;approach;art results", "pdf_keywords": "unsupervised frame induction;frame induction task;frame induction;triclustering task;triclustering algorithm;clustering objects;triclustering;standard clustering;several triclustering methods;frame induction problem;framenet;biclustering;fair corpus;triframes;algorithms;dataset;generalization;new graph;replicable benchmarks;independent evaluations;graph;task;church;straightforward comparison;cf;par;evaluation;svo triples;new approach;verb class"}, "6eb5029dabd60eb47fddebb5919c613d399fddc6": {"ta_keywords": "speech recognition;various discriminative feature transformation techniques;sequential discriminative criterion;discriminant analysis;sequential lda;sequential maximum mutual information linear;lda;sequential maximum mutual information;discriminability;speech;effective feature transformation technique;generalized eigenvalue problem;neural network;slda;transformation matrix;optimization methods;gaussian statistics;linear;objective function;class variance;mmi;gradient;training;errors;descent;simple extension;techniques;form solution;mpe;special case", "pdf_keywords": ""}, "edca37b2004861513c54e7e97b64d4e00e72003f": {"ta_keywords": "depth determinate clauses;single horn clause;logic programs;several practical learning systems;clauses;indeterminate clauses;learning system;machine learning;generalizations;logarithmic depth;examples;representations;reducibilities;language;dnf;warmuth;consequence;primary technical tool;method;problem;results;pitt;active area;paper investigates;research", "pdf_keywords": ""}, "49775f20431c4a605c5dcc7111c9fe785bf00c62": {"ta_keywords": "markov coherent risk;policy gradient;coherent risk functionals;reinforcement learning;markov decision processes;coherent risk;risk aversion;risk;optimality;global optimum;markov;consistent surrogate;mcr objectives;policy;gradient;cvar;familiar algorithms;objective;mcr;dependence;convergence;pg;stationary points;class;return;tractable manner;suboptimality;nonlinearity;ii;updates", "pdf_keywords": "markov coherent risk;coherent risk functionals;policy gradient;reinforcement learning;risk aversion;optimality;risk;optimality gap;mcr gradient;stationary state distribution;policies;state distribution;sensitive policies;familiar algorithms;cvar;mcr;importance;pg;computer science;knowledge;gradient magnitudes;stability;1machine learning department;stationary points;global convergence;convergence;algorithm;liu leqi1;audrey huang1;class"}, "4350ce87dd3ec067f1e583ad415f71ef4ba6075e": {"ta_keywords": "training dependency parsers;dependency parser;annotated corpora;japanese dependency;art dependency parsers;annotated data;dependency tree;corpora;available linguistic resources;japanese;new training data;sentence;rapid training;word;pointwise approach;accuracy;effective use;approach;costs;reduction;experiments;state;edge;show", "pdf_keywords": ""}, "598e2d69d3573adae1f0e3bbe54d10c43f48e0b0": {"ta_keywords": "proximal stochastic gradient method;stochastic optimization;stochastic algorithms;stochastic dynamics;distributional drift;gradient noise;tracking efficiency;iterate averaging;convex function;time drift;optimization error;expectation;stepdecay schedule;efficiency;initialization quality;decision variable;high probability;bounds;time;problem;contributions", "pdf_keywords": "proximal stochastic gradient method;stochastic optimization;stochastic algorithms;stochastic dynamics;gradient oracle;distributional drift;learning rate;tracking error;iterate averaging;time drift;convex function;time e\ufb03ciency estimates;step improvement guarantee;tracking e\ufb03ciency;expectation;noise variance;stepdecay schedule;\ufb01xed problem min \u03d5t;lemma;initialization quality;bounds;nov;time;decision variable;oc;problem;high probability;joshua;math;work"}, "22f93927c487e0e0e0d2844489423bcb5d21b45c": {"ta_keywords": "discrete optimization", "pdf_keywords": ""}, "19803adec3b97fb2e3c8097f17bf33fabf311795": {"ta_keywords": "sentence pair classification tasks;many natural language processing;weak supervision;language models;only weak supervision;training framework;language model;regularized self;nlp;strongest baseline;training approach;contrastive self;tuning pre;contrastive;lms;noisy labels;tuning methods;sequence;tuning;tasks;tuning stage;cosine;competitive performance;data;high capacity;large margins;model;fine;experiments;enormous success", "pdf_keywords": "tuning pretrained language model;language models;sentence pair classi\ufb01cation tasks;many natural language processing;weak supervision;contrastive regularization;only weak supervision;language model;nlp;regularized self;only weak labels;regularization methods;training framework;strongest baseline;tuning pre;training approach;model \ufb01tting;training;contrastive;new algorithm cosine1;lms;tuning methods;contrastive self;sequence;\ufb01netuning stage;label qualities;models;error propagation;tasks;cosine"}, "53dc99155c52979e311a403571f1b1d57ff73b48": {"ta_keywords": "biological tissue modeling;model biological tissues;neural operator learning model;neural operator learning approach;digital image correlation;digital image correlation measurements;material database;dic displacement tracking measurements;displacement field;material response;data;material microstructure;material microstructure properties;anterior leaflet;porcine tricuspid valve;physics;resultant displacement field;specific constitutive model form;knowledges;solution operator;measurements;unseen loading scenarios;workflow;dic;network parameters;protocols;loading;end", "pdf_keywords": "biological tissue modeling;model biological tissues;material modeling;dic displacement tracking measurements;heterogeneous material modeling tasks;dic measurement data;soft tissue response;digital image correlation measurements;displacement \ufb01eld;neural operator learning model;deep neural operator model;mechanical engineering;digital image correlation;operator learning framework;traditional constitutive modeling;material database;neural operator learning approach;constrained uniaxial tension tests;biological materials;neural operator;mechanical engineering iowa state university ames;porcine heart tval specimen;porcine tricuspid valve;partial physics constraints;constitutive model form;material microstructure;physics constraints;data;nonlinear behaviors;physics"}, "6bca949b7ce69d6a43120d75e65f43d4c5a80ed4": {"ta_keywords": "incentive design;resource constraints;economics;intelligent infrastructure;machine learning;mechanisms;exogenous uncertainties;core communities;control theory;dynamic environments;parties;system operations;humans;self;domains;interesting avenues;face;research;future research;area;information asymmetries;art;unexpected outcomes;challenging new class;problems;interface;article;clear need;current state;tight coupling", "pdf_keywords": ""}, "0ee468b9b709a2610c4b574d67218e7960350224": {"ta_keywords": "neural machine translation;simple data augmentation strategy;data augmentation policy;data augmentation;efficient data augmentation algorithm;translation datasets;augmentation schemes;word dropout;other random words;consistent improvements;switchout;target sentence;vocabularies;text;nmt;source sentence;words;strong alternatives;tasks;comparable performances;bleu;experiments;desirable properties;solution;work;different scales;methods;optimization problem;design;generic analytic solution", "pdf_keywords": "neural machine translation;simple data augmentation strategy;data augmentation policy;data augmentation techniques;data augmentation;data augmentation algorithm;ef\ufb01cient data augmentation technique;ef\ufb01cient data augmentation algorithm;translation datasets;augmentation schemes;word dropout;other random words;consistent improvements;aug;vocabularies;target sentence;nmt;switchout;source sentence;words;nmt fall;text;strong alternatives;2google brain;tasks;comparable performances;bleu;experiments;knowledge;hieu"}, "4b22503d6da9ff3222d94106cc7425ea4fea43af": {"ta_keywords": "dependency parsing;parsers;dependency parsing problem;nlp;programmable probabilistic firstorder logic;machine translation;efficient probabilistic logic programming approach;traditional newswire corpora;information extraction;question answering;weibo;social media data;parallelizable arc prediction tasks;dependency arc;social media;dependency;sentence;task;token;core task;big challenge;many applications;domain mismatch issue;era", "pdf_keywords": ""}, "1fa69608666e66452df56b1f71282def7ac16035": {"ta_keywords": "many theoretical voting paradoxes;computational social choice;preference aggregation;preference information;voting;bribery;social choice;uncertain information;irregularities;artificial intelligence;uncertainty;paradoxes;empirical results;perfect information;decision;manipulation;agents;orders;more data;situations;new dataset;access;dissertation;work;subfield;means;magnitude;field;practice", "pdf_keywords": ""}, "2f7c03f0d3c6f51728e925a874c49a25559cc6b3": {"ta_keywords": "many other retrieval;end multihop retrieval;long documents;multihop retrieval method;entailment reasoning;different qa tasks;dochopper;document;answers;compositional questions;paragraph;text;qa;academic papers;factual qa;query;sentence;multiple pieces;compositional question;neural representation;token sequence;rag;complex questions;baseline models;paper;datasets;art results;information;next step;evidence", "pdf_keywords": ""}, "c13c400d1f481863d57ec265d296b0a08ec77876": {"ta_keywords": "audio segmentation;practical automatic speech recognition;connectionist temporal classification;token sequence;asr;end models;unsegmented evaluation sets;japanese dataset;better accuracy;insertion;ctc;segment;loss;end;baseline ctc;iterations;model;full context;device;systems;limited computing capability;single model;promising approach;method;experimental results;hypothesis", "pdf_keywords": ""}, "0a2ba7b1c05062d2bb7cd35e218fe08d6ea29488": {"ta_keywords": "meeting descriptions;meeting;structural graph;meeting assistant;email;graph walks;social networks;joint graph;graph;related tasks;address aliases;structure;other nontextual objects;rich data;timeline;documents;corresponding name string;information;task;person;content;framework;general framework;paper;full set", "pdf_keywords": ""}, "fd54706252a094d592feadf53a0a3ffed4af9295": {"ta_keywords": "far field speech recognition technology;3rd chime challenge;automatic speech recognition;chime challenge series;channel microphone array;acoustic modeling reference system;tablet device;recognition;signal processing;challenge;data collection;baseline systems;systems;task definition;data simulation;person;dnn;mvdr array processing;interface;overview;performance;design;scenario;paper;world;strategies;successful relative;outcomes;research;enhancement", "pdf_keywords": ""}, "142407d3cb61067e88d385f95ae238c74b19d554": {"ta_keywords": "corpus;gold data;archive;facebook posts;text files;excel file;data;posts;sentiment;statistics;labels;bipolar posts;lines", "pdf_keywords": ""}, "75983c55a489d526427fe399ce2670376168a2f0": {"ta_keywords": "japanese paraphrase resources;domain paraphrase database;paraphrases;statistical machine translation;parallel corpora;similar language pairs;phrases;japanese;word ordering;phrase;alignment techniques;preprocessing;syntax;grammar;several domains;english;resources;mismatch;previous works;addition;varieties;quality;particular phenomenon", "pdf_keywords": ""}, "5bc188b4ab7b27649236fad6a686b2cfe6368219": {"ta_keywords": "document topic modeling;topic modeling;topics;opinion mining;average agglomerative clustering;commonsense knowledge;particular word distributions;probabilistic models;categorization;texts;algorithms;documents;algorithm;text auto;paper;composition;collection;features;group;approach;kind;technique;tasks;contrast;length;training;improved performance", "pdf_keywords": ""}, "d8d49cc56b303d6ed0e821f8593e2f7acd1b4fb4": {"ta_keywords": "sound event detection;audio feature sequence;dcase2020 task4;wise convolution networks;attention;convolution;local context information;event;macro f1 score;domestic environments;depth;separation;technical report;augmented transformer;model;validation set;submission system;self;conformer blocks;method;baseline score", "pdf_keywords": ""}, "a61ef7be5b5c9fbc6654f7c17fa595976652416b": {"ta_keywords": "online organ matching;kidney transplants;matching;organ;deceased patients;tissue authority;donations;patients;new mechanism;waiting list;real world data;complex algorithm;mechanisms;simple mechanisms;australia;experiments;number;consideration", "pdf_keywords": ""}, "ff1a1e39a94b9ca31e6013d12bc2d27f7a31567c": {"ta_keywords": "end speech recognition;different attention functions;multiple decoders;attention level;head;attention;encoder;decoder framework;recognition performance;different speech;final output;outputs;new network architecture;linguistic contexts;ensemble effect;end;other hand;location;extension;different modalities;order;integration;improvement;paper;method;experimental results;conventional methods", "pdf_keywords": "end speech recognition;multihead decoder;speech recognition;attention;decoder framework;encoder;corpus;different speech;new network architecture;dynamical neural network;end;tomoki toda1;shinji watanabe2;linguistic contexts;extension;tomoki hayashi1;kazuya takeda1;2johns hopkins university;spontaneous japanese;1nagoya university;conclusions;cl;effectiveness;index terms;paper;method;experimental evaluation;jul;abstract;conventional methods"}, "3b4b5e72a2f84d079d0d1d825309c2f6ded76539": {"ta_keywords": "speaker adaptation experiments;transfer vector estimation;accurate transfer vectors;transfer vectors;transfer vector;speech recognition performance;adaptation data;conventional map adaptation;novel adaptation technique;individual gaussian class;gaussian class;adapted model;direction vector;gaussian mean;estimation;fine training;fine class;coarse class;scaling factor;proposals;initial model;parameters;paper;small number;amount", "pdf_keywords": ""}, "77e5c4fa595466aa51d29327a60f9d4af4436876": {"ta_keywords": "concept learner;intensive inductive learning algorithm;learnability;alternative learning algorithm;learning system;learning algorithm;learning;perceptron learning algorithm;incremental abductive ebl;knowledge;background knowledge;abductive explanation;logical theory;ebl;model;cover;extension;littlestone;ia;article;previous work;performance;output;mistake;most other respects", "pdf_keywords": ""}, "3c0d4dc4237934e37467f4ede3af859bcb140abf": {"ta_keywords": "attention module;crowd counting;total person count;wise attention;transformer layers;transformers;features;tokens;classification;pure transformer;image patches;global context;channel;various datasets;global information;context;true channel;tam;regression;module;role;image;jhu;input sequence;rtm;fact;art performance;information exchange;wise interactions;nwpu", "pdf_keywords": "crowd;attention module;global receptive \ufb01elds;vision transformers;popular challenging datasets;total count;encode features;features;regression;learning;image patches;transformers;global information;module;context;art performance;pure transformer;novel module;strong baseline;tam;auxiliary loss;rtm;knowledge;point;nwpu;jhu;ucf;qnrf;shanghaitech;state"}, "9f49ed155d7575d181d16dd5bc92b754cae0bea9": {"ta_keywords": "blind subspace identification;subspace methods;nuclear norm minimization;output linear systems;system identification;blind identification;identification problem;subspace;convex relaxation;optimization;rank;inputs;system;input;output;n2bsid;novel extension;many practical applications;paper", "pdf_keywords": ""}, "91a2d496553cfee2b66906f704b8e3d081e2d1bf": {"ta_keywords": "augment logic programs;inductive logic programming;description logics;calling tree;ii faults;counting;fault density;implementation;flip;clauses;flipper;training example;ilp;prior knowledge;extensions;errors;methods;extension;performance;problem;variation;bias;per;user", "pdf_keywords": ""}, "2bbb33ab8124e5078ec39e821a25c24c20a31b9b": {"ta_keywords": "crowd science workshop;crowd science;second workshop;workshop;audio transcription;participants;paper presentations;researchers;regular paper submissions;47th international conference;users;talks;research challenges;task;large data bases;panel discussion;vldb;technology;overview;art;world;results;events;person;science;place;businesses;hybrid format;transition;goal", "pdf_keywords": ""}, "0e96925c57b3325e7e37c1964b518e9276024cbf": {"ta_keywords": "natural language processing;empirical methods;emnlp;conference;november;proceedings;austin;texas;usa", "pdf_keywords": ""}, "7c2ff8fa0d24ed712e4bc2dbdb370a1cd62c965b": {"ta_keywords": "automated discrimination;heart disease;artificial", "pdf_keywords": ""}, "3d846cb01f6a975554035d2210b578ca61344b22": {"ta_keywords": "graph embeddings;entity classification;entity extraction;embeddings;text classification;class labels;transductive variant;class label;feature vectors;input feature vectors;graph;instance;benchmark tasks;neighborhood context;instances;models;training;inductive variant;diverse set;predictions;improved performance;parametric function;method", "pdf_keywords": "semisupervised learning framework;graph embeddings;graph context prediction;embeddings transductively;laplacian regularization;embeddings;novel graph;embedding;planetoid;graph;class label;labels;novel instances;instance;neighbors;novel inductive approach;input features;joint training;second best inductive method;context;inductive setting;novel approach;data;inductive method;classi\ufb01cation;substantial improvement;methods;signi\ufb01cant improvement;accuracy;incontrast"}, "b6de9d0ca42a03967287aa7abfd59479e086a35a": {"ta_keywords": "automatic gloss finding;available ontological constraints;knowledge base;ontological constraints;datasets;low supervision settings;supervision;glofin;art ssl algorithms;knowledge;kbs;freebase;further research;task;code;user contributed;robustness;wide variety;paper;limited amounts;effective use;other state;first system;area;nell;problem;experiments", "pdf_keywords": ""}, "d39478dd8d825bbd6c963d6a5ef2cee6857f6c21": {"ta_keywords": "computational argumentation;argument quality;argumentation;argument reasoning;arguments;semantics;fallacies;logical structures;common sense;multifaceted communication tool;logic;talk;parties;emotions;several recent attempts;rational way;textbooks;different distinguishable parts;humans;social context;easy tasks;opinions;online;real world;classical view;capabilities;light;journey", "pdf_keywords": ""}, "358d7d6333d3edd530e37efd8004cb9da8cfd5d4": {"ta_keywords": "structured procedural knowledge extraction;structured procedural knowledge;instructional cooking videos;cooking videos;semantic role labeling;instructional videos;interpretable structured knowledge;videos;level annotations;visual action detection;structured form;tasks;video clip;argument tuples;vocabulary resource;procedures;task;action;unsupervised segmentation;procedure;sentence;benchmark;models;form;standard modeling approaches;work;analysis", "pdf_keywords": "vocabulary narrative videos;multimodal comprehension;instructional cooking videos;structured procedural knowledge;multimodal information;procedural knowledge;cooking recipes;videos;challenge dataset;video clip;level annotations;structured representation;vocabulary resource;text information;noisy transcripts;key clips;dataset;neural model;largescale archive;benchmark;sentence;baselines;new task;paper;best model;\ufb01ne"}, "adf726bdcdddacee1c70d911b8f84b6a16841a32": {"ta_keywords": "prominent review aspects;textual reviews;customer reviews;prominent aspect terms;customer feedback;prominent aspects;phrases;product types;products;new products;product type;service;novel framework;large number;costly approach;systems;supervision;framework;paper;number", "pdf_keywords": ""}, "0dff2b00fd6e8e7b5f3c0707b0e51e3628988420": {"ta_keywords": "adversarial training;sensitive information;adversarial training method;new privacy;nlp community;privacy;fairness risk method;aware text;approximate fairness risk;biased decisions;fair decisions;better semantics;text;translation methods;research communities;data providers;data;task;human decision;unknown decision systems;makers;better way;fluency;automatic systems;concerns;recent work;light;trails;building systems", "pdf_keywords": "adversarial training;adversarial one;privacy risk loss;new privacy;privacy;aware text rewriting;sensitive information;approximate fairness risk;fairness risk;aware text;sensitive attributes;translation methods;models;world datasets;cui1;reconstruction loss;demographical attributes;qiongkai;leakage;model;smdsp model;research communities;task;lizhen qu3;australia 3monash university;automatic systems;abstract;relevance;australia 2data61 csiro;australian national university"}, "694c0c5a4d0176e29bb85e1b9ca8ea84075fbbbb": {"ta_keywords": "softmaxes;speech induction;rnns;bridging hmms;neural networks;hidden representations;language modeling;interpretability;hidden states;backward computation;welch algorithm;baum;sequential data;architectural transformations;propagation algorithm;back;expressivity;model family;addition;empirical effects;comprehensive empirical study;placement;hmms;parts;insights;key design factors;order;observation;special case;interplay", "pdf_keywords": ""}, "194a1e5f9af0ea00b22def879d90b926187fbb64": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "c02da00857c33fa39b115c0eb6c655ff6cf96878": {"ta_keywords": "asian translation;2nd workshop;overview", "pdf_keywords": ""}, "ca201db9980e49647feedf39eb30b19f074bf68a": {"ta_keywords": "end speech recognition;transcribed financial audio;transcription;neural transcription;text;formatted text;new stt task;many formatting tasks;target labels;english speech;acoustic models;stt;uncased latin characters;end;capitalization;punctuation;acoustic signal;machine;semantic information;task;spgispeech;hours;necessary orthography;limits performance;denormalization;complexity", "pdf_keywords": "end transcription;corpus;neural transcription;speech recognition;new stt task;end task;formatted text;training models;stt research community;target labels;new end;earnings calls;complete english orthography;baseline conformer;english;end;acoustic model;task;models;large scale;cer;spgispeech;work;contribution;hours;conclusions;feasibility;approach"}, "48530f3d6425f2f150f07ccdd61ba951951a0a7d": {"ta_keywords": "universal machine translation;individual bilingual models;neural machine translation;massively multilingual nmt;multilingual model;multilingual dataset;domain adaptation;domain adaptation demonstrate;scalable adaptation;new languages;most language pairs;tiny task;languages;adaptation approach;tasks;model capacities;nmt;models;tuning;specific adapter layers;dataset sizes;various domains;model;domains;full fine;fine;par;way;gap;experiments", "pdf_keywords": "universal machine translation;neural machine translation;multilingual translation;massively multilingual nmt;individual bilingual models;multilingual model;\ufb02exible universal translation model;multilingual nmt;high resource language pairs;multilingual dataset;domain adaptation;scalable adaptation;new languages;most language pairs;nmt adaptation;different adaptation tasks;adaptation;languages;corpus size;adaptation approach;target task complexity;transfer performance;nmt;capacity;tuning;models;ankur bapna naveen arivazhagan orhan firat google ai;low resource;huge regression;single model"}, "e3a85c5defe60f1f394fc4e7245fc071a249cf5b": {"ta_keywords": "occupants behavior;building occupants;behavioral models;behavioral model;social game experiments;occupants;social game;sensing;automation;office building;building;generative model;learning;reliable estimation;estimation;control;time algorithm;confidence;framework;competitive environment;systems;actuation;more energy;algorithm;experiment;method;goal;time;rest;management", "pdf_keywords": ""}, "c99e050b83360e5cbeee8fd2957aaab5b31aa638": {"ta_keywords": "language models;generative sequence model;lstms;memory;prediction;art language models;entropy rates;generations;term discrepancies;model;calibration;transformers;true distribution;discrepancies;end;state;time;amount;approach", "pdf_keywords": "neural language models;language models;generative sequence model;memory;lstms;temporary liquidity guarantee department;prediction;business plan;solar energy;model;iterative generation;art language models;entropy rates;entropy rate;large degradations;completion;e\ufb03cient completion;business customers;term discrepancies;generations;comcast;energy e\ufb03ciency;original model;transformers;timing;acquisition;statements;water demands;risks;electric utility transmission"}, "7ad913d1c6eddbdad1ab4571ab91f00f055ab735": {"ta_keywords": "machine translation tasks;speech recognition;most sequence transduction tasks;automatic speech recognition;regular rnn;asr tasks;sequence modeling;multiple asr benchmarks;fast recurrence;various language modeling;attention;form speech inputs;attention mechanism excels;attention mechanism;transformer architecture;asr;improved compute efficiency;novel network architecture;range dependencies;models;dominant architecture;conformer;strong capability;advantages;benefits;state;ofthe;work;art results", "pdf_keywords": "speech recognition;multiple asr benchmarks;automatic speech recognition;asr tasks;most sequence transduction tasks;form speech inputs;popular librispeech benchmark;form speech;asr;asr experiments;attention;attention mechanism excels;fast recurrence;conformer encoders;transformer architecture;transformer;art conformer encoder;conformer;range dependencies;conformer model;dominant architecture;addition;advantages;par;art conformer model;competitive performances;state;test;eess;results"}, "40947612162cc4644f9489721ec1ca94fe7e765c": {"ta_keywords": "russian semantic relatedness;semantic relatedness;lexical databases;thesaurus;semantic relation type;numerous language resources;first open distributional thesaurus;language processing systems;language resources;russian;evaluation resources;scale crowdsourcing study;evaluation;english;terms;multiple evaluations;human judgements;task;associative norms;datasets;native speakers;benchmarks;information;kind;coverage resource;list;purpose;triples;high accuracy;systems", "pdf_keywords": "russian semantic relatedness;open russian distributional thesaurus;semantic relatedness measures;semantic relatedness systems;distributional thesaurus;open distributional thesaurus;russian texts;russian language;\ufb01ve language resources;new language resources;word collection;russian;similarityij;annotation guidelines;wordj;wordi;gram model;resources;scale resource;relation type;evaluation;coverage resource;wi;list;\ufb01ve;\ufb01rst;di\ufb00erent scale;purpose;skip;table"}, "69379f55de081938ae9d8b91ef549542ed78f5f0": {"ta_keywords": "speaker diarization;deep learning;review;recent advances", "pdf_keywords": "speaker diarization;speaker diarization systems;speaker identity;speech activity;speech recognition applications;spoken language processing;deep learning;international speech communication association;deep clustering embeddings;label audio;video recordings;spectral features;robust detection;noise;classes;volume;international conference;task;annual conference;citeseer;casapp;auniversity;recent advances;components;usa djohns hopkins university;nov;presence;mountain view;eess;proceedings"}, "d74c5b5ed8eb467dc7f313b70a08880fcd74c39d": {"ta_keywords": "technology acceptance model;electronic filing;web questionnaire survey;user assessment;information system;national tax survey;system evaluation;payment system;local residents;local governments;success;users;residents;tam;credibility;comparison;results;intentions;findings;factors;paper;theoretical extension;purpose;same time;order;march", "pdf_keywords": ""}, "625764f8e3e1334ffbfe5b3139e555499e6df4d5": {"ta_keywords": "natural language website update requests;understand web site update requests;natural language processing;requests;corpus;request types;nlp;intelligent system;information;subject experiments;specific language styles;training;performance;user;system;robustness;little prior work;paper", "pdf_keywords": ""}, "b5241fcbfbf30f6fd8ff1ae19d947dd2ca23244f": {"ta_keywords": "automatic event extraction;events;particular emotion;emotion;clustering;aggregation;discovery;web data;several evaluation measures;evaluation;seed expansion;subjects;dictionary;effectiveness;first attempts;simple extensions;survey;person;creation;baseline;previous work;paper", "pdf_keywords": ""}, "21c39ce886dc38dd2006ea25d6bd1eff4cdba0b8": {"ta_keywords": "latent dirichlet allocation;online political blogs;novel comment prediction task;blog community;blog users;discussions;comments;posts;verbal reactions;authorship;models;contents;primary documents;paper;generation;data;model;various ways;post;different characteristics", "pdf_keywords": ""}, "51321a60f5ec2c80253394ef86e8b5fcc768f52a": {"ta_keywords": "data integration;information extraction methods;identifier names;databases;identifiers;dimensional data sets;different databases;textual names;world entities;similarities;sets;particular domain;web;objects;better performance;part;process;sense;techniques;paper;problem", "pdf_keywords": ""}, "6954a6bb9d6f3e365b26b694c963ae1d62a03444": {"ta_keywords": "long text modeling performance;additive attention;global context representations;additive attention mechanism;text understanding;token representation;long sequences;input sequence length;fastformer;global contexts;tokens;efficient transformer model;transformer acceleration;transformer;transformer models;powerful model;datasets;interaction;paper;wise interactions;extensive experiments;pair;quadratic complexity;many methods", "pdf_keywords": "additive attention;effective context modeling;aware attention values;attention query;inference speed comparison;attention values;attention keys;input attention query matrix;memory;attention key;additive attention mechanism;transformer fastformer;fastformer;memory cost;text understanding;ad cvr;global contextaware;ef\ufb01cient transformer variant;fastformer1;transformer;linear complexity;global context;linear transformation;latency 176ms;accuracy;powerful model;key matrix;global key vector;table;query sequence"}, "03006aefccdd0c5c6736ab11ed574d02ba1cc086": {"ta_keywords": "neural machine translation;resource machine translation;monolingual data;many language pairs;language sentences;data augmentation methods;divergent languages;translation;syntactic divergence;nmt models;nmt;additional source;parallel data;standard benchmarks;time supervision;resource scenarios;training;source;order;back;target;impressive empirical successes;effective solution;paper;issues;application", "pdf_keywords": "resource machine translation;monolingual target sentences;monolingual target data;target sentences;divergent language pairs;divergent syntactic structures;pseudoparallel sentences;language pairs;translations;effective semisupervised learning framework;translation;augmentation;step data augmentation method;nmt;baseline systems;nmt system;english;signi\ufb01cant improvements;resource;reorder;head \ufb01nalization;en;data;source;ja;performance;motivated method;ug;hf;uyghur"}, "acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269": {"ta_keywords": "gpt language model;codex powers github copilot;large language models;docstrings;gpt;python code;programs;code;github;available code;codex;functional correctness;new evaluation;difficult prompts;operations;variables;humaneval;limitations;capabilities;model;difficulty;long chains;careful investigation;problems;effective strategy;solutions;distinct production version", "pdf_keywords": "powerful code generation technologies;natural language docstrings;large language models;codex powers github copilot;code bodies;github copilot;docstrings;codex models;several early codex models;code;programs;github;correct code bodies;new evaluation;gpt;functional correctness;openai api;models;strong performance;security;easy interview problems;safety;task;humaneval;performance pro\ufb01les;model;paper;dataset;human;\ufb01ne"}, "b5a667bf189a0cfda22bac702d97b601ae6adb6f": {"ta_keywords": "free optimistic gradient descent;adversarial distribution shifts;approach learns models;ascent algorithm;gradient information;dependent learning problems;convex minimization problems;strategic classification literature;gradient;strategic decisions;order algorithms;illustrative simulations;concave;algorithm;finite sum structure;random reshuffling;existing methods;data sources;decision;same convergence rate", "pdf_keywords": "free optimistic gradient descent;concave minmax problems;adversarial distribution shifts;convex minimization problems;max optimization;ascent algorithm;approach learns models;minimization;distributional robustness perspective;dependent learning;performative prediction;gradient;convex;robustness;order algorithms;1electrical engineering;abstract min;dependent risk;order methods;concave;illustrative simulations;strategic decisions;strategic classi\ufb01cation literature;algorithm;berkeley 2electrical;computer engineering;\ufb01nite sum structure;computer sciences;eric mazumdar1;math"}, "26cc9e13a7a76e3cf5f9885d08cdafabd6fbd7ec": {"ta_keywords": "tournament solution sets;tournaments;computational social choice;tennis;social choice;soccer;political science;economics;reasoning;performance;computer science;theoretical results;comsoc;many results;practice;study;experiments;real wold data;field;intersection;worst case;end", "pdf_keywords": "realistic tournament data;real world tournaments;tournament model;tournament;synthetic tournaments;tournaments;computational social choice;popular condorcet random;atp world tour;tennis;statistical physics;soccer;english premier league;real world instances;social choice;german bundesliga;empirical evaluation;robust statistical methods;political science;real wold data;economics;real world data;seeding;team;log;australia;computer science;principled methodology;experiments;cr"}, "ac46562e61cfef6213a915bbb80d1a1a2901542a": {"ta_keywords": "multiple information sources;technical paper recommendation;recommendation service;conference paper submissions;online data sources;preference data;researchers;daily pointers;papers;resources;committee members;data;actual submissions;approaches;different approaches;interest;other methods;members;fields;study;variant;approach;people;instance;need;new opportunities;proliferation;problem", "pdf_keywords": "information retrieval;recommendation process;recommendation algorithm;technical paper recommendation;multiple information sources;conjunctive queries;conference reviewing;cial intelligence research;formulating queries;reviewer interest information;online data sources;conference paper submissions;collaborative approach;data representations;di erent approaches;information;resources;web;content;other approaches;committee members;computer science;questions;data;more speci;single source;chumki basu;novel autonomous procedure;journal;rutgers university"}, "559fdae33f0b7733b80a7dbcb902c79598a0d26e": {"ta_keywords": "treatment effect estimation;strong treatment effect estimators;treatment effect estimators;inductive biases;transformers;causal effects;natural language;transformer architecture;datasets;estimation problems;text;treatments;dominant methods;covariates;methods;transtee;diverse domains;research;experiments;computer vision;dosage;general framework;paper;problems;variety;sorts;tee;sequences", "pdf_keywords": "propensity score modelling;propensity score network;propensity score model;versatile treatment effect estimators;propensity score;treatment effect estimation;selection bias;causal inference;bias;covariate adjustment;competitive baselines;covariates;outcome model;matching;conditional density estimation;benchmarks;extensive experiments;regularization;impacts;estimators;adversarial training algorithm;transtee;weighting;results;adversarial manner;features;practical use cases;common goals;expressiveness;treatments"}, "bf63276c90a803fe0d069ce0a3a4a8236e756363": {"ta_keywords": "comic book narratives;comic book panels;visual narrative;comics;comic book story;narratives;dialogue;narrative;artwork;drawing inferences;style tasks;natural images;various deep neural architectures;text;content;character;context;human baselines;language;models;explicit information;panels;centric aspects;vision;details;plot;image;depth analysis;amazing mysteries;tasks", "pdf_keywords": "comics understanding;comic book narratives;visual question answering dataset;multimodal models;multimodality;visual narrative;comics;visual storytelling;various deep neural architectures;text models;contextual understanding;neural architectures;encode context;text;different neural models;style tasks;different neural architectures;automatic textbox transcriptions;human baselines;drawing inferences;character;narrative;context;language;models;vision;tasks;image;details;panels"}, "83165cf62e62a013c2bad61c98120ccb9a0087ae": {"ta_keywords": "peer review;other sociotechnical intelligent systems;bias;unfairness;fairness;scholarly research;empirical studies;challenges;open problems;tutorial;domain;part ii;several problems;number;backbone;solutions;urgent need;part", "pdf_keywords": ""}, "e8deeebc7ff6315115f01fd70a343d62db202888": {"ta_keywords": "specific lexical resource;glossaries;specific glossaries;natural language processing system;genus;sophisticated general purpose resources;hypernymic relations;species;individual terms;synsets;such domain;such resources;terms;domain;sense definitions;match;thesuari;noisy pairs;workflow;ambiguity;performance;paper;problem;form", "pdf_keywords": ""}, "b778a7c4001898a1c3888577154d747522f16db4": {"ta_keywords": "adversarial losses;adversarial loss;different adversarial losses;valid adversarial loss functions;discriminative adversarial networks;loss functions;regularization approaches;regularization terms;divergence;deeper understanding;component functions;dantest;model distributions;different component functions;functions;data;like measure;certain types;simple framework;framework;effects;sufficient conditions;order;paper;extensive set", "pdf_keywords": "various adversarial loss functions;different adversarial losses;adversarial losses;adversarial loss;adversarial training objectives;discriminative adversarial networks;discriminative adversarial network setting;discriminative models;regularization terms;regularization approaches;divergence;deeper understanding;component functions;dantest;different component functions;training;model distributions;new comparative framework;hsuan yang;simple comparative framework;yi;empirical results;wen dong;data;dans;future research;framework;like measure;hao;reference"}, "0453bab552e83f19dd6ba12061949f128fa9b045": {"ta_keywords": "exploratory learning;classes;datasets;ssl;exploratory;data;seed examples;examples;unknown number;f1;variants;number;performance;terms;paper;case", "pdf_keywords": "alternative exploratory learning algorithm;classes;datasets;like ssl methods;new classes;fisher distributions;chinese restaurant process;several popular em;seed examples;multinomials;classi\ufb01ers;crpgibbs;ssl;mixtures;ssl performance;different models;exploratory;several instantiations;seeded version;data;variants;seeds;exploratory version;gibbs;different approaches;em;section;terms;performance;paper"}, "b36dc8db9930a785edd55ca30328ace2896523e6": {"ta_keywords": "semantic corpora;semantic annotation;standardized annotated corpus;atis corpora;annotation tools;corpus;atis corpus set;semantics;cooperation;research;whole research community;progress;individual findings;science;main means;other teams;result;methodology;set;practical deployment;purpose;different systems;trends;basic necessity;article;such problems;problems;years;today;problematic", "pdf_keywords": ""}, "87eece8d39d1e25ba87550be8b01af32738cbf2c": {"ta_keywords": "speaker parallel attention;talker speech recognition systems;multiple attention modules;automatic speech recognition;parallel attention;attention module;talker end;talker;speaker model;speaker;speech;knowledge distillation;asr;knowledge distillation transfers;curriculum learning;invariant training;end model;word error rate;character error rate;knowledge;basic end;separation ability;training strategy;enhanced end;wer;permutation;system performance;final system;cer;tracing", "pdf_keywords": ""}, "e2ece7ea0924b4f95f65587973118bea9a44a3d2": {"ta_keywords": "relation discovery;term relationships;software entities;human labeling results;entities;similarity measure;classifier;coordinate term relationships;contexts;java classes;technical domains;classes;software domain;distributional information;software;discovery;world objects;detection;information;text;pairs;statistics;methods;distribution;additional information;approach;f1 score;end;access", "pdf_keywords": "interesting code taxonomy;relation discovery;common usage patterns;namespace hierarchies;java classes;java;code repository;coordinate term relationships;text entities;java class;coordinate term prediction task;java class type;usage pattern;underlying class type implementation;classes;standard libraries;distributional similarity measure;distributional similarity;classcontext;simple entity;hierarchical organization;code;software;discovery;implementation details;grounding;class;prediction accuracy;domain;functional connections"}, "bbc7e533e5bfb388af1afd85bfb7ba17330cae76": {"ta_keywords": "high voltage shore power supply;shore power supply;bridge inverter current;dc bias suppression method;transformer;dc current;output voltage;converter chain;dc voltage component;dc component;dc bias phenomenon;main circuit topology;dc bias;pwm pulse;suppression;control strategy;output characteristics;positive feedback;output;compensation;test platform;real time;design;experimental results", "pdf_keywords": ""}, "92cee1e209f2d9a311416b0d9fd8a49b0fbe7df2": {"ta_keywords": "symbolic learning methods;text categorization;several learning methods;several different learning methods;classifiers;generalization performance;feature selection method;classifier;information filters;features;transfer;direct transfer;collaborative setting;diverse set;more conventional evaluation settings;documents;poor performance;initial training phase;data;beneficial variation;stability;several concrete proposals;users;new user;experiments;effect;system;rise;distribution", "pdf_keywords": ""}, "956aa64b0d5f5802b98bf551d5bab8993b114fd0": {"ta_keywords": "tfidf similarity;good similarity functions;sensitive similarity metrics;similarity metric;similarity function;large data collections;soft joins;many data sources;tfidf;data integration;dataset;certain datasets;training data;shares tfidf;many smaller collections;parallelization;data;many important subtasks;important properties;few passes;context;modification;passes;paper;experiments", "pdf_keywords": ""}, "f52f7964febd6d6d72aa23505b50d33e1d4ce0aa": {"ta_keywords": "novel labeling rules;rule discovery;quality labeling rule;supervised learning;many nlp tasks;complementary weak labels;rule templates;interactive weakly;boosting;label scarcity;learning;candidate rules;rules;human experts;prboost;wsl model;wsl;promising results;prompt;lms;data;error instances;current model;problem", "pdf_keywords": "novel labeling rules;rule discovery;rule annotation;rulelevel annotation;many nlp tasks;rule discovery framework;weak labels;supervised learning;rule generation;quality labeling rule;iterative boosting strategy;relation extraction;boosting;interactive weakly;weakly;level annotation;annotate;\ufb02exible rule representation;learning;new rules;prboost;label scarcity;subtle semantics;ensemble;ensemble strategy;rules;interactive wsl;complementary weak models;instance;interaction prediction"}, "60f3e69e4f18e8e8e7dcc4ba66c1e216b49ad982": {"ta_keywords": "sense knowledge acquisition;commonsense knowledge acquisition;commonsense knowledge representation;game engine;gecka;natural language understanding;game designers;gamers something;reasoning;games;sense;serious games;platform;tasks;information;acquisition;entertainment value;world;development;humans;difficult task", "pdf_keywords": ""}, "09b87b6e7bfbf66d355574d292586595e0185d6e": {"ta_keywords": "typological knowledge bases;typological kbs;typological features;linguistic properties;linguistic probing;languages;most languages;annotations;haspelmath;features;few features;kbs;information;feature values;task;error analysis;systems struggle;broader adoption;wals;sense;world;major drawback;downstream applications;dryer;focus;wide coverage", "pdf_keywords": "typological knowledge bases;typological features;linguistic properties;language structures;languages;small languages;haspelmath;prediction;task description;eurasia;conclusions;world atlas;\ufb01rst sigtyp;task;information;accuracy;mayan;world;wals macroareas;variety;abstract;nilotic;wals;north america;kbs;papuanesia;africa;south america;system submissions;cl"}, "5b16d138bf16762d43b55b6e21d9b0b61021180e": {"ta_keywords": "transcription networks", "pdf_keywords": ""}, "b15ea460c77a4ee8aa159a30ab0331deedfcf392": {"ta_keywords": "large language models;expert allocation;sparse layers;high capacity sparse layers;sparse models;specialized expert modules;optimal assignment scheme;optimal assignment;expert;experts;base layers;training;linear assignment problem;new hyperparameters;layer;tokens;token;new balanced assignment;model parameters;inference;base;auxiliary losses;balanced compute loads;efficiency;small fraction;equal number;contrast", "pdf_keywords": "sparse experts;sparse models;expert specialization;language models;expert;experts;multiple experts;simple sparse base layer;expert contribution;neural model;training;sparsity;training cost;linear assignment algorithm;layer;dense models;complexity;tokens;strong performance;capacity;assignment;base;additional loss term;modi\ufb01ed residual connection;paper;little increase;effective solution;new balanced assignment;use;ef\ufb01cient"}, "bbb7eb10c45cabaee6e427242fce7180c0217ef1": {"ta_keywords": "programming languages;abstract syntax tree;different programming languages;variable names;program;languages;different prediction tasks;python;programs;code;java;representations;javascript;discriminative models;method names;learning;paths;representation;tokens;different learning algorithms;crf;effective learning;tasks;general path;full types;ast;task;structured nature;different tasks;evaluation", "pdf_keywords": ""}, "cbf941fef87830efa4de98455cfe943917909b66": {"ta_keywords": "hessian approximation;superlinear convergence;inverse hessian approximation;local superlinear convergence;bfgs methods;strong convexity parameter;bfgs method;convex broyden class;gradient;new theoretical analysis;lipschitz constant;dfp;iteration counter;worst case;trace;moment;condition number;analysis;rates;logarithm;potential function;form;problem;results;dimension", "pdf_keywords": "superlinear convergence rate;superlinear convergence;classical gradient method;convex broyden class;smooth unconstrained optimization;exact hessian;newton method;linear convergence;approximation;broyden;iterations;positive de\ufb01nite linear operator;algorithms;method;fletcher;condition number;bfgs;quadratic function;goldfarb;certain formulas;shanno;powell;davidon;main examples;rate;form;class;paper;dfp;qk"}, "d8551a4b49aa547ad8884ba9f545480860fcadd1": {"ta_keywords": "deep implicit fourier neural operators;implicit fourier neural operator;novel deep neural operator architecture;material models;heterogeneous material modeling;learned solution operators;deep networks;implicit neural operator;neural network;fast fourier transformation;material modeling problems;material response;modeling;fidelity simulation;fourier space;integral kernel;displacement fields;integral operator;displacement;damage fields;material heterogeneity;conventional constitutive models;ifno;material;solution operator;implicit mappings;data;fft;network;differential equations", "pdf_keywords": "learning deep implicit fourier neural operators;material models;heterogeneous material modeling;implicit fourier neural operator;learned solution operators;novel deep neural operator architecture;fast fourier transformation;constitutive modeling;deep networks;material heterogeneity;mechanical engineering;displacement \ufb01elds;conventional constitutive models;integral kernel;materials;fourier space;integral operator;mechanics theory;mechanical responses;ifno;digital image correlation;aerospace;fft;mathematics;huaiqian youa;ifnos;dic;complex responses;quinn zhanga;network"}, "cee25a535ec7165eae38f498a391050077ad9f65": {"ta_keywords": "dirichlet process mixture model;infinite mixture model;conventional hierarchical agglomerative clustering;speaker model;utterances;speaker;sampling;utterance;markov chain monte carlo;speakers;dpmm;model;scale data;optimization;large amounts;evaluation;framework;uo;number;present paper;purpose", "pdf_keywords": ""}, "7668b23aadf43bebe5e2d3abf37938b44bd16200": {"ta_keywords": "unified multimodal reasoning models;visual question answering;multimodal qa;richer visual online world;fluent language response;query language knowledge;visual representations;visual representation learning;knowledge aggregation;challenging new benchmark;language groundable;language generation;web searches;webqa mirrors;webqa;knowledge;art models;source modality;images;digital assistants;web;text;challenge;questions;vqa;way humans;humans;community;model;sources", "pdf_keywords": "tanabata festival;tanabata festivals;tanabata festivapl;sendai tanabata festival;festivalsctaarlinghyt;festival;shopping malls andthe festival;oktoberfest tpiinlvaacledss aoirnemjhapeplldaan;largest tanabata afleostnivgalshopbpaivnagrianmanlalms eanodf tshtereets;syonan hiratsukatanabata;hiratsukatanabata;oktoberfest;scale tanabata;oktoberfestbier;hiratsuka;sienndtthhaeei summer;wiesenbier;castplleaceisninthjeapbana;whfeisctihval sairtee;efemrrinaginltyo tahleong shopping malls;lights;nldyoktolianbrgejearsptfaents;hiratsuk tobetrfeasnt awbasatraenamefdetsotivtshatrele;aolmlmsaian;ajraeplanar;starlight;masskruege four mugs;pthagoseutrasenaant dmosfefrosr;titvhael;thpaelljoacn2segs4esnhi0nodp2apjai9inpgadnm"}, "c688e187cede868e35fc1b53913e0fbbe6e38ea0": {"ta_keywords": "structured prediction;complex structured prediction task;structured prediction algorithm;biomedical event extraction;various natural language processing tasks;paradigm algorithms;imitation;algorithms;search;expert demonstrations;particular task;paradigm;context;paper;dagger;free versions;state;order;investigation;stable performance;searn;art performance;advantages;parameter;daume iii et al", "pdf_keywords": ""}, "2448e63a7bb626d09001fe37e60befdb2919f6e6": {"ta_keywords": "commonsense information extraction;commonsense knowledge;information extraction;readable knowledge bases;basic commonsense facts;sense knowledge;robust extractions;markov chains;web search;scale language models;factual knowledge;markov chain approach;robust graph;graph representation;web;local search;candidate facts;mobile assistance;other sources;graph;world;most machine;accuracy;way;paper;challenging nature;previous work;user;method;experiments", "pdf_keywords": ""}, "cee96ee69adacfdeb648c230d2c9b01011724724": {"ta_keywords": "end neural diarization handling overlapping speech;online streaming end;speakers;flexible numbers", "pdf_keywords": ""}, "007371feab4af758b74580c43e74827b3500c67e": {"ta_keywords": "demand streaming system;vod content distribution problem;simple fractional storage architecture;convex content placement problem;several individual node resource constraints;topology selection;user demand;node;markov approximation technique;content;network condition;optimization problem;demand;churn;disk space;video;network link;node degree;implementation;simulations;system;design;hard problem;codes;solution;account;changes;general framework;theory", "pdf_keywords": ""}, "2a0cb1a1e78b77fe9981e4935410cf3ea900e370": {"ta_keywords": "speech recognition system;untranscribed data report;jhu workshop;honza;sanjeev khudanpur;daichi mochihashi;najim dehak;santosh kesiraju;jan;jan trmal;takahiro shinozaki;umbach;raghavendra pappagari;shinji watanabe;jinyi yang;ond\u0159ej;leda sari;\u010dernock\u00fd;yibo yang;mirko hannemann;ming sun;luk\u00e1\u0161 burget;chunxi liu;lucas ondel;report;editor;graham neubig;reinhold haeb;alena rott;thomas glarner", "pdf_keywords": ""}, "d60b4594fb0404329d9ebf6fd88702ca3479e904": {"ta_keywords": "abbreviation extractor;abbreviations;abbreviation definitions;biomedical text;alignment hmm;comparable alignment;unlabeled examples;definitions;chemical formulas;results;additional test set;algorithm;definition;standard data set;improvement;set;probability;specific types;associates;model;approach;methods;several advantages", "pdf_keywords": ""}, "99546b4d1f2547095bb15eec36e03f64b74a78d4": {"ta_keywords": "community feedback;past community feedback;new users;newcomers;wsb community;newer users;users;subsequent message topics;term users;us markets;gamestop short;emojis;changes;wsb;wallstreetbets;stock prices;topics;worldwide attention;affected companies;increase;respective writing styles;post length;january;choices;significant difference;significant short squeeze;paper;activity;comparative analysis;number", "pdf_keywords": ""}, "5e3d1bece9dd2356fd2b31312bd62c8f7126882d": {"ta_keywords": "energy disaggregation;privacy tradeoff;utility", "pdf_keywords": ""}, "b990331a5394f3642a1fd1791d70bfa2d85d9d1d": {"ta_keywords": "tweets;twitter;latent dirichlet allocation;content;youtube videos;vaccines;youtube links;topics;external content;vaccination;conspiracy theories;topic;learning;legacy media organizations;agenda;conversations;external websites;urls;url domain;web domains;unique urls;domain;transcripts;objective;theory;analysis;methods;machine;model;days", "pdf_keywords": ""}, "8b98f7ff3bb1b199db85fc219a5c27b355adf1be": {"ta_keywords": "osseous crown lengthening procedure;osseous crown lengthening;osseous crown;erbium laser;flap surgery;sufficient tooth structure;postoperative complications;lengthening;healing process;aesthetic outcome;procedure;conventional treatment;final restorations;tissue position;biologic width;invasive alternative;smile;closed flap;clinician;bleeding;present technique;patient;appearance;infection;adverse effects;placement;violation", "pdf_keywords": ""}, "a604ad4654f31d325b888806e276123a704cb5c8": {"ta_keywords": "support vector machine;classification robustness;minimum error classification;classifiers;geometric margin maximization;minimum classification error;new mce training method;svm;classification tasks;geometric margin;geometric margin value;discriminant functions;high robustness;conventional mce framework;practical optimization procedures;general class;training;mce;patterns;wide range;prototype;new method;various types;attention;effectiveness;great deal", "pdf_keywords": ""}, "652e3c774da47c0c8788111ec886a00d3b8fc637": {"ta_keywords": "tumour cavity surface;tissue deformation;tumour boundary;ventricle surface;tumour cavities;brain deformations;tumour;biomechanical modelling;healthy parenchyma tissues;mri;computer simulation;parenchyma;resection;skull;surfaces;ventricles;hausdorff distances;cerebrospinal fluid;problem geometry;gravity;loading;data;points;reaction forces;results;limits;potential;method;problem;approach", "pdf_keywords": ""}, "d0ea87ce3bcd86428d379fd478c365c64f870200": {"ta_keywords": "dialogue state tracking models;dialogue systems;dialogue;dialogue research;schema robustness;schema sensitivity;schema variations;linguistic variations;shot generalization;schema;schemas;simple modelagnostic data augmentation method;unseen services;robust generalization;joint goal accuracy;services;task;benchmark;shot transfer;robustness;critical challenge;sgd;novel metric;models;dataset;additional data collection;paradigm;unlimited number;use", "pdf_keywords": "schemaguided dialogue state tracking models;schema guided dialogue extended;dialogue state tracking models;dialogue state tracking;dialogue models;dialogue systems;novel schema sensitivity metric;schema robustness;schema sensitivity;dialogue research;schema variants;schema;original schema;joint goal accuracy;accuracy metrics;sgd;linguistic distance functions;benchmark;standard performance metrics;sgd dataset;robust generalization;release sgd;novel metric;average sgd;training models;robustness;shot generalization;model predictions;translation;stylistic variations"}, "429b65937d4922578a81e1f0ef5aeab7361ae36b": {"ta_keywords": "semantic parser;semantic parsing methods;bash commands;natural language interface;specific scripting;nl2bash;corpus;english sentences;file manipulation;english;search;linux operating system;operations;term goal;application;new data;goals;user;problem", "pdf_keywords": "semantic parsing benchmarks;semantic parser;semantic parsing methods;natural language interface;target meaning representations;natural language control;nl2bash;bash commands;commands;corpus;bash1 commands;bash programmers;english descriptions;english sentences;large new dataset;descriptions;quality descriptions;new dataset;task;dataset;ambitious domain;new data;linux operating system;performance levels;operating system;\ufb01rst step;set;washington;abstract;domain"}, "ba45a346690f3c5b6f8c371b5c6cf1d7cce5619d": {"ta_keywords": "abstract blind system identification;constrained rank minimization problem;relaxed convex formulation;arx model;only output measurements;linear subspace;unique solution;input;solution;task;further assumptions;problem;hand;contribution", "pdf_keywords": "arx model identi\ufb01cation;arx model;only output measurements;convex optimization problem;optimization;measurement noises;outputs;\ufb02exible framework;constraints;lifting;novel method;method;task;di\ufb00erent types;products;williamson;complicated problem;shor;paper;schrijver;technique;form;goemans;nesterov;contribution;main contribution"}, "65c2a39f1579a947926ac5746888445ea4afdf6e": {"ta_keywords": "unsupervised grammar induction;grammar induction;grammar induction benefit;free grammar;lexical dependencies;disparate syntactic formalisms;neural lexicalized;cfg;context;dependencies;pcfgs;popular current methods;constituents;methods;previous approaches;sparsity;paper;return", "pdf_keywords": "unsupervised dependency parsing;constituency parsing;lexical dependencies;neural parameterization;neural parameterization method;structure grammar;novel neural models;abstract syntactic structure;novel lexicaly;uni\ufb01ed phrasestructure;variational inference;syntax;pcfgs;inference;dependencies;semantic guide;dependency;constituency;compound variables;pcfg model;parameter;pcfg;constituents;dynamic programming;compound;modeling;continuous mixture;introduction;single model;model"}, "562f33611cdc0d8ed6609aa09f153e6238d5409e": {"ta_keywords": "missing data;rnns;clinical time series;missingness patterns;lstms;multivariate time series;diagnoses;intensive care unit;improved classification;data;multilabel classification;sequential inputs;binary indicators;sequences;icu;linear models;mlps;several diseases;observations;f1;auc;results;substitution values;major urban medical center;tests;task;work;arbitrary functions;simple strategy;effective use", "pdf_keywords": "modeling missing data;clinical time series;representative lstm models;rnns;imputation;lstm;missing indicators;diagnosis classi\ufb01cation performance;baseline models;machine learning;data indicators;diagnoses;sequential inputs;data;predictive power;linear models;sequences;healthcare;mlps;best overall model;hospital la los angeles;patterns;metrics;indicator values;values;zeroimputation;indicators;multilayer perceptrons;indicator;diagnosis auc"}, "a36f7d5d8f724168e534925edff97b3680e545c9": {"ta_keywords": "tensor contraction layers;tensor contraction layer;activation tensors;imagenet datasets;parsimonious deep nets;trainable neural network layers;tensor contractions;neural network layers;tensor contraction;tensors;significant model compression;alexnet;networks;image recognition;natural representation;machine learning;tcl;popular networks;tcls;parameter reduction;accuracy;model parameters;performance;dimensionality;task;data;vgg;use;end;number", "pdf_keywords": "activation tensors;tensor contraction layer;activation tensor;order activation tensors;tensor contractions;image recognition network;tensor contraction;tensor;neural network layers;trainable neural network layers;imagenet datasets;\ufb01nal convolutional layer;new neural network layer;image recognition;alexnet;dimensional representation;tcl;tcls;parameter reduction;popular networks;task;multidimensional dependencies;vgg;end;performance;paper;algebraic techniques;effect;use;several ways"}, "c2ff76c75acc777e005360e9d4c4d928d95c0432": {"ta_keywords": "distributed storage networks;solomon codes;redundant storage;such storage systems;optimum codes;individual storage nodes;simple replication schemes;storage system;network reliability;codes;reliability;repair;reed;multiple nodes;node;reconstruction property;failure;network;data;paper;minimization;order;property;amount;must;overview;interest;explicit construction;manner;discussion", "pdf_keywords": ""}, "6c3b8e65dc45cb62172f9425dcff4c48055d47eb": {"ta_keywords": "textual features;twitter;social media;visualization;visualization tools;food;corpus;language;datasets;community characteristics;many latent population characteristics;dataset;posts;temporal histograms;geo;geographic locale;data;heatmaps;geographical location;political leaning;time query;models;global patterns;majority;authors;predictive power;home;diabetes rate;overweight rate;tasks", "pdf_keywords": "tweets;twitter;textual features;visualizations;food;annotating;visualization;large corpus;community characteristics;datasets;interactive visualizations;different foods;posts;corpus;data;many latent population characteristics;dataset;various daily meals;geographical location;language;geographic locale;geographic location;predictive models;temporal dimensions;political leaning;political learning;drinks;diabetes rate;time query;additional information"}, "5e00596fa946670d894b1bdaeff5a98e3867ef13": {"ta_keywords": "captioning tasks;simple visual language model;language pretraining;clean image captions;expensive annotations;minimalist pretraining framework;many multimodal downstream tasks;generative vision;language benchmarks;textual representations;single prefix language modeling objective;nlvr2;vision;training complexity;weak supervision;task;simvlm;recent progress;snli;image;impressive performance;vlp;art results;regional labels;model;joint modeling;extra data;vqa;average cider score;score", "pdf_keywords": "language pretraining;simple visual language model;many multimodal downstream tasks;minimalist pretraining framework;textual representations;vision;shot coco evaluations;text;uni\ufb01ed objective formulation;visual question;weak supervision;objective outperforms;strong generalization;language;text pairs;objectives;brain team;image;naive lm;impressive performance;transfer ability;data;effectiveness;vlp;joint modeling;recent progress;abstract;constraints;results;importance"}, "96bb4b49f69419c31857e928969fcaa137e15060": {"ta_keywords": "question answering task;answer generation;available product reviews;review;relevant reviews;available reviews;many questions;informational retrieval techniques;annotations;qa;knowledgeable customer;comprehension;answer;provisional answer;new task;strong baselines;amazon dataset;task;models;new dataset;question;number;end;method;time;challenging nature;deployed system", "pdf_keywords": "product review dataset;neural qa models;answerable questions;top review snippets;information retrieval;information retrieval techniques;answerability classi\ufb01er;product reviews;relevant reviews;most questions;automatic community question;923k questions;qa;reviews;questions;qa models;question answerable;review;annotations;comprehension;dataset;answer;products;snippet extractor;amazon;new resource;new dataset;outliers;mcauley;models"}, "2873f78efd7adcb118a70f8ea3ca7fa1501e320a": {"ta_keywords": "shot relation classification models;shot relation classification;fewrel dataset;domain adaptation;nota relation choice;fewrel;new dataset;more challenging few;nota detection;more attention;new domain;aspects;instances;challenges;different domain;challenging task;world issues;new test;further efforts;handful;techniques;research;art;extensive experimental analysis;state", "pdf_keywords": "shot domain adaptation;shot relation classi\ufb01cation task;shot relation classi\ufb01cation models;domain adaptation;domain adaptation methods;biomedical domain;shot models;dataset fewrel;original fewrel dataset;biomedical literature;new dataset;biomedical sciences;shot none;pubmed;shot da;umls;shot nota;scale knowledge base;theabove detection;fewrel;new test;challenges;new task;aspects;nota detection;database;above detection;extensive experiments;techniques;realworld issues"}, "3f311aee9d25b0284d21274cfc8706d6f0277f87": {"ta_keywords": "deep quantization;dnn layers;deep neural networks;quantization;heterogeneous quantization;bit weights;several neural networks;neural networks;bitwidths;networks;lower bitwidths;dnns;different bitwidth;layer;memory;activations;weights;limited computing resources;hyperparameter optimization;network;entire network;rl agent;computing power;mnist;accuracy;cifar10;wide range;less power;reinforcement learning approach;inference", "pdf_keywords": "deep reinforcement learning framework;quantization hyperparameter space;proximal policy optimization;deep networks;reinforcement learning;quantization;quantization levels;releq;parametric reward;unique reward formulation;rl agent;mobilenet;alexnet;layers;rl;unified rl process;objectives;speed;neurips workshop;discovery;relative accuracy;ml;end;computation;accuracy;quality;solutions;constraint;desirable region;sample efficiency"}, "bcd6cd7bdd661bd86c58b7251ae4633a6ba9979e": {"ta_keywords": "conference reviewing process;conference paper submissions;technical paper recommendation;suitable reviewers;actual reviewing preferences;reviewers;keywords;abstracts;papers;program committee members;web;interests;committee members;mining;long lists;home pages;current attempts;greatest interest;appropriate set;people;task;approach;background;variant;data;cases;general problem;problem", "pdf_keywords": ""}, "705794a57cca12c2e58b2d77ac32bd4f92ed31ab": {"ta_keywords": "crowdsourcing;readable thesaurus;russnet;russian;yarn;pilot user study;results;project;large open machine;objectives;paper;end", "pdf_keywords": ""}, "fd306df2809c7acc19dd1994e8ecb11caa33290d": {"ta_keywords": "personal adaptive communication environment;spatial;behaviors;knowledge;objects;operations", "pdf_keywords": ""}, "99e56ebc2f3739dfca93d5a92ebc1e6e2a3050d2": {"ta_keywords": "grading;student evaluation;massive open online courses;peergrading;students;graders;moocs;assignments;assessment;peer;dimensionality reduction;many topics;machine learning;instructors;teaching assistants;lower dimensional set;numbers;statistics;high error rates;practice;answers;systems;number;interest;large number;fundamental understanding;serious criticism;technology;result;approach", "pdf_keywords": ""}, "65b226f71faaac9b8a4d63445c85601a16635464": {"ta_keywords": "gradient descent;nonconvex optimization;convex optimization problems;sgd;scale machine learning;machine learning;saddle points;algorithms;dimension dependence;stochastic;performance;stationary points;gd;more recent theory;points;dimension;dependence;theory;workhorses;gap;analyses;methods;practice;order;classical theory;notable successes;account;versions;possibility;same time", "pdf_keywords": "nonconvex optimization problems;lipschitz stochastic gradient;global minima;stationary points;general stochastic setting;nonconvex problems;nonconvex problem;stochastic setting;sgd;simple local search approaches;dimension dependence;signal processing;order stationarity;machine learning;\u01eb2;global optima;ef\ufb01cient guarantees;dimensionality;gd;overheads;overhead;dimension;broad class;logarithmic factors;wide class;linear factor;suf\ufb01ciency;second;order;previous literature"}, "c6bb9e4a9eaa0f0f8309597af2cefe03bd3f1bb5": {"ta_keywords": "chaotic systems;chaotic dynamical systems;chaos;diverse dynamics;strange attractors;attractor;symbolic regression;modern statistical learning techniques;static time series;additional datasets;dataset;striking fractal geometry;model training;time series classi\ufb01cation;unique generative properties;generative nature;astro;granularity;feature analysis;benchmarks;surrogate transfer;concept experiments;systems;database;mathematical properties;unique challenge;quanti\ufb01able mathematical properties;information;arbitrary length;physics", "pdf_keywords": "chaotic systems;strange attractors;attractor;delay model;chaos;scroll attractor;dimensional convection;simple delay equation;modelling;sprott family;forecasting;striking fractal geometry;physics;system;generative nature;probability distributions;eco;bird;symmetric limi;data;interpretable benchmark;oden institute;abstract;member;information;\ufb01sh;horizontal lay;el;harvard university department;oct"}, "ede108538033ae00d1667685afbd488380020613": {"ta_keywords": "severe acute respiratory syndrome coronavirus;antiviral drugs;antibodies;other variants;variants;sars;cell culture infection;optimal drug treatment;variant emergence;casirivimab;assay;alpha;gamma;diverse sensitivities;imdevimab;analyses;insight;impact;delta;different efficacies;intrinsic sensitivity;concern;essential evidence;many countries;loss;response", "pdf_keywords": ""}, "f9f862f48599526147bbb110ba986ff6872ef4b0": {"ta_keywords": "indoor trajectories;movement uncertainty;mobile sensing data;lstm;approach", "pdf_keywords": ""}, "be0c64252a2c3071236d88feeab47d06ef6e0fb7": {"ta_keywords": "recipient recommendation systems;recipient recommendation;enron email corpus;email systems;corporate email collection;email clients;email client;recipients;multiple recipients;email server side;recipient;reranking scheme;classification;email headers;email;address book;email address;appropriate expertise;similar topic;network information;textual contents;features;important collaborator;organization;class;manager;types;best scheme;current contents;message", "pdf_keywords": ""}, "b661520bf0061b7d96ccf12016e351dd3a6ee780": {"ta_keywords": "importance weighting;realistic deep networks;deep learning;deep linear networks;deep neural networks;l2 regularization;importance weighting impacts models;batch normalization;sgd;many practical datasets;correct weighting effect;weight;models;separable data;dropout;wrong abstraction;successive epochs;training;recent theoretical results;impact;surprising finding;capacity;effect;agnostic solutions;work;practitioners", "pdf_keywords": "importance weighting;deep learning;deep networks;deep neural networks;unregularized neural networks;art attention;standard neural networks;gradient descent;simple convolutional networks;weighting;sgd;tasks;class imbalance;training;epochs;images;salient \ufb01ndings;loss function;models;architectures;datasets;transformer;surprising \ufb01nding;transfer;capacity misspeci\ufb01ed models;stochastic;\ufb01ndings;effect;signi\ufb01cant effect;effects"}, "2cd2df06d488565063e0600ff840d293be2eaf31": {"ta_keywords": "regret;play converge;other strategies;game;adaptive procedure;simple adaptive procedure;current play;players;matching;correlated equilibria;probabilities;probability;past;empirical distributions;measures;set;procedure", "pdf_keywords": "nash equilibria;adaptive procedure;play converge;simple adaptive procedures;simple adaptive procedure;correlated equilibria;equilibria;regret;other strategies;correlated equilibrium1;game;current play;matching;convex polytope;players;global convergence;measures;comparison;points;probabilities;set;by sergiu hart;\u017eseptember;procedures;general classes;empirical distributions;probability;past;other hand;procedure"}, "372657f609f5a95b378a1aad7b08deb9b9b510c0": {"ta_keywords": "reinforcement learning framework ampo;better policy optimization;continuous control benchmark tasks;reinforcement learning methods;model adaptation;simulated data;real data distributions;inaccurate model estimation;real data;feature distributions;sample efficiency;agent;model;data;novel model;potential distribution mismatch;dynamics model;maximization algorithm;degraded performance;integral probability;state;ipm;range;environment;return;gap;art performance;end;paper;terms", "pdf_keywords": "reinforcement learning framework ampo;better policy optimization;policy optimization;unsupervised model adaptation;model adaptation;reinforcement learning methods;reinforcement learning;model adaptation procedure;continuous control benchmark tasks;ampo;adaptation;simulated data;inaccurate model estimation;agent;novel model;model;feature distributions;real data;dynamics model;ipm;real data distributions;mbpo;data;maximization algorithm;rockyshen;environment;mfrl methods;concepts;state;art mbrl"}, "a0511f02a867bf19e2fa01e6cbd3663f4bd1b953": {"ta_keywords": "causal relationships;book review;michael pazzani;memory", "pdf_keywords": ""}, "1ae1850bcfa3c31d7bc828cc33f7dd3926cee26f": {"ta_keywords": "tac knowledge base population entity discovery;entity linking;entity discovery;linking;probabilistic logics;discovery systems;similarity;language text;data resources;relations;graphs;edl;tale;walk strategies;track;term research agenda;systems;group;pursuit;goal;scale problems;potential", "pdf_keywords": ""}, "30cf652bd33049aaf111a5f84eb262a87c045bdb": {"ta_keywords": "text similarity;document sentences;corresponding evidence;veracity;human fact;several strong baselines;document;suitable evaluation measures;fact;journalists;rank approach;claims;checkers;dataset;stance;task;list;learning;regulatory authorities;analysis;importance;research;sizable performance gains;media;output;such support;system;interest;account", "pdf_keywords": "debates;sentences;manual fact;veri\ufb01ed claim pairs;veracity;human fact;text similarity;false claims;task formulation;claims;suitable evaluation measures;fact;task;sentence;document;checkers;new dataset;effort;dataset;stance;analysis;target veri\ufb01ed;qatar computing research institute;lot;abstract;sshaar;falam;padova;importance;qatar"}, "31412f9b23511e212895305927d9ccddb445bcbc": {"ta_keywords": "statistical voice timbre control;voice timbre control parameters;converted voice timbre controllability;voice timbre;converted voice timbre;multiple voice timbre expression words;acoustic basis vectors;voice timbre expression word;gaussian mixture models;voices;natural voices;individual control parameters;control parameters;perceptual scores;regression;gmm;control;annotation;several axes;mr;axes;development;method;independences;experimental results;investigation", "pdf_keywords": ""}, "633ee881c594cface387557359ef13613d8eaef0": {"ta_keywords": "random assignment mechanisms;different random assignment mechanisms;prominent random assignment mechanisms;optimal egalitarian value;achievable egalitarian value;egalitarian welfare;random serial dictatorship;unrestricted cardinal utilities;probabilistic serial mechanism;utility functions;envy;efficiency;freeness;ordinality;agents;tradeoffs;distributions;properties;objects;truthfulness;oev;different classes;detailed experiments;bounds;effect", "pdf_keywords": ""}, "1ccd031f28dccfb226f6c0c588c93a97a50bf95f": {"ta_keywords": "automatic code generation;code generation performance;code generation;large language models;arbitrary natural language specification;satisfactory python code;programming;code;benchmark;machine learning models;benchmark measures;gpt;art machine learning models;recent models;apps;github;neo;syntax errors;models;challenge;introductory problems;rigorous manner;applicable skills;test cases;training set;years;advancements;tune;ability;prior work", "pdf_keywords": "upstream program synthesis advancements;code generation;apps benchmark;copyright;large language models;apps;benchmark;python programming problems;github;infringement;apps dataset;generative models;overall performance;fair use;judging functionality;models;such use;art;syntax errors;original problems;testing framework;substantiality;nonpro\ufb01t educational purposes;challenge;several websites;cases;use;commercial nature;research;\ufb01ne"}, "ac5e7f9bbc5d46bebc4ec5616aba9d014a6d237f": {"ta_keywords": "science fiction reviews;undergraduate computer science curriculum;research reviews;technical papers;science fiction book;research literature;topic;students;much research;most students;tools;recent research;movie;tv show;gateway;imagination;field;skills", "pdf_keywords": ""}, "615b823d1fc9548ce384f1bb4f544445175e8537": {"ta_keywords": "pea starch;gelatinization;alcohol solution;rheological properties;pasting", "pdf_keywords": ""}, "556a4a0b5fcda4d9f9fad637f2655aeb1b1a00b2": {"ta_keywords": "paralinguistic information;speech translation;many different possible paralinguistic features;output speech;input speech;digit translation task;target language speakers;speech;emphasis;duration;translation;features;information;power;continuous space;method;paper;first step", "pdf_keywords": ""}, "d6fc0fcf0764065f6e58c57ca850abfdd918504b": {"ta_keywords": "linear scoring model;minimum error rate training;intersentence features;features;qa4mre;score;threshold;document;candidate answer;questions;certainty;mert;criterion;weights;input;log;clef;paper;model;main task;nara institute;technology;system;science;novel method;question;core;addition", "pdf_keywords": ""}, "7de4a82edf68b69a9c007fe8e840edf4ade1171c": {"ta_keywords": "ficin;sulphydryl enzyme;enzymic action;arginine derivatives;acetylation;free arnino;kinetics;stability;optimal conditions;activity;further characterization;groups;properties;general attributes;work;effect;literature", "pdf_keywords": ""}, "2cae732250b59f9e2238626d8d7e0064b97de3c9": {"ta_keywords": "signal reconstruction;signal reconstruction problem;wavelet transform domain;image representation;edge intensity;norm optimization problem;early vision;threshold operation;iterative algorithm;salient feature;representation;extension;solution;dimensional case;linear simultaneous equation;information;amount", "pdf_keywords": ""}, "616c15dd765c36c21efc75c7ed52e5af81c21053": {"ta_keywords": "ai technologies;ai;acm sigai;funding proposals;artificial intelligence;strong outreach component;researchers;students;public;practitioners;activities", "pdf_keywords": ""}, "bf9b069242f0af129c2aad8430a52454b008c327": {"ta_keywords": "stochastic gradient langevin dynamics;stochastic gradient descent;gradient descent;learning rate;linear convergence rate;nonconvex optimization;sgd;optimal linear rate;schrodinger operator;laplacian;dependent stochastic differential equation;dependent sde;nonconvex functions;rate decay;convex functions;learning;linear rate;convex problems;nonconvex;time formulation;convergence;objective functions;witten;rate;spectrum;surrogate;general theoretical analysis;lr;analysis;broad class", "pdf_keywords": "stochastic gradient langevin dynamics;learning rates;gradient descent;learning rate;linear convergence rate;optimal linear rate;sgd;stochastic;dependent stochastic di\ufb00erential equation;laplacian;nonconvex functions;dependent sde;convex functions;learning;optimization;linear rate;neural networks;objective functions;nonconvex;convergence;rate;time formulation;training;spectrum;witten;surrogate;lr;important parameter;broad class;analysis"}, "250f8f71f7cff972a70482229ca9053b356217cd": {"ta_keywords": "online unsupervised voice activity detection;online voice activity detection;online variational bayes method;variational bayes framework;online model comparison;unsupervised context;vad;noise;vad decision;models;signal situation;solid statistical scheme;model;parallel;use;only situation;paper;scheme;study;goal", "pdf_keywords": ""}, "3d2ceea5dea234ae9a20f8e1c9e558735757e90e": {"ta_keywords": "multilingual acoustic models;multilingual allophone system;universal phone recognition;multilingual asr experiments;speech recognition;dependent phoneme distributions;phone accuracy improvements;phonemes;corresponding phones;phone inventories;indigenous languages;dependent recognizers;languages;independent phones;independent phone;recognizer;particular language;language;lexical contrasts;model;resource conditions;testing performance;database;inuktitut;joint model;sounds;phoible;tusom;difference;experiments", "pdf_keywords": "multilingual acoustic modeling;multilingual recognition;phonetic annotation;phoneticians;multilingual model;standard phonemic transcriptions;dependent phoneme distributions;allophone system;allophone list;phoneme distribution;phonemes;phonology;allophone layer;universal speech;phoneme;phone distribution;transcription;independent phone;universal narrow phone set;standard asr encoder;language;automatic recognition;phone mismatch;allosaurus;model;accuracy;model \ufb01rst;resource conditions;joint model;knowledge"}, "8234049255a0e03fc745457de456634d1aab214b": {"ta_keywords": "web page classification;web pages;discovering structure;hyperlinks;pages;html;web page;entity extraction;classification;page;web;learning;structure;collaborative filtering;entities;wrapper;information;format;techniques;machines;music;commands;sort;tasks;ways;active research area", "pdf_keywords": ""}, "e11b4750e288785134f042c144f057a11dc0180a": {"ta_keywords": "flexible representative democracy;interactive democracy;representative democracy;direct democracy;various democratic systems;majority voting;representatives;representative;voters;full participation;issues;binary issues;outcomes;system;computational approach;dependent weights;issue;dd;novel hybrid;set;rd;introduction;frd;model;literature;line;degree;ideal baseline", "pdf_keywords": "flexible representative democracy;scale representative democracy;representative democracy;majority voting;proxy voting;various democratic systems;direct democracy;representatives;voters;voter participation increases;speci\ufb01c delegations;committees;symmetric issues;hardness results;binary issues;issues;decision;outcomes;dependent weights;empirical results;limitations;variants;issue;optimal set;computational approach;results;nick mattei;rd;novel hybrid;abstract"}, "b8b813111c411ae61881ab9cd25707d9de6444ec": {"ta_keywords": "value attention;compositional attention;value attention blocks;standard attention heads;attention mechanism;retrieval;novel attention mechanism;disentangling search;certain tasks;key combination;relevant features;key interactions;search;selection;relevant entity;pairing;redundant parameters;query;entity;heads;hinder generalization;independent scaling;standard head structure;value;value matrix;context;fundamental computations;learning;lead;dependent manner", "pdf_keywords": "compositional attention;value attention;standard attention heads;attention mechanisms;retrieval;disentangling search;dynamic specialization;tasks;search;machine learning models;independent scaling;variety;successful transformer model;key combination;dependent manner;context;variants;mechanism;type;network;backbone;query;additional soft competition stage;integral parts;value;conference paper;abstract;sharath chandra raparthy;irina rish;lieu"}, "a469f2ec3ab15f20f06d95aea1839b1263d3385e": {"ta_keywords": "random assignment mechanisms;different random assignment mechanisms;prominent random assignment mechanisms;optimal egalitarian value;achievable egalitarian value;egalitarian welfare aspects;random serial dictatorship;probabilistic serial mechanism;unrestricted cardinal utilities;utility functions;envy;efficiency;freeness;ordinality;tradeoffs;agents;distributions;properties;objects;truthfulness;different classes;detailed experiments;bounds;effect", "pdf_keywords": "prominent random assignment mechanisms;randomized mechanisms;assignment mechanisms;utility functions;probabilistic serial mechanism;utilitarian welfare;envy;random serial dictatorship;nash equilibria;assignment problem;exponential utilities;fairness;ef\ufb01ciency;rsd;freeness;tradeoffs;borda utilities;average ratios;distributions;truthfulness;different classes;par;detailed experiments;results;ps;introduction"}, "18f4ec53a4221a97e1482f091f41a23f3d873cf2": {"ta_keywords": "evidence annotations;evidence extraction;few evidence annotations;weak supervision;evidence;many prediction tasks;stakeholders;training examples;abundant document;level labels;predictions;task;correctness;new methods;paper;minority;human;practice", "pdf_keywords": "evidence sequence labeling tasks;evidence annotations;few evidence annotations;evidence extraction;annotations;generating evidence;weak supervision;text classi\ufb01cation;predicted label;classi\ufb01cation tasks;evidence;label;classify;supervision;level labels;interpretability literature;abundant document;predictions;baselines;task;models;multiple classes;input;new methods;methods;paper;improved performance;framework;characteristics;problem"}, "c4536a5c7f47bfc48df202ba882002531248f955": {"ta_keywords": "automatic fundamental frequency control;physical electrolarynx;enhanced electrolarynx;electrolarynx;laryngectomees;electrolaryngeal;statistical prediction;fundamental frequency patterns;statistical prediction model;fundamental frequency;el speech;control method;excitation;speech;prototype system;more natural excitation;el;aid device;method;performance;sounds;type;time;paper", "pdf_keywords": ""}, "f43ae70242aea3dbb80b7c3b5474356e9ee9079b": {"ta_keywords": "meaning representation;amr;semantic graph;natural language;multilingual natural language processing;meaning;computational typology;sentence;popular formalism;recent developments", "pdf_keywords": ""}, "72c9663494827b2e87ad5a65a6ff7e769eb15a57": {"ta_keywords": "visual storytelling dataset;human evaluation demonstrate;coherent story;story;expressiveness;reward functions;art baselines;quality;relevance;quality criteria;good story;rl model;reinforcement learning framework;rl;reco;coherence;human eye;end;assessment criteria;vist;empirical analysis;new criteria;traditional metrics;essence;experiments;better performance;paper;different angle;problem;state", "pdf_keywords": "story generation quality;visual storytelling dataset;visual storytelling;text generation;human evaluation demonstrate;reinforcement learning framework;policy gradient;recorl;quality;composite rewards;expressiveness;automatic metrics;art baselines;rl;reco;training;rl model;relevance;task;conclusion;art methods;assessment criteria;vist;human eye;better performance;novel approach;coherence;model;criteria;traditional metrics"}, "15bb07d0996ece844de8cae24d3dc15972e6841a": {"ta_keywords": "summarization datasets;popular summarization datasets;summarization complexity;art summarization systems;art summarization models;automatic metrics;popular metrics;faithful summaries;massive datasets;datasets;distinct data quality;thorough analysis;key insights;references;system performance;data noise;reliability;poor diversity;low scores;complexity distributions;samples;collection process;web;study;rouge;prevalence;characteristics;state", "pdf_keywords": "popular summarization datasets;summarization models;art summarization models;automatic metrics;metric performance;popular metrics;metrics;distinct data quality;popular datasets;thorough analysis;datasets;complexity;complexity distributions;sample complexity;key insights;data quality issues;performance;modelcentric evaluation;analysis;system performance;cnn;reliability;conclusion;xsum;typology;models;samples;study;sample;collection process"}, "674833d48a77ef009f751a66988590592dd5d996": {"ta_keywords": "\u4e00\u822c", "pdf_keywords": ""}, "49ee2270f3265ee27b36e05e130be79e05d5ba29": {"ta_keywords": "textbook knowledge;natural language understanding;logical theory;textbooks;texts;inconsistencies;machine learning;omissions;text;illustrative examples;case study;simplification;grand challenges;problem;problems;paper", "pdf_keywords": ""}, "68ea2572584068befd441dccf461f3444ff14f4a": {"ta_keywords": "like learning agent;educational robot;cognitive robot;simstudent robot;intelligent agent;physical agent;skill knowledge;agent;student learning;simstudent;toe game;education;knowledge;students;human;games;physical world;learning sciences;calliope5kp;abilities;humans;significant achievement;essential goal;understanding;integration;users", "pdf_keywords": ""}, "4cfc7d3c6a61f6db48b1f3c75235592c1609a54f": {"ta_keywords": "assisted transcription quality;scratch transcription interface;automatic transcription quality;quality speech transcription;automatic transcription;transcription;iterative user interfaces;iterative interfaces;interface;interface design;human effort;considerable quality gains;computer;similar quality;user study;effects models;many errors;difficulty;costs;variations;analysis;parts;segment;other factors;conclusions;circumstance", "pdf_keywords": ""}, "e2ac96254d7e9ec0dde882e3a09797d00f26220f": {"ta_keywords": "machine learning;icml;third international conference;usa;june;pennsylvania;pittsburgh;proceedings;twenty", "pdf_keywords": ""}, "757acf616a38422c7186952e1075a28fed1a07c0": {"ta_keywords": "methods fetal rat nerve cells;fetal rat nerve cells;xylazine;xylazole;veterinary anesthetic;cgmp pathway;anesthetic mechanism;analgesic effects;amino acid neurotransmitters;background xylazole;nerve cells;nitric oxide;xyl;cgmp;cyclic gmp;pathway;inhibition;atpase;findings;conclusions;new evidence;days;aants;study;variations", "pdf_keywords": ""}, "fc912e9af47bf10428396b687b2bfb1e5832fcb1": {"ta_keywords": "speech recognition;automatic speech recognition;connectionist temporal classification;efficient auxiliary loss function;ctc encoder network;intermediate loss regularization;intermediate ctc loss;ctc training;wsj corpus;word error rate;ctc;language model;various corpora;character error rate;asr;greedy search;cer;training;intermediate layer;code;wer;performance;overhead;small modification;method;inference;objective", "pdf_keywords": "automatic speech recognition;speech recognition jaesong lee1;intermediate loss regularization;autoregressive decoder;ef\ufb01cient auxiliary loss function;external language model;intermediate ctc loss;wsj corpus;stochastic depth training;ctc encoder network;word error rate;language model;character error rate;art asr systems;various corpora;asr;ctc;connectionist temporal classi\ufb01cation;loss;greedy search;cer;stochastic depth;transformer;conformer network;beam search;training;wer;shinji watanabe2;conformer architectures;intermediate layer"}, "f3132572bb3870dbe99b2d1c01ce17fa38783a2f": {"ta_keywords": "robust speech processing;uncertainty propagation;observation uncertainty;session;paper overview", "pdf_keywords": ""}, "213e471bacff5c0852943988fcb955797f1e591f": {"ta_keywords": "reference translations;machine translation;translationese language;automatic metrics;translation;standard references;typical references;human evaluation;references;linguists;evaluation;metrics;english;german;human judgment;bleu;quality;bias;quality systems;poor diversity;mt output;high quality output;ape;wmt;task;submissions;value;systems;higher correlation;low correlation", "pdf_keywords": "machine translation;automatic metrics;human evaluation;translationese artifacts;translation;standard references;evaluation;metrics;references;multi reference bleu;isaac caswell google research;quality;human judgment;mt output;baselines;more natural output;quality systems;top submissions;wmt;bt;high quality output;ape;submissions;bleu;value;stronger correlation;systems;cl;david grangier;higher correlation"}, "77568c594470f9aa029f92774e2c12ab0451d9bb": {"ta_keywords": "language models;training distribution;priori unknown target distribution;topics;mle;potential test distributions;test distribution;standard maximum likelihood;robust optimization;case mixture;text;news;restaurant reviews;test performance;knowledge;training;reviews;model;fiction;paper;dro;loss;procedure;data;sufficient overlap;wide range;approach", "pdf_keywords": "distributionally robust language modeling;language models;language modeling;standard maximum likelihood training;corpus;training distribution;priori unknown target distribution;topic cvar;mle;topics;standard maximum likelihood;test distribution;common sentences;1stanford computer science 2stanford statistics;robust optimization;restaurant reviews;heterogeneous dataset;challenges;test performance;model;literature;text;news;cvar;risk;reviews;case subpopulation;subpopulations;case mixture;conditional value"}, "89c64fd60ca58f4753a818cd0923f5041b51a807": {"ta_keywords": "wireless relay network;network cost objective;multihop network;possible alternate routing;relay;multiple available paths;relays;link quality measurements;forest trail;potential placement points;forest;sink interconnection;sensor;optimal policy;numerical study;line;deployment;sink;objective;such location;point;disadvantages;advantages;order;insights;structural results;like environment;paper;idealisation;start", "pdf_keywords": ""}, "612d577534dbbf546405d4036d912666523a8164": {"ta_keywords": "description logics;simple description logic;learnable sublanguage;learnability;polynomial learnability;terminological logics;syntactic restrictions;predicate calculus;enable tractable learning;order logics;expressive power;order logic;type languages;examples;few formal results;concepts;vocabulary;positive examples;different syntax;order representations;kl;subsets;subset;size;different set;results;paper;amount;experimental research", "pdf_keywords": ""}, "0d516b476559485e04290e859ca59101c0a91ae1": {"ta_keywords": "relay exploration;local relay selection;observable markov decision process;millimeter wave d2d communication;average exploration time;additional exploration time units;relay;stationary threshold policy;dynamic obstacles;millimeter wave;mmwave;new relay;obstacles;d2d link qualities;extensive simulation;finite horizon;pomdp;severe penetration losses;switching;uncertainty;vicinity;delay;end delay;d2d;few milliseconds;tradeoff;blockage;communication;potential user equipments;seconds", "pdf_keywords": "relay exploration;local relay selection;millimeter wave d2d communication;millimeter wave;average exploration time;additional exploration time units;relay;mmwave;optimal threshold policy;stationary threshold policy;dynamic obstacles;new relay;obstacles;severe penetration losses;delay;extensive simulation;few milliseconds;blockage;end delay;vicinity;switching;communication;successive acknowledgment successes;tradeoff;beam alignment;seconds;d2d;potential user equipments;e2e;ues"}, "99fe5475ab28fa7ad4bce51d7b294b3f40caad4d": {"ta_keywords": "concept learning;features;web", "pdf_keywords": ""}, "31392ad8722d9c66181b621936e2013199e02edc": {"ta_keywords": "language model knowledge probing;language understanding;nlu tasks;typical downstream nlu tasks;linguistic features;classifier probing;enough commonsense knowledge;skills;knowledge;exact knowledge;model ability;other skills;lms;semantic features;transformer lms;scale pretraining;models;information;relative acceptability judgments;ability;theoretic probing;recent improvements;1b words;data;evaluation;tuning;less data;roberta models;results;data volume", "pdf_keywords": "human language understanding;nlu tasks;nlu task performance;linguistic ability;linguistic knowledge;linguistic features;downstream nlu tasks;classi\ufb01er probing;words;1b words;skills;theoretic probing;lms;large data scales;more data;information;data;roberta models;billions;tuning;transformer lms;results;robertabase;relative acceptability judgment;roberta;extent;main \ufb01ndings;different measures;variety;data volume"}, "6c82727731955a2332a0cc38ec56b35a971061eb": {"ta_keywords": "extensible neural machine translation toolkit;machine translation;source nmt toolkits;xnmt;modular code design;speech recognition;fast iteration;experiment configuration system;tasks;utility;reliable results;focus;purpose;design;paper;research", "pdf_keywords": "extensible neural machine translation toolkit;machine translation task;machine translation;nmt toolkit;nmt system;xnmt;parsing;nmt design dimensions;speech recognition;sequence model;toolkit;tasks;model structure;model;training;sequence;extensibility;utility;design;level design decisions;mind;speci\ufb01cation;goal;inference;experiment con\ufb01guration system;various design decisions;ease;paper;use;practical research settings"}, "7e406537f52528527d10872d1807ad974599b13a": {"ta_keywords": "efficient neural machine translation;neural generation;computational linguistics;translation;many possible translations;level generation;language;text;summaries;fourth workshop;document;nmt;structured data;tasks;nmt systems;creation;results;annual conference;staple task;input text;findings;papers;dgt;proceedings;participants;assistance;acl;systems;concert;finding", "pdf_keywords": ""}, "5babe5334c6867db13fa7e6943f64059c7cba6ce": {"ta_keywords": "information representation language;word;whirl", "pdf_keywords": ""}, "c0cce8955bf10b21753161ffaa1978a7c8b78a16": {"ta_keywords": "nam microphone;statistical voice conversion;conductive microphone;silent speech communication;audible murmur;conductive microphones;soft whispered voice;nam enhancement;quiet environments;noise;external noises;noisy environments;conductive recording;statistical conversion;several enhancement methods;vc models;nam;dependent vc models;faint volume;vc;air;spectral changes;quality;techniques;performance;promising medium;special body;effectiveness;body;possibility", "pdf_keywords": ""}, "6027ef3b4e5585b45db0b9d333956425d3972351": {"ta_keywords": "several popular commonsense reasoning benchmarks;current commonsense reasoning research;commonsense reasoning research;commonsense reasoning;commonsense knowledge;commonsense facts;commonsense question;candidate answers;natural language;multiple new answers;choice questions;opencsr;knowledge facts;opencsr methods;small list;strong baseline methods;corpus;choices;crowd;resource;sourcing;drfact;models;task;large margin;experiments;approach;step;efficient differentiable model;test question", "pdf_keywords": "current commonsense reasoning research;commonsense reasoning;commonsense knowledge;knowledge corpus;commonsense;reasoner;reasoning process;knowledge facts;opencsr;naacl;corpus;multiple answers;opencsr versions;facts;fact;hypergraph;symbolic links;google research;haitian sun2;datasets;choice questions;list;sparse tensors;task;manzil zaheer2;drfact;collection;models;matrix computation;combination"}, "a38e0f993e4805ba8a9beae4c275c91ffcec01df": {"ta_keywords": "program synthesis;large language models;general purpose programming languages;programming tasks;short python programs;natural language descriptions;level programmers;python;program execution;semantic grounding;python version;new benchmarks;code;dialog;basic programming problems;benchmarks;more complex text;mathqa benchmark;human feedback;models;current generation;python dataset;such models;shot;dataset;model;results;entry;ability;137b parameters", "pdf_keywords": "neural code completion;large transformer language models;general purpose programming languages;program execution;short programs;python;code;new benchmarks;semantic grounding;poisoning vulnerabilities;mathqa benchmark;synthesis;python version;models;such models;more complex text;results;tuning regimes;python dataset;ability;\ufb01ne;mathqa;137b parameters;shot;problems;collection;paper;mbpp"}, "4f4da6fdb9496b0295764b2db11381dd390de02d": {"ta_keywords": "speech transcripts;sensitive manual correction;sensitive correction;transcription process;transcriber enrollment;segmentation;cost;faster algorithm;fly updates;segments;models;human effort;fly updating framework;minimizes;baseline method;previous work;framework;sensitive fashion;fly user", "pdf_keywords": ""}, "c581686edbd7227e9eb4a0841cce16728ca27369": {"ta_keywords": "multimodal comprehension;instructional recipes;recipes;cooking recipes;reasoning tasks;recipeqa;comprehension;procedural knowledge;procedural text;descriptions;text;images;challenge dataset;joint understanding;understanding;machines;events;dataset;answer pairs;fruitful research direction;temporal flow;titles;sense;multiple modalities;set;question;work", "pdf_keywords": "multimodal comprehension;machine comprehension systems;instructional recipes;reasoning tasks;cooking recipes;recipes;comprehension;procedural knowledge;recipeqa;procedural text;descriptions;cinbis hacettepe university computer vision lab;understanding;joint understanding;images;challenge dataset;text;machines;events;fruitful research direction;dataset;titles;sense;aykut erdem;challenging test bed;answer pairs;turkey;erkut erdem;nazli ikizler;temporal \ufb02ow"}, "ad48174ccbff6259a7d3cb0d0985e5aefa314b84": {"ta_keywords": "level machine translation;machine translation;translation quality;subword systems;level modeling;level systems;wmt competitions;character;robustness;competitive setups;literature;mt;empirical survey;beam size;source side noise;art;time;people;evidence;state", "pdf_keywords": "level machine translation;characterlevel natural language processing;machine translation;level modeling;speech processing;subword;level mt;character;recent modeling innovations;mt systems;jindr\u02c7ich libovick\u00fd1;literature;mt;prague;lmu munich;charles univeristy;mathematics;empirical survey;czech republic;physics;cl;faculty;counterparts;paper;information;abstract;alexander fraser2;people;helmut schmid2;art"}, "1e3e2b03e28f48bb4d48154992cd6b62969c643e": {"ta_keywords": "value protein sequence database;annotated sequence entries;protein;annotations;prot;other databases;wide web;species;swiss;domain structure;world;challenges;description;variants;future;high level;popular one;integration;many different distribution media;talks;users;redundancy;minimal level;function", "pdf_keywords": ""}, "7b51209e7d9cbedc18b6ab202e6fcdabaebbb088": {"ta_keywords": "discriminative language modeling;product feature representation;continuous space model;neural network;embeddings;structured classification problem;linear models;features;lower word error rate;convolutional layers;alone model;log;compact parameterization;word;standard dot;paper;use;problem;experimental results", "pdf_keywords": ""}, "795aca47df94300fa6bfd464e6873aef56c7f3ae": {"ta_keywords": "large lexical semantic resources;recurrent extraction tasks;babelnet extract;multilingual babelnet;natural language processing;wordnet;babelnet;semantic relations;semantic network;effective extraction;synsets;individual word senses;open source tool;omegawiki;wiktionary;evaluation;tool;evaluation experiments;output format;samples;training purposes;construction;manner;use cases;architecture;paper;scale", "pdf_keywords": ""}, "4cd66273298128dfb5be290e891870085ecfc455": {"ta_keywords": "end speech recognition;automatic speech recognition;attention architecture;connectionist temporal classification;hmm systems;end asr;conventional dnn;end architectures;attention;attention mechanism;ctc;hybrid ctc;acoustic frames;asr;joint ctc;end;pronunciation dictionary;linguistic resources;tokenization;dependency trees;sequential problems;dynamic programming;markov assumptions;context;building process;alignment;algorithm;symbols;simplified model;need", "pdf_keywords": ""}, "7099d5a4b2d4ed47905071fc23aff08580401e42": {"ta_keywords": "echo state speech recognition;recurrent neural networks;echo state network;automatic speech recognition;rnn;asr models;efficient training;decoder;models;trainable counterparts;layers;esn;conformer models;model quality;asr;storage;components;subset;common practice;study", "pdf_keywords": "rnn layers;recurrent neural networks;echo state speech recognition;rnn;speech recognition;automatic speech recognition;echo state network;popular speech models;asr models;encoders;esn layers;acoustic inputs;asr tasks;esn;proper representations;decoder;recurrent;state network;input weight matrices;models;layers;asr;conformer models;model quality;sequential signals;excellent ability;special type;paper;contrast;abstract"}, "af460a6b3ecaddd4015b34255564c366ecfef802": {"ta_keywords": "computer ethics;moral imagination;science fiction;students;capacity;way", "pdf_keywords": ""}, "5861dbfcb253ca02067dd182d42b7d567433c834": {"ta_keywords": "frontdoor estimators;confounders;causal model;causal effect;causal graph;estimators;frontdoor formula;observed mediator;backdoor formula;estimator;observational joint distribution;mediators;optimal estimator;backdoor;treatment effects;statistical properties;variables;example;linear gaussian;functionals;scenario;model parameters;sample variance;unbounded constant factor;paper;calculus", "pdf_keywords": "frontdoor estimators;causal inference;linear causal model;causal model;confounders;estimators;econometrics;model assumptions;backdoor graph;optimal estimator;estimator;observed variables;backdoor;semiparametric setting;mediators;analysis;linear gaussian;unbounded constant factor;applicability;lower mse;experiments;methods;study;graph;paper;scenario;improvement;gains;sample variance;wright"}, "0f655f0e1937ad19b038952e2df69e30d447aac8": {"ta_keywords": "missingness patterns;recurrent neural networks;missingness;imputation;clinical time series;diagnoses;training models;multivariate time series;multilabel classification;sequential inputs;pediatric intensive care unit;data;linear models;superior predictive performance;hospital los angeles;features;diseases;simple binary indicators;children;observations;results;tests;task;picu;signal;artifacts;simple strategy;alternative strategy;improvement", "pdf_keywords": ""}, "4857e0e3d720b87b4523a6435cc166bcb7ae328a": {"ta_keywords": "neural machine translation;2nd workshop;generation;proceedings", "pdf_keywords": ""}, "8ff620f704a4151fd7abba1db792463fbd32bfe5": {"ta_keywords": "long document summarization;abstractive summarizer bart;salient sentences;several competitive salience detection baselines;pretrained language models;long documents;long legal briefs;average source document length;independent human labeling;documents;document;summary;words;novel algorithm;data scarcity;source;low resource regime;low resource setting;bart;paper;domain experts;resource setting;pairs;rouge;method", "pdf_keywords": "long document summarization task;abstractive summarizer bart;salient sentences;extractive summary;bart abstractive summarizer;language model perplexity scores;sentence saliency classi\ufb01er;several competitive salience detection baselines;long document;long documents;source sentences;sentence salience;average source document length;long legal briefs;resource;more resource;training data;complex legal briefs;salience;extractive model;document;summary;low resource regime;ground summary;low resource setting;gpt2;words;data scarcity;source;resource setting"}, "baf34ac4080a365a7cec30b6877fa1a018eb31cf": {"ta_keywords": "larger answer generation models;downstream question answering;multiple distinct answers;retrieval;better answer coverage;joint passage ranking;autoregressive reranker;fewer passages;same answer;jpr;task;passages;different valid answer;models;prior approaches;joint probability;joint modeling;sequence;novel training;question;algorithms;new state;use;problem;cost;art", "pdf_keywords": "joint passage retrieval model;\ufb01rst joint passage retrieval model;retrieval recall;decoder reranker;autoregressive reranker;downstream qa accuracy;diversity;new answers;jpr;passages;encoder;passage;passage references;tree;sequence;new training;probability;algorithms;dependencies;algorithm;use;paper;new state;timestep;degree;function;art;\ufb02exibility"}, "f4465442a9b850a2c5b71a63fff0d24396b15f2c": {"ta_keywords": "gradient descent ascent;finite timescale separation;local convergence analysis", "pdf_keywords": ""}, "7fb1262d4484732c8f7295fa5fb5e6ed6eabb6a0": {"ta_keywords": "energy market models;energy market simulations;zonal energy markets;electricity markets;market simulation;locational marginal pricing;ancillary services markets;simulation methodologies;modeling formulation;prices;full transmission representation;energy;detailed transmission representation;modeling;lmp;practical implementation considerations;network;europe;various applications;inclusion;methodology;nodal;certain other simplifications;case;exclusion;united states;factors;paper;insights", "pdf_keywords": ""}, "9f208842f70503e8b71fd4c34ba682dcd0ea4788": {"ta_keywords": "adaptive incentive design;design incentives;incentives;agent problems;multiple agents;strategic decision makers;adverse selection;agents;principal;utility functions;optimization techniques;control;objective;algorithm;decision;interaction;processes;process;data;response", "pdf_keywords": "adaptive incentive design;incentive mapping;incentive design step;planner;incentives;agents;utility functions;utility;algorithm;desirable response;process;processes;response converges;decision;noisy cases;new method;step;noise;response;illustrative examples;value;value vd;conclusion;convergence results;unknown type;perspective;converges"}, "f136a0fdc2065485c83396ae41d431395de51af4": {"ta_keywords": "recruiting reviewers;tier machine learning conference;ai conferences;qualified reviewers;conference peer review;reviewers;icml reviewers;large conferences;reviewer experiment;major conferences;submissions;review process;best submissions;others;performance;whole research area;pipeline;computation process;ideas;icml;pool;novice;acceptance;procedure;future;general population;small set;population;number;ii", "pdf_keywords": "conference peer review;reviewer pool;traditional reviewer pool;reviewers;tier machine learning conference;reviewer experiment;new reviewers;quali\ufb01ed reviewers;icml reviewers;experimental reviewer;review process;large conferences;reviews;conference;best submissions;neurips reviewers;recruiting;program committee;performance;results;others;superior quality;whole research area;insights;meta;computer science;quality;computation process;acceptance;senior members"}, "b24e2c3983c3207b1c7124c48d691cf459a3197b": {"ta_keywords": "approximate bayesian inferences;practical bayesian inference methods;bayesian machine;hidden markov models;gaussian mixture models;latent topic models;gram models;automatic speech recognition;statistical models;information retrieval;mcmc approximations;language processing;speaker verification;speech;information systems;detailed examples;straightforward applications;techniques;applications;comprehensive guide;performance;case studies;full derivations;formulas;calculations;useful notations;vb;evidence;map;various problems", "pdf_keywords": ""}, "0c0d9ecde0efead75e15353ac6c179c4fc22bdda": {"ta_keywords": "local nash equilibria;differential nash equilibria;continuous games;such equilibria;strategies;characterization;order conditions;sufficient condition;unified framework", "pdf_keywords": "differential nash equilibria;local nash equilibria;continuous games;competitive environments;such equilibria;different equilibrium behavior;nearby game;games;agent behavior;inverse modeling;characterization;measurement noise;property;contrast;computation;tractable tools;design;suf\ufb01cient condition;errors;rise"}, "e8b026b36d8be73ed428f7e4e55c26b27c34a544": {"ta_keywords": "bifunctional electrochemical sensor;therapeutic drug monitoring;simultaneous determination;effective platform;universal", "pdf_keywords": ""}, "f20d7185c47ce55cdcd9b839ef6fce595baba029": {"ta_keywords": "speech;15th international conference;computer;proceedings;volume", "pdf_keywords": ""}, "3ebed41fa35e5902b692a3e380c7c9a035c04426": {"ta_keywords": "ai ethics;modern ai research;ai researchers;ai;science fiction;machines;ethical questions;modern military;advanced visualizations;political implications;advanced control systems;mechanized workforce;appropriate tool;students;potential impacts;world;image processing techniques;concern;current state;things;slow creep;use;public", "pdf_keywords": ""}, "6b02fe6e0f6b2120a08e098513511e15a05f9073": {"ta_keywords": "dataset shifts;dataset shift;shift malignancy;classifiers;several datasets;shifts;shift;ml systems;dimensionality reduction;label distributions;data;empirical study;warnings;software systems;testing;approaches;covariates;unexpected inputs;methods;sample;exemplars;magnitudes;domain;approach;paper;various perturbations;fractions;problem", "pdf_keywords": "dataset shifts;shift malignancy;dataset shift;comparable shift detection performance;shifts;shift;soft predictions;distribution shift;box shift detection;machine learning;several datasets;ml systems;label distributions;malignancy;univariate tests;dimensionality reduction;surprising insights;latent dimension;predictions;data;testing;critical stumbling block;type;wide variety;characterization;sample tests;underlying assumptions;approaches;classi\ufb01ers;covariates"}, "3483d04a89dd69afd7b1393eadd8e8e4c5376d59": {"ta_keywords": "unsupervised conceptual clustering algorithm;period disambiguation system;classification;classification accuracy;hierarchical clustering;enhance classification accuracy;greek financial newspapers;brown corpus;cobweb;articles;accuracy;collection;modifications;new approach;approach;efficiency;order", "pdf_keywords": ""}, "b1a8c6de4fbfe485c8f1c7723404467b72788ff2": {"ta_keywords": "medical decisionmaking;deep learning;rnns;healthcare;clinical time series data;machine learnings;machine learning;impressive results concern point estimates;illnesses;computer vision;breakthroughs;machine;data;natural language processing;recent breakthroughs;uncertainty quantification;assumptions;recent efforts;standard machine;multivariate;field;decision;interest;aspects;causal;availability;conditions shift;financial support;prevalence;something", "pdf_keywords": ""}, "b6b76f529d273a35180d0dc65912db1538539067": {"ta_keywords": "document categorization;conventional supervised document classification;topic label;such metadata;categorization framework;categorization;metadata;annotated data;compelling topic indicators;tags;label scarcity;metacat;document;same semantic space;text;datasets;training samples;generative model;encode heterogeneous signals;thorough evaluation;many competitive baselines;same generative process;studies;bottleneck;various additional information;authors;effectiveness;scarcity;many domains;cases", "pdf_keywords": "metadata;novel framework metacat;metacat;minimally supervised categorization;document categorization;same semantic space;generative model;topic label;encode heterogeneous signals;text;same generative process;training samples;label scarcity;supervision;bottleneck;generation module;many competitive baselines;document;jiaxin huang1;jiaxinh3;hin;usa 2language technologies institute;abstract;1department;yumeng5;framework;effectiveness;significant contribution;urbana;module"}, "ac713aebdcc06f15f8ea61e1140bb360341fdf27": {"ta_keywords": "nlp tasks;natural language inference;model extraction;bert;language model;nlp community;natural language processing;effective queries;adversary;apis;meaningful queries;exploit;attacker;victim model fine;real training data;victim model;attack;model;only query access;words;task;query budget;random sequences;question;dollars;devlin et al;transfer;methods;fact;local copy", "pdf_keywords": "model extraction;large pretrained language models;bert model;nlp models;bert;language model;attacker architecture;victim models;adversary;natural language processing;attacker;extraction;thieves on sesame street;api;victim model;based apis;model;dataset complexity;training data;model distillation;nonsensical inputs;nicolas papernot google research;query ef\ufb01ciency;only query access;iclr;further investigation;google research;access;abstract;gaurav singh tomar google research"}, "3671dabbfd2e854060e1e382bad96b6bb00fcb46": {"ta_keywords": "robust speech recognition;noise exemplars;speech exemplars;speech features;robust asr;dictionary adaptation;target noise;exemplars;noise;low snrs;training data;sparse linear combination;signals;model;state;art performance;unknown types;conventional approach;paper;approaches;process", "pdf_keywords": ""}, "6bea71fa6deb19c67e9586428f8f240e789fb3df": {"ta_keywords": "linear stochastic bandit problem;linear stochastic bandits;linear stochastic;constant regret;ucb algorithm;stochastic;regret;empirical performance;auer;high probability;improved algorithms;algorithms;algorithm;logarithmic factor;vast improvement;experiments;simple modification;dani et al;analysis;modification;theoretical analysis", "pdf_keywords": "linear stochastic bandit problem;various stochastic bandit problems;novel tail inequality;martingales;constant regret;ucb algorithm;auer;empirical performance;algorithms;high probability;algorithm;analysis;vector;dani et al;theoretical analysis;conclusions;paper;simple modi\ufb01cation"}, "2f0221142db900e75bd9c54fa153fb770a72f672": {"ta_keywords": "crowdsourcing;assembly interface;large open thesaurus;yarn;russnet;project;usage scenarios;russian;design;implementation details;aims;paper;first experimental results;motivation", "pdf_keywords": ""}, "7dce2877758b0103d1f7a454c184dc641e123359": {"ta_keywords": "document retrieval task;unstructured queries;query language;annotation compression;nlp pipelines;annotation graphs;corpus sentences;trec qa topics;queries;indexing;aquaint text collection;factoid question;solr annographix;query;better graph matching algorithms;qa;original documents;di erences;software suite;software;purpose;constraints;cases;report;sec;early termination heuristic;system;end;signi;addition", "pdf_keywords": ""}, "309b2c75dcdafea19a053876e56cef9747d428fb": {"ta_keywords": "previous neural lattice models;attentional models;model lattice inputs;speech translation task;lattice inputs;recurrent neural networks;lattice scores;lattices;lattice structure;natural language processing tasks;attention;multiple speech recognition hypotheses;probabilistic reachability masks;sequence modeling technique;encode ambiguity;models;such models;multiple linguistic analyses;slow computation speeds;example;various tasks;inputs;model;computational efficiency;inference;improvements;upstream systems;pairwise similarities;strong results;self", "pdf_keywords": "previous neural lattice models;attentional sequential encoders;standard speech translation benchmarks;attentional encoder;attentional model;positional embeddings;speech translation task;lattice self;lattice;lattice nodes;lattice structures;lattices;positional encodings;global lattice structure;decoder model;previous recurrent approaches;natural language processing tasks;encode ambiguity;encoder;multiple speech recognition hypotheses;encoder component;model positioning;probabilistic reachability masks;reachability masks;multiple linguistic analyses;example;local context;model;inference;ordering"}, "975551547fef77605fb85a551bbd7523b77746b7": {"ta_keywords": "repository classification;keyword enrichment;topic modeling;topic label functionality;github repository collections;higitclass framework;github repositories;higitclass;github;repositories;hierarchical classification methods;pseudo document generation;unstructured data;heterogeneous information network;supervision format;search;topic;code sharing;supervision scarcity;scientific exchange;labels;bias;key challenges;important platform;modules;recognition;massive number;challenges;utility;majority", "pdf_keywords": "keyword enrichment;topic modeling;higitclass framework;higitclass;github repository collections;dataless hierarchical classi\ufb01cation methods;bioinformatics research community;github repositories;repository classi\ufb01cation;pseudo document generation;unstructured data;heterogeneous information network;datasets;machine learning;recognition;construction;modules;challenges;experimental results;ability"}, "46ed42e4318e1363a0ec3dde195422cdfecf2017": {"ta_keywords": "paraphrase generation model;phrase embeddings;bert embeddings;phrase representations;powerful phrase embeddings;diverse phrasal paraphrases;neural topic model;semantic relatedness;lexical similarity;complex phrasal compositionality;bert;phrases;corpus exploration;simple autoencoder;books3 corpus;phrase;topics;context;words;mixtures;nearest neighbor search;space;contrastive fine;dataset;model;tuning objective;paper;case study;application;scale dataset", "pdf_keywords": "diverse phrasal paraphrase pairs;diverse phrasal paraphrases;phrase embeddings;powerful phrase embeddings;phrase representations;box bert phrase embeddings;paraphrase generation model;semantic relatedness tasks;level paraphrases;semantic relatedness;phrases;diverse phrase;complex phrasal compositionality;lexical similarity;bert;lexical overlap cues;corpus exploration;phrase;strong baseline models;tunes bert;books3 corpus;contrastive learning;word overlap;context;phrasal;contrastive objectives;short texts;tokens;incontext;datasets"}, "d4af2654f97c09741aba9f0da9ace7bc84b9a63f": {"ta_keywords": "continuous time bayesian networks;bayesian network;modeling progression;integrated social services;model paths;model situations;social service provider;events;event occurrences;event;system evolution;greedy search procedure;poverty;novel event;ectbns;clients;structure;continuous time;graphical structure capture;occurrences;citylink center;system;model parameters;state variables;ectbn;dynamics;limited data;interventions;influence;cincinnati", "pdf_keywords": ""}, "73a6e4574de038878be1bbb5985400998e420a5b": {"ta_keywords": "strategyproofing peer assessment;peer assessment;peer grading;dishonest evaluations;assignment quality;strategyproofness;conference peer review;assignments;strategic behavior;assignment;evaluators;competition;submissions;own submission;individuals;expertise;employees;proposal review;variety;own work;individual;compromise;paper;constraint;form;work;world applications;order;different subsets;issue", "pdf_keywords": ""}, "78438b61afc2c9123c28ca4d6b58e598462ae9be": {"ta_keywords": "single source domain adaptation;source domain adaptation;adversarial task;specific adversarial training;adversarial training process;adversarial training;embedded adversarial training;discriminative target representations;target domain;deep insight;novel task;task;specific classifiers;tmda;tmda detects;specific decision boundaries;mda;min optimization;clustering;classical domain;specific framework;refines;max;great success;analysis;first time", "pdf_keywords": ""}, "1f0446dddd192e94f3930a3a449bd89796f4200f": {"ta_keywords": "single feature transformation matrix frame;multiple transformation matrices;single transformation matrix;space adaptation framework;acoustic features;automatic speech recognition;space adaptation;deep neural network;efficient adaptation;posteriori linear regression;adaptation;matrices;map estimation;linear regression;space adaptations;feature;regression tree;gmm framework;same generative model;gaussian mixture model;gmm;preprecessing;dnn;frame;multiplication operation;weighted sum;prior distributions;fsmaplr;addition;space maximum", "pdf_keywords": ""}, "2226560f94c1e90d6900d4674b649cc5522b78cc": {"ta_keywords": "multilingual neural machine translation;attentional translation models;single translation model;multilingual self;translation accuracy;attentional transformer model;multiple languages;target languages;full parameter sharing;parameter sharing methods;full sharing;partial sharing;bleu scores;self;individual training;models;parameters;parameter;performance gains;competitive performance;substantial improvements;different families;happy medium;techniques;methods;noticeable drop;work;case", "pdf_keywords": "multilingual neural machine translation;multilingual machine translation;attentional translation models;single translation model;multilingual self;language pairs;multiple distant languages;multiple languages;target language;target languages;shared encoder source language;attentional mt models;full parameter sharing;partial parameter sharing approach;partial parameter sharing;parameter sharing strategies;shareable parameters;parameter sharing methods;languages;shared decoder;shared encoder;separate decoder;query weights;encoder;graham neubig language technologies institute;decoder;embedding;best bleu scores;sep;models"}, "04b91791225a4f86b0715b41c6f56c00c197d810": {"ta_keywords": "bandwidth optimal convertible codes;conversion bandwidth;convertible codes;variable capacity edges;code conversion problem;bandwidth optimal;mds codes;information flow graphs;bandwidth;conversions;conversion;access cost;mds;nodes;explicit construction;data;amount;present constructions;important subclass;fundamental limits;paper;important resource;number;shows;study;work;regimes", "pdf_keywords": "optimal convertible codes;accessoptimal convertible codes;convertible codes;mds codes;variable capacity edges;code conversion problem;bandwidth cost;network information;mds;conversion;lower bounds;bounds;access;merge regime;graphs;substantial savings;important parameter regime;default approach;ri;room;new construction;regime"}, "43fe2d8781473360eeaae7a3284169a303200846": {"ta_keywords": "fake news stance detection;stance classification task;fake news challenge;classifiers;classification accuracy;fake news;ensemble method;journalism;ensemble;leader board;detection;11th place;individual models;topic;improvements;paper;entry;development data;purpose;performance", "pdf_keywords": ""}, "d9b89de5c2a39479768c6e32f13ac3e816635cc1": {"ta_keywords": "translation models;lexical translation parameters;translation model;word lattices;consistent word error rate reductions;automatic speech recognition;speech input;transcription;translation;model;datasets;minutes;task;hours;computer;best path", "pdf_keywords": ""}, "44e24aabd05bef8cb45646486f1a24b7caecee45": {"ta_keywords": "recurrent neural network language model;multilingual seq2seq model;multilingual model;multilingual sequence;sequence speech recognition;language modeling;monolingual models;other babel languages;babel languages;transfer learning;seq2seq model;rnnlm;transfer learning approach;model training;more training data;models;recognition performance;transfer;significant improvements;architecture;lexicon;alignments;data;prior model;terms;paper;substantial gains;approach benefits;work;approach", "pdf_keywords": "recurrent neural network language model;multilingual seq2seq model;prior multilingual seq2seq model;multilingual training approaches;multilingual model;monolingual models;language model;other babel languages;multilingual approaches;babel languages;target language;transfer learning;rnn;seq2seq models;transfer learning approach;hybrid dnn;rnnlm;seq2seq model;attention;recognition performance;search decoder;seq2seq;transfer;character;target data;different architectures;joint ctc;data;prior model;importance"}, "8b468872cf915c98ff46a2bea4d2a34112b7b0b0": {"ta_keywords": "relational classification;longer relational rules;relational rules;relational features;backward random walks;faster algorithms;first order rules;algorithm;retrieval tasks;rules;features;pra;path;scalability;cor;types;large scale;key contribution;larger space;class;constants;enhanced system", "pdf_keywords": ""}, "d8704a63517868475b3af7ec25eaa2fb2a44362b": {"ta_keywords": "cnn loss minimization;grid crf loss;such grid crf losses;cnn segmentation;powerful loss functions;gradient descent;poor optimization;neighbor potts loss;computer vision;optimization;adm;art training quality;gd;variants;state", "pdf_keywords": "regularized segmentation losses;deep cnn segmentation;deep segmentation;cnn segmentation;regularized losses;deep learning;gradient descent;loss minimization;regularization models;loss function;losses;segmentation;complex neural networks;training schemes;current training methods;better optimization;alternative optimizer;computer vision;backbone optimizer;dense crf;cvpr;pattern recognition;simplicity;crf;gd;context;optimization method;ieee conference;use;adm"}, "6dd6d4dfc3cf9ff41aad7e903cf1294de2ac5629": {"ta_keywords": "vehicle safety assessments;safety assessment;automated vehicles;driving systems;systems safety assessment;japanese highways;world traffic data;driving system developers;foreseeable parameter ranges;traffic data;parameter ranges;reasonable risk acceptance thresholds;safety;ranges;deceleration scenarios;vehicles;scenarios;validation;specific concrete scenarios;representative values;foreseeable parameter;international environments;specific parameter;sakura initiative;outcomes;standardization bodies;biggest challenges;contextualization;applicability;comparisons", "pdf_keywords": ""}, "1288d6570085a28518a9f3495e77dbb75899421c": {"ta_keywords": "active annotation;entity recognition;popular active learning framework;human annotator;biomedical domain;training material;unsupervised method;data;encouraging results;seed;paper;reusability;errors;main advantages;main intuition", "pdf_keywords": ""}, "163a67b5b0371035fa6e0f88b36ba97a32e735bc": {"ta_keywords": "code conversions;code conversion;mds decodability constraint;convertible codes;decodability properties;size constructions;optimal mds;codes;explicit construction;mds;high field size;achievability result;merge regime;broad range;lesser resources;tight bounds;important parameter regime;nodes;resource;efficient manner;parameters;parameter values;framework;data;distance;field;new class;notion;property;linearity", "pdf_keywords": "code conversions;code conversion;convertible codes;decodability properties;code;size constructions;codes;explicit construction;optimal mds;merge regime;data;novel framework;high \ufb01eld size;broad range;parameter values;parameters;nf;achievability result;default approach;distance;mds;resource;framework;lesser resources;notion;property;ni;new class;process;concept"}, "027c5e44164a2ee3543ecdff73cd4d7888a42a90": {"ta_keywords": "flexible value alignment system;value alignment;ai system;ai systems;ethical systems;metric learning;ethical principles;machines;preference;orderings;decisions;user preferences;tools;preferences;actions;cp;recommendations;humans;same formalism;guidelines;formalism;certain norms;nets;system;decision;distance;paper;use", "pdf_keywords": ""}, "c17ccb7f0372ec98b7e070b0f70518f28516ecd5": {"ta_keywords": "stochastic processes theory;markov decision processes;markov chain monte carlo;markov;ergodic theorem;correlation theory;lectures;book;von neumann;mathematical foundations;macrosystem equilibrium concept;informatics;chapters;standard chapters;secretary problem;applied mathematics;control;moscow institute;spring semesters;department;course;professors;birkhoff;physics;technology;school;khinchin;year bachelor students;format;decades", "pdf_keywords": ""}, "23e03cd57b5d75993545127f3fecf99d25021583": {"ta_keywords": "tumor status representation;tumor embeddings;cancer genome atlas;multiple cancer phenotypes;deep neural network model;cancer drivers;phenotype prediction;cancer cell lines;encoder;tumors;tumor;genes;genome;genomic impact transformer;potential driver sgas;multiple phenotypes;abstract representation;model;decoder architecture;git model;patient survival time;sga events;drug response;cellular processes;sgas;layer;degs;attention mechanism;functional impact;git", "pdf_keywords": "gene embeddings;cancer genome atlas;tumor embeddings;tumor status representation;deep neural network model;encoder;phenotype prediction;representations;cancer drivers;regulatory networks;genes;gene;cancer;powerful gene;neural networks;knowledge representation;genomic impact transformer;git model;tumors;sga events;tumor;sgas;decoder architecture;model;clinical phenotypes;git;patient survival time;keywords;downstream degs;degs"}, "1d3539a8d94bd3ab78993d7cc584efc06ed0e460": {"ta_keywords": "explainable machine learning;feature attribution;popular explainability techniques;model explainability;different feature attribution methods;model predictions;attribution methods;synthetic benchmarks;machine learning models;synthetic datasets;empirical evaluation metrics;realworld datasets;several evaluation metrics;shap;world datasets;evaluations;other metrics;groundtruth shapley values;xai;library;data;efficient computation;scientific research;tools;research;variety;power;lime;values;flurry", "pdf_keywords": "empirical evaluation metrics;popular explainability techniques;feature attribution;several evaluation metrics;synthetic datasets;evaluation metrics;realworld datasets;different feature attribution methods;popular explainers;other metrics;evaluations;world datasets;feature correlation;groundtruth shapley values;shap;data;world data;ef\ufb01cient computation;library;xai;comparison;data distribution type;variety;shapr;values;wide variety;power;maple;bench;model type"}, "8a14b3a9e642f4ca7fad4df997fc1941bdcfb935": {"ta_keywords": "statistical models;language processing;speech", "pdf_keywords": ""}, "ffecb8b8b415149f5351b64a2dbb1a1fa64219f0": {"ta_keywords": "end speech translation;multilingual end;multilingual training;machine translation;multilingual models;target languages;automatic speech recognition;source languages;many translations;resource language pair;speech utterances;sequence architecture;transfer;end st problem;end st;universal sequence;asr;end;available data;generalization;mt;st;scenarios;scenario;paper;effective framework;effectiveness;first time", "pdf_keywords": ""}, "9c78481004b7dbb601b83cc081ec23c02e6f5270": {"ta_keywords": "learning dynamics;continuous games;gradient learning dynamics;differential nash equilibria;game dynamics;stable equilibria;scalar games;stability;corresponding game;equilibria;scalar action spaces;individual gradients;instability;nash;formal guarantees;natural model;points;rates;variations;comprehensive understanding;set;gap;spectrum", "pdf_keywords": "differential nash equilibria;learning dynamics;gradient learning dynamics;nash optimality;continuous games;stable equilibria;local stability;scalar games;sum gradient learning;stability;equilibria;dynamics;scalar action spaces;nash;spectral properties;game;matrices;player;variations;rates;\ufb01xed points;set;comprehensive understanding;paper;conclusion;\ufb01nd"}, "8b231737e0048a400527d89aa56c712e8b9bc690": {"ta_keywords": "end speech translation;multilingual training;machine translation;multilingual end;multilingual models;automatic speech recognition;target languages;source languages;speech utterances;many translations;resource language pair;sequence architecture;transfer;end st problem;end st;universal sequence;asr;end;available data;generalization;mt;st;scenarios;scenario;effective framework;paper;effectiveness;first time", "pdf_keywords": "multilingual end;end speech translation;multilingual e2e;multilingual training;target languages;bilingual ones;source languages;resource language pair;speech utterances;many translations;speech processing;sequence architecture;language;end st models;universal sequence;tosequence model;st models;shinji watanabe2;end st;kyoto university;resource st task;japan 2center;transfer;kyoto;available data;informatics;generalization;hirofumi inaguma1;st;effective framework"}, "da20ab7724335eb48bcd0e9be30f0ac4b6a464c6": {"ta_keywords": "novelty detection;network saliency;new image similarity metric;trustworthy prediction;detection;deep learning;critical autonomous systems;autonomous systems;vision;novel scenarios;visual;safety;cars;prediction model;model;safe decision;situations;machine;life;information;self;box;one;paper", "pdf_keywords": "visual saliency preprocessing;visual navigation;world driving;vision;autoencoder;detection;autonomous systems;training data;novel scenarios;car;wild;datasets;similarity metric;prediction model;house racing environment;novel loss function;new image;loss function;key component;feasibility;novelty;bene\ufb01ts;self;encountered situation;information;framework;input data;approach;network model;preprocessing phase"}, "e54e0d9eaa922cefb1c69e105979399fd34497b1": {"ta_keywords": "group fairness;fair classifiers;algorithmic group fair;partially annotated group labels;fairness;demographic group labels;group label annotations;target labels;external target label;aware learning;aware learning method;group;datasets;vanilla training;dataset;fair;privacy issues;accuracy;full data;cgl;pg;strategy;such assumption;availability;world applications;paper;methods;increas;practical scenario;problem", "pdf_keywords": "learning fair classifiers;fairness metrics;fairness;art fairness;demographic group labels;several benchmark datasets;partially annotated group labels;aware learning;celeba;target accuracies;celeba experiments;artificial intelligence;interdisciplinary program;seoul national university;compas;baselines;naver ai lab;scale dataset;ece;aware inprocessing methods;cgl;asri;utk;adult;department;scalability;methods;abstract;purpose;state"}, "dcb28c8ba94434eb8a06e81eb55bfdbc343d2340": {"ta_keywords": "ary relation extraction;ary relation extraction methods;novel multiscale neural architecture;small text spans;various text spans;entity mentions;biomedical machine reading show;such relations;consecutive sentences;entire document;subrelation hierarchy;document;recall;distant supervision;potential recall;representations;multiscale modeling;paper;level;noisy labels;weak signals;precision;purview;system;work;experiments;presence;approach", "pdf_keywords": "ary relation extraction;ary relation extraction methods;most information extraction methods;binary relations;various text spans;novel multiscale neural architecture;multiscale representation learning;entity mentions;small text spans;single sentences;consecutive sentences;documentlevel;such relations;recall;ary relations;biomedical machine reading show;distant supervision;document;representations;subrelation hierarchy;multiscale modeling;drug;precision oncology;microsoft research;paper;stanford;weak signals;redmond;stanford university;cliff wong2"}, "900b785dbbea7ccd5846eafb14c6715f76fe5e00": {"ta_keywords": "more malware;malware;deep learning;deep learning model;security risks;devices;unseen threats;dynamic anomaly detection method;mobile devices;personal mobile devices;difficult security challenge;device;detection;enterprise networks;wireless networks;ping responses;channel analysis;many features;guest;academic enterprise networks;bring;industry;use;government;system administrators;byod;extension;side;additional experiments;prior work", "pdf_keywords": ""}, "2a81081c987da2bb8184b8e9a884cf6a73712ee8": {"ta_keywords": "\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "126be977c03d732fbef2381565a41b957d41a2cc": {"ta_keywords": "nlp tasks;deep learning mohit iyyer;level language understanding;deep learning architectures;contextual language;contextual representations;question answering;deep learning models;level discourse structure;natural language processing;nlp;many deep learning;sentence level;linguistic context;comic book narrative modeling;discourse;sentences;language;text;neural networks;paragraphs;narrative;learning problems;unsupervised learning;fictional relationship understanding;representations;similar neural network modules;tasks;chapters;information", "pdf_keywords": ""}, "aae8d332c3ff9d081ae36967d3d7b5f394b51bcc": {"ta_keywords": "learning tasks;entity recognition tasks;classification;stackelberg game;teacher;prediction performance;training process;student framework;training;teacherstudent;self;drift;predictions;student;differentiable self;follower;semiand;model;advantageous position;leader;game;large margins;method;approaches;enormous success;experimental results;issue", "pdf_keywords": "differentiable selftraining framework;training framework drift;entity recognition tasks;training methods;training approach;text classi\ufb01cation;drift framework;student framework;differentiable self;training;drift;stackelberg game formulation;self;stackelberg game;teacher;student approach;framework;graphs;performance;paper;conclusion;discussion;set;contributions;ef\ufb01cient substitution;following"}, "2270b8628fd8ca67ae39d277f45bc3c38ac63d5f": {"ta_keywords": "tensorflow;word language modeling benchmark;tensorflow graph compiles;splitting tensors;tensor computations;parallel version;parallel operations;parallelism;batch;large models;memory constraints;tensor;small batch sizes;cores;deep neural network;processors;transformer models;transformer sequence;allreduce;splitting;dnn;efficient data;tpu meshes;mesh;sequence model;french translation task;language;programming;spmd program;splitting suffers", "pdf_keywords": "tensorflow;word language modeling benchmark;tensorflow graph compiles;tensor computations;parallel version;parallel operations;transformer models;french translation task;sequence model;cores;mesh;such processors;tpu meshes;language;collective communication primitives;transformer;spmd program;allreduce;sequence;dimensional array;ef\ufb01cient data;general class;parameters;state;art results;problem"}, "e2bd274c8dd2a3b2a0a6f5d8a29baee07df34eb9": {"ta_keywords": "string machine translation system;other machine translation;hierarchical phrase;accurate translation;t2s systems;t2s;previous reports t2s systems;tree;translation;alignment;performance gap;search;systems;string;accuracy;phrase;construction;mt;results;much promise;peripheral elements;elements;promise;reason;methods;paper;number", "pdf_keywords": ""}, "98b7d5611c0a128f45db100cc796b981573adcc5": {"ta_keywords": "information retrieval introduction;machine learning;special issue", "pdf_keywords": ""}, "bcd4c46e4d75ddedb6138cfd77600c6d964a9aa8": {"ta_keywords": "code translation;code models;program semantics;tocode tasks;program selection;generative models;output programs;program implementations;program;natural language;generated candidate;programs;code;semantic equivalence;language;same semantics;large corpora;execution results;execution;minimum bayes risk;training;test inputs;mbrexec;execution result;models;exact equivalence;shot performance;small number;many problems;work", "pdf_keywords": "program selection;code models;representative programming languages;output programs;execution accuracy;program implementations;tocode tasks;programs;mbrexec;executability checker;execution;generated candidate;noexecution baselines;evaluation;language;code;minimum bayes risk;mbr;training;bleu;datasets;exec;execution result;risk function;mbpp;inference algorithm;test cases;shot performance;inputs;promising alternative"}, "8688169ad5701e726968e293ff7dc53d76dd8007": {"ta_keywords": "ml papers;research;flaws;stymie future research;practice", "pdf_keywords": ""}, "4f78624defde3b60551cfeb37e3943b267ea704a": {"ta_keywords": "compressed gradient differences;large machine learning models;compression;learning method;gradient differences;learning;bottleneck;quantization;model updates;gradients;batch mode;updates;dqgd;diana;qsgd;several methods;terngrad;methods;convergence;computing approach;sparsification;method;true optimum;communication;signsgd;first convergence rate;none;issues;work;analysis technique", "pdf_keywords": "large machine learning models;compressed gradient differences;learning method;learning;compression;gradient differences;bottleneck;model updates;terngrad;training;\ufb01rst convergence rate;unbiased estimator;computing approach;communication;jun;method;mipt;konstantin mishchenko kaust;saudi arabia;eduard gorbunov mipt;de\ufb01nition;analysis technique;issues;russia;abstract;formula;usa;work;variance"}, "dbdefb498b619912a726fec7c85533594a1c6a1b": {"ta_keywords": "smooth algorithmic adversaries;minimax optimization;nonconcave maximization;computable optimality notions;full maximization;gans;generative adversarial networks;such optimization problems;smooth algorithms;adversary;robust models;max;algorithms;nonconvex;nonconcave;challenging setting;monotonic progress;computational budget;algorithm;new algorithm;limit cycles;iterations;player;polynomial number;stationary point;many machine;many fundamental issues;paper;absence;framework", "pdf_keywords": "minimax optimization;nonconcave minimax optimization problems;adversarial training problems;adam optimization method;smooth algorithmic adversaries;adversarial training;min player;max player;full maximization;smooth algorithms;adversary;max;new e\ufb03cient algorithms;algorithms;generative adversarial network problems;attacks;new algorithm;nonconvex;\u03b72;generative adversarial network;nonconcave;player;models;challenging setting;knowledge;theoretical framework;practice;problems;new framework;abstract"}, "a3ce3004a0eade48a3ae652dbf5c04a60c2416aa": {"ta_keywords": "personalized dialogue generation;aware dialogue generation models;personalized dialogues;dialogue generation;personaldialog;explicit personality traits;personality traits;persona;sociolinguistics;aware attention;aware bias;several anonymization schemes;proper traits;privacy;sequence;various traits;trait;speaker;different contexts;information;speakers;model;scale dataset;large number;end;framework;social science;process;study;techniques", "pdf_keywords": "personalized dialogue generation;personalized dialogue generation models;personalized dialogues;dialogue generation;dialogue generation process;persona representation;persona information;explicit personality traits;personality traits;trait fusion module;trait fusion methods;persona;diversified traits;aware attention mechanism;decoder framework;context vectors;several variants;encoder;aware bias;speaker;aware models;features;bias;different combinations;final generation distribution;models;model;schemes;process;approaches"}, "54a13bcc9613dcaa76fb25fbe96572f376cfcca9": {"ta_keywords": "adaptive learning rates;neural network weight matrices;stochastic optimization methods;german machine translation task;sublinear memory cost;adaptive methods;optimizer;squared past gradients;parameter updates;adam;second moment accumulator;adam regime;adadelta;decay rate;second moments;update clipping;adafactor;transformer model;updates;rmsprop;little auxiliary storage;wmt;decay rate scheme;row;column sums;sums;parameter;averages;comparable results;inverse square roots", "pdf_keywords": "adaptive learning rates;scale machine translation task;adaptive gradient methods;popular machine translation task;learning rate;sublinear memory cost;squared gradient accumulator;adafactor;adaptive methods;update clipping;memory usage;parameter updates;adam;second moment accumulator;second moment accumulators;full accumulators;sublinear amount;accumulators;decay rate;comparable performance;updates;training steps;relative change;adaptivity;absolute step size;decay rate scheme;remedies;outof;extra space;expensive models"}, "957e3ec3c722f5cb382fe8ac54fc846ee772a95f": {"ta_keywords": "adversarial bandits;dependent regret bounds;logarithmic regret;online mirror descent framework;more adaptive algorithms;small regret;faster convergence rates;regret;optimism;small loss;generic algorithm;loss;best arm;partial feedback;normal form games;arm;algorithm;barrier regularizer;adaptivity techniques;others;important negative term;arms;previous works;examples;main idea;lengths;variance;sum;length;special log", "pdf_keywords": "generic bandit algorithm;adversarial bandits;combinatorial bandit problem;dependent regret bounds;more adaptive algorithms;wellknown online mirror descent framework;learning theory;generic algorithm;barrier regularizer;optimism;sebastien bubeck;algorithm overview;algorithm;chen;special log;previous work;adaptivity techniques;jun;haipeng luo university;southern california;main idea;vianney perchet;editors;yu wei university;various new data;philippe rigollet;31st annual conference;abstract;work;proceedings"}, "c4ce6aca9aed41d57d588674484932e0c2cd3547": {"ta_keywords": "prominent pubmed search;interdisciplinary scientific search;scientific literature;scientific papers;knowledge base;unified schema;sciences;useful knowledge;mechanism relations;natural language;schema;relevance;clinical experts;mechanisms;causal relations;tools;papers;information;experiments;fundamental concept;dataset;activities;breadth;interest;study;cellular processes;utility;model;economic impacts;construction", "pdf_keywords": "mechanisms anotated;open mechanism knowledge base;structured search;mechanism relations;annotated dataset;mechanisms;nanotechnology;scienti\ufb01c papers;schema;breakthroughs;search engine;uni\ufb01ed schema;natural language;ai;relevance;mechanic;interdisciplinary endeavor;information;dataset;papers;experts;breadth;introduction;utility;dots;model;comb;effort;vice;\ufb01eld"}, "73b22457a2f52a834d73d73a76b4124c1cb326be": {"ta_keywords": "multiplayer performative prediction;player performative prediction;adaptive gradient algorithms;dependent games;nash equilibria;gradient method;gradient steps;player alternates;stochastic;empirical risk;derivative free methods;stable equilibria;game;new game;algorithms;latter equilibria;retraining;strong monotonicity;mild assumptions;theoretic framework;distinct solution concepts;variety;distribution;parametric description;paper;decision;ii;transparent su\ufb03cient conditions;phenomenon", "pdf_keywords": "multiplayer performative prediction;player performative prediction;adaptive gradient algorithms;nash equilibria;player alternates;learning problems;game;gradient method;empirical risk;gradient steps;stochastic;stable equilibria;new game;derivative free methods;algorithms;decision makers;interesting feedback mechanism;actions;retraining;strong monotonicity;population data reacts;variety;distinct solution concepts;mild assumptions;decision;theoretic framework;evan;abstract;distribution;paper"}, "6eb974721719056ba8dc74a898c64ae1d081e0ae": {"ta_keywords": "black box models;diagnostic curves;univariate diagnostic curve;black box model;models;machine learning;test accuracy;critical applications;datasets;various qualitative properties;standard metrics;safety;features;sample behavior;undesirable changes;feature;usefulness;outcomes;input space;framework;output;cases;oscillations;response;various properties;multiple use;monotonicity;respect;property;differences", "pdf_keywords": "partial dependence plots;dependence plots;directional dependence plots;generative model;visual tool;interesting pdp plots;bias detection;ice plots;model selection;datasets;models;textual data;plot utility functions;raw feature space;example;sample behavior;model response;interesting pdps;single features;model;latent space;instance;selection;pdps;usefulness;multiple instantiations;more general directions;pdp;speci\ufb01c pdps;arbitrary directions"}, "4e2c41466c8246af0a563ea36fbe80c896bbab2c": {"ta_keywords": "neural machine translation;word sense disambiguation literature;machine translation systems;aware word embeddings;word sense;global sentential context;homographs;context;input word;encoder;different meanings;words;correct translation;nmt;same surface form;systems;difficulty;methods;problem;advent;account", "pdf_keywords": "neural machine translation;machine translation systems;graham neubig language technologies institute carnegie mellon university;word translation;different language pairs;baseline nmt system;strong baseline model;nmt systems;homographs;standard nmt systems;words;different meanings;accuracy;correct translation;word;baseline;ambiguous words;senses;overall bleu score;bleu score;model;context;results;empirical evidence;signi\ufb01cant problems;mar;errors;fig;dif\ufb01cult;paper"}, "e9c52a3fac934919eca036909cc18d909db0d467": {"ta_keywords": "molecular dynamics;continuum model;peridynamic;data", "pdf_keywords": "md displacements;optimal linear peridynamic solid;continuum model;nonlocal models;discretizations;molecular dynamics;md data;dimensional tests;peridynamics;mechanical property tests;peridynamic;model;several numerical tests;di\ufb00erent domain shapes;integrands;materials;physical system;lps;nm ccomputational science;mathematics;validation data sets;data;robustness;integral operators;external loadings;analysis;computing research;algorithm;sci;methods"}, "52ec4713343083e69b87e36a7a12c7b5898e2780": {"ta_keywords": "multichannel speech enhancement;end speech recognition;speaker adaptation;unprocessed noisy speech;automatic speech recognition;speech recognition functions;end multichannel asr;deep neural network;multichannel end;other recent dnn;end asr approaches;speech;hidden markov model;dnn;previous end;asr;ami corpora;end;hybrid architectures;effectiveness;hmm;pathway;system;recent work;results;experimental results", "pdf_keywords": ""}, "4d1a14352ffb526a1fa0e1cd90e2484e188cddc0": {"ta_keywords": "dialogue data;dialogue systems;source domain dialogues;new dialogue scenarios;dialogue system;transfer learning;reinforcement learning;natural language;training data;user simulator;agents;structured reward functions;target domain data;behaviors;interaction;modelling framework;aim;self;play;framework;collection;performance;goal;tuning;further fine;possibility;lack;difficulties;small amount", "pdf_keywords": "transferable dialogue systems;dialogue systems;dialogue data;source domain dialogues;dialogue system;rich dialogues;transfer learning;user simulators;natural language;user simulator;reinforcement learning;agents;training data;structured reward functions;interaction;target domain data;behaviors;joint optimisation;framework;bo;aim;performance;abstract;tuning;collection;cambridge;paper;further \ufb01ne;possibility;work"}, "6d00b1024298e5b64ee873028385f7bb4396b05d": {"ta_keywords": "compositional generalization ability;compositional generalization;semantic parsing tasks;comprehensive compositional generalization benchmarks;latent syntactic algebra;neural sequence models;semantic algebra;semantic operations;latent syntax;algebraic recombination;lear;interpreter;neural model;composer;task;modules;key insight;homomorphism;end;toend;model;paper;experiments;effectiveness", "pdf_keywords": "compositional generalization;latent syntactic algebra;structured expressions;semantic algebra;algebraic recombination;novel expressions;lear;recursive manner;algebraic capability;human intelligence;neural model;components;chomsky;task;key insight;pylyshyn;homomorphism;end;principle;toend;paper;fodor;lepore;in\ufb01nite number"}, "6ccac8a95bc77549b98d045db6d5e0de3d356ba4": {"ta_keywords": "neural lexical translation models;bert models;lexical translation model;document embeddings;english text retrieval;information retrieval;embeddings;interpretable neural model;contextualized query;bert;large tensors;free neural model;neural model1;ranking model;ibm model;neural variants;maximum sequence length;expensive index;context;interpretability;aggregator layer;query;layer;end;top;limitation;accuracy;efficiency;effectiveness;cpu", "pdf_keywords": "bert models;lexical translation model;interpretable neural model;embeddings;free neural model;english text retrieval;bert;large tensors;only neural model;ibm model;neural model;maximum sequence length;neural variants;interpretability;expensive indextime precomputation;context;limitation;knowledge;accuracy;cpu;layer;end;gpu;network;query;e\ufb03ciency;utility;top;time operations;combination"}, "69c515a62403fcc19125d3a6dd8e878aa5cde604": {"ta_keywords": "incomplete utterance restoration;large conversation data;dialogue systems;frequent coreference;novel semi autoregressive generator;text editing;deep learning;autoregression;faster inference speed;sequence;sarg;generation;high efficiency;challenge;model;art models;state;information omission;great success;development;open domain;experiments;flexibility", "pdf_keywords": "incomplete utterance restoration;text generation;utterance restoration task;utterance restoration;sequence labeling;dialogue systems;turn corpus;novel semi autoregressive generator;autoregressive generation;text editing;frequent coreference;autoregression;faster inference speed;deep learning;inference speed;netease games ai lab;sarg;sequence;bert weights;model;art models;benchmarks;quality;overall model;appropriate model;conclusion;challenge;summary;abstract;creative fusion"}, "d2f327736c9b68f68ad64d0b1cefed9b4dd83313": {"ta_keywords": "structured prediction task;natural language generation;structured prediction;language generation;natural language;imitation;phrase templates;incremental model;nlg;linguistic resources;training data;learning;search space;large search space;unaligned datasets;unaligned data;meaning representation;explicit enumeration;most machine;task;outputs;approaches;domain;current rule;work;use", "pdf_keywords": ""}, "e37fb85e8869d464bae8eeebf4cd9321ec8c70ad": {"ta_keywords": "interpretable classifiers;interpretability;empirical risk minimization;interpretable hypotheses;binary classification;excess statistical risk;statistical learning theory;statistical implications;accuracy;formal study;restriction;case analysis;model;constraint;offs;results;perspective;starting point;act;shift;reason;work;cost;setting;set;trade", "pdf_keywords": "enforcing interpretability;interpretability;interpretable hypotheses;empirical risk minimization;interpretable formula;learning algorithm;computational complexity;constraints;constraint;data;accuracy;simple logical formula;statistical impacts;example;perspective;concrete model;offs;shift;preprint;act;work;trade;set"}, "8b0b2b69657076fc1ce7cce75a6d69e3e5ba2d63": {"ta_keywords": "performance supercapacitors;nickel foam;free electrode;organic framework;cobalt;metal;binder;high", "pdf_keywords": ""}, "6a173e22819480b891306eac65fd44be010dfca8": {"ta_keywords": "pandemic influenza virus;influenza virus;seasonal influenza virus isolate;ph1n1 virus infection;viral pathogenesis;immune cell signaling;viral rna sensing;inflammation;immune response;future pandemics;macaque lungs;immunomodulatory therapies;virus;transcription factor;lungs;pathogenicity;successful virus clearance;host gene sequences;protein interaction data;zinc finger;arthritis;cynomolgus macaques;disease;cell cycle;h1n1;protein;maz;cell cycle arrest;pathway enrichment analyses;microarrays", "pdf_keywords": ""}, "1d2a2b14ef14eeaf89169f738f7634cdc685c785": {"ta_keywords": "similarity predicate;query language;relational databases;relational database;similarity constraints;sql;query;whirl;statistical ir systems;relation;term vectors;document;tfidf;term vector;tuple;score;degree;answer;atomic symbol;properties;extension;cell;hybrid system", "pdf_keywords": ""}, "c968e8dc442102b38b134b1afadc7cc78fc5b5fb": {"ta_keywords": "named entity recognition;entity recognition;natural language processing tasks;interpretable evaluation;holistic metrics;diverse datasets;interpretable;models;accuracy;ner;model design choices;task;bleu;relative merits;f1;general methodology;differences;paper;particular methods;proliferation", "pdf_keywords": "entity recognition;interpretable evaluation;interpreteval;evaluation framework;evaluation;current evaluation methodology;single holistic score;ideal evaluation methodology;evaluation method;analysis tool;accuracy;score;datasets;analytical views;models;neulab;similar analyses;comparison;task;model;ner;multiple datasets;strengths;progress;weaknesses;systems;methodologically;interplay;general methodology;users"}, "7a56aba1a4d4020c4933319588b9ed2b34d51125": {"ta_keywords": "secure computation;theoretical mpc protocols;mpc protocol;cryptography;malicious security;privacy guarantees;mpc;spdz framework;spdz;sensitive data;popular machine learning;computation;machine learning;implementation;ml;efficiency;world data;multiple sources;project;area;context", "pdf_keywords": "secure computation;privacy guarantees;malicious security;cryptography;theoretical mpc protocols;sensitive data;popular machine learning;stronger security;mpc protocol;spdz framework;mpc;spdz;machine learning;predictors;computation;logistic regression;previous implementations;implementation;linear regression;model;ml;regression analysis;applications;jan;world data;project;many machine;multiple sources;dependent variable;ef\ufb01ciency"}, "e02f79b710cdcaa9135b835fad964f6f2c78b1a7": {"ta_keywords": "recent tokenization approaches;explicit tokenization;efficient tokenization;tokenizers;abstract pipelined nlp systems;language representation;explicit tokenization step;neural encoder;character sequences;subword lexicons;free encoder;subwords;neural modeling;characters;languages;canine;soft inductive bias;vocabulary;models;model;data;use;end;paper;ability;techniques", "pdf_keywords": "free deep encoder;tokenization;language modeling;tokenizationfree;encoder;heuristic tokenizers;characters;language understanding;linguistic properties;rich languages;character;canine;polysynthetic morphology;vanilla bert;text;lossy information bottleneck;free model;models;input;model;long sequences;ef\ufb01cient model architecture;knowledge;level model;mind;upsampling;speed;downsampling;free technique;means"}, "4572ded23106285cbd8ebbe6c3b354973ac06ff7": {"ta_keywords": "indonesian conversational speech;emotion;\u7b2c16\u56de\u97f3\u58f0\u8a00\u8a9e\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0;recognition;analysis;\u97f3\u58f0", "pdf_keywords": ""}, "e214d2a6399925ce60fa5ce90c0374127a32b47e": {"ta_keywords": "impromptu deployment;wireless path;wireless sensor networks;sequential decision algorithms;wireless relay network;deployment progresses;radio propagation model;stochastic approximation;deployment agent;relays;learning algorithms;deployment;optimal policies;previous relay;algorithms;such networks;field deployment;placement location;free algorithms;explore;forward approach;end traffic carrying capability;locations;several consecutive steps;approaches;aim;sink;knowledge;multihop;approach", "pdf_keywords": "wireless relay networks;wireless relay network;wireless sensor networks;stochastic approximation;sequential decision algorithms;impromptu deployment;optimal policies;radio propagation model;deployment progresses;such networks;learning algorithms;\ufb01eld deployment;deployment;deployment agent;algorithms;free algorithms;forward approach;explore;several consecutive steps;placement location;several approaches;approaches;knowledge;measurement;need;large regions;measurements;light traf\ufb01c assumption;paper;ii"}, "7ee55c115470e1b86e552c5594e2e4258b4ccefb": {"ta_keywords": "oxygen reduction reaction;nx active sites;fe;configuration engineering;edge", "pdf_keywords": ""}, "a7766d4c41df235764dfaa9971ce861f6120ac27": {"ta_keywords": "latency meeting recognition;group meetings;time meeting analyzer;meeting browser;meeting situation;distant microphones;microphone array;online manner;table;visual information;demo videos;omni;understanding;system;directional camera;center;demonstration", "pdf_keywords": ""}, "252ef125a8874fe8face4540f87f2e000275cc96": {"ta_keywords": "latent terrorist communities;terrorism research;cluster perpetrators;terrorist groups;clustering algorithm;innovative clustering algorithm;similarity measure;similarity;communities;grouping;groups;interesting patterns;hidden patterns;different dimensional weighting schemes;unweighted algorithm;algorithm;common behaviors;different ideologies;gower;data;key task;outcomes;coefficient;different types;light;present work", "pdf_keywords": ""}, "803c7fdd6e01e1ff8cd43297f4e052078409456d": {"ta_keywords": "social inferences;continual hierarchical adaptation;coordination;communicative context;communication;wide social conventions;dyadic interactions;hierarchical bayesian theory;continual learning;convention formation;gradual transfer;inference;linguistic representations;adaptation;languages;strangers;interactions;intentions;interaction;coordination problems;stable priors;language use;conventions;nonstationary social environment;computational foundation;old words;multiple partners;new empirical data;simulations;previous accounts", "pdf_keywords": "coordination;human generalization behavior;hierarchical bayesian inference;convention formation;communicative context;hierarchical bayesian theory;continual hierarchical adaptation;language communication experiment;uni\ufb01ed cognitive model;inference;conventions;interaction;emergence;linguistic representations;strangers;convention;small networks;level conventions;new empirical data;language use;gradual transfer;empirical puzzles;common ground;community;computational foundation;simulations;speci\ufb01c meanings;basic observations;expressions;chai"}, "c6488f0c62ee4a4d48d0fbf8e8185655226294c1": {"ta_keywords": "attack detection;attack detection probability;attack design problem;controller manipulation attack;different attack detection models;attack;ris controller;new attack;attacker;threshold detection;semidefinite relaxation;novel optimization formulation;communication system;simple energy detector;reconfigurable intelligent surface;energy detector;receiver;various snr moments;detection;transmitter;snr moment;fading block;ris;snr;linear program;channel gains;large ris;cma;goal;blocks", "pdf_keywords": "controller manipulation attack;recon\ufb01gurable intelligent surface aided wireless communication;attack design problem;ump energy detector;attack detection probability;ris controller;attack;attacker;new attack;communication system;recon\ufb01gurable intelligent surface;receiver;threshold detection;multiple fading blocks;various snr moments;transmitter;snr;ris;detector;block;linear program;large ris;phase shift;goal;data rate;cma;ris elements;constraint;moments;eess"}, "2e4cdd36d77b9d814638fc2cd6c703535cb1d2f7": {"ta_keywords": "nlg tasks;frozen pretrained models;language model;corpus;continuous prompts;tuning;frozen plm;unfamiliar inputs;input representations;frozen plms;input;tasks;numerous downstream tasks;plm;inputs;large performance gap;example;tunes;better performance;development;preliminary exploration;paper;step;fine;factors;effective way;experimental results", "pdf_keywords": "input unfamiliarity;soft prompts;nlg tasks;continuous prompts;unfamiliar inputs;language model;tuning;input representations;input;corpus;inputs;wise inputadapter;frozen plm;inputadapter;frozen plms;unfamiliarity;numerous downstream tasks;plm;tunes;performance;development;\ufb01ne;step;results;paper;factors;essential ingredient;experimental results;effective way;conclusion"}, "4c2d9136c579a0393d4f50bbbbc6f8dab43c38e9": {"ta_keywords": "blind estimation;backpropagation;source priors;shape parameter estimator;differentiable neural network;dereverberation signal processing methods;automatic speech recognition;gaussian;prediction;distant speaker scenario;asr network;wpe;priors;shape parameter;tvg;shape parameter value;conventional baseline methods;square error;whole network;outputs;demand estimation;weighted;signal;asr;cgg;asr errors;sources;evaluation;processing;computational graph", "pdf_keywords": ""}, "6f49026ff623c64ce6de81fd04cf6e1ffe7dd6d9": {"ta_keywords": "deep convolutional generative adversarial networks;convolutional generative adversarial networks;convolutional gan model;polyphonic music generation;gans;binary neurons;piano;music;refiner network;output layer;additional refiner network;generator;binary;hard thresholding;pitch matrices;final binary;discriminator;models;rolls;objective measures;bs;number;better results;paper;time;form;bernoulli;ht;results;experimental results", "pdf_keywords": "polyphonic music generation;convolutional gan model;deep convolutional generative adversarial networks;novel convolutional gan;convolutional generative adversarial networks;gans;binary neurons;piano;music;generator;output layer;rolls;binary;pitch matrices;discriminator;model;re\ufb01ner network;additional re\ufb01ner network;hsuan yang research center;yi;number;form;paper;bs;objective measures;conclusion;taiwan;abstract;taipei;better results"}, "57e7be6b404abfd7a56a73c0ff9bccc5b27ad7ae": {"ta_keywords": "unsupervised domain adaptation;neural machine translation models;previous unsupervised domain adaptation strategies;neural machine translation;translation models;domain shift;aware feature embeddings;output sentences;domain data;auxiliary language;specific domain;generic representations;domain;text;adapts models;specific representations;outputs;task;words;model;high quality;data;recent success;work;availability;approach;methods", "pdf_keywords": "unsupervised domain adaptation;effective unsupervised domain adaptation technique;neural machine translation models;neural machine translation;domain adaptation;domainaware feature embedding;aware feature embeddings;language modeling;translation results;back translation;output domain;domain data;dafe;domain;graham neubig language technologies institute;test domain;yi dou;training data;zdou;nmt;representations;adapts models;auxiliary language;different parts;transformer;nmt system;task;scenarios;model;junjie hu"}, "2b3ab7e9c66bffc7af9e4413036e7bba686a7734": {"ta_keywords": "novice reviewers;peer review;competent reviewers;reviewers;reviewer pool;bias;review pipeline;potential bias;reviews;review;modern machine learning;computer science conferences;submissions;skepticism;machine learning;several conferences;peer;submission;previous submission history;lower overall score;resubmission;trial;authors;papers;quality;knowledge;recommendations;paper;recent graduates;information", "pdf_keywords": "novice reviewers;conference peer review;competent reviewers;peer review;reviewer pool;reviewers;bias;mean reviewer score;review pipeline;peer;review;reviews;computer science conferences;single review;submissions;modern machine learning;prejudice;conference;submission;machine learning;trial;recent graduates;prior;resubmissions;junior phd students;computer science;resubmission;quality;scores;master"}, "536ce077f08886b5834b639da25068d877c98b2c": {"ta_keywords": "lasers;dentistry xxiv", "pdf_keywords": ""}, "b54efe01969adaa1c623331d5791897a4dd9f886": {"ta_keywords": "fruit fly genomics;adaptive information extraction;interactive information extraction system;pdf extraction;flybase curation;flybase;commercial ocr package;curatable information;gene;curators;seed;papers;format;information;paper;learning technique;curation;machine;allele;tool;prespecified ie templetes;mapping;logical structure;font;ie;proformas;incorporation;team;system", "pdf_keywords": ""}, "0e8da301b098f96fed39c5aa8e2194f678690a16": {"ta_keywords": "secret share dissemination;eavesdropping;general network;shares;network;direct communication links;respective shares;secret;most protocols;communication;dealer;algorithm;deterministic solution;participants;participant;nodal;solution;paper;problem;case;instance;literature", "pdf_keywords": ""}, "73569460b023f9ac1fe5a1876c3401460d2fc15d": {"ta_keywords": "code clone detection;source code understanding;code data;code search;graphcodebert;code;codebert;natural language;semantic features;copies;lightweight approach;curriculum;algorithm classification;downstream data diversity;models;downstream tasks;tasks;classroom use;equivalent transformations;art models;hard copies;above tasks;model;data;improvement;much room;full citation;transformation;paper;finding", "pdf_keywords": "code clone detection;code search;code data;source code;language model fine;natural language;models codebert;code;semantic knowledge;graphcodebert;codebert;diverse syntactic forms;algorithm classification;lightweight approach;method outperforms roberta;model roberta;testing;same model architecture;tasks;models;downstream tasks;bridge;tuning paradigm;results;original models;target;paper;state;satisfies;art performance"}, "23f1d4b46bc7c8f357a5a89144d5d32af7be13a5": {"ta_keywords": "news summarization;generation models;generation strategies;simple training modification;summary properties;content selection;training dynamics;knowledge;copy behavior;training;cnndm;iterations;training process;mediasum;loss tokens;abstractiveness;different goals;xsum;model;factuality;hallucination;observations;different stages;tuning process;properties;different datasets;complementary approaches;work;fine;domains", "pdf_keywords": "abstractive summarization models;summarization models;target summarization goals;summarization;generation models;cnn;entire training data;noisy datasets;factual consistency;factuality;cnndm;abstractiveness;copy behavior;training dynamics;truncation strategy;hallucination;notable improvements;insights;mediasum;input article;myanmar;xsum;later stages;people;level loss;observations;essential components;section;naypyidaw;\ufb01ne"}, "9389af659f14239319186dff1cef49e8ece742c8": {"ta_keywords": "core graph learning tasks;graph ml;scale graph ml;graph regression;scale graph data;graphs;link prediction;ef\ufb01cient machine learning;simple scalable baselines;ogb;machine learning;world datasets;expressive models;lsc datasets;team registrations;scale challenge;node classi\ufb01cation;lsc;ml;acm kdd cup;signi\ufb01cant performance im;scale;ones;collection;common techniques;advancements;dedicated efforts;provements;current best practices;solutions", "pdf_keywords": "expressive graph ml models;scale graph ml challenge;massive modern datasets;art graph ml models;graph ml;scale graph ml;massive datasets;simple scalable baselines;expressive models;datasets;world datasets;ogb;simpler baseline models;scale challenge;lsc;kdd cup;scale;dedicated efforts;collection;advancements;dedicated effort;dedicated baseline experiments;better performance;common techniques;current best practices;opportunities;solutions;state;opportunity;research advances"}, "c68349ba142be731d6f3339d894764921c69b774": {"ta_keywords": "twitter;like quiz;social media;training data;diabetes mellitus;health model;data;obesity;future classification;preventable chronic illness;relevant data;participant engagement;questions;quiz;level data;t2dm;statistics;individuals;game;media;type;government agencies;individual level;groups;risk;early detection system;entire communities;training set;strategy;high engagement", "pdf_keywords": "obesity detection;social media data;twitter statuses;twitter;training data;overweight communities;random forest classi\ufb01er;social media;diabetes mellitus;like quiz;data;early detection system;t2dm;preventable chronic illness;data collection algorithm;questions;type;model;level statistics;game;daniel fried;media;risk;individuals;machine;classi\ufb01cation;mar;huangfuluwen;strategy;dane bell"}, "6665e03447f989c9bdb3432d93e89b516b9d18a7": {"ta_keywords": "effective rule induction;fast", "pdf_keywords": ""}, "e92de0c4ef62a84201fac284eb66c37330b5fe1c": {"ta_keywords": "bug repair;neural machine translation;fix code;future bugs;corrective patch generation system;corrective patches;prone code query;past fixes;bugs;code base;actual fixes;fixes;neural sequence;ratchet;fix;valid statements;bug;qualitative validation;findings;statements;addition;sequence model;output;f1;work;survey;same line;paper;respect;participants", "pdf_keywords": "neural machine translation;corrective patch generation system;prone code query;neural sequence;ratchet;code base;\ufb01x code;sequence model;past \ufb01xes;actual \ufb01xes;valid statements;bug;f1;\ufb01ndings;respect;time;measure"}, "90848c88f56fcd421ac3cfd2c87d3e61211103ea": {"ta_keywords": "text categorization;relational learning", "pdf_keywords": ""}, "051a85bd1384767ea5882dcefa98aee5664aa2cf": {"ta_keywords": "novel deep architectures;deterministic deep neural networks;deep network;deep neural networks;discriminative training;speech processing;nonnegative matrix factorization;associated inference algorithm;efficient spectral clustering;complex gaussian microphone array signal processing;novel networks;reinterpret inference iterations;networks;model;machine learning;problem domain knowledge;conventional networks;inference;layers;such frameworks;network;powerful network;parametrization;new understanding;constraints;methods;expense;difficulties;approach;successful paradigms", "pdf_keywords": ""}, "6fde1c63b1a353cf539d319341ae9396000660ed": {"ta_keywords": "automatic pronunciation proficiency estimation;automatic pronunciation evaluation;pronunciation scoring system;noisy classroom;noise reduction technique;microphone;asr systems;call systems;noise reduction algorithm;microphone noise;additive noise;noise;automatic evaluation approaches;other learners;asr;speech;students;main noise sources;training data;splice;performance;robustness;testing environments;channel distortion;gop;distortion characteristics;degradation;mismatches;baseline system;technologies", "pdf_keywords": ""}, "e03d9684a19c8f8e29ee97b347d4f1e280a88e44": {"ta_keywords": "gesture space;gestures;gesture;language grounding;spoken language representations;contrastive learning;crossmodal grounding;spoken language;crossmodal;crossmodal cluster nce;new contrastive loss function;grounding relationships;grounding;hands;representations;different phrases;example;available dataset;key technical challenge;similarities;qualitative evaluations;molecules;prior approaches;physical point;model;self;paper;scientific phenomena;part;entire bottom row", "pdf_keywords": ""}, "d31b5b60e1b3af84cd977da8db0ed4faeb79e7f7": {"ta_keywords": "text style transfer;style transfer;shot text style extraction;style vector space;style vector;text model;style;text;tunable targeted restyling;available unlabeled text;adjacent sentences;decoder;free training results;training data;specific attributes;label;many facets;transfers;inference time;novel approach;input;vector operations;previous approaches;data;implicit connection;t5;others;method;use;problem", "pdf_keywords": "shot text style transfer;text style representations;style transfer;style transfer model;translation training;textual style;text models;shot style transfer;diverse corpus;tunable inference;shot generalization;unlabeled corpus;text;many different styles;adjacent sentences;style attributes;style vector;style space;dialect;sentiment;decoder;style;politeness;unlabeled web text results;transfers;sentence adjacency;lightweight \ufb01ne;input;directional operations;formality"}, "5812e30eb4756aeaf0b013a65b98f8f8aa0f8315": {"ta_keywords": "recurrent neural net language models;language models;hierarchical phrase;naist smt systems;english mt tasks;domain adaptation;smt systems;compound word splitting;evaluation campaign;englishgerman;individual smt systems;ntt;english;generalized minimum bayes risk system combination;german;iwslt;data selection;forest;systems;string;paper", "pdf_keywords": ""}, "cf2a953dc82115d34de51737fef46bf3ff4cd5a6": {"ta_keywords": "speech separation;chime;recognition challenge;overview", "pdf_keywords": ""}, "c44addf352f25f28f69ca9f9422c0e463783206f": {"ta_keywords": "general word synonym extraction show;parsed text corpus;specific word similarity measure;entity coordinate term extraction;moderate size text corpora;similarity measures;syntactic relations;parsed text;graph walks;adaptive graph walk;graph walk process;nodes;global information;dependency;words;empirical evaluation;graph;tasks;task;vector;edges;instance;techniques;framework;models;model", "pdf_keywords": ""}, "9c16dcbcdfe6991f5d448543e6f4cbdf37149883": {"ta_keywords": "multimodal model learn cross;less expressive models;art benchmarks;function projection modifies model predictions;expressive models;performance improvements;unimodal structure;performance;interactions;additive function projection;model;new diagnostic tool;performance degradation;emap;task;many cases;consideration;new state;capacity", "pdf_keywords": "multimodal classi\ufb01cation models;multimodal models;multimodal classi\ufb01cation tasks;multimodal model;empirical multimodally;unimodal baselines;additive projection;additive function projection;additive1 function projection;model;performance;emap;new diagnostic tool;task;full recommendations;future work;takeaways;authors"}, "335bf6f23ccdae43e45a7c12f33bc4f3488e3762": {"ta_keywords": "machine translation;multilingual corpora;multilingual translations;many multilingual corpora;source translations;incomplete corpora;such incomplete corpora;translations;multiple source languages;additional auxiliary language;source languages;large corpora;target language;data augmentation approach;source nmt;auxiliary language sentence;single source;word ordering;nmt;relevant languages;incomplete parts;original source;standard nmt;machine;ambiguities;word choice;mistakes;information;ambiguity;test", "pdf_keywords": ""}, "82459c972cc1e439c759010acf7ddce1a89b66e0": {"ta_keywords": "fuzzy graph clustering;global graph clustering;semantic frame induction;semantic class induction;watset meta;synonymy graph;distributional thesaurus;synset induction;watset;frame induction;nodes;input graph;algorithm;computational complexity;sense;dependency triples;computational analysis;domains;variety;competitive results;ambiguity;approach;intermediate representation;applications", "pdf_keywords": "fuzzy graph clustering;global graph clustering;distributional thesaurus;linguistic data;semantic classes;watset meta;disambiguation;graphs;watset;local context;frame induction;words;graph;algorithm;structures;domains;symbols;computational analysis;sense;processing;variety;third type;skolkovo institute;mannheim;dt;science;riedl;technology;section;university"}, "684821e2459c7fc3ef8a2ec8102678af3613a962": {"ta_keywords": "downstream speech applications;multiple speech tasks;speech representations;speech understanding;specialized prediction heads;natural language representation learning;performance benchmark;speech;multiple downstream tasks;learning methods;generalization abilities;self;representations;available self;models;task;minimal architecture changes;unlabeled data;tuning;wide range;network;large volumes;results;community;gap;quality;research;superb;complete framework;similar setup", "pdf_keywords": ""}, "2467b2daea0398709d7ea57d084cc1f00f9d168f": {"ta_keywords": "conditional speaker features;input mixture speech;connectionist temporal classification;speaker;mixed speakers;other nar models;speakers;encoder;latency;ctc;nar;intermediate ctc loss;wsj0;wers;mix;pit;total inference steps;model;conformer ar model;conformer;performance;output;3mix sets;parallel computation;number;variable numbers;one;librimix corpora;2mix;data", "pdf_keywords": "conditional speaker chain module;conditional speaker chain;nar models;conformer ctc encoders;transformer models;conditional chain model;conformer ctc model;encoders;conformer ctc;hybrid systems;module;end ar;improved model;systems;pit;condchain;end;method;variety;effectiveness;study"}, "a1588ac6d582d30742f998464500bb5ead125dc6": {"ta_keywords": "regretnet;regret trade;auctions;regret;loss modification;deep learning;attention;alternative loss function;single interpretable hyperparameter;attention mechanism;hyperparameters;incentive compatibility constraint;new neural architecture;revenue;network;generalization;modifications;success;independent modifications;varied input sizes;transregret;settings;effectiveness;participants;expressivity;follow;approach;extensive experimental study", "pdf_keywords": "regretnet;auctions;regretformer;deep learning;regret;alternative loss function;new neural architecture;attention;hyperparameters;revenue;incentive compatibility constraint;attention mechanism;optimal;network;generalization;dmitry ivanov;russia igor filippov;architectures;design;jetbrains research;modifications;participants;settings;russia iskander safiulin;experiments;varied input sizes;recent breakthrough;usa;independent modifications;myna labs"}, "1c682dca13e47e6e1ee3c8db54af631a8e5e5792": {"ta_keywords": "graph signal processing methods;direct spectral decomposition;probability transition matrices;spectral techniques;cost mdp;optimal policy;low complexity computation;single stage cost vector;large state space;policy iteration;wireless system;various algorithms;spectral properties;matrix;moderate complexity strategies;projections;ptm;best performance;psd;numerical results;outer product;dominant subspace;long run;trade;bases;value function;offs;end;performances;order", "pdf_keywords": ""}, "48e32ba9a891f36183a26f35316e8906d14d83c0": {"ta_keywords": "purpose crowdsourcing computational quality control toolkit;crowdsourcing;whole crowdsourcing process;computational quality control toolkit;computational quality control algorithms;major annotation tasks;computational quality control methods;toolkit;computational quality control techniques;categorical annotation;quality control;crowd;sequence aggregation;aggregation methods;consensus methods;python;labels;workers;tasks;several datasets;latent label assumption;extensive evaluation;kit;uncertainty measures;efficient implementations;worker selection;uniform;golden tasks;complex tasks;reproducible way", "pdf_keywords": "purpose crowdsourcing computational quality control toolkit;crowdsourcing;computational quality control toolkit;major annotation tasks;categorical annotation;computational quality control methods;toolkit;aggregation methods;quality control;sequence aggregation;crowd;extensive evaluation;latent label assumption;python;kit;yandex;several datasets;moscow institute;complex tasks;reproducible way;moscow;general;abstract;russia;purpose;piskariovski prospekt;moscow region;paper;dolgoprudny;institutskiy"}, "d4756d1a7b81f53e71f939ab387cad5f0a4a13b7": {"ta_keywords": "polyphonic sound event detection;sound event activity;lstm;voice activity detection;bidirectional lstm recurrent;sound activity detection network;sound event;sequence detection;speech recognition systems;sound event insertion errors;term memory;frame detection;duration;sequence;neural network;frame methods;segments;blstm;postprocessing;frame;thresholding;mask;sed;art sed method;noisy conditions;conventional frame;paper;state;modeling technique;benefits", "pdf_keywords": ""}, "19418493b1f9c82809fe4584af427b8807b8ae2d": {"ta_keywords": "purpose relation classifier;entity pairs;mentioned entity pair;natural language understanding;locatednear relation;sentences;useful commonsense knowledge;such relationship;machine comprehension;objects;benchmark datasets;physical objects;pairs;sentence;computer vision;level classifier;tasks;baseline methods;results;type;research;scores;large number;state;art", "pdf_keywords": "locatednear relation extraction;textual corpora;large corpus;entity pairs;commonsense locatednear relation;sentences;benchmark datasets;lstm;locatednear relation;objects;scene;physical objects;sentence;neural architectures;feature;such relationship;novel tasks;models;pairs;tasks;human;future research;label;certain pair;scores;evaluation;systems;several methods;paper"}, "298ddceada580c46e40e2a0323c0e3b16ed5f3c9": {"ta_keywords": "eeg signals;incongruity detection;asr outputs", "pdf_keywords": ""}, "562fbb5d706d46f3e250429ac48e6acd2bf18cb1": {"ta_keywords": "speech separation systems;end speech enhancement;speech enhancement;optional downstream speech recognition module;rich automatic speech recognition;separation toolkit;source separation;asr integration;feature extraction;espnet;channel;benchmark datasets;evaluation pipelines;denoising;se;data pre;quick development;dereverberation;resources;models;training;single framework;end implementation;wide range;new project;recipes;systems;various functionalities;end", "pdf_keywords": "source speech processing toolkit espnet;source speech separation;audio source separation;speech recognition integration;different speech data;art speech enhancement;source toolkit espnet;other open source toolkits;enhancement library;western university source separation library;separation models;toolkit;se toolkit;espnet;multiple speakers;major benchmark datasets;espnetse1;multiple channels;rich features;new e2e;unmix;frameworks;adaptability;extension;reverberant conditions;se;several important functionalities;range;open;asteroid"}, "2dbe78aa516cc911a71ff333a35a5ce0b1a49640": {"ta_keywords": "automatic speech recognition;speech information;mode asr;various latency requirements;different latency requirements;asr;latency budget;latency;different latency budgets;larger latency;multiple models;stochastic future context;higher accuracy;single model;longer future context;models;reliable accuracy;librispeech datasets;model;context;future context;simple training procedure;fewer errors;different constraints;baselines;inference;iteration;constraints;pursuit;set", "pdf_keywords": "practical streaming asr;baseline streaming models;streaming mode;streaming;mode asr;asr models;multiple latency budget situations;different latency budgets;speech analytics solutions;\ufb01xed latency budget;context mode;stochastic future context;librispeech datasets;smartphone applications;single model;mode approach;mode;different modes;context;simple training procedure;context size;500ms;baselines;100ms;stochastic condition;pursuit;framework;con\ufb01guration;set;iteration"}, "0dc379de3a613110c5fdc9c0361372c1114ee18d": {"ta_keywords": "conversion ion source;los alamos neutron scattering center;energy beam transport;pop ion source;proton storage ring;ion source;ma design beam current;beam emittance;beam;los alamos national laboratory;lawrence berkeley national laboratory;kev;mu;operational surface;psr;lanl;lansce;lebt;operation;lbnl;improved version;pop;status;proof;results;column;factor;initial tests;application;principle", "pdf_keywords": ""}, "c6c6b4d328381a530e933c208bb43db2a7fa93c8": {"ta_keywords": "", "pdf_keywords": ""}, "7225c2a42990f850f692f8d82e7f3bfaf312145c": {"ta_keywords": "neural machine translation;curriculum learning;large neural networks;training examples;training samples;specialized learning rate schedules;recurrent neural network models;nmt;training time;curriculum;training;art nmt systems;large batch sizes;accuracy improvements;optimization tricks;specialized heuristics;many heuristics;current competence;competence;performance;transformers;overall better performance;model;sample;better solution;bad local optima;difficulty;bleu;current state;framework", "pdf_keywords": "curriculum learning;neural machine translation;neural machine translation models;large neural networks;specialized learning rate schedules;training framework;curriculum;large batch sizes;nmt systems;nmt;training time;training algorithms;training data;specialized heuristics;art nmt systems;many heuristics;optimization tricks;competence;learning department;novel competence;current competence;overall better performance;examples;model;idea;sample;future work;framework;robust way;paper"}, "4a76869cda286efb20eb78cc6adb13daab37a0d1": {"ta_keywords": "stochastic simulations;planck equations;particle density;planck solutions;interacting particle system;comparable particle number;stochastic systems;particles;fokker;probability density functions;reliable particle;simulations;numerical solutions;fluctuating statistics;mean field limit;novel statistical estimator;time evolution;computational approach;interactions;logarithm;various scientific fields;gradient;moderate dimensions;method;effortless;level;behaviour;terms;analytical treatment;framework", "pdf_keywords": "stochastic simulations;planck equations;planck solutions;interacting particle system;cumulant trajectories;small particle numbers;reliable particle;distribution cumulants;simulations;fokker;wasserstein distance;same particle number;steady state solutions;divergence;time evolution;temporal \ufb02uctuations;kullback leibler;computational approach;mean \ufb01eld limit;moderate dimensions;different dimensionalities;kl;distances;method;low order;squared error;framework;effortless;terms;accuracy"}, "674f892caa52fa400109defa1773a10088918124": {"ta_keywords": "model predictive control;integral projected gradient method;optimal control problem;novel first order primal;dual methods;input constraint set;input constraints;finite horizon;dual method;mpc;lagrangian;optimum;gradient method;single projection;constraint violation;objective function;iteration;iteration number;augmented;iterates;method;rate;state;sequence;interest;distance", "pdf_keywords": ""}, "cc549a11d277d86f6228443cb16c231c9bda6c96": {"ta_keywords": "emphasis estimation;level emphasis modeling;hmm state clustering;utterances;emphasis;speech;state clustering;adaptive training;state clustering approach;more natural audio;contextual factor;continuous word;word;focus;hybrid approach;hybrid system;effectiveness;modeling;active research field;important aspect;previous work;experiments", "pdf_keywords": ""}, "c1546da843be7ea3e0adfb85b69a0b08d41c7159": {"ta_keywords": "dissertation;phd;template", "pdf_keywords": ""}, "5b3ca06a7673e2bf372d5f89afb15ae1eb714075": {"ta_keywords": "bayesian network;model situations;greedy search procedure;model paths;system evolution;ectbns;structure;ectbn;events;social service provider;event occurrences;poverty;clients;novel event;system;graphical structure capture;occurrences;citylink center;model parameters;limited data;state variables;dynamics;continuous time;influence;interventions;cincinnati;bic score;various types;representation;way", "pdf_keywords": ""}, "594827fdb2047bc7be4ea2f0d2364f46d187247e": {"ta_keywords": "new japanese speech corpus;largesize speech corpora;japanese asr benchmark;japanese speech;corpus;speaker verification;speech recognition;japanese asv;subtitles;jtubespeech;such corpora;youtube;youtube videos;languages;end learning;english;data;construction;hours;recent end;paper;scale", "pdf_keywords": "new japanese speech corpus;speech corpus;speech corpus construction strategy;largesize speech corpora;japanese speech;speech recognition;japanese asr;corpus;automatic speech recognition;japanese asv systems;automatic speaker veri\ufb01cation;speaker verification;speaker variation;jtubespeech;speaker veri\ufb01cation;connectionist temporal classi\ufb01cation;subtitles;such corpora;youtube;takaaki saeki1;languages;youtube videos;asr;language;shinji watanabe4;many audio \ufb01les;end learning;shinnosuke takamichi1;audio;japan"}, "539631a828bf0badd20d2241784b4e06c223250e": {"ta_keywords": "gaussian mixture model;phoneme contexts;robust sampling method;mixture;speech;speaker;iterative conditional modes;novel sampling method;gmms;mogmms;gmm;noisy data;speakers;hierarchical structure;icm;gibbs;model;blocked gibbs;singularity solution;difference;component;attributes;problem;existence", "pdf_keywords": ""}, "d5181375d242ed181bcde0d682a3c7ec4c4c6102": {"ta_keywords": "autism;social skills;autistic conditions;training;minute learning session;training tool;communication;improvement;results;general population;people;members;relationship;position;number;effects;trouble;analysis;paper;reasons;variety", "pdf_keywords": ""}, "562fe9b2f5e7ede128dd9a93edc3971c5e0a2394": {"ta_keywords": "artificial dialog acts;dialog acts;dialog act;dialog act information;word prediction accuracy;polylogue;generative model;word use;cache model;words;word;interlocutors;influence model;context;effect;influence;usage;knowledge;extension;terms;basic idea;perplexity;approaches;work;new approach", "pdf_keywords": ""}, "05710169c48ac1ffe6af514cc10e72d025023343": {"ta_keywords": "nonlocal models;fidelity simulations;learning;constitutive laws;data", "pdf_keywords": ""}, "14a6452d6d026a3f384e425add6ab68f8e65037f": {"ta_keywords": "public crowdsourcing marketplaces;crowdsourcing;efficient data labelling;largest crowdsourcing marketplaces;efficient label collection;data labelling;real label collection tasks;label collection project;labelling process;efficient data collection;incremental relabelling;yandex;data;aggregation;participants;pricing;audience;beginners;researchers;tutorial;unique industry experience;interests;portion;engineers;key components;introduction;toloka;practice session;background;practice", "pdf_keywords": ""}, "ea1ba6f5e5852e38ace7bbae4e4f60ffeeabe5b1": {"ta_keywords": "sustained microfracturing;hydraulic fractures;formation;classes", "pdf_keywords": ""}, "70a2a554829f2cebb9fa89829994444fa1ec5a7b": {"ta_keywords": "sequential plurality voting;conditional qualitative preferences;distance rationalizability;tractable approximations;collective decision;partial orders;consensus;kendall;cp;preference;nets;disagreement;preferences;formalism;tau distance;notions;features;distance;notion;individuals;time;number;paper;amount", "pdf_keywords": ""}, "39c5740304b5f4072f92e4e012a4b57e7bc2e817": {"ta_keywords": "channel speech separation studies;channel speech separation;speech enhancement techniques;speaker verification;signal quality;evaluation metrics;deep learning;perfect ground truth waveform;intrinsic metrics;evaluation;metrics;diversity;single class;single;systems;instance;lack;overwhelming majority;cases", "pdf_keywords": ""}, "470fd4faf9b8499e8bf21c5d143145305d07fe83": {"ta_keywords": "tweets;temporal proximity;collective entity;spatial proximity;common mentions;entities;geographical points;space;spatio;events;time;fact;interest;relaxed version", "pdf_keywords": ""}, "5667f934c5bc008d0464878729eed34cbf7ec1df": {"ta_keywords": "relation extraction;many natural semisupervised learning heuristics;unlabeled data;traditional supervised classification tasks;classifiers;constraints;walks;modeling capability;graph;task;approach;general approach;outcome;experimental results;better performance", "pdf_keywords": ""}, "2f1743d1a1be46452ab90691ead8bf916ffd912b": {"ta_keywords": "probabilistic enhancement;eeg component;prior distribution;correlations;channels", "pdf_keywords": ""}, "402ab2adcf9da95e6aad9884b1ec53271f39cd32": {"ta_keywords": "inverse kalman filter;inverse filtering;inverse filters;kalman filter;inverse state;inverse;forward filter;adversary;bayesian perspective;theoretical stability guarantees;recursive cram\u00e9r;nonlinear process dynamics;ekf;unknown matrix approaches;nonlinearity;estimate;space models;benchmark;recent advances;rao;unknown input;example;recent formulations;numerical experiments;ikf;context;methods;key challenges;future steps;interest", "pdf_keywords": "inverse stochastic \ufb01ltering;kalman \ufb01lter;inverse \ufb01ltering;inverse \ufb01ltering problem;inverse \ufb01lter;inverse state;inverse \ufb01lters;such inverse cognition applications;inverse;forward \ufb01lter;unknown matrix approaches;theoretical stability guarantees;nonlinear process dynamics;ekf;nonlinearity;ekfs;step prediction error;unknown inputs;gaussian;benchmark;space models;unknown input;numerical experiments;rao;sum;formulations;key challenges;methods;summary;context"}, "f82ae0a87cae2f3a43d4c0289d0cdf7ca57461d0": {"ta_keywords": "global \u79d1\u5b66\u6280\u8853\u7dcf\u5408\u30ea\u30f3\u30af\u30bb\u30f3\u30bf\u30fc", "pdf_keywords": ""}, "217074971e3dfdbfab3a8c3819cd7953ae666da4": {"ta_keywords": "automatic biomedical text;text mining;biomedical text;constructing reliable genetic association database;deep reinforcement learning;genetic association database;scientific literature;biomedical science research;ficial intelligent reader;pubmed;articles;text;mining;latest knowledge;authentic articles;like mining;automatic human;directional lstm;genes;knowledge;researcher;results;reliable curation;umls;answers;challenge;mary task;human;network;human behaviors", "pdf_keywords": ""}, "1b759204e7c13f0e4af9fe00b052af4456ac3669": {"ta_keywords": "reinforcement learning;atari domain;many atari console games;sequential decision making;smaller task horizon;skip;agents;skipping;sensing;better policies;frame;gain;loss;rl;images;steps;state information;state;algorithms;states;practice;compute costs;further benefit;paper;regular intervals;parameter;analysis;fact;role;recent results", "pdf_keywords": "loop action sequences;defensive play;control;atari domain;action;soccer;game;prediction;repetition;skipping;skip;prediction setting;same action;defense variant;frame;actionrepetition;rl;td;loss;consistency;loop;images;length;task;aspect;inertia;choice;terms;role;dependent quantity"}, "c1125fa33a239ef4fd3378ccd46b2a0a0cf79a15": {"ta_keywords": "storage system;lower storage overheads;erasure codes;disk io;data replication methods;additional storage;data centers;erasure;new erasure;warehouse cluster;efficient data reconstruction;unavailable data;same fault tolerance;degraded reads;faster recovery;latency;io;data;workloads;higher reliability;reconstruction;time traffic;network bandwidth;computation time;hitchhiker;facebook;network traffic;machines;codes;higher resources", "pdf_keywords": ""}, "ac8d33e4c0a45e227a47353f3f26fbb231482dc1": {"ta_keywords": "aware language models;temporal knowledge bases;temporal data;most language models;temporal context;memorization;factual knowledge;snapshots;training time period;lms;new data;future time periods;models;facts;diagnostic dataset;unseen facts;data;abstract many facts;time;predictions;basketball team lebron james;expiration date;scratch;name;president;end;specific moment;problems;need;wide range", "pdf_keywords": "temporal language model analysis;temporal knowledge;temporal data;knowledge probes;temporal shift;temporal calibration;knowledge;diagnostic dataset;pretraining;better memorization;factual knowledge;lms;timestamp;future;new dataset;sensitive knowledge;text;time;ef\ufb01cient updates;adaptation;templama;evaluations;improvements;summary;acquisition;adaptation come;blank queries;qualitative analysis;part;single model"}, "9b1057e1f6eb17abf3962d6cd2f49468d27b94c6": {"ta_keywords": "emphasis translation system;speech translation systems;pause prediction;pause prediction model;prosodic emphasis;pauses;machine translation;emphasis;speech;level emphasis;target language;human listeners;translation;words;duration;communicating;word;human subjects;f0;example;overall gain;importance;power;active research target;vital element;paper;number;previous work;experiments", "pdf_keywords": ""}, "c985600f0aa223ddc76a2ea628f1fa23504dcbcd": {"ta_keywords": "field location guided target speech extraction;target speech extraction module;target speech extraction;promising target speech recognition results;end speech recognition objectives;speech recognition module;speech enhancement;automatic speech recognition;source separation;source separation systems;target speaker;anchor speech;anchor speech examples;separation objectives;asr error minimization criteria;transcription;auxiliary information;asr;speakers;location;word error rates;noise;permutation ambiguity;input;far;performance;mixtures;objective;end;system", "pdf_keywords": ""}, "0e141942fa265142f41a2a26eb17b6005d3af29e": {"ta_keywords": "linguistic diversity;language technologies;nlp world;nlp conferences;languages;different languages;language;resources;types;systems;inclusion;representation;current models;world;fate;terms;applications;disparity;paper;time;relation;small number;trajectory;status;state;quantitative investigation;question", "pdf_keywords": "nlp conferences;languages;nlp technology;language disparity;language;rich languages;language technologies;different languages;poor languages;embeddings analysis;wikipedia;conferences;taxonomical hierarchy;many resource;typological features;classes;resources;resource;web;individual resource availabilities;types;class;systems;current models;terms;representation;interesting insights;ldc;history;acl"}, "683e201783bf76ab99791a02e3763fd3ab8dad96": {"ta_keywords": "named entity recognition;entity recognition;deep active learning;labeling data;deep learning;active learning;deep neural networks;large public datasets;training data;smaller amount;large budget;state;work;result;classical methods;art", "pdf_keywords": "lightweight deep neural network;word encoders;long short term memory;lstm;lstm architecture;active learning;new cnn;convolutional word;tag decoder;lstm model;practical active learning algorithms;sequence tagging;ner task;cnn;convolutional character;active learning algorithms;ner;level encoder;many dnn;tags;words;characters;features;word;standard supervised fashion;character;less data;models;lightweight architecture;sequences"}, "e318e554098224c9475dfc80765cbbb82fa4a409": {"ta_keywords": "ai collaboration pipeline;peer review;science dissemination;ai;ml conferences;artificial intelligence;fifth aaai conference;research;tools;science;submissions;human decision;academia;human;makers;experimental procedure;efficient manner;decades;ways;thirty;sustainability;backbone;novel;issues;number;rapid growth;call;primary mechanism", "pdf_keywords": ""}, "8c9033f976e7787dde9af5ba952d7f9ac9c34496": {"ta_keywords": "evolving data streams;ensemble outlier detector;outlier detection;streams;outlierness;outlier detection problem;stream;xstream;extreme streaming setting;feature;life datasets;density;dimensionality;incoming update;granularities;space;row;art detectors;state;noise;modest space;algorithm;scenarios;distance;time;dimensions;competition;solution;projections;experiments", "pdf_keywords": ""}, "36cbc3c24429ba3b69def38e6e64b41485b0a023": {"ta_keywords": "available general web crawl;large web corpus;tokens;commoncrawl;creativecommons license family;urls;languages;date", "pdf_keywords": ""}, "119c33321fc0e1db837ce293f1b65cc26c1cc34e": {"ta_keywords": "key sentence matching;key sentences;sentence templates;article reranking;novel reranker;lexical information;semantics;event information;article fact;debunk claims;events;articles;event;fact;explanations;human evaluation;matching;pattern information;claims;article;memory;patterns;checks;mtm;claim;regression;world datasets;transformers;transformer;paper", "pdf_keywords": "key sentence matching;article reranking;claim detection;novel reranker;key sentences;knowledge engineering;false claims;fact;event information;intelligent information processing;\ufb01rst chinese dataset;matching;articles;diverse sources;checked claims;event;data engineering;observations;pattern information;social media;model mtm;mtm;sciences 2university;memory;candidates;xirong li3;key laboratory;xueyao;abstract;memoryenhanced transformers"}, "708dcd8456426cd609c89a86344e0007c04c80bf": {"ta_keywords": "multilingual factual knowledge retrieval;multilingual benchmark;factual knowledge retrieval;multilingual lms;language models;several benchmark languages;pretrained language models;diverse languages;many languages;language variations;different languages;factual representation ability;factual knowledge;english;access knowledge;knowledge;lms;code;punta cana;style probes;switching;algorithms;blank questions;effectiveness;ability;studies;methods;method;style fill", "pdf_keywords": "crosslingual factual retrieval benchmark;new multilingual benchmark;multilingual benchmark;multilingual lms;several benchmark languages;factual knowledge retrieval;multilinguality;diverse languages;different languages;languages;factual knowledge;access knowledge;knowledge;lms;results;code;switching;prediction;style probes;algorithms;task;conclusion;intersection;ability;effectiveness;experiments;dif\ufb01culty;method"}, "db0c587111cfed85dcea413e385b17881e6e0cbb": {"ta_keywords": "neural network language model;speech recognition performance;covariance matrix adaptation;language models;term memory;structure discovery;lstm;parameter tuning;neural network;evolution strategy;parameter optimization problems;improved recognition performance;optimization;cma;parameters;other black box;computational time;computational time reductions;wise unit types;pareto;initial baseline system;layer;es;robustness;generations;relative wer;wer;configuration;method", "pdf_keywords": ""}, "3b30422b372040ad19a713b35006c21808287720": {"ta_keywords": "optimal erasure codes;erasure codes;storage systems;storage;storage space;practical msr codes;popular rs codes;fault tolerance;rs codes;replication;network resources;unavailable data;network transfers;reliability;codes;reconstructions;reconstruction;network;data;regeneration;os;solomon;optimality;reed;rs;significant savings;msr;design results;alternative;superior alternative", "pdf_keywords": ""}, "6fa7de6f3ce3a599de6fab273a0d43939e176e9d": {"ta_keywords": "navigation agent;autonomous behavior;assistant;agent;assistance;tasks;simulated human;subtasks;general interactive framework;navigation problem;learning;useful information;information;responses;policy;context;humans;unseen environments;rich forms;success rate;process;advantage;method;place;benefits;challenges;framework;rich;decision;practicality", "pdf_keywords": "assistant;human assistance;agent;elicit information;agents;tasks;simulated human;assistance;general interactive framework;interactive framework;communication;subtasks;humans;actions;information;speaker problem concerns;listener problem;pomdp;context;speaker problem;responses;useful information;navigation problem;policy;process;solutions;challenges;rich forms;framework;fundamental problems"}, "48e4ba2d04bd98843d5aab6e227b29584d63f7b6": {"ta_keywords": "crowdsourcing taxonomies;popular russian linguistic resource;crowdsourcing;linguistic resources;cooperation;gamification;motivated people;survey;existent genres;data;evidence;use;recommendations;example;such approaches;efficiency", "pdf_keywords": "crowdsourcing taxonomies;popular russian linguistic resource;crowdsourcing;linguistic resources;cooperation;annotated examples;crowd;team member;keywords;dmitry ustalov;team;dmitry;russia;user activity;krasovsky institute;contributions;existent genres;survey;abstract;gami\ufb01cation;games;evidence;work;mechanized labor;purpose;si;results;number;mathematics;use"}, "43a87867fe6bf4eb920f97fc753be4b727308923": {"ta_keywords": "efficient transfer learning methods;text classification benchmarks;machine translation;tuning methods;modifications;less parameters;text summarization;models;new parameter;tasks;modification;transfer;strong performance;efficient fine;language understanding;parameters;model;previous methods;parameter;comparable results;design elements;tune;model size;recent work;unified view;unified framework;important design choices;design dimensions;paper;art parameter", "pdf_keywords": "large pretrained language models;nlp benchmarks;machine translation;efficient transfer learning;ef\ufb01cient transfer learning methods;nlp;general language understanding;text summarization;downstream tasks;text classi\ufb01cation;iclr;less parameters;tasks;variants;variant;ef\ufb01cient tuning methods;parameter;pre\ufb01x tuning;tuning;critical design choices;taylor berg;results;cl;unified view;unified framework;general framework;paper;methods;conference paper;abstract"}, "3e24375a1810375183d47ceadc7418e94533ba5f": {"ta_keywords": "novel online scheduling algorithms;fair online allocation;online allocation;electric vehicle charging;electric vehicle;perishable goods;perishable resources;offline settings;computational power;empirical performance;agents;energy;trade;different objectives;offs;time;application;terms;analyse;theoretical properties;main application;mechanisms", "pdf_keywords": ""}, "b63b698d177ba2861fe97d23763d66324bb1236a": {"ta_keywords": "defective m2 ion channel activity;efficient viral replication;m2 ion channel activity;viruses;ion channel activity;m2 protein;virus;m2 transmembrane domain;cell culture;mutants;type virus;chimeric mutant;hemagglutinin glycoprotein;mutant;transmembrane domain;cytoplasmic domains;mice;replication;growth;assay;function;activity;apparent loss;direct support;multiple cycles", "pdf_keywords": ""}, "dcd39e2eb27d17c369f3bf7a5a7a2a30bb9201c8": {"ta_keywords": "language models;unlabeled text data;artificial datasets;artificial dataset;semantics;datasets;explicit dependencies;downstream tasks;implicit dependencies;exceptional downstream performance;tokens;pre;transferability;downstream fine;token;sequence;lms;tuning;specific traits;model;lm;counterparts;study;length;scratch;different characteristics;presence;effect;scale;work", "pdf_keywords": "language models;token dependencies;english downstream performance;downstream tasks;natural language;certain human language;semantic features;explicit dependencies;implicit dependencies;transferability;mlms;mlm pre;tokens;arti\ufb01cial datasets;positive transferability;transformer lms;unlabeled text data;downstream \ufb01ne;tasks;arti\ufb01cial dataset;exceptional downstream performance;lms;token;certain arti\ufb01cial datasets;sequences;sequence;model;abstract;pre;tuning"}, "c6af1ad95917badd7bc65b303a40f54950360279": {"ta_keywords": "statistical dialog managers;statistical dialog manager;conventional statistical dialog approaches;dialog manager;automobile dialog scenario;more robust decisions;bayes decision theory;task completion;speech recognition;natural language understanding;inefficient actions;penalizes system actions;regularization cost;system actions;rule;task;uncertainties;efficiency cost;parts;destination;cost function;system;parameters;limited data;errors;fewer turns;method;large number;counterparts;paper", "pdf_keywords": ""}, "595306f993993e44e2c2f674367103f44df03d9b": {"ta_keywords": "resource machine translation;unsupervised machine translation framework;machine translation;translation quality;translation baselines;resource translation;monolingual data;generalized data augmentation;resource language pairs;data augmentation;data augmentation techniques;resource language;resource words;resource datasets;resource data;parallel data;available resources;resource settings;low;fluency;paucity;bleu points;extensive experiments;target;challenges;side;best use;true distribution;step;general framework", "pdf_keywords": "resource machine translation;resource translation;machine translation;monolingual data;induced bilingual dictionary;resource languages;generalized data augmentation;highresource language;data augmentation;hrl sentences;resource mt;resource data;translation;lrl words;available resources;related lrl;graham neubig language technologies institute;concatenation;hrl;lrl;hrls;sle;lrls;information;abstract;low;terms;target;true data distribution;xiangk"}, "5d6f87e31d806a77d22e344106d0310be3342259": {"ta_keywords": "randomized reviewer assignments;reviewer assignment;conference peer review;malicious reviewer;peer review;reviewers;reviewer;total optimal similarity;torpedo reviewing;positive reviews;certain papers;assignment;assignments;algorithms;assignment code;manipulation;assignment problem;past conferences;algorithm;constraints;similarities;paper;paper pair;datasets;authors;challenges;part;order;release;important challenges", "pdf_keywords": "reviewer assignment;reviewer deanonymization;peer review;malicious reviewer;peer review process;total optimal similarity;reviewer pair;untruthful favorable reviews;reviewers;reviewer;total similarity;empirical evaluations;algorithms;assignment data;overall algorithm;assignments;assignment;assignment problem;algorithm;academic conferences;papers;datasets;same paper;paper pair;past conferences;paper;constraints;such challenges;challenges;same subset"}, "68d0b245e9754de9f36cba305e4ce50ff868cb6a": {"ta_keywords": "combinatory categorial grammars;combinatory categorial grammar;grammar induction algorithm;simple robust grammar induction;grammar;general linguistic principles;categories;simple em;longer sentences;prior language;ccgs;specific knowledge;ccg;other systems;other approaches;state;approach;minimal number;art performance;previous work", "pdf_keywords": ""}, "7cc74ffa1215321712d4a830bb9dee19d9f0fb47": {"ta_keywords": "question answering models;question answering;grounded graph decoding;compositional generalization;compositional freebase questions;language representations;structured predictions;graph decoding;input syntax context;novel compositions;cfq;syntax information;structured graph;generalization;grounding;attention mechanism;end models;training patterns;challenging benchmark;input;longer sequences;query clauses;complex inputs;complex test structures;conjunctions;dataset;question;model;art baselines;group", "pdf_keywords": "conjunctive query graph decoder;semantic composition;semantic compositions;grounded graph decoding;novel complex sparql queries;syntactic composition;compositional generalization;natural language questions;graph decoder;language representations;structured predictions;conjunctive queries;compositional freebase questions;learnable vector embeddings;conjunctive query;semantics;sequence encoder;cfq;generalizable predictions;attention mechanism;challenging benchmark;competitive baselines;graph;models;vector addition;art baselines;question;speci\ufb01c models;dataset;generation"}, "ee3ce47b79917974d30b6eeaaeeba99f1b1a5c59": {"ta_keywords": "decoding strategies;task learning;espnet;end asr;auxiliary loss;transducer;benchmarks;datasets;task;performance;end;models;systems;librispeech;pos;architecture;different auxiliary criteria;speed;various archi;use;conformer;strategies;art systems;powerful systems;tectures;own proposition;study;other state;sibility;regards", "pdf_keywords": "espnet speech recognition toolkit;external language model;espnet;transducer models;decoder part;time decoding;language model;encoder part;auxiliary tasks;lm tasks;promising performance;models;performance;ctc model;ctc;features;task;speed;others models;transfer;extension;llm;lctc;particular model;systems;work;experimental evaluation;paper;other techniques;state"}, "5f96e3e00b36c5eeebff09a1bf4c804bd4ce4620": {"ta_keywords": "malicious sensors;quickest attack detection problem;remote state estimation;linear attack scheme;remote estimator;false data injection attack;false alarm constraint;detection delay;noisy linear observations;constrained markov decision process;attack;quickest detection;probability belief;estimator;gaussian noise;observations;optimal policy;random time;state;estimates;time linear process;system;challenge;threshold;order;set;paper;presence", "pdf_keywords": "quickest attack detection problem;linear attack scheme;linear attack;remote state estimation;attack initiation instant;false data injection attack;remote estimation;detection delay;remote estimator;constrained markov decision process;quickest change detection algorithm;attack;noisy linear observations;fdi attack;quickest detection;false alarm constraint;timescale stochastic approximation;bayesian;gaussian noise;simultaneous perturbation stochastic approximation;observations;probability belief;estimator;algorithm;constant threshold;spsa;time linear process;sy;state;mdp"}, "64a106b707586345a055aa22c3356c4dc3d01877": {"ta_keywords": "network dynamics;germany network dynamics;event timing patterns;inferring network connectivity;computational neuroscience;dynamics;complex systems;theoretical physics;max planck institute;advancing electronics dresden;bccn;physics;dresden;germany advanced study group;mpids;organization;germany bernstein center;institute;self;germany;technical university;cfaed;g\u00f6ttingen;marc timme chair;center;jose casadiego;dimitra maoutsa", "pdf_keywords": ""}, "d5a95567e079685322cd485033d334284c4b0a62": {"ta_keywords": "reversible polymerization systems;reversible polymerization approaches;reversible polymerization;controlled polymerization systems;polymerization systems;polymerization;vinyl polymers;polymer materials;reversibility;polymer scientists;degradability;biomedical applications;environmental sustainability;recent developments;property;future directions;variety;unprecedented rates;structure;applications;utility;recent progress;recent years;perspective;current challenges;insight;promise;new opportunities;problems;general concern", "pdf_keywords": ""}, "f16cf130ae75d1ea1ad3b926f605adef41af4af1": {"ta_keywords": "conservation based uncertainty propagation;uncertainty propagation;las vegas uncertainty;conservation laws;dynamic systems;robust control design;prior distribution;probability structure;conservation;transportation systems;generalized theory;financial markets;initial condition;everyday decision making process;universe;physics;fundamental concepts;method;structure;nevada;methods;computer engineering university;electrical;understanding;first steps;terms;perfect sense;addition;examination committee chair professor;development", "pdf_keywords": ""}, "b13e9d23983273c0c67b91ae70c55d4c3f745b8b": {"ta_keywords": "neural machine translation;simultaneous translation;outputs translation words;conventional machine translation methods;delay;beam;nmt;agent;input sentence;nmt environment;simultaneous mt setting;search applicable;interaction;time;various targets;decisions;quality;challenging problem;framework;method", "pdf_keywords": "neural simultaneous machine translation;formulating translation;translation;nmt;nmt system;learning algorithm;german;write;conventional segmentation methods;write decisions;read;interleaved sequence;optimization criterion;algorithm;en;englishrussian;strong improvements;actions;target delay;ru;model;de;paper;uni\ufb01ed design;in\ufb02uence;trade;method;directions;framework;quantitative results"}, "ed1c17451a23471afde91c109ecadc6aab8b2ba6": {"ta_keywords": "multimodal disinformation detection;disinformation detection;disinformation;textual content;propaganda;videos;fake news;misinformation;text;modalities;multiple modalities;time images;different modalities;video;factuality;more attention;images;harmfulness;temporal information;different research communities;popularity;simple text;current challenges;art;network structure;audio;proliferation;survey;future research directions;recent years", "pdf_keywords": "multimodal disinformation detection;multimodal factuality prediction;harmful content detection;multimodality;multimodal;disinformation online;disinformation;harmful factual;modality;speech;content signals;harmfulness;modalities;text;harm;audio;images;different modalities;temporal information;video;factuality;intents;image;7facebook ai;propaganda;information;tanmoy chakraborty3;stefano cresci2;research;temporal"}, "8c838c7631a7408d5ea5801c9360213782665c9c": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "db1dafd0c356491cbbf53338b9984de324e7239c": {"ta_keywords": "bilingual lexicon induction;bilingual lexicons;unaligned word embeddings;languages;isometric assumption;distribution matching;isometry;spaces;bliss;novel hubness filtering technique;assumption;recent work;bli;question;larger set;technique", "pdf_keywords": "bilingual lexicon induction;bilingual lexicons;distant language pairs;language pairs;unaligned word embeddings;translation loss;merous language pairs;unsupervised counterparts;weak orthogonality constraint;different supervised loss objectives;distribution matching;orthogonality assumption;instantiations;bliss;isometric assumption;constraint;alignment;shortcomings;bli;muse datasets;datasets;above observation;limitations;state;larger set;best model;methods;framework;technique;form"}, "9bb9b23823b45ba7521d872bb3e970ede4aafb8a": {"ta_keywords": "joint speaker diarization;speech recognition;region proposal networks", "pdf_keywords": ""}, "41675d91ad815f64b0df382c0944247811a62cc9": {"ta_keywords": "statistical machine translation;joint phrase alignment;bilingual phrases;phrase table;machine translation systems;phrase extraction approach;parallel corpus;step word alignment;several language pairs;phrases;sentences;phrase;word level;method phrases;many granularities;granularity;extraction;list;accuracy;model;level;key contribution;work;center;previous methods;method;experiments;fraction;original size", "pdf_keywords": ""}, "1fc6290fa3e6784501ca67cbef33a6a8edcbdb9e": {"ta_keywords": "wasserstein distance;empirical measures;empirical measure;probability measures;measures;measure;closeness;statistics;metric space;sample rates;independent samples;convergence;machine learning;sample results;probability;existence;approaches;different rates;order;applications;fundamental question;work", "pdf_keywords": "wasserstein distance;empirical measures;empirical measure;general measures;measures;probability measures;measure;general compact metric spaces;closeness;convergence;metric space;statistics;sample rates;machine learning;sample results;di\ufb00erent rates;technology inria;massachusetts institute;existence;probability;applications;rate;math;ens;abstract;pr;order;jul;fundamental question;work"}, "f5b6819e05e087d2bbae3ddb6d58d2ab4e1d7ca2": {"ta_keywords": "inverse reinforcement learning;environment reward;reinforcement learning;contextual bandit orchestrator;ai agents;environmental rewards;constrained policy;reward;bandit;agent;policy orchestration;agents;environment;pac;policies;constraints;algorithms;demonstrations;constraint;ethical values;implicit constraints;unspecified constraints;orchestrator;best actions;novel approach;complex ways;values;novel ways;set;society", "pdf_keywords": ""}, "bfb13c6889626e833bf449fdb361d186467919af": {"ta_keywords": "feature feedback;feature feedback methods;supplemental annotations;auxiliary annotations;domain evaluations;sentiment analysis;domain evaluation;intuitive appeal;domain datasets;findings;salient evidence;alternative benefit;sample gains;attempts;spurious patterns;holdout sets;domain;experiments;data;significant gains;sample;recent works;gains;test;practical benefits;training;methods;myriad mechanisms;efficient algorithms;sensitivity", "pdf_keywords": "feature feedback;sentiment analysis dataset;supplementary annotations;sentiment analysis models;sentiment analysis;domain accuracy;nlp;domain datasets;domain tests;datasets;classify;nli;models;domain bene\ufb01ts;imdb data;primary aim;domain;empirical study;data;performance;improvement;test;vanilla counterparts;cad;techniques;spurious patterns;collection;primary research questions;methods;table"}, "df9949abc06cb4f0f4c0ac1eb7ce0bc62ed5ec02": {"ta_keywords": "phoneme sequence estimation;phoneme sequences;word segmentation;word sequence list;pointwise phoneme sequence estimator;pointwise word segmenter;corpus;phoneme estimation;gram model;phoneme pairs;japanese tts front;sentences;various language resources;compound words;sequences;sequence;input sentence;example;word;tts front;unsegmented list;few words;tasks;end;accuracy;pointwise approach;results;framework;approach;paper", "pdf_keywords": ""}, "5331a846c854c3ecedf9ecf3ea516cb6dcaba4c8": {"ta_keywords": "saliency methods;synthetic evaluation tasks;synthetic evaluation framework;predictive reasoning;feature attribution tools;model reasoning;underlying model reasoning;smerf;input image;evaluation;accurate method evaluation;model;relative simplicity;truth;experimental evaluations;lack;complexity;development;ground;work;popular class;significant limitations;adoption;access", "pdf_keywords": "saliency methods;leading saliency methods;simulated model reasoning evaluation framework;model reasoning;world object detection tasks;natural images;perspective;complex model reasoning;reasoning;feature attributions;object detection problems;conditional reliance;model;game evaluations;image;tasks;synthetic framework;evaluation;smerf;performance;full reliance;complexity;aforementioned limitations;fact;figure;work;simple;reliance;truth;plexity"}, "807600ef43073cd9c59d4208ee710e90cf14efa8": {"ta_keywords": "neural information retrieval;retrieval models;information retrieval models;diverse text retrieval tasks;retrieval systems;information retrieval;theart retrieval systems;heterogeneous evaluation benchmark;heterogenous benchmark;beir benchmark;benchmarking;generalization capabilities;available datasets;shot evaluation;ir;beir;careful selection;models;insights;generalizable systems;ood;effectiveness;researchers;progress;zero;considerable room;future;other approaches;domains;improvement", "pdf_keywords": "information retrieval models;diverse text retrieval tasks;retrieval datasets;neural information retrieval;news retrieval trec;entity retrieval dbpedia;theart retrieval systems;heterogeneous benchmark;query docs dbpedia articles;query natural query docs wikipedia articles;iryna gurevych ubiquitous knowledge processing lab;query docs;medical query pubmed articles;news query news articles;query financial query docs investment articles;ir;available datasets;query news headline docs twitter tweets;generalization capabilities;beir benchmark;datasets;diverse tasks;insights;medical ir trec;query nutrition facts docs pubmed articles;news headline news articles;model generalization;models;query argument docs idebate arguments;wiki"}, "3a40cdd82f0706cda6c247e586d5054abeab4e1f": {"ta_keywords": "list question answering;automatic set expansion;extended list;list;new list;candidate answers;qa system;qa;resistant se algorithm;original list;answers;entities;expansion;small set;additional members;seeds;textual resources;certain class;class;answer;se;hypothesis;noise;paper;question;use;mine", "pdf_keywords": ""}, "2c3d02ce8780cc6648caf4ee996d9628c6388751": {"ta_keywords": "regularized minimax conditional entropy;real crowdsourcing datasets;minimax conditional entropy principle;crowdsourcing;unique probabilistic labeling model;data labeling;labels;objective measurement principle;ordinal labels;ground truth;item difficulty;principle;worker ability;paper;variety;only method;method;interest", "pdf_keywords": "regularized minimax conditional entropy;minimax conditional entropy;minimax conditional entropy principle;real crowdsourcing datasets;probabilistic labels;unique probabilistic labeling model;crowdsourcing;data labeling;multiclass labels;labels;ordinal labels;crowd;ground truth;dual form;over\ufb01tting;principle;item di\ufb03culty;abstract;variety;worker ability;paper;interest;section;method;mar"}, "ce5ff42d629e67a84731b3c62b57b47fc7f2b20d": {"ta_keywords": "attention network;monotonic chunkwise attention;transformer encoder;automatic speech recognition;e2e asr system;transformer decoder;neural transducer;ordinary batch transformer model;neural networks;attention;transformer self;block processing;librispeech english task;transformer;asr;entire input sequence;speaker attributes;e2e;local acoustic information;block processing method;block;channel;transformer outperforms;additional training;knowledge distillation technique;training;blockwise;additional context;promising performance;context", "pdf_keywords": "streaming transformer asr;attention network;blockwise synchronous beam search;automatic speech recognition;monotonic chunkwise attention;e2e transformer asr;synchronous beam search algorithm;beam search;encoder;neural networks;japanese tasks;transformer algorithm;attention;entire input sequence;transformer self;transformer;transformer outperforms;asr;feature blocks;blockwise processing;target attention;shinji watanabe2;block;sequence;novel blockwise;response time;yosuke kashiwagi1;boundary detection technique;librispeech english;evaluations"}, "945d4addf8e94487f6199af71dc15a298791c1b4": {"ta_keywords": "infinite horizon markov decision process;markovian energy arrival processes;markovian channel;single energy harvesting source node;energy harvesting characteristics;optimal source node;learning algorithm;optimal status update policy;available energy;instantaneous channel quality;threshold policy;unknown channel state;decision variables;minimization;channel;mdp;policy structures;process;unknown dynamics;policy;aoi;performance trade;instantaneous age;stage action;time;source;buffer;theory;offs;problem", "pdf_keywords": "in\ufb01nite horizon markov decision process;markovian energy arrival process;markovian energy arrival processes;aoi minimization;aoi minimization problem;markovian channel;information minimization;energy harvesting;power selection;single energy harvesting source node;packet transmission energy;opportunistic sampling;markovian system model;transmission scheduling;optimal channel probing;energy harvesting source;average aoi expression;minimization;data transmission policy;mdp;optimal policy;remote sensing setting;\ufb01nite battery capacity;in\ufb01nite time horizon;minimal age policy;sampling;average aoi;learning algorithm;hop network;aoi"}, "27df24c537b2d3c2a769d917adf92a6a059c5917": {"ta_keywords": "fast multiscale modeling;multiscale modeling;multiscale simulations;multiscale systems;deeponet inference cost;deep neural operators;finite element methods;multiphysics systems;expensive solver;neural operator representation;refined discretization;standard pde solvers;unknown finescale dynamics;fine solver;models;heterogeneous descriptions;deeponet;efficient surrogate;neural operator;disparate size features;solver;various benchmarks;smoothed particle hydrodynamics;model;microscopic features;homogeneous features;mechanics problems;coupling schemes;continuum model;coupling algorithm", "pdf_keywords": "fast multiscale modeling;multiscale modeling;multiscale simulations;multiscale active force generation models;multiphysics systems;continuum model;\ufb01nite element methods;smoothed particle hydrodynamics;models;deep neural operators;neural operator representation;finite elements;deeponet inference cost;heterogeneous descriptions;uniaxial tension problem;machine learning;various benchmarks;expensive solver;coupling algorithm;mechanics problems;hyperelastic material;disparate size features;e\ufb03cient simulation;neural operator;fem;particle system;e\ufb03cient concurrent coupling framework;coupling schemes;engineering;computational cost"}, "46ef61536a01578e79b6d4e35e803a914afeb629": {"ta_keywords": "line emission intensity;tunability;solids", "pdf_keywords": ""}, "65ee083ce61576955d76b36819bf3ac271335597": {"ta_keywords": "optimal exact regenerating codes;exact regenerating codes;minimum storage point;storage systems;storage;peer systems;linear code;peer;erasure;minimum bandwidth point;mail;subspace;codes;exact regeneration property;node;reliability;server applications;bandwidth tradeoff;repair;uniqueness;data;additional property;sufficient conditions;explicit construction;paper;construction;parameters;techniques;approach", "pdf_keywords": "exact regenerating codes;code construction algorithm;storage systems;storage;erasure;mbr point;codes;mbr;subspaces;certain subsapce properties;new node;complexity;\ufb01eld size requirement;exact replica;node;reliability;following lemmas;paper;section;values;email;point;oct;techniques;notion;conclusion;alternative viewpoint"}, "092ee3a32b6cd951da971124a24872c7cccf3a9f": {"ta_keywords": "transductive transfer learning;unsupervised transductive transfer learning;transfer learning;protein name extraction;transfer;supervised version;target domain;training;related task;data;information;task;models;research;previous work;methods;approaches;challenging case;comparative study;important new area;current state;problem;performance;art", "pdf_keywords": ""}, "fce10a1a9727cbda33d44b62409e303f1009417a": {"ta_keywords": "recurrent neural network grammars learn;recurrent neural network grammars;probablistic generative modeling family;latent attention;attention mechanism;natural language;art language modeling;phrasal representation;rnng;linguistic perspective;syntax;head rules;headedness;predictions;model;data;ga;information;performance;hand;central role;various ablations;state;important differences;closer inspection", "pdf_keywords": "recurrent neural network grammars;syntactic derivations;rnng composition function;attention mechanism;phrasal representation;linguistic perspective;sentences;syntax;more interpretability;nonterminal category labels;inductive bias;rnngs;rnng;composition function;probability distributions;various ablations;model;ablation study;ablation scenarios;data;role;class;ga;information;\ufb01ndings;importance;novel variant;introduction;conclusion;individual heads"}, "49af035c598901fbf766da2cfb040cca7336a8ac": {"ta_keywords": "abstract meaning representation;semantic parsers map;dependency parse;such semantic formalism;greedy decoding;imitation;natural language statements;exploration;syntactic phenomena;exploration steps;representation;word senses;representations;concepts;ambiguous interpretations;large action;algorithms;context;anaphora;amr;noise reduction;accumulation;novel extensions;space;such errors;traditional manner;most information;systems;errors;graph", "pdf_keywords": ""}, "d47ad0a606bedf41dcea614bfa7b7494879c7ba0": {"ta_keywords": "open domain procedural text;procedural text;new task formulation;text;tracking entities;state change tuples;state changes;open vocabulary;entities;attributes;vocabulary;attribute;entity;dataset;state values;arbitrary domains;task;input;example;state;first dataset;set;previous formulations;fog removal;step;fidelity;car window;potatoes;location;solution", "pdf_keywords": "tracking entities;annotators;open domain procedural text;amazon mechanical turk;training dataset;dataset;general domain text;entities;quality dataset;procedural text;dataset openpi;\ufb01rst dataset;data collection;vocabulary;state changes;sentence template;task;sentence;examples;arbitrary domains;computer science;open domain;guide;cmu;human;nikett;keisukes;scale;yi;abstract"}, "188928df74f9ce00bd1b58686db93ac8cdd07275": {"ta_keywords": "faster beam search;speech recognition;multiple speech utterances;multiple utterances;beam search;right beam search algorithm;original beam search algorithm;speech;encoder decoder network;vectorization;batch;encoder decoder;rnnlm;parallelism technique;attention;speedup;search process;line recognition use;ov;multiple hypotheses;gpu;loop program;shallow fusion;processing unit;traverse;inference step;ctc;hypotheses;external modules;addition", "pdf_keywords": ""}, "2f369845ae7191196d65310210db2485feb3aa86": {"ta_keywords": "new g2p conversion training method;narrow adaptive regularization;phoneme conversion;robust g2p conversion;speech recognition field;learning rate;grapheme;weights;multilingual tasks;narow;input data;hyperparameters;algorithm;features;mistake bounds;domain;predecessor arow;objective;need;online", "pdf_keywords": ""}, "bd2f3822801a7e2f933d06c261b8783764d8ce18": {"ta_keywords": "text classi\ufb01cation model;hidden representations;adv attacks;ood datasets;adv samples;output probability distributions;anomalies;ood samples;observations;output probabilities;samples;exceptional results;classi\ufb01er;distribution;adv;model;deeper layers;analyses;input;ood;types;aberration;ones;id;performance;aspects;abnormalities;layer;method;paper", "pdf_keywords": "similarity score;adv datasets;id samples;hidden representations;adv samples;features;bow features;detection method;adv data;anomalies;separate ood samples;adv ones;separate adv;ood samples;observations;output probability distributions;model;id ones;id;output probabilities;aspect;ood;abundant experiments;output distribution;analyses;input;comprehensive analyses;different aspects;aspects;analysis"}, "576860f910ea8fde366deb03c910ab30cd776966": {"ta_keywords": "continuous speech separation;speaker inventory;long recording", "pdf_keywords": ""}, "95a35473fd1936927dd4a53fe0a5d2d6762d99b3": {"ta_keywords": "realistic neural audio synthesis;midi;musical notes;musical instruments;musical performance;realistic audio;fidelity audio;expressive performance;musical expression;detailed control;synthesis;interpretable differentiable digital signal processing;notes;hierarchical modeling;synthesis parameters;novel note sequence;timbre;creative assistance;articulation;performance;note sequence;listening tests;detailed user control;performance attributes;hierarchical model;control;level hierarchy;level properties;ddsp;hierarchy", "pdf_keywords": "realistic neural audio synthesis;realistic audio synthesis;hierarchical music modeling system;midi;musical notes;musical performance;musical instruments;hierarchical generative model;level synthesis parameters;synthesis levels;synthesis;music;synthesis parameters;different instruments;expressive performance;audio;timbre;interpretable differentiable digital signal processing;notes;articulation;hierarchical model;performance;detailed user control;generation;note expression;ddsp;level properties;control;realism;single model"}, "55a3b36fd21dbbe9384ab3ba1bcf901235d95f47": {"ta_keywords": "unsupervised question decomposition;question answering;questions;existing qa systems;unsupervised approach;qa;decompositions;heuristic decomposition methods;answers;hard questions;recomposition model;onus;shelf qa model;question;algorithm;different kinds;fluency;millions;methods;utility;final answer;internet", "pdf_keywords": "supervised question decompositions;machine translation;ton unsupervised sequence transduction;qa system;best qa approach;qa;heuristic decomposition methods;questions;answers;hidden test evaluation;decomposition;shelf qa system;recomposition model;dev evaluation;common crawl;shelf qa model;onus;stages;artetxe;conclusion;mining;methods;question;\ufb01nal answer;classi\ufb01er;different kinds;common approach;utility;xu;koehn"}, "e153713b0423b4bae325340b2211e704effd5252": {"ta_keywords": "augment logic programs;inductive logic programming;description logics;abstract logical representation;fault density;counting clauses;algorithms;counting;flipper;software;ilp systems;ilp;numerical metrics;prior knowledge;number restrictions;clauses;methods;systems;performance;class;foil;extensions;possible hypotheses;reasons;hypotheses;bias;large space;extension;analysis;automated fashion", "pdf_keywords": ""}, "e718ffe247a61a77b45953a7e8a5b86a45ed579f": {"ta_keywords": "dependency parsers;dependency parser;annotated corpora;dependency tree;art dependency parsers;japanese dependency;annotated data;corpora;available linguistic resources;new training data;maximum spanning tree;sentence;mst;rapid training;ofthe;accuracy;effective use;costs;edge;approach;reduction;pointwise approach;state;experiments;show", "pdf_keywords": ""}, "84e50df18c284b985d287b462c63c20186cc5da1": {"ta_keywords": "cognitive tutors;ai programmers;simulated student;programming;cognitive model;demonstration;educators;study;target task;agent;authoring;task;technique;steps;production rules;algebra equation;evaluation;pbd;machine;authors;author;shows;tool;wrong production rules;performance;example domain;aim", "pdf_keywords": ""}, "efada589efdb0adf3aa9dc2b6cb6979a50658276": {"ta_keywords": "rumour debunking;article headline stance;associated news articles;digital journalism project;natural language processing tasks;veracity;headline;journalists;claims;fact;claim;logistic regression classifier;article;world data source;associated article;novel data;stance;features;dataset;emergent;context;data;checking;task;agreement;purpose;estimation;variety;set;respect", "pdf_keywords": ""}, "3c6407554fb4ee599f42501cf5cba8fcefa88783": {"ta_keywords": "automatic speech recognition;unpaired data training scenario;raw speech signal;speech encoder state sequence;pronunciation dictionaries;speech utterances;audio data;transcriptions;asr systems;unpaired data;speech;consistency training;asr;word error rate;librispeech corpus show;consistency losses;language;data;unsupervised data;text;models;expert knowledge;tts;loss;reverse operation;example;cycle;end;hour;hours", "pdf_keywords": "automatic speech recognition;transcriptions;audioonly data;language model;librispeech corpus;consistency training;audio data;training data;encoder;word error rate;asr model;asr;validation accuracy;consistency loss;unpaired data;tte;tacotron2based text;models;model;attention;differentiable loss;data;shallow fusion technique;development data;cycle;end;consistency manner;hour;lm;hours"}, "b568c562fcfad8d7a943a9ea63aca36c487b6d7d": {"ta_keywords": "counterfactual target label;natural language inference tasks;natural language processing;indirect causal effects;spurious associations;classifiers;spurious features;causality;spurious patterns;sentiment analysis;training models;unnecessary changes;language;vice;internal coherence;genre;initial labels;original data;alarm;resources;data;models;term;documents;common cause;machine;coherent meaning;document;mentions;ii", "pdf_keywords": ""}, "afa9364ec48e38d19099cfc22ac9cb679c4baa39": {"ta_keywords": "multimodal language models;gender biases;biases;intraand intermodality associations;bias analysis methods;language models;stereotype;multimodal settings;visual scene;biases compound;bert;less attention;text;vision;models;vl;worlds;numerous works;work", "pdf_keywords": "gender biases;gender bias;linguistic models;gender information;language models;multimodal language models;gendered entities;language context;bias sources;different genders;intermodality associations;gender;bias;biases;bias analysis methods;visual contexts;language;word predictions;masked language modeling head;linguistic pretraining;language input;visual context;stereotypes;model predictions;models;multimodal setting;sources;text;model;popular visuallinguistic transformer"}, "8b5071a38718194063cf17ca446ba8d9f4907a18": {"ta_keywords": "natural language processing tasks;deep learning models;words models;dropout;simple deep neural network;sentiment analysis;word order;compositionality;aware models;such models;input;tasks;syntax;significant improvements;inputs;factoid question;many expensive computations;network;model;previous bag;similar errors;novel variant;training time;cases;fraction", "pdf_keywords": ""}, "4240d8e1e5c2ef82d62ba9d7bb323c357c718c1c": {"ta_keywords": "efficient topological layer;novel topological layer;topological features;persistence landscapes;general persistent homology;persistent landscapes;layer inputs;layer;subsequent layers;networks;general deep learning models;input data structure;learnability;arbitrary filtration;network;filtration;input data;pllay;dtm function;novel adaptation;stability analysis;noise;outliers;differentiability;critical information;work;task;respect", "pdf_keywords": ""}, "1678eccf0f3895dbea6dfac44fc9d4f86de15ff6": {"ta_keywords": "affective conversation;emotion trigger;affective communication;emotional reaction;emotional triggers;emotion;conversational partner;online conversation;human interaction;prediction;utterances;person;response;recognition;reaction;speaker;interest;role;simulation;ability;study;paper;addition;first place;previous works;issue;traditional works", "pdf_keywords": ""}, "751816df0027c0ae6c337ba392a5447bef86ca77": {"ta_keywords": "phase oligothiophenes;excited state energy;transfer learning;transfer learning models;oligothiophenes;state energies;polymers;p3ht;state energy distributions;optoelectronic properties;crystal;oligomers;training data;tddft calculations;experimental absorption spectra;neural networks;machine learning;short oligomers;sufficient training data;chemistry;transferability;hexylthiopnene;transfer;data;solution phases;ml;remarkable progress;data scarcity issue;average error;difficulty", "pdf_keywords": ""}, "a4577911d247e472772e2101d21aeaf8f46053cc": {"ta_keywords": "semantic parsing;synchronous grammars;free grammars;grammars;ambiguous input;natural language;ambiguous paraphrase;ambiguity;synchronous context;target string;multiple strings;nl;sentence;processing;scfgs;formalism;traditional scfgs;meaning representation;concrete approach;multi;sp;framework;mr;target side;column;paper;applications;new variety;new method;problem", "pdf_keywords": ""}, "fdb3969b654ab01be1807bbf84707a80e6283a52": {"ta_keywords": "synthesis information;materials science synthesis procedures;synthesis procedures;computational synthesis planning approaches;analogous synthesis planning methods;materials science journal articles;procedural text;organic chemistry;experimental syntheses;structured representations;inorganic compounds;inorganic materials;structured representation;action graphs;unsupervised approaches;generative model;texts;structures;supervised learning;scientific entities;articles;text;strong heuristic baseline;expert;research;nature;results;directions;data;events", "pdf_keywords": "entity extraction;ary relation extraction;structured neural network model;structured representations;scienti\ufb01c entities;token representations;entities;material science text;neural network models;structured representation;chain crf models;neural network;generative model;single neural network;texts;unsupervised approaches;materials science journal articles;procedural text;models;small training dataset;chain crf;inorganic compounds;classic linear chain crf model;ner task;different neural network architectures;event chains;inorganic synthesis routes;logistic regression;articles;formalizations"}, "19f727b7a42a21bc3f99536e8368029f4b9b8e14": {"ta_keywords": "mapping noun images;foreign language lexical resource;bilingual dictionary;lexical resource;foreign language;natural languages;nouns;annotated collection;art;word senses;photography;uniform language;drawing;meanings;pictures;such pictures;tagbag;usage;paper;things;study;such forms;order", "pdf_keywords": ""}, "97ef5081aa4e2984c16ea78b862266e4852c7faf": {"ta_keywords": "real world email data;activity management;email messages;email;ongoing activity;activity;folders;tasks;novel tasks;link analysis method;novel task;folder;task;inverse task;do item;messages;ongoing project;future involvement;enterprise;empirical evaluation;graph;space model;potential utility;vector;persons;multiple choice", "pdf_keywords": ""}, "af034b0e893a0a24e41cdb54afb35d4250407f50": {"ta_keywords": "international speech communication association;interspeech;13th annual conference;oregon;portland;usa;september", "pdf_keywords": ""}, "7657b56d2ac9269b32e8bcbe2a20f99ea17afe09": {"ta_keywords": "statistical voice timbre control technique;statistical voice conversion;voice conversion;voice characteristics;singing voice;voice timbre;gaussian mixture model;voice;singer individuality;singers;singer;perceived age;age control;direct waveform modification;dependent modeling;differential models;dependent spectrum;regression;age;gender;listener;gmm;spectrum;understandable measures;varieties;physical constraints;technique;mr;method;svc", "pdf_keywords": ""}, "869d53277b0ec5e47a30b874aeb157df88649ea0": {"ta_keywords": "\u7b2c11\u56de\u97f3\u58f0\u8a00\u8a9e\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "bff4d630cbea6a90b149b28caff5489c1a4ccaad": {"ta_keywords": "language model estimation;stochastically tagged corpus", "pdf_keywords": ""}, "7e0342b304ca8ce564a664eb17e85358b07488fe": {"ta_keywords": "noise mixture model estimation;unsupervised joint speaker adaptation;noise mixture model;speaker adaptation;noise suppression;accurate noise model;unsupervised estimation method;speaker characteristics;joint processing method;joint processing;mmse estimates;estimation;vector taylor series;nonlinear transformation;vts;accurate parameters;model;variation;approach;crucial problem;paper;influences;former problem;crucial factor", "pdf_keywords": ""}, "fcdac45272543b4f8b8eaa59d66044d1b7018494": {"ta_keywords": "neural machine translation;better final translation models;translation model;better translation quality;translation;pseudoparallel data;validation set;nmt;back;diverse data;performance;stronger results;quality;novel method;algorithm;effective strategy;several recent works;paper;method", "pdf_keywords": "neural machine translation;many translation tasks;translation model;multilingual translation;translation;ground truth parallel data;multilingual setting;yiming yang1;metabt;training data;2google ai;nmt;forward model;bt;large models;iclr;backward model;standard nmt setting;back;improvements;performance;brain team;abstract;base model;evaluations;set;mountain view;feb;transformer;novel method"}, "e8f42dd98d7f546036fa4a1109c3fe3dd98f9647": {"ta_keywords": "natural language argument;argument reasoning comprehension;argument reasoning comprehension task;argument component identification;argument comprehension;abstractive argument summarization;other argumentation;authentic arguments;news comments;scalable crowdsourcing process;language understanding;logic skills;language models;stance detection;neural attention;correct implicit reasoning;common sense;task;tasks;new task;empirical common ground;dataset;claim;2k;reason;results;quality instances;article;goal;capability", "pdf_keywords": ""}, "4358335263622fe189cf95c613f4d6fdcb67fbea": {"ta_keywords": "\u7b2c16\u56de\u97f3\u58f0\u8a00\u8a9e\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0", "pdf_keywords": ""}, "03fff40cff6ac531e340f6ffb376e34609770846": {"ta_keywords": "coordinated twitter accounts;coordinated campaigns;influence campaigns;social media platforms;retweets;coordination networks;networks;accounts;arbitrary behavioral traces;hashtag sequences;hong kong protests;temporal patterns;cryptocurrencies;general network;groups;users;identities;free exchange;information;diverse contexts;images;syrian civil war;cases;critical challenge;method;case studies;framework", "pdf_keywords": "coordinated twitter accounts;coordinated campaigns;social media;in\ufb02uence campaigns;social media platforms;coordinated networks;retweets;coordination networks;hashtag sequences;networks;information warfare scenarios;hong kong protests;accounts;temporal patterns;arbitrary behavioral traces;coordination;cryptocurrency manipulation;groups;network;free exchange;users;information;identities;diverse contexts;syrian civil war;methods;methodology;images;cases;pik"}, "eb07ff030df4c3dc20e85d89c2e0d0cc730918a0": {"ta_keywords": "continuous speech separation;speech separation;speaker inventory;long recordings;long recording;separation performance;additional speaker information;external speaker signals;target speaker;additional speaker signals;voice snippet;target speech;speakers;clustering;inventory;ssusi model;ssusi;datasets;input signal;long;attention;self;need;method;scheme;recent research;recent years;experiment results;various conditions;pool", "pdf_keywords": "speaker clustering methods;speaker inventory;long speech mixture;speaker embeddings;long recordings;long recording;external speaker enrollments;external speaker signals;recording;clustering;conference rooms;embeddings;separation performance;cssusi;inventory;ssusi;continuous ssusi;ssusi model;css task;mixed signal;participants;global information;input signal;realistic dataset;robust features;large proportion;self;use;need;scheme"}, "4c66979a31fa4be5b5814fdb5cb8411572d61da8": {"ta_keywords": "language data;normalization;aware rewrite rules;luther bible;high german;baseline;exact matches;characters;sequences;rules;early new;versions;context;evaluation;frequency;approach;paper;form", "pdf_keywords": ""}, "729260566c7fdf689bb04eaaecef59d40da93ef7": {"ta_keywords": "malicious deception attacks;deception attack;deep neural network;image classifier;image classification;classifier;detection;attacker model;detection probabilities;dnn;such attacks;external attacker;false alarm;principal component analysis;images;threshold policy;stochastic approximation;image;vulnerability;threshold values;random perturbation;adaptive version;random number;pixel values;human eye;perturbations;algorithm;number;computational complexity;change", "pdf_keywords": "high attack detection probability;popular white box attacks;detection probabilities;detection;adversarial examples;attacker model;neural network classi\ufb01er;low false alarm probability;adversary;principal component analysis;detector;neural network;image classi\ufb01er;pca;false alarm;threshold policy;gaussian process regression;clean image data set;dnn;threshold values;algorithm pert;such modi\ufb01ed images;test image;image;prinicipal component analysis;runtime;stochastic approximation;random perturbation;gprbd;algorithm"}, "ede8ba65c4db10d357d9c3bf8e75b092f536fc84": {"ta_keywords": "natural language instructions;baseline instruction follower;language navigation;instruction followers;perceptual context;enough annotated data;data augmentation;instruction;well candidate action sequences;navigation;pragmatic reasoning;panoramic action space;generic sequence models;level motor behaviors;vision;new instructions;landmarks;reasoning process;machine;speaker;speaker model;challenging reasoning problem;information;performance;level decisions;components;scratch;standard benchmark;approach;issues", "pdf_keywords": "language navigation challenge;language navigation task;language navigation challenge3;language navigation;baseline instruction follower;mapping action sequences;instruction generation;action sequences;panoramic action space;well candidate action sequences;data augmentation;vision;instruction interpretation;instruction;action space;mapping instructions;online challenge;navigation routes;tosequence architectures;speaker;speaker model;pragmatic reasoning;new instructions;follower model;r2r dataset;components;follower;instructions;model;performance"}, "d5634a21b3727258822b78f5c5ababf7261a5c79": {"ta_keywords": "speech enhancement;speech enhancement suppresses background noise;speech separation;voicebank;mel filterbank;ssl representations;supervised learning;separation methods;ssl frameworks;ssl;enhancement;separation;learning;speech;baseline features;fbank;stft;libri2mix;speakers;representation properties;self;time fourier transform;upstream methods;downstream tasks;good performance;great number;magnitude;paper;studies;experimental results", "pdf_keywords": "speech enhancement;voicebank;ssl representations;ssl upstream models;ssl models;ssl frameworks;ssl paradigm;waveform generation tasks;s3prl toolkit;ssl;mel \ufb01lterbank;universal performance benchmark;speech;remarkable improvements;stft;stft magnitudes;separation tasks;time fourier transform;fbank;fbanks;downstream tasks;models;baseline features;enhancement;separation;representation properties;libri2mix;upstream methods;tasks;magnitude"}, "3813627f7fec57aa4c15b791e36912f470273bb1": {"ta_keywords": "twitter hashtags;hashtags;hashtag usage;social media data;twitter;hashtags shift;topical clusters;discussion topics;social media sites;topics;communities;distinct temporal trends;online activity;discussion;greater trends;quality clusters;unique insights;analysis;flurry;others;users;first analysis;multiple different data types;course;study;order", "pdf_keywords": ""}, "3e8420d1bebb3f93d285da2de801d2e43b290880": {"ta_keywords": "neural sequence labeling models;neural sequence labeling;massive multilingual ner datasets;named entity recognition;human annotation;many natural language processing;slot tagging datasets;dialog systems;label scarcity challenge;slot tagging;semantic parsing;nlp;benchmark datasets;unlabeled data;datasets;tasks;ner;learning;task;several tasks;self;adaptive self;data access constraints;training;shot setting;privacy;large amounts;domains;extensive experiments;sensitive user applications", "pdf_keywords": "neural sequence taggers;neural sequence labeling models;slot tagging datasets;training framework;dialog systems;training samples;massive multilingual ner;multilingual ner;slot tagging;shot learning setup;language model;training;few labels;benchmark datasets;iterative knowledge exchange;label scarcity challenge;effective data exploration;task;adaptive;different tasks;data acquisition strategy;self;student model;validation;data acquisition;overview;meta;teacher;slot type;techniques"}, "e51bca890c004c43b25c5a5e7aa968fe70ec2668": {"ta_keywords": "traditional machine learning methods;graphical learning;many relational datasets;graphical models;base learner;relational data;other related instances;graphical model;relation template;social networks;instance;instances;hyperlinked web pages;scientific literature;dependencies;algorithm;features;citations;other methods;real data;predictions;thesis;performance improvement;thesis proposal;performance;recent work;approach;reality;scheme", "pdf_keywords": ""}, "622e05f5d3dd430644288d5048f6050f37947de7": {"ta_keywords": "domain adaptation;named entity recognition;transfer learning;entity recognition;supervised transfer;related target domain;natural language data sets;target domain;source domain;domains;novel hierarchical prior structure;related task;genres;tasks;feature hierarchy;feature spaces;task;information;important new area;concept;useful information;common structure;data;spurious signals;model;subproblem;groups;performance;research;problem", "pdf_keywords": ""}, "146b84bdd9b9078f40a2df9b7ded26416771f740": {"ta_keywords": "inverse reinforcement learning;inverse reinforcement learning algorithm;sensitive reinforcement learning algorithm;markov decision processes;risk;coherent risk metrics;loss function;human decision;gradient;economics;convergence guarantees;agent;models;decision;contraction map argument;behavioral psychology;observed behavior;respect;theoretical underpinning;model parameters;work;making;origins;use;problem", "pdf_keywords": ""}, "77899bac8f463b7a77c0c282748e989d419386e7": {"ta_keywords": "difficult relation extraction task;individual ssl heuristics;bayesian optimization methods;agreement constraints;entropic regularization constraints;specific heuristics;multiple heuristics;ssl benchmarks;heuristics;ensembles;novel domain;learners;ssl;consistent improvements;strategies;suite;method;technique;art result;new state;addition", "pdf_keywords": "declaratively speci\ufb01ed entropy constraints;constrained entropy;constrained speci\ufb01cation language;\ufb02exible underlying learning system;haitian sun machine learning department;dif\ufb01cult relation extraction task;descent optimizers;learners;several ssl constraints;dce;disease domains;learner;lidong bing tencent ai lab;model;gradient;abstract;ssl;ability;section;drug;full model;framework;variant;extenive libraries;paper;pa;carnegie mellon university pittsburgh;state;strategies;may"}, "1a53e7446274016f737236bdd48e3ff05d966384": {"ta_keywords": "code mining;code retrieval;quality code snippets;code summarization;natural language pairs;code synthesis;natural language;snippets;programming languages;stackoverflow;mining methods;code;classifier;mine aligned code;stack overflow;language;correspondence features;python;nl;alignments;features;neural networks;examples;java;answers;parallel data;promising source;testing;questions;structure", "pdf_keywords": "natural language pairs;machine translation;snippet structural features;original natural language query;snippets;code pairs;annotated examples;code snippet;informative features;correspondence features;code;bidirectional conditional probabilities;other languages;classifier;neural networks;so posts;features;python;quality;neural network model;nl;correspondence;structure;lessons;structural aspects;java;probabilistic model;following contributions;performance;data sets"}, "d0e9c5cb669dec908a38eab4315cbf101bc4b0a0": {"ta_keywords": "neural language models;language models;machine translation;language pairs;domain corpora;adaptation data selection;data selection;domain text;training data;similar sentences;unknown word contexts;spanish;domain data;words;bleu;grams;improvements;comprehensive evaluation;continuous vector representation;viable tools;use;idea;experiments;gains", "pdf_keywords": ""}, "308eb6751a3a1da0f64f291366c8ee27f84b3f16": {"ta_keywords": "dual dfa learning problem;learning first;order representations;hardness results;programming;extended abstract;demonstration", "pdf_keywords": ""}, "2550fafc0cbd8bbf7aadd864ac569596d33db038": {"ta_keywords": "nlp tasks;nlp usage;nlp community;language technologies;cognitive science;grounding;text;coordination;definitions;intent;new tasks;interaction;interlocutors;definition;scope;linking;community;term;successful communication;mutual information;data;advancements;constraints;process;complete sense;aspects;current definition;answers;following questions;substantial recent interest", "pdf_keywords": "discourse patterns;natural language processing;linguistic diversity;multilingual datasets;knowledge grounding;multilinguality;annotations;language;interplay;new datasets;media dialog;tasks;new tasks;world scopes;data types;trends;empirical methods;representations;modalities;challenges;current progress;speci\ufb01c approaches;interview;proceedings;coordination;constraints;conference;largescale modeling;emnlp;part"}, "7ce80c7df1774e4483b32a813d54a8ff35dd0163": {"ta_keywords": "stackelberg equilibria;stackelberg games;stackelberg equilibrium concepts;stackelberg equilibrium;stackelberg gradient dynamics;hierarchical game;sum games;simultaneous gradient descent;only stable critical points;stable critical point;dynamics;critical points;games;gradient;continuous action spaces;learning rule;best response strategy;leader;nash;follower;initialization;class;convergence;attraction;conditions;connections;insight;number;paper;update", "pdf_keywords": "stackelberg learning;stackelberg gradient dynamics;stackelberg games;stackelberg game;simultaneous gradient descent dynamics;learning dynamics;stackelberg equilibria;stackelberg equilibrium concepts;simultaneous gradient descent;gans;generative adversarial networks;generalsum games;sum games;gradient;learning rules;mization landscape;dynamics;only stable critical points;critical points;convergence;connections;empirical bene\ufb01ts;nash;illustrative experiments;electrical;computer engineering;abstract;conditions;computer engineering university;natural structure"}, "203636315f7c9526189d88c541bedf623d63ea7c": {"ta_keywords": "factoid questions;reliable evaluation metrics;factoid question;ambiguous questions;form qa tasks;answer summaries;qa;reliable metric;factual information;different correct answers;answers;ambiguity;questions;human judgments;strong baselines;original ambiguous question;asqa;task;correctness;performance;form summary;metric;good summary;eli5;interpretation;human performance;novel dataset;datasets;different interpretations;strong progress", "pdf_keywords": "factoid qa;human evaluations;factoid questions;reliable evaluation metrics;factoid question;evaluations;evaluation;form qa dataset;qa;form qa;evaluation procedures;human judgments;questions;form answers;reliable metric;correctness aspect;answer summaries;asqa;conclusion;long;task;metric dr;performance;human study;datasets;\ufb02uency aspect;novel dataset;strong progress;high agreement;abstract"}, "018bf5da2ba1f1901e98f72c7eedbf6b91967192": {"ta_keywords": "privacy preservation;privacy protection;preserving bert;privacy;local differential privacy;privacy configuration;bert;adaptive lm pretraining methods;lms;natural language understanding;nlu applications;nlu;utility;data mining;d\u03c7;utility implications;key challenge;findings;level;variant;guidance;future explorations;groundwork;same level;experiments;approach;tuning", "pdf_keywords": "privacy preservation;preserving bert;local differential privacy;privacy protection;privacy;privacy configuration;original bert;bert;denoising mlm;adaptive lm pretraining methods;denoising mlm objective;natural language understanding;privatized content;nlu applications;nlu;adaptive pretraining;utility;abstract;aug;weize kong;data mining;utility implications;level;key challenge;google mountain view;liu yang;variant;chen qu;marc najork;level privatization approaches"}, "a6a7374c5ddac1446ceab9d7cbe5a3305238d0ee": {"ta_keywords": "conversation dialog corpora;conversation corpora;trigram conversation turn;most conversation corpora;dialogue systems;natural conversation templates;conversations;conversation;actual conversations;response generation;response pairs;movie scripts;filtering;web;query;television;speakers;people;examples;various types;example;order;unit;end;previous work;hand", "pdf_keywords": ""}, "963c4c34f1292f64a6e9fc04428fc7a0893b8ef3": {"ta_keywords": "residual attention group;residual deep attention mechanism;channel attention processing module;convolution kernels;feature fusion;feature processing groups;visual quality;adaptive reconstruction network;lr images;stronger feature expression;upsampling module;hierarchical features;sisr;pixels;level image;fpgs;novel spatial;raan;network;scale;art sisr methods;distance dependencies;task;spatial domain;scam;small gray changes;several source skip connections;adjacent areas;abilities;skip connections", "pdf_keywords": ""}, "53feb3b34425ea95c259e8d0693edd490d6b470f": {"ta_keywords": "auditory stimuli version;erp experiments;auditory stimuli;semantic violation words;visual stimuli experiment;mistaken words;brain wave;brain activity;mismatch feelings;world knowledge violation words;semantic processing;japanese sentences;erp analysis;erp;n400 erp component;correct words;japanese;experiment;sound;light;n400;category;result;kind;other hand", "pdf_keywords": ""}, "a792d5a1e9a6a53edd8cbc00e387bc07c54e423c": {"ta_keywords": "bayesian truth serum;massively crowdsourced evaluation tasks;simple truth serums;truthful responses;agents;peer;extraneous elicitation;answers;prediction method;beliefs;literature;topic;paper;absence;new mechanisms;class;problems;most works;problem", "pdf_keywords": ""}, "10efdde1ae3a9d359ac1aae0bd5ef7bfd68810dd": {"ta_keywords": "multilingual representation learning;multilingual language models;language modeling;strong representation learning capability;several natural language processing;nlp;key language;language;mlm;mlm objective;agnostic representation;specific token;dict;text;representations;words;word;models;tasks;shot;objective;model;key goal;mbert;inherent limitation;approaches;immense gains;help;principle", "pdf_keywords": "multilingual representation learning;crosslingual sentence retrieval;monolingual corpora;multilingual model;bilingual dictionaries;languageagnostic representation;diverse languages;sequence labeling;languages;strong representation learning capability;language;dict;training data;mlm;xtreme;mlm objective;ner;agnostic representations;mldoc;xnli;multiple downstream tasks;benchmark;token;headline;speci\ufb01c;tatoeba;key goal;model;paws;classi\ufb01cation"}, "ef1d93b03c20b2f488b66e8e2c24fceb2105d58f": {"ta_keywords": "metaphor detection;metaphoric expressions;lingual model transfer;bilingual dictionary;lexical semantic features;syntactic construction;other languages;english resources;language;model transfer approach;words;construction;art performance;model;previous work;state", "pdf_keywords": ""}, "3993788eb252f5eb7fc19e9f98357a72f9f0476d": {"ta_keywords": "mixed membership stochastic block model;membership network models;membership block models;classical network models;latent roles;many graphs;nodes;different latent roles;generative model;models;aggregate statistics;aggregates;novel regularization method;membership;graph;entropic regularization;entropy;noisy copies;node;model;observations;many possible roles;distribution;pseudo;handful;different interactions;variables;effect;degree;actual degree", "pdf_keywords": ""}, "71c7104eaed93497824cf197949c77e7d6cb36d3": {"ta_keywords": "knowledge bases;knowledge base;iterative retrieval;corpus;heterogeneous information;pullnet;answers;corpora;questions;reasoning;retrieve;information;text;qa;reason process;specific subgraph;best answer;incomplete kb;open domain question;question;iterative process;large kbs;improvements;kb;domain question;framework;prior state;combination;art;setting", "pdf_keywords": "heterogeneous information;pullnet;corpus;reasoning;information;answers;net;tasks;questions;single data structure;text;graft;qa framework;kb;best answer;conclusions;reason;framework;system;combination;paper;hits;previous research;\ufb01nd;hours;setting"}, "911536dc3dfbbbf2bb8d71181b31e0aa7920b9f6": {"ta_keywords": "expert solutions;expert strategies;adaptive algorithm;financial markets;experts;hedge algorithm;weight expert solutions;algorithms;sustained losses;prediction interval;losses;algorithm;strategies;games;predictions;regret;share method;best combination;stochastic assumptions;ada;methods;numerical experiments;solutions;approach;set;inaccuracy;mixing;certain quantity;previous papers;fixed", "pdf_keywords": ""}, "798e45ea830884be36c3f526d3b169eaba95f989": {"ta_keywords": "continuous zerosum games;strict local nash equilibria;local nash equilibria;sum continuous games;differential nash equilibria;adversarial learning;sum games;generative adversarial network approaches;hyperbolic critical points;critical points;optimization;sum setting;hyperbolicity;machine learning;stronger results;alternative;many works;interest;result;previous results;purpose;extensions;assumption", "pdf_keywords": "strict local nash equilibria;local nash equilibria;nondegenerate differential nash equilibria;differential nash equilibria;continuous zerosum games;differential nash;local optimality;sum continuous games;sum games;player costs;players;smooth perturbations;games;characterizations;perturbations;aforementioned structural assumptions;theorem;properties;dense subset;measure;order conditions;class;eric mazumdar1;addition;terms;paper;re\ufb01nement;set;feb"}, "8a0a8568acf2b95c9cb471e28ee6b25c5e4fe186": {"ta_keywords": "senticnet;affective resource;sense knowledge representations;affective information;level sentiment analysis;semantics;sentics;typical symbolic systems;neural networks;concept;energy flows;mining;graph;information;models;symbolic opacity;dimensionality;various parts;intermediate nature;use;reduction techniques", "pdf_keywords": ""}, "e75c388b60cf447be7148be25feeee3e10d12cf4": {"ta_keywords": "extrapolation definition;interpolation;extrapolation;generalization performances;deep learning;current interpolation;training data;datasets;dataset;approximation;high dimension;many intuitions;art algorithms work;theories;tasks;points;assumption;results;notion;state;validity;various fields;fact;ability;indicator", "pdf_keywords": "extrapolation notions;extrapolation;intrinsic dimension;interpolation;data dimension;generalization performances;deep learning;high dimension;dataset size;dimensional spaces;dataset;learning;real data;new samples;data;intuitive geometrical characterization;ai research;approximation;theoretical results;thorough experiments;notion;location;various \ufb01elds;abstract;paper;randall balestriero1;2nyu;goal;use;indicators"}, "42c3c50b8e368ee2e1b52d010b6c53b3d732770c": {"ta_keywords": "speech sentiment analysis;human sentiment annotation;end speech sentiment approach;sentiment information;sentiment analysis;sentimentspecific information;unlabeled speech;sentiment;language models;automatic speech recognition;text representation;language model;sentiments;transcripts;texts;speech signals;different linguistic characteristics;pseudo label;latent information;human supervision;acoustic characteristics;asr;training;data;step pipeline approach;use;end;large amount;paper;performance", "pdf_keywords": "human sentiment annotation;e2e speech sentiment analysis system;end speech sentiment approach;speech dataset;human annotation;speech sentiments;unlabeled speech;sentiment analysis;automatic speech recognition;limited training data;speech domain;language model;transcripts;text;human supervision;pseudo label;e2e framework;training;data;bert;step pipeline;knowledge;step pipeline approach;asr;end;step pipeline setup;lm;large amount;effectiveness;performance"}, "5dcbdb9bf80575953b5d21f378d8139f0a44168b": {"ta_keywords": "dialogue system;human spoken dialogue;user emotion;support vector machine;svm;situated dialogue;emotion triggers;emotion;human communication;emotional aspects;automatic recognition;recognition;interaction;analysis;triggers;further analysis;other speakers;role;method;reason;current situation;ability;paper", "pdf_keywords": ""}, "bc632f81dab322ac610a8d11463cc1bba6130eda": {"ta_keywords": "historical text normalization;autoencoding;auxiliary tasks;small training datasets;phoneme mapping;training data;related datasets;target task;datasets;languages;grapheme;significant improvements;lemmatization;improvements;recent work;sequence;data;synergies;systematic study;paper", "pdf_keywords": "historical text normalization;shot learning outperforms;shot learning;autoencoding;normalization models;small training datasets;computational linguistics;auxiliary tasks;different auxiliary tasks;training data;languages;target task;language;datasets;improvements;shot;previous work;lemmatization;identity baseline;signi\ufb01cant improvements;sequence;grapheme;data;tophoneme mapping;several contributions;comparison;abstract;target;natalia korchagina;zurich"}, "13b674bb3078623608045a18570b47f6e49a8358": {"ta_keywords": "image coreferences;textual description;text descriptions;art results;paintings;descriptions;artistic work;text information;text;entity mentions;associate image regions;visual question;task;text spans;visual themes;bipartite matching;ontology;layout;dataset;contour data;most question;distorted skull lies;computer;systems;bottom center;method;align regions;state;new instance", "pdf_keywords": ""}, "4b9795493a937b9034be9c26afab23f6dc751f62": {"ta_keywords": "retrieval automaton;datastore search;costly datastore search;language models;retrieval;automaton;standard language model;text collection;natural language text;finite automaton;original training corpus;entries;previous entries;clustering;retomaton;state transitions;models;flat list;examples;model;states;lm;major bottleneck;probability;paper;test time;domain;creation;top;time step", "pdf_keywords": "weighted \ufb01nite automaton;automaton states;cheaper traversal;automaton;knn searches;knn search;datastore;datastore entries;searches;nearest neighbors;search;domain adaptation settings;similar neighbors;pointers;inference time;unsupervised way;strong lms;similar entries;knn;neighbors;other time steps;wfa;states;domain;\ufb02at list;time steps;transition;perplexity;retomaton;step"}, "a7b6802f20c399615dbac161678cd6a6d2df5a97": {"ta_keywords": "crowdsourcing;spatial crowdsourcing;crowd;subjective human opinions;tools;quality estimation;datasets;online maps;aggregation;loop pipelines;social impactful applications;ai;training data;data production;reliable quality control;source library;impactful human;human;mortar businesses;python;rank models;agnostic implementations;platform;kit;quality control;structured data;search applications;loop;learning;model selection", "pdf_keywords": ""}, "7df6aa19f50c8ec5f12d58e0685ed5c6e9a08bb2": {"ta_keywords": "product reviews;recommender system;personalized rankings;natural language approaches;recommendation focus;plausible reviews;reviews;valuable auxiliary information;historical feedback;latent user preferences;text;products;model information;preference;product;model;item properties;inputs;item;preferences;such methods;output;simple numerical quantities;interaction;character level;paper;performance;large volumes;user;traditional approaches", "pdf_keywords": ""}, "a3e3a9d878999c7038c275e75f5cd8a232aa4999": {"ta_keywords": "transfer learning;limited task supervision;generative capabilities;enhanced speech;task diversity;model representation;universal performance benchmark;speech;tasks;new benchmark;representations;models;semantic;such models;computational resources;natural language processing research;generalizability;holistic understanding;sg;consistent evaluation methodology;superb;efficient use;robustness;lightweight methodology;different types;shifts;difficulty;effective recipe;researchers;paper", "pdf_keywords": "voice conversion;enhanced speech;speech enhancement;speech translation;speech separation;speech;generative capabilities;speaker characteristics;transfer learning;domain asr;learning transfers;universal performance benchmark;natural language processing research;model representation;task diversity;limited task supervision;models;semantic;benchmark;speci\ufb01c model architectures;level representations;model;tasks;many tasks;representations;ssl models;new tasks;sg;usa 7lxt;usa 4meta ai"}, "b5002aa334f8d0c0e1a4dedad79580e10a928c30": {"ta_keywords": "low resource speech recognition;ssl training;ssl representations;ssl models;low resource speech tasks;automatic speech recognition;target language data;speech translation;conventional sf extractors;low resource datasets;interpretable framework;target data domain;asr;spectral;translation;features;framework outperforms;sf;domain mismatch;tasks;self;last model;st;effective approach;quality;present work;baseline;relative contribution;relatedness;assumption", "pdf_keywords": "low resource speech recognition;ssl representations;ssl training;ssl models;automatic speech recognition;speech tasks;target language data;deep learning;ssl;speech translation;various deep learning;low resource datasets;learning;end models;conventional sf extractors;models;1language technologies institute;corpora;interpretable framework;target data domain;conventional hidden markov;translation;asr;spectral;data;self;domain mismatch;features;shinji watanabe1;tasks"}, "8809d0732f6147d4ad9218c8f9b20227c837a746": {"ta_keywords": "end speech processing applications;speech translations;automatic speech recognition;espnet toolkit;speech separation;available corpora;espnet;open source;speech;recent developments;text;recipes;conformer;various training tips;models;convolution;transformer;tts;asr;wide range;above tasks;different tasks;significant performance benefits;end;ss;results;paper;architecture;st;study", "pdf_keywords": "speech separation;automatic speech recognition;end speech processing applications;various speech applications;speech translation;asr corpora;st corpus;ss corpus;tts corpora;speech;available corpora;many asr;tts tasks;asr;conformer encoder;conformerbased models;espnet toolkit;conformer;text;pure ctc model;transducer model;tts;conformer model;recent developments;by conformer;resource sets;competitive results;2labri;signi\ufb01cant improvements;various end"}, "d8252e24b6036ca895800b547698ab44d09ae350": {"ta_keywords": "personal information management tools;information management;machine learning;personal information;email messages;difficult searches;management;machine;computer technology;items;workstation documents;task;performance;calendar entries;context;track;techniques;awareness;type;part;experimental evidence;others;whole;ways;cost error;certain types;directions;visible current uses", "pdf_keywords": ""}, "f91c24b0dc56a6b377e99e046d7540e5bb7aa46e": {"ta_keywords": "college student information management system;student information management;cs information management system;information management module;information system structure framework;higher vocational college management;information technology;student curriculum module;basic information module;data access layer;user management module;student achievement module;information security;business logic layer;scholarship management module;informatization;user interface layer;tier architecture;college student;tuition module;students;management;data statistics;higher education reform;module use;implementation;automation;web;cs;intelligent scientific management means", "pdf_keywords": ""}, "a6a7724763d8adba466519489b0b9d209e7f2d15": {"ta_keywords": "text generation;machine translation;text generation problem;nlp applications;sequence models;summarization;decoder;source text;text;texts;evaluation;sequence;reference output;dialog;metric bartscore;encoder;bart;higher scores;leaderboard;metric;interactive leaderboard;number;task;explainaboard platform;bartscore;models;code;variants;model;major challenge", "pdf_keywords": "text generation task;text generation problem;other textual inputs;sequence models;source text;text;decoder;reference output;encoder;sequence;evaluation;outputs;metric bartscore;bart;higher scores;models;number;variants;future directions;model;unsupervised fashion;formulation;general idea;paper;idea;probability;different perspectives;ef\ufb01cacy;implications;work"}, "e3f1a9c3d87e9828cdeb08ba90a260c69e974a75": {"ta_keywords": "large dance sequences;large dance sequence;basic dance generation;deep recurrent method;deep recurrent neural networks;motion beat;basic dance step generation;dance;basic dance steps;lstm;music input;music;baseline dancer motion;baseline dancer;dnn;audio input;low cross entropy;training;audio power spectrum;convolutional layers;cross entropy measure;dnns;small dataset;motion;term memory;network;contrastive cost function;input;weak labels;data", "pdf_keywords": "large dance sequences;dance generation tasks;new dance sequence;deep recurrent model;deep recurrent method;deep recurrent neural networks;basic dance generation;basic dance;music rhythm;basic dance steps;dancer;deep learning;solo dancer;baseline dancer motion;deep learning models;baseline dancer;music;generative model;low cross entropy;cross entropy measure;training;motion;lower cross entropy;motion pattern;small dataset;audio power spectrum;model;input;models;accurate timing"}, "78d57a1ecd724c5f8b1534372969d5b35daa6d4b": {"ta_keywords": "neural parsing;base parsers;several generative neural models;generative models;constituency;candidate outputs;direct search;ptb;disentangling model combination;gold data;explicit model combination;external data;f1;performance;reranking effects;state;new state;art results;art numbers;recent work", "pdf_keywords": "generative parsers;generative parsers rg;generative parser;recurrent neural network grammar;parsers;strong base parser;discriminative parser;discriminative parser rd;base parser;generative neural models;parses;parse trees;generative models;lstm language;rnng;new constituent;models;explicit model combination;current constituent;rg;right traversal;shift;model combination effects;direct search;lm;\ufb01ndings;gain;choe;lower evaluation performance;gold data"}, "b6c6e06b4bc68349845b30e01e01d7603f468547": {"ta_keywords": "optimal capacity relay node placement;optimal relay location;optimal power allocation;relay channel;relay nodes;relay node;total cost markov decision process;single relay case;optimal placement;relays;individual power constraints;cost function;loss channel models;placement policy;theoretic achievable rate formulas;nodes;placement;sink node;law path;numerical exploration;exponential;explicit formulas;power;source node;hops;information;impromptu;line;length;value function", "pdf_keywords": "optimal relay locations;optimal relay location;optimal capacity relay node placement;optimal power allocation;relay channel;relay nodes;relay channel1;total power constraint;multiple relay case;relay node;individual power constraints;single relay case;relays;loss channel models;transmission powers;exponential pathloss;optimization problem;allocation;cost function;exponential path;exponential;power;nodes;theoretic achievable rate;communication;placement;law path;source node;explicit formulas;loss"}, "7729fbebff327bebb9292dc1c51c51dd55390954": {"ta_keywords": "compositional distributional semantics;sentence similarity;transitive verb construction;rank tensors;verbs;order tensor;full tensors;verb;rank approximations;fewer parameters;orders;parameters;low;effect;magnitude;paper;results;performance;fraction;original number", "pdf_keywords": ""}, "f3271e61dc0507183ee399393129d7888c2f82b9": {"ta_keywords": "automatic quality estimation approaches;supervised quality estimation;overall quality estimate;quality scores;annotation effort;test corpus;machine translation;evaluation measures;manual evaluation;quality standards;evaluation;domain reference data;quality;language processing systems;speech recognition;rapid quantitative comparison;reference;full references;scores;domains;bleu;output;wer;customers;particular domain;document;small number;essential step;segments;practical use", "pdf_keywords": ""}, "68aa7c7b65365c3303d5024b1273408fb435d178": {"ta_keywords": "dialogue systems;dialogue;dialogue acts;entrainment changes;entrainment;lexical level;lexical choice;effect;similar manner;guidelines;structural level;users;results;paper", "pdf_keywords": ""}, "b0ddd849c5ae0004678fa483908c06d87894f3ab": {"ta_keywords": "speech recognition;state hidden markov model;state hidden markov model structure;word recognition;hmm structure;bayesian model selection criterion;variational bayesian approach;bayesian criterion;acoustic model;practical bayesian framework;training data;selection;ss;criterion;appropriate ss;hmms;tuning parameter;conventional asymptotic criteria;hmm;paper;method;case;shared;practical use;amount;insufficient amount;experimental results", "pdf_keywords": ""}, "b0d644277933988c00b22d8ae012512fe498ad62": {"ta_keywords": "word sense disambiguation;word sense inventory;linguistic knowledge representations;word embeddings;fasttext word embeddings;disambiguation;sense inventories;word senses;languages;knowledge;word;supervised training instances;context;automatic approaches;free approaches;wsd;task;input;inherent zipfian distribution;models;ii;collection;basis;humans;model;method;major challenge;paper;quality;development", "pdf_keywords": "unsupervised word sense induction;the\ufb02y word sense disambiguation;fasttext word embeddings;disambiguation;word vectors;sense inventories;multilingual application;single sense;graph vector induction;languages;context;multiple senses;word;particular context;sense;task;input;participants;wsi;new algorithm;basis;probability;collection;grave et al;ego;egvi;model;system;paper;method"}, "ebc64974e9e0021984a0158b3c04b60327730a88": {"ta_keywords": "neural semantic parsing framework;large scale knowledge base question;typical webquestionssp benchmark;checker;retriever;grailqa leaderboard;syntax correctness guarantees;logical form;relevant kb items;transduction procedure;transducer;kbqa;retrack;overall performance;top1;framework;system;users;efficiency;competitive performance", "pdf_keywords": ""}, "f0cd4de3cdf547dcdcc6995dca9ab3f65955b324": {"ta_keywords": "recurrent highway networks;lattice recurrent units;lattice recurrent unit;lstm;accurate language models;sequence modeling;new lru models;lru models;lru model;lru;flow;better empirical computational convergence rates;models;computational convergence rates;second flow;first flow;units;statistical efficiency;projected state;depth dimension;time dimension;limited resources;available datasets;grid;challenge;reset gate;convergence;different components;update gate;statistical efficiency values", "pdf_keywords": "lattice recurrent units;recurrent neural networks;lattice recurrent unit;sequence modeling;new lru models;lru models;lru model;models;lru;depth;computational convergence rates;sequences;depth dimension;projected state;time dimension;units;language technologies institute carnegie mellon university pittsburgh;reset gate;update gate;limited resources;different components;information;challenge;\ufb02ow;convergence;second \ufb02ow;chaitanya ahuja;louis;abstract;\ufb01rst \ufb02ow"}, "485b3f77b9913e151e7ca897d99497e70e7f30d1": {"ta_keywords": "neural machine translation;subword units;general subwords;segmentation granularity;new bpe vocabulary;rare words;granularity;open vocabulary;larger units;hyperparameter;smaller units;training efficiency;validation loss;specific units;language;performance improvements;infrequent words;training pass;training;grid search;nmt;way embeddings;accuracy;task;parameter;paper;course;method;benefits;methods", "pdf_keywords": "tune subword granularity;subword granularity;frequent subwords;tune segmentation granularity;segmentation granularities;component subwords;new vocabulary online;expensive parameter search;expensive grid search;new embeddings;new vocabulary item;autoencoder;rare words;translation accuracy;sweep;grid search;pytorch;online training method;embeddings;single embedding;incremental bpe;single training run;training;single training pass;training process;languages;best bleu;avg;best performance;single pass"}, "1e4e2aceed87febcc643f1473507c9535ba5c19a": {"ta_keywords": "target language translations;speech translation;several speech processing tasks;ctc translation output;automatic speech recognition;simultaneous translation;blockwise streaming transformer;contextual block processing;intermediate loss regularization;synchronous beam search;language understanding;slu task;ctc prefix score;simultaneous st task;online processing;st task;slu;transformer;attention;offline models;ctc branch;transformers;search space;classification performance;joint ctc;simultaneous st;blockwise;addition;st;baselines", "pdf_keywords": "blockwise streaming transformer;ctc translation output;automatic speech recognition;target language translations;simultaneous translation;intermediate loss regularization;slu task;contextual block processing;simultaneous st task;slu;st task;synchronous beam search;ctc pre\ufb01x score;transformer;attention;simultaneous st;classi\ufb01cation performance;blockwise;ctc branch;search space;joint ctc;baselines;addition;bleu gain;\ufb01rst step;competitive results;\ufb01rst time;of\ufb02ine models;paper;methods"}, "6e24bcfcdb31afbb313a13c1c84cb779ceb17500": {"ta_keywords": "prospect theory value function;sequential decision maker;hidden markov model;decision problem;same decision problem;maximization algorithm;decision;expectation;person;value function;gain;reference point;actions;outcomes;action;loss;paper;time", "pdf_keywords": ""}, "0d20360c5d533760d97d7ce19b78d4791a5173cb": {"ta_keywords": "terrorist target prediction;terrorist attacks;terrorist targets;terrorist organizations;complex networks;network analysis;network outcomes;terror;inference algorithm;network;statistics;broader machine learning models;algorithm;computer science;popular mathematical methods;accuracy;many social problems;novel method;dynamics;results;context;research;precision;heterogeneous dynamics;power;developments;creation;high levels;work;period", "pdf_keywords": ""}, "5d9fe38b750f59b4ef0a2b58fde0f60d4317c7ad": {"ta_keywords": "several metadata attributes;multiple metadata attributes;single metadata attribute;single attribute;attribute;domains;best domains;domain;classification;world datasets;data;extensions;techniques;order", "pdf_keywords": ""}, "242c35b91fe1d7aedab9d1da7652aad2219d4784": {"ta_keywords": "how2 speech translation task;speech translation system;deeper speech encoder;end speech translation;rnn models;rnn;nmt model;knowledge distillation;espnet submissions;espnet;iwslt2019;iwslt;transformer models;models;transformer;e2e;drastic improvements;corpora;tasks;end;baseline model;top;systems;st;paper;year", "pdf_keywords": ""}, "924e43c4de98743d2e7c14c241b03b2109325b90": {"ta_keywords": "speech tagging;metropolishastings rejection sampling;word segmentation tasks;sampling;gibbs;sampling method;samples;memory;parallel run;training data;multiple processors;large sized blocks;block;empirical results;convergence speed;part;true distribution;correct distribution;methods;method;end", "pdf_keywords": ""}, "030fade3049e0847702393dde3100ecc41a5e86a": {"ta_keywords": "climbing search;many learning tasks;global optimum;local optimum;many practical learning systems;optimal element;climbing;algorithm;random test cases;hill;future utility;utility values;utility value;high probability;task;performance elements;performance element;performance;distribution;discrete space;basis;element;simple forms;paper;problems;problem;fact;settings", "pdf_keywords": ""}, "bea54062d105b9fe3250ce3569cf817e54772894": {"ta_keywords": "neural sequence labeling tool;historical treebanks;sequence labeling approach;probabilistic parser;historical syntax;unlexicalized parser;different historical corpora;annotated data;longer phrases;incorrect phrase boundaries;modern german;error analysis;accuracy;data sets;data;errors concern;evaluation;scores;improvement;f1;theories;further potential;lack;methods;variety", "pdf_keywords": "historical treebanks;corpus;neural sequence labeling tool;automatic phrase recognition;different historical corpora;german text archive dta;linguistics;historical syntax;probabilistic parser;berkeley parser;annotated data;hipkon corpus;historical german;neural crf;texts;historical data sets;phrases;katrin ortmann department;ortmann;data sets;time periods;data;overall f1scores;different genres;study;present paper;other test sets;evaluation;fakult\u00e4t f\u00fcr philologie ruhr;abstract"}, "38705aa9e8ce6412d89c5b2beb9379b1013b33c2": {"ta_keywords": "semiparametric inference;semiparametric inference results;valid semiparametric inference;deep feedforward;deep nets;deep neural networks;deep learning;neural nets;other semiparametric estimands;nonparametric regression;estimation rates;neural networks;estimation;inference;mail marketing;feedforward;logistic losses;monte carlo analysis;new rates;rates;nonasymptotic bounds;empirical application;causal effects;linear unit activation function;depth;sample size;effectiveness;convergence;standard least squares;use", "pdf_keywords": "deep feedforward;deep neural networks;deep nets;deep learning;neural nets;deep relu networks;semiparametric inference results;neural networks;general nonparametric regression;nonparametric regression;networks;estimation rates;feedforward;novel bounds;common recti\ufb01ed linear unit activation function;convergence rates;novel rates;type loss functions;other generalized linear models;nonasymptotic bounds;bias;feedfoward;depth;logistic regression;mail marketing;monte carlo analysis;empirical application;constant propensity score;il coverage;main theoretical results"}, "4dd85ae17a5fd0bce09ffef0455b6e827d7e1e2b": {"ta_keywords": "linear attacks;linear attack;attack detection probability;false data injection attack;online stochastic gradient descent;consensus filtering;external attacker;multiple agent nodes;stochastic approximation;attacker;kalman;sensor observations;agent nodes;agent node;cyber;multiple sensors;gaussian noise;stochastic process;optimal parameter values;constrained optimization problem;linear dynamics;estimate;neighbouring nodes;constraint;physical system;parameters;estimates;errors;messages;goal", "pdf_keywords": "optimal deception attack;networked vehicular cyber;optimal linear attack;attack scheme;false data injection attack;deception attack;service attack;wireless jamming attack;attacks;false data injection;attack;attacker;cyber;network;integrity;fdi;physical systems;denial;physical system;system resources;information;arpan chattopadhyay;sy;numerical results;ef\ufb01cacy;design;erik strom;paper;herein;parameters"}, "5143ebd23322fe805bed2667fcfb70920c105f7f": {"ta_keywords": "cognitive tutor;computerized tutor;cognitive skills;simulated student;expressive demonstrations;effective demonstrations;cognitive modeling;demonstration;implicit mental operations;cognitive model;demonstrations;better demonstration;learning;human students;accurate learning;training sequence;agent;human experts;detail;empirical studies;machine;efficiency;accuracy;paper;results;speed;characteristics;findings;level;solutions", "pdf_keywords": ""}, "cfbe9183f2fe2847f7a3c811f6309a2cab3f85cf": {"ta_keywords": "scientific summarization dataset;summarization datasets;extractive summarization system;extractive summarization;corpus;pretraining;bert;scientific documents;significant performance improvements;scitldr;target tasks;target task;input sequence;art results;step;length;effect;work;size;influence;domain;state", "pdf_keywords": ""}, "20086d6a9fab6081f300e08d3f952cb9b16e6de8": {"ta_keywords": "approximate search algorithms;shortest retrieval times;residual dictionary strings;indexing;huge indices;fastest benchmarks;perfect hash function;benchmarks;residual strings;deletion neighborhoods;less space;fastss;extraordinary space requirements;superior performance;data;implementation;great interest;set;sizes;methods;respect;maximum allowable number;times;experiments;approach;experimental evaluation;same time;experimental analysis", "pdf_keywords": ""}, "693f5d55e0561099944f5e00e301bf26db0b972d": {"ta_keywords": "stochastic semantic analysis system;statistical semantic analysis;spoken language understanding;computer dialogue systems;acoustic utterance;semantic representation;semantic analysis;annotation effort;stochastic approaches;input;data;system;systems;task;expert;slu;overview;model;thesis;computer science;engineering univerzit\u0144\u0131;pilsen;czech republic;subject;comparison;pilsen department;surface mail;west bohemia;goal;amount", "pdf_keywords": ""}, "939a149f156425b83e48ea72e9e09a55ea33b8d7": {"ta_keywords": "signal reconstruction;complete signal reconstruction;signal reconstruction problem;wavelet transform domain;norm optimization problem;interval accuracy;reconstruction;iterative algorithm;convex sets;crossings;algorithms;projections;salient feature;linear simultaneous equation;representation;computational efforts;formulation;dimensional case;solution;positions;common drawbacks;variants;drawbacks;large amount;difficulty", "pdf_keywords": ""}, "0fbb90b8fe1d02a4f0f616df9a09ec42eace53bd": {"ta_keywords": "voice activity detection;online unsupervised classification;variational bayes framework;online expectation maximization;classifier;conventional vad algorithms;variational bayes;remote recording condition;vad method;vad;conventional vad methods;statistical model;decision threshold;vb;log evidence;model comparison;decision level;snr;vb framework;new online;model;explicit approximation;heuristics;free energy;method;reliability;online fashion;approach;em;effect", "pdf_keywords": ""}, "e21633b0b5e55dce56bc07e919c6d12ecf8cef0c": {"ta_keywords": "several practical inductive logic programming systems;logic programs;constant locality;depth determinate clauses;nonrecursive determinate clauses;obvious syntactic generalizations;nonrecursive clauses;locality;clauses;constant depth;formal results;pac;new restriction;language;paper", "pdf_keywords": ""}, "c305e3314c0853b14911f704c68b04cfc9ea7aa1": {"ta_keywords": "hindi dependency treebank;hindi treebank conforming;crosslingual dependency parsing;multilingual language technology;hindi;annotation;universal dependencies;formalisms;international standard ud scheme;paninian karakas;systematic evaluation;ud;conversion;differences;weaknesses;resource;line;schemes;much attention;strengths;paper;work;experiments", "pdf_keywords": "hindi dependency treebank;hindi treebank conforming;10th linguistic annotation workshop;indian languages;computational linguistics;hindi;annotation;multilingual language technology;hindi map;universal dependency scheme;universal taxonomy;dependency relations;nian dependencies;dependency scheme;formalisms;nian framework;types tokens chunks sentences avg;pos tag set;tags;international standard ud scheme;differences;ud;hdtb;conversion;association;weaknesses;resource;schemes;proceedings;august"}, "652579315d767331d8e05ea46489e6bd081ef48a": {"ta_keywords": "peer evaluation;ordinal peer;ordinal approach;other students;students;evaluation;moocs;conventional classrooms;lectures;student;evaluators;conventional cardinal approaches;feedback;download study material;answers;videos;number;information;critical aspect;experts;expertise;ease;anyone;means;set;lack;internet connection;case;severe mismatches", "pdf_keywords": ""}, "b293e4659e20815bcf0b6d31ce46b8bd9437c1fa": {"ta_keywords": "private machine learning;privacy preservation;privacy preservation problems;privacy protection;privacy;privacy attack;privacy problems;traditional data privacy protection;privacy issues;machine learning process;machine learning;deep learning;corresponding protection schemes;smart healthcare;surveillance systems;ml;preservation;machine;survey;paper surveys;ii;solutions;problem;categories;methods;iii;future research directions;industries;financial technology;state", "pdf_keywords": "privacy preservation;privacy;traditional data privacy protection;machine learning;machine;data61;australia farhad farokhi;technology sydney;australia sina shaham;survey;sydney;university;csiro;friend;melbourne;australia;australia wenny rahayu;la trobe university;context;australia zihuai lin;outlook;australia ming ding;foe;problem;nov"}, "8d17543c20f23b6a40bec9334d50e9c15a08c1c4": {"ta_keywords": "open domain question answering;large text corpus;knowledge bases;deep neural networks;entity;benchmark tasks;net;text;questions;graft;training data;early fusion;kb completeness;qa;kb;incomplete kb;kbs;suite;end;difficulty;combination;systems;amount;paper;methods;problem;state;practical setting;setting;art", "pdf_keywords": "text networks;graph representation learning;novel graph convolution;natural language;subgraph;rich relational structure;speci\ufb01c subgraph;relations;graphs;nodes;heterogeneous graph;kb entities;heterogeneous graphs;information sources;kb facts;facts;training data;early fusion;benchmark tasks;text documents;neural network;kb completeness;net;text;graft;questions;answers;recent advances;kb;fusion model"}, "1808b64aec21863489f0fe66f250890a3ac2b843": {"ta_keywords": "verifiable secret sharing;privacy;many unbiased coins;random noise;gaussian noise;noise generation;statistical databases;databases;database;protocols;gaussian;shares;malicious participants;implementation;computational power;database query;data;rows;query;row;recent papers;sum;addition;technique;simple form;purpose;small amount;previous approaches;generation;work", "pdf_keywords": "noisy sums;secret sharings;noise generation;secure evaluation;privacy;poisson noise;algorithms;byzantine faults;coins;statistical databases;shares;implementation;binomial;computational power;sums;server;interactive solution;combination;simplicity;participants;extractors;massive numbers;recent papers;number;order;generation;course;assumption;work;purpose"}, "c3a662b864673d8cc7469051419ab8819926d4b0": {"ta_keywords": "multilingual bert;small bert models;multilingual representations;multilingual pretraining setup;bert;multilinguality;languages;linguistic properties;xnli;vecmap;shot transfer;mix;fast experimentation;natural data;masking strategy;architectural properties;insights;elements essential;findings transfer;alignment;larger scale settings;mbert;high quality;efficient setup;small setup;experiments", "pdf_keywords": "small bert models;multilinguality;multilingual pretraining setup;in\ufb02uence multilinguality;bert;position embeddings;languages;linguistic properties;linguistic elements;special tokens;tokens;random tokens;vecmap;xnli;natural data;mix;masking strategy;fast experimentation;main takeaways;architectural properties;alignment;necessary elements;\ufb01ndings transfer;insights;ef\ufb01cient setup;larger scale settings;limited amount;parameters;small setup;experiments"}, "b1d24e8e08435b7c52335485a0d635abf9bc604c": {"ta_keywords": "fact extraction;textual sources;annotators;oracles;correct evidence;evidence;sentences;wikipedia;necessary evidence;verification;claims;notenoughinfo;fleiss kappa;sentence;best accuracy;claim;dataset;knowledge;refuted;fever;judgment;available dataset;challenge;pipeline approach;classes;supported;paper", "pdf_keywords": "fact extraction;evidence retrieval;textual entailment components;textual sources;annotation consistency;information retrieval;identi\ufb01es relevant documents;dataset presents;evidence;sentences;new dataset;available dataset;documents;claim veri\ufb01cation classi\ufb01cation;claim veri\ufb01cation;fever;accuracy;shef\ufb01eld 2amazon research cambridge;claim;veri\ufb01cation;james thorne1;christos christodoulopoulos2;suitable guidelines;challenges;challenge;task;scale dataset;abstract;fleiss;pipeline approach"}, "4a4bc9f6c5ec76b0d501b641d3092aceb2e083bd": {"ta_keywords": "preference knowledge;preference handling;food preferences;diner profiles;preference;restaurant;preferences;regular customer;restauranteurs today;expert server;overall meal;table booking;services;list management apps;sweetbreads;business solutions;social network integration;variety;marketing;buzztable;opentable;things;community;noshlist;kaci;many software packages;fivestars;special;canonical examples;examples", "pdf_keywords": ""}, "d5eeaac5c5e524ad05d9b1f3f3f41aece082955a": {"ta_keywords": "sparse training data;speech recognition;bayesian predictive classification;variational bayesian estimation;data sparseness;variational bayesian posteriors;bayesian predictive distribution;sparse data problem;total bayesian framework;robust classification method;clustering;vbec;vb;bpc;others;effects", "pdf_keywords": ""}, "04d96a75b4383240cb15fb729b29f5775219d724": {"ta_keywords": "popular neural machine translation toolkit fairseq;deep learning library pytorch;neural automatic speech recognition;language model fusion;decoder;art asr performance;asr;data augmentation;espresso;toolkit;end systems;librispeech;esresso supports;gpus;other end;extensible end;switchboard data sets;word;source;end;training;similar systems;wsj;nodes;11x;state;approaches", "pdf_keywords": "extensible neural machine translation toolkit;end asr toolkit;\ufb02exible deep learning framework pytorch;language model fusion;benchmark asr data sets;decoder;novel neural end;popular nmt framework fairseq2;pure python;toend asr;language model;pytorch;fairseq codebase;data preparation pipelines;parallelization;fairseq;nlp;source end;espresso;speech;end system;ahead word;words;word;recipes;end;easy interoperability;software architecture;librispeech;inference algorithms"}, "312b12dd6aa558b92df3ddd9b1057aa80a0ad718": {"ta_keywords": "relation classification systems;relation classification;shot relation classification;relation descriptions;available textual entailment datasets;textual entailment models;textual entailment;shot classification performance;conditional encoding;datasets;task;f1;ii;formulation;approach;use;iii;several advantages;performance;leverage;experiments;ability", "pdf_keywords": ""}, "5885625fac055f4f8f47b0d6b5c026c8806896f0": {"ta_keywords": "free learning theory;distribution", "pdf_keywords": ""}, "098076a2c90e42c81b843bf339446427c2ff02ed": {"ta_keywords": "shallow networks;influence estimates;improved influence estimation methods;general influence functions;influence functions;deeper networks;influence function;neural network models;deep learning;gradients;underlying loss function;imagenet;hessian;group influences;quality influence;decay regularization;estimates;linear models;convexity;training samples;model;datasets;mnist;time predictions;model changes;uncertainty estimation;accuracy;effect;empirical study;certain network architectures", "pdf_keywords": "complex deep architectures;deep learning;imagenet;training samples;accuracy;complex models;in\ufb02uence estimates;depth;resnets;interpretability;time predictions;uncertainty estimation;stochastic approximation;datasets;network;strong effects;vggnets;iclr;network architecture;architectures;mnist;failures;decay;influence functions;extensive experimental study;fragile;width;computer science university;machine;in\ufb02uence"}, "446f1eaec22a90574670491073cd5b03bfa1e273": {"ta_keywords": "supervised models;simple statistical claims;knowledge base;explicit supervision;data;numerical information;statistical properties;inflation rate;simple claims;text;countries;population;property;properties;freebase;raw text;country;baseline approach;identification;verification;claims;recent work;experiments;paper;tasks;interest;approach;problem;order", "pdf_keywords": ""}, "76468db928e18f97dadbd25c04c80ebd491fec9b": {"ta_keywords": "nd0 transition metal cations;crystal field splitting;zircon compounds;7f1 manifold;pyrochlore;influence", "pdf_keywords": ""}, "aaf7e94e1a2f8891e5c5f4d11d4f135a1687bb0a": {"ta_keywords": "arms cooperate;assembly;free bearing end;bearing end;rotational displacement;arms;axial displacement;positions;tabs;arm;interference surface slopes;capture tabs;structure;aperture;free ends spring;position;aperture edges;panel;tab;spring;arms lies;plateaus;force;capture plateau;center;component;pair;free end;end", "pdf_keywords": ""}, "c589c4ec7247980f38a6bd22f215fea8028a0f66": {"ta_keywords": "interpretable nlp;annotation quality;annotation results;annotations;annotation process;certain annotations;speci\ufb01c explanation methods;explanation methods;ground truth rationales;workers;evidence;quali\ufb01cation;careful interpretation;results;input texts;rationales;rationale;experiments;unsaid details;datasets;experiment results;benchmark datasets;particular instructions;observations;instructions;model;decision;importance;complete details;different levels", "pdf_keywords": "annotation quality;annotation results;annotation process;certain annotations;interpretable nlp;recruit workers;online crowd;jobs;workers;eraser;tasks;datasets;benchmark datasets;source platforms;discussion;results;requesters;work;benchmarks;unsaid details;quali\ufb01cation;websites;places;world;experiments;details;platforms;rationales;rationale;instructions"}, "ecc520794da34d2b141235002c70b06c999bda73": {"ta_keywords": "interpretable sense representations;evaluations uncover sense representations;sense embeddings;sense representations;sense induction;new coherence evaluation;sense inventory;sense;centric evaluations;language;gumbel attention;centric tasks;minimal model;discrepancy;computer", "pdf_keywords": ""}, "c12e46d7d0bb9fa062bce0549f2a6a9de00758d5": {"ta_keywords": "novel sound event detection;convolutional recurrent;attention modules;weak label prediction;input feature sequence;natural language processing field;bert;transformer encoder;whole sequence information;attention mechanism;dcase2019;input sequence;neural network;global context information;self;special tag;sed;transformer;multiple self;great success;scenario;baseline method;paper;aggregation;method;account;experimental results", "pdf_keywords": ""}, "f2fb4a931580c4f1c5bdb47ebc80c801b422cd1a": {"ta_keywords": "grounding language;artificial intelligence;grounds language;neuroevolution;natural language instructions;robot;simple english commands;neural network;actions;motor control;grounding;separating control;final agent;logic;tasks;experimenter;task;understand;objects;computer;separation;ability;area;research;world;necessity;substantial literature;major goal", "pdf_keywords": ""}, "57b972ebe314cfe8e57fd6b9f9239123eb70e979": {"ta_keywords": "connectionist temporal classification;recurrent neural networks;rnns;lstms;convolutional encoders;deep convolutional neural networks;cnns;encoder;cnn;automatic speech recognition;typical rnn;switchboard eva12000 corpus;popular sequence prediction approach;training time;ctc;decode;word error rate;explicit representation;models;performance;entire sequence;time;wer;terms;study;advantage;model size", "pdf_keywords": "connectionist temporal classification;conversational speech recognition;recurrent neural networks;rnns;convolutional ctc models;deep convolutional neural networks;automatic speech recognition;convolutional encoders;connectionist temporal classi\ufb01cation;convolutional neural networks;convolutional architectures;encoder;conversational telephone speech;cnn;cnns;encoders;free recognition;term memory;dimensional convolutional layers;ctc models;popular sequence prediction approach;typical rnnbased models;ctc;ctc loss function;switchboard eval2000 corpus;microsoft ai;training time;models;character;timit"}, "6f79cbe893ae46a6f97617d14656ab57c26e6faf": {"ta_keywords": "directional automatic speech recognition;speaker data;explicit speaker locations;source speaker locations;source localization;microphone array;directional asr;localization;localization models;neural network manner;asr error minimization objectives;single differentiable neural network;better asr performance;recognition;explicit direction;asr;arrival;e2e;azimuth angle;doa;field;data;latent variable;separation;realistic data;sources;advantages;supervision;end;methods", "pdf_keywords": "directional automatic speech recognition;speaker speech recognition;speech processing;source speaker locations;directional asr;source localization;asr error minimization objectives;neural network manner;speech;single differentiable neural network;neural network;localization;asr;recognition;multichannel end;joint separation;e2e multi;separation;language;network;individual sources;source;eess;me2e;shi;novel technique;bellevue;wa;functionalities;shenzhen"}, "5cb74e269c57263d475734a66d34e4d2d2f9e1ac": {"ta_keywords": "truss core panels;laser additive manufacturing;truss core panels base;vibration characteristics;finite element method;additive manufacturing;modal test;structures;laser;lam;fem;dynamic behavior;analysis;present study;sample;subject;considerable current interest", "pdf_keywords": ""}, "cefd3993db4d065b95ab8f105452fb728c02b60e": {"ta_keywords": "good review generation system;scientific reviewing;pass peer reviews;natural language processing;such reviews;review;nlp;reviews;scientific papers;scientific publications;possible evaluation measures;machine learning domain;papers;subject matter experts;more future research;paper;content;core ideas;peer;text;models;rapid development;science;subject;author;aspects;challenges;human;lower constructiveness;technology", "pdf_keywords": "good review generation system;scienti\ufb01c reviewing;natural language processing;pass peer reviews;nlp;review;scienti\ufb01c papers;machine learning domain;papers;more future research;models;paper;content;scienti\ufb01c;introduction;subject;challenges;author;dataset;system;question;work;pursuit;train;possibility;different aspects;art;bornmann;mutz;number"}, "f491a5f09ee01436d772a6cff25f22d700d8c9c0": {"ta_keywords": "way power distribution networks;power flow analysis;fast power flow analysis;distribution network solution;reactive power support;renewable generation;robust augmented nodal analysis approach;renewable energy;nodal analysis;generator;node voltages;voltage support;reactive powers;electricity;dg;dgs;network support services;currents;energy;jacobian matrix;transport sector;dns;dn;provision;mana;side management;state variables;state estimation;formulation;robustness", "pdf_keywords": ""}, "72213e24713264da816f43a42d606f115998fe7b": {"ta_keywords": "stacked learning;graphical learning;text mining;stacking;base learner;datasets;inhomogeneous gibbs;instances;minimal memory;examples;greedy manner;algorithm;algorithm modified balanced window;local features;dependencies;feature set;neighbors;memory cost;many applications;process;training time;predictions;online version;several real problems;addition;real problems;convergence;intuition;time;pass", "pdf_keywords": ""}, "c04c865c8b33ce0251c9f37d0cccf2b3b1e4fd34": {"ta_keywords": "observable navigation tasks;causal state representations;observable markov decision processes;agnostic state abstractions;partially observable environments;reinforcement learning problems;rnns;causal states;rich observation spaces;observation processes;subsequent observations;policies;agents;observations;traditional memory;actions;history;gridworld;ale;joint history;vizdoom;algorithm;task;paper;methods;mechanisms", "pdf_keywords": "learning causal state representations;approximate causal states reconstruction;causal state representations;causal state representation;partiallyobservable markov decision processes;state representations;causal feature sets;partially observable environments;causal states;causal inference literature;next step prediction;latent representations;pomdps;pomdp;observable states;multiple gridworld navigation tasks;causal;computational mechanics;rnn;observations;partial observability settings;optimality;actions;data;states;equivalent systems;principled approach;theoretical guarantees;explicit requirements;minimal su\ufb03cient statistic"}, "8504a5eb4638aeb2f61f8b7f93440b9e495b443b": {"ta_keywords": "dynamic sensor subset selection;dynamic sensor activation;centralized tracking;active sensor selection;sensor networks;stochastic approximation;efficient tracking mechanisms;tracking;stochastic process;cyberphysical systems;global optimality;learning;algorithms;algorithm;internet;gibbs;energy;process;distribution;high performance;unknown parameter;methods;case;order;things;key theoretical result;cases;numerical results;efficacy;problem", "pdf_keywords": ""}, "8e7d063c681557c94382ff3da6415d3720fe11a7": {"ta_keywords": "twitter stance detection corpus;stance detection;conditional lstm encoding;bidirectional conditional encoding;tweets;tweet;text;test target;test targets;training data;targets;hillary clinton;target;semeval;task;attitude;representation;challenging version;approach;paper;system;previous work;performance", "pdf_keywords": "twitter stance detection corpus;present stance detection methods;semeval stance detection;stance detection;word embeddings;twitter task;short term memory;conditional lstm encoding;lstm;second lstm;positive stance;twitter dataset;tweets;bidirectional encoding;tweet;novel stance;detection task;unlabelled domain data;conditional encoding;politicians;target donald trump;training data;targets;representation;example;task;entities;unseen targets;encoding;target"}, "8568f6eda2e4cb7921fe175ab44b2f5ecbb2b870": {"ta_keywords": "more reading difficulty;reading difficulty;human readers;misspelling;misspellings;unimpaired comprehension;letter transpositions;error words;reading times;more natural errors;error rate effect;unexpected letter combinations;error rates;words;upcoming words;eye;correct words;surprisal;transpositions;error types;character;errors;effect;traditional word;results;presence;tracking study;computational model;context;paper", "pdf_keywords": ""}, "ae77189921ffade5ee4c4d4a0e93e879d7280b80": {"ta_keywords": "multimodal forecasting body;grounded pose forecasting;pose;poses;virtual avatars;gestures;avatar;dialogue;second person views;end model;narrative;language;speaker;acoustics;data;other modalities;end;research;correlations", "pdf_keywords": ""}, "93e012cbf8e29aacb9654313250a81d53bbcbdf2": {"ta_keywords": "email leak detection;email leaks;real email examples;email client;email server side;outlier detection task;leak;enron corpus;unintended recipients;outliers;recipients;test cases;network patterns;experiments;effective solution;real cases;variation;changes;task;result;important problem;technique;method;problem;paper;separate set;other baselines;first attempt", "pdf_keywords": ""}, "df99459a75328393a9a989498db46ec445335724": {"ta_keywords": "peer review data;peer review;review data;privacy mechanism;privacy guarantees;privacy;review data analysis;reviewers;ratings;peer;certain conference peer;information;such data;reviews;data;public;subjectivity;release;accuracy;utility;paper;authors;unavailability;techniques;need;identities;crux;utility tradeoff;distributions;terms", "pdf_keywords": "review data;privacy guarantees;privacy mechanism;privacy;reviewers;ratings;certain conference peer;peer;dissemination;public;reviews;information;data;release;statistical analysis;subjectivity;paper;accuracy;utility;techniques;need;distributions;identities;literature;crux;negative theoretical results;miscalibration;time algorithm;part;manner"}, "c4bc2f7e04e02107aa6eaa0c811c3c046efbbc14": {"ta_keywords": "free prolog clauses;natural learning problems;deterministic finite automata;simple learning problem;learning problem;description logic classsic;formal problems;ground clauses;programming;examples;partial traces;straightline programs;strings;demonstration;dfas;hardness results;order representations;string;alphabet;concepts;hardness;output pairs;operator;arity;subconcepts;function;first;set;area;result", "pdf_keywords": ""}, "69b184f62c97513b03deed96a1443f79b34af0d7": {"ta_keywords": "dishonest reviewers;bid manipulation attacks;such bid manipulation attacks;paper reviewing robust;paper reviewing assignments;paper bidding;reviewers;unprecedented submission numbers;integrity;quality assignments;review process;papers;assignment system;paper;authors;robustness;most computer science conferences;expertise;internal workings;access;friends;merit;anecdotal evidence;acceptance;work;inputs;door;efficacy;system;full knowledge", "pdf_keywords": "bid manipulation attacks;such bid manipulation attacks;paper reviewing robust;dishonest reviewers;assignment system;multiple adversaries;box adversaries;assignment quality;security;reviewer pool;robustness;new threat model;paper;defense;detection mechanism;realistic paper;novel paper;access;detects;inputs;depth knowledge;internal workings;system;ment system;results;full knowledge;ef\ufb01cacy;approach;settings"}, "b21fa4f31c4813444e50259dfbe2c56660161174": {"ta_keywords": "machine translation;active learning;selecting syntactic", "pdf_keywords": ""}, "89fd287f7eacc7a40d0216ba3b919812da658b94": {"ta_keywords": "lfads models;deep inference;model hyperparameters;selective backpropagation;latent dynamics;autolfads;regularization strategy;dataset;largescale framework;dropout;appropriate hyperparameter;tuning;training;appropriate hp tuning;optimal hp combinations;spatio;framework;hp;time;cd;main text;population;pbt", "pdf_keywords": "relevant neural dynamics;neural population dynamics;real electrophysiology data;sequential autoencoders;neural population activity;sparse datasets;latent dynamics;training data;sparse data;deep generative models;selective backpropagation;macaque motor cortex;novel neural network training strategy;calcium imaging data;state space modeling;dimensional dynamics;data;challenging sparsity levels;synthetic 2p calcium imaging simulation;early layers;time series data;models;data model;sbtt learn;high frequency features;sbtt capture;time step;experiments;time;sbtt"}, "c5950fa3ee124cf2dcb8783db6f582f49170fb45": {"ta_keywords": "guarantee generalization;empirical risk minimization;generalization gap;generalization;classifiers;deep learning;linear classifiers;empirical risk;gradient descent;true labels;random label noise;vacuous guarantees;unlabeled data;true risk;holdout data;early learning phenomenon;noisy labels;random data;networks;intuitive assumption;guarantee erodes;validate;training;models;clean data;low error;holdout set;insights;machine;scientists", "pdf_keywords": "deep learning;generalization bounds;benchmark datasets;nlp tasks;random label noise;generalization;natural language processing;canonical computer vision;nlp;unlabeled data;noisy labels;true labels;randomly assign;networks;track;early learning phenomenon;computer vision;train;actual performance;holdout data;true risk;intuitive assumption;insights;experiments;paper;ratt;work;test error;range;population error"}, "a7822238f5db7d62731eaeabf9725a65f4edf893": {"ta_keywords": "language modeling;term dependency;transformer;xl", "pdf_keywords": ""}, "9cdf512f273083efa1ea01f7b31daa97a7bbe884": {"ta_keywords": "computation schemes;computational locality;computation frameworks;exploit locality properties;muller codes;computation;locality;multivariate polynomials;code;codes;efficient alternative;schemes;generalized notion;parity units;servers;nonlinear functions;reed;frameworks;data;function;distinct servers;workers;fewer workers;multiplicative;inadmissible technique;paper;multiple units;units;recent results;resource", "pdf_keywords": "coded computation;computational locality;multivariate polynomial computations;computation schemes;exploit locality properties;locality;computation;multivariate polynomials;oblivious approaches;new locality;reduced worker threshold;codes;lower worker threshold;workers;input data;frameworks;inadmissible technique;input;models;local recovery;domain;design;equivalence;number;model;leverage results;section;based model;uni\ufb01ed viewpoint"}, "6aeb477e5f0882f8363a3a8e5e6f83962d91edc6": {"ta_keywords": "accelerated future learning;future learning;better learning strategies;better learning strategy;prior learning;learning mechanisms;learning;prior knowledge learning;learning process;stronger prior knowledge;robust learning;feature recognition;demonstrates;instructional treatments;models;students;real students;little study;model;computational model;techniques;machine;outcomes;simulation study;studies;human;model variations;like error patterns;pattern;behavior", "pdf_keywords": ""}, "39ab4b9cdeb4a71b3e25fe5339962654c7c9ff8c": {"ta_keywords": "fake news spreader prediction;false information spreaders;real world twitter datasets;social networks;graph neural network;credibility;false information;spreader;spread path;true information fact;nodes;spread paths;trust;node;network structure;explainable attention;historical behavioral data;accuracy;neighborhood;model;people;features;efficient strategy;co", "pdf_keywords": "fake news spreader prediction;graph neural network model;social network;graph neural network;false information spreaders;real world twitter datasets;credibility;interpersonal trust features;trust;nodes;spreader;spread path;node;neural network model;false information;graph;network structure;likely action;attention;historical behavioral data;accuracy;explainable attention;model;neighborhood;people;scarlet;idea;xavier morales2;paper;features"}, "00799dceb9e7209bb9d71b38fa5b49483e886978": {"ta_keywords": "dynamic nn architectures;dynamic nn;recent deep learning;dynamic neural network;dynamic nns;dynamic network;dataflow graph construction;static graph optimization techniques;tensorflow fold;bottlenecks;efficient training;static graphs;dynamic instance;nn structure changes;graph optimization techniques;pytorch;dl programming models;graph construction;runtime system;nn;architectures;training;optimizations;dl;models;processing;example;dynet;inference;operations", "pdf_keywords": ""}, "ab57c70c14b82d07c40c75fecaac98b0e2dc0510": {"ta_keywords": "record linkage;hierarchical graphical model;referent records;hierarchical graphical model framework;linkage methods;hierarchical model;unsupervised methods;classifiers;linkage problem;graphical model;record;latent variables;general graphical model setting;monotonicity constraints;unsupervised setting;other names;above model;field;paper;interest;techniques;approach;task;method;experimental results", "pdf_keywords": "hierarchical graphical model framework;hierarchical latent;hierarchical model;variable graphical model;graphical model;unsupervised methods;latent variables;continuous data;linkage methods;linkage;monotonicity constraints;unsupervised setting;noisy labels;record;linkage problem;paper;classi\ufb01ers;section;figure;approach;general problem;method;problem;experimental results"}, "6413e6a4f68be0ea6aed0082b205147d9f893699": {"ta_keywords": "morphological inflection generation;inflection generation;sequence learning;neural encoder;character sequence;particular linguistic transformation;inflected form;decoder model;rich languages;datasets;art models;variant;lemma;task;system;state;problem;comparable results", "pdf_keywords": "morphological in\ufb02ection generation;sequence learning;neural network sequence;character language model;sequence transducer;character sequence;particular linguistic transformation;in\ufb02ection generation;neural encoder;decoder model;language;string transducer;supervised model;unlabeled data;vocabulary;in\ufb02ection tables;model;task;forms;abstract;form;variant;root form;information science;lemma;technology;nara institute;paper;2graduate school;japan"}, "8dd85c3a3700d0d282ddbd4dff5e238f24c00676": {"ta_keywords": "gaussian mixture modelling;speech spectral envelope;mixture model;variational bayesian;spectral envelope;novel variational bayesian;histogram representation;histogram data;model parameter distributions;glottal excitation information;bayesian modelling;histogram;maximum likelihood;mixture;gaussians;fewer gaussians;speech;like peaks;objective function;objective measure;iterative algorithm;better modelling;mog model;ml;model structure;parametrisation;mog;method;vb;derivation", "pdf_keywords": ""}, "74dccd379776bbb50b352c19b8caf2a7896d58ee": {"ta_keywords": "many power system optimisation problems;large power system optimisation problems;operating constraints;coherent constrained variables;coherency analysis method;constraints;coherency analysis;large power systems;control variables;mathematical formulations;sensitivity;solution model;efficiency point;control;application;set;large number;small number;actions;number;view;paper", "pdf_keywords": ""}, "6a3cc30d5d6342d912851deb4362b8c47fa5ede3": {"ta_keywords": "unknown biases;debiasing methods;many nlu tasks;bias;biases;nlu models;challenge datasets;certain biases;datasets;high dataset;examples;models;task;self;specific performance;methods;sets;tendency;improvement;framework;advance;major assumption;gap;types;application;first step;reliance;work", "pdf_keywords": "biased features;bias results;biased examples;debiasing methods;many natural language understanding tasks;biases;challenge datasets;synthetic dataset analysis;certain biases;examples;better overall robustness;neural models;models;shallow model;training distribution;prior knowledge;self;insight;framework results;target labels;general framework;evaluation;impressive performance;high improvement;super\ufb01cial surface patterns;\ufb01rst model;introduction;nlu;improvement;tendency"}, "51f6654b9d5925002ccaa5cd339b4377b96719ce": {"ta_keywords": "clustering emails;user activities;unsupervised clustering methods;user activity;cluster;ongoing activities;key ongoing activities;information extractors;briefing folder;activity;activities;workstation users;emails;calendar;workstations;online calendar;meeting;workstation;workstation user;calendar events;email;classifiers;web accesses;collection;projects;most users;data;files;knowledge;committees", "pdf_keywords": ""}, "f4906089f0720c83e57e4a46ae75283df4d67e5a": {"ta_keywords": "peer evaluation;peer selection;peer review;peer selection problems;scientific funding bodies;participants;political science;proposals;us national science foundation;funding;submitters;review load;economics;selection;evaluation;athenian society;moocs;council;motivation;citizens;choices;computer science;considerable attention;foundational process;mechanisms;agent;athens;random subset;best subset;mechanism design pilot", "pdf_keywords": ""}, "05f8dd59d4184d38e240bdea4d58e424b8cd055c": {"ta_keywords": "argumentation platform;persuasion;past debate competition;reputation;debates;persuasive power;successful persuasion;argument content;deliberation online;unstructured argument text;deliberation;votes;neural models;influence;additional reputation points;other critical offline behavior;cognitive overload;language;donations;ethos;double machine;causal effect;learning framework;purchases;heuristic information;impact;characteristics;platform average;opinions;individual", "pdf_keywords": "endogenous opinion selection;large online argumentation platform;persuasion;argumentation platform;opinion text;successful persuasion;past debate competition;debates;rhetoric;reputation;neural models;unstructured argument text;persuasive power;challenger;response;response text;deliberation online;language;conclusion;causal effect;skill increases;text;reference cue;opinion;cognitive complexity;instrument validity;learning framework;ethos;predictions;individual"}, "59f41c5024a238ae8843f3dd67692961ecc63e75": {"ta_keywords": "phoneme recognition;dnn systems;dnn structure;appropriate dnn structure;deep neural networks;digit detection tasks;speech processing applications;deep understanding;dnns;covariance matrix adaptation evolution strategy;learning rate;network structure;genetic algorithm;skilled experts;simple binary vector;above binary vector;acyclic graph;layer;other tuning parameters;several tuning parameters;expertise;development;complicated configurations;optimal performance;such systems;number;hidden states;performance;respect;approach", "pdf_keywords": ""}, "f9e32b30fd9ad50cce12ffb753c7be88100b6dc2": {"ta_keywords": "crowd labeling;crowdsourcing platforms;crowd;optimal estimation;efficient estimators;massive datasets;wan estimator;workers;data;different estimators;significant generalization;permutation;minimax;global minimax rates;ordering;new error metric;skene model;task;robustness;simpler dawid;model;lower bounds;classical dawid;terms;advent;logarithmic factors;significance;setting;abilities", "pdf_keywords": "objective labeling tasks;labeling;estimation;crowd;empirical evaluations;labels;wan estimator;binary choices;approximate ordering;task;di\ufb00erent estimators;e\ufb03cient estimators;workers;statistical guarantees;ordering;new error metric;e\ufb03cient estimator;data;new permutation;discussion;signi\ufb01cant generalization;e\ufb03cient algorithm;obiwan;single correct binary answer;obi;model;popular dawid;terms;skene model;question"}, "15ac2d8629ca9241ea558eb2b816272d82447ac7": {"ta_keywords": "crowdsourcing;incentive mechanisms;statistical bias;estimation;estimators;people;models;form people;accurate learning;algorithms;minimal modeling assumptions;quality data;data;fundamental challenges;critical challenges;challenge;assumptions;various algorithms;industry;natural requirement;variance tradeoff;academic research;payment mechanisms;second challenge;several canonical problem settings;multiplicative mechanisms;strong parameter;many societal causes;context;surprising win", "pdf_keywords": ""}, "18ddcd250bbbe716a0616412ea329a8343f60542": {"ta_keywords": "crowdsourcing supplementary material;crowdsourcing;incentives;approval voting;probability;p1;worker;belief;option", "pdf_keywords": ""}, "c18700ed4ef07dd85ba8bceab3b9584c6e6af49c": {"ta_keywords": "available general web crawl;large web corpus;tokens;commoncrawl;creativecommons license family;urls;languages;date", "pdf_keywords": ""}, "af4e11436268cf68505f1caee5d6f7ff0df9c99a": {"ta_keywords": "causal inference;causal relationships;nlp models;causality;natural language processing;causal effects;nlp;computational linguistics community;nlp remains;language processing;predictive tasks;text;interpretability;fairness;social sciences;outcome;more emphasis;interdisciplinary research;estimation;distinction;prediction;statistical challenge;benchmark datasets;interpretation;critical role;unified overview;research;fundamental goal;scientific research;unified definitions", "pdf_keywords": "causal formalization;causal inference;nlp models;causal formalisms;causal conclusions;nlp methods;causality;causal approaches;nlp modeling;causal effects;computational linguistics community;bias problems;complex machine learning models;fairness;interpretability;text data;text;discussion;interpreting;researchers;robustness;behavior;uni\ufb01ed overview;ideas;brie\ufb02y review;performance;recent advances;section;intersection;potential uses"}, "f8b32c2edcd7ef098ce40b7fd2e68448ac818191": {"ta_keywords": "personalized unknown word detection;support vector machines;novel eye movement features;eye gaze;svm;gaze duration;word rarity features;tracking features;natural reading;personalization;eye;unknown words;detection;previous approach;method;previous work;effect;paper", "pdf_keywords": ""}, "11e4346e60ac76ad018231a851fbbdb2112044d2": {"ta_keywords": "claim phrase veracity;interpretable fact verification;public fact verification benchmark show;natural language statement;textual knowledge source;accurate interpretability;veracity;interpretability;wikipedia;logical rules;final claim verification;phrases;phrase;whole claim;loren;explanations;verification;latent variables;certain results;aggregation;merit;final verdict;key insight;previous approaches;additional benefit;paper;experiments;approach;scale;level", "pdf_keywords": "regularized reasoning;weakly supervise phrasal veracity;textual knowledge source;interpretable fact veri\ufb01cation;claim phrase veracity;veracity;natural language statement;wikipedia;logical rules;logic;interpretable method loren;phrases;claim sentence;latent variable modeling;aishu cognitive intelligence joint research center;resources;key insight;data science;loren;latent variables;abstract;sunchangzhi;chenjiaze;shanghai key laboratory;mrc module;qbbao19;jjchen19;contributions;aggregation;paper"}, "bcbac71ac64cd6a6aaae41e37ebe960f508ab741": {"ta_keywords": "neural language model;massive language models;interpretable neural memory;subsymbolic neural knowledge;interpretable factual information;symbolic knowledge;modern nlp modeling;symbolic representations;factual information;training corpora;knowledge;new facts;facts;commonsense;experts;earlier models;model;interpretation;adaptable;latent parameters;ones;explicit interface;impressive amounts;ways;core;world;problems;inspection", "pdf_keywords": "external fact memory;subsymbolic neural knowledge;neural language model;interpretable factual information;memory;language model;symbolic representations;memories;new knowledge;facts;additional training;explicit interface;model;interface;output;end users;experiments;conclusion;parameters;paper;method;problems"}, "1ca247158522991ad54cccaac6c6938576a8bd26": {"ta_keywords": "ms marco document ranking;most bert;traditional ir system;traditional ir;several neural runs;neural models;large pretrained transformer model;models;submissions;short document", "pdf_keywords": "ms marco document ranking leaderboard;ms marco document ranking;trec nist data;traditional ir system;traditional ir;tuned bm25 system;queries;neural models;overview;documents;own evaluation;short document;data;system;mar;system description;form;abstract"}, "2eef9173946078c402596b9b080b6878db00b8ac": {"ta_keywords": "other social media data;twitter;obesity;social media;community data;type ii diabetes mellitus;t2dm;data;stock market prediction;food;early detection;marketing;level data;language;wide variety;risk factor;methods;challenges;development;peculiarities;task;applications", "pdf_keywords": ""}, "38bd034e6a0589bf1132d3e8c79818b271377290": {"ta_keywords": "discriminative training;weightedclassi\ufb01cation error;margin use;mmi functionals;margin values;scale discriminative training withwell;weightedhmmtraining;margin;support vectormachines;mpe loss;speech recognition;svms;mpe;mmi;generalized error;hmm optimization;learning;hinge loss;corpus;new framework withmargin;context;scale tasks havebeen;hamming distance;differencing;maximummutual information;objective function;scaleasr tasks;mce;relative gains;performance", "pdf_keywords": ""}, "3429a6b440fb6f71990bbeda9d097d709634a913": {"ta_keywords": "parser selftraining;parser self;parser accuracy;machine translation;parse tree;parse trees;parser output;translation accuracy;automatic evaluation metrics;syntax;training data;translation;self;training;noisy data;accuracy;errors;variety;method;paper", "pdf_keywords": ""}, "9ce09b03f056253252f3e8c0c65d86a27117a0ac": {"ta_keywords": "unlabeled test data;training data;supervised model confronts;time adaptation;entropy minimization;adaptation;entropy minimization approach;testing;test;entropy;predictions;different data;different distribution;confidence;objective;model;setting;help", "pdf_keywords": "test entropy minimization;adversarial domain adaptation;domain adaptation;entropy minimization;model predictions;predictions;adaptation;time adaptation;time entropy minimization scheme;testing;normalization;test data;test;time normalization;batch;time training;normalization statistics;entropy;fully test;ganin;generalization error;channel;new model;new methods;iclr;lee;shaoteng liu1;model;domain classi\ufb01er;target data"}, "2db020e3398c06e3a22f12d8caffe76b0d9d1dda": {"ta_keywords": "commonsense tasks;neural language modeling;general semantic reasoning;language models;global knowledge graph;tasks;individual knowledge graph;knowledge sources;specific tasks;task;commonsense question;external knowledge;novel neuro;informative questions;shot question;different tasks;symbolic framework;models;benchmarks;data generation strategies;training regimes;hypotheses;accuracy;recent developments;addition;set;paper;leaps;form;structure", "pdf_keywords": "commonsense question answering;commonsense tasks;question generation techniques;neural language modeling;general semantic reasoning;language models;zeroshot evaluations;language model;general reasoning abilities;shot evaluation;zeroshot qa;data construction;commonsense question;tasks;knowledge sources;knowledge;speci\ufb01c tasks;benchmarks;shot question;data generation strategies;external knowledge;machine collaboration;models;accuracy;symbolic framework;hypotheses;recent developments;1language technologies institute;arti\ufb01cial data;novel neuro"}, "68dca6ee694f22e2af66b56e60fdfa74041242e6": {"ta_keywords": "espnet2;pretrained model;shinji watanabe", "pdf_keywords": ""}, "a0f8733dd84608b3cad97904624f8bfdc2d2fcbf": {"ta_keywords": "medical equipment;aim", "pdf_keywords": ""}, "890317710697a9e41d0d9961d99986c4d865393f": {"ta_keywords": "aware app usage representations;temporal app usage representation;app usage prediction task;app usage graph;app usage;aware representations;apps;personalized mobile apps;aware spatio;graph convolutional network;app;representations;spatio;gcn;location units;meta path;edges;graph;novel representation;nodes;time units;user experience improvement;location;locations;complexity;vectors;time;recent years;use;co", "pdf_keywords": ""}, "b6c4a96e09b9f11e7c70e7f1fbe3f3971b92762d": {"ta_keywords": "text generation;language generation;machine translation;fudge models terms;text;future discriminators;topic control;generation;poetry;attribute predictor;bayesian decomposition;fudge;conditioning;attribute;conditional distribution;original probabilities;output logits;tasks;formality;formality change;predictor;outputs;example;partial sequence;couplet completion;distribution;modular method;interest;gains;access", "pdf_keywords": "topic control tasks;sentence constraints;formal machine translation;poetry couplet completion;machine translation;language generation;topic control;multiple attribute constraints;individual words;fudge;poetry;topic bag;attributes;modular fashion;words;rhyme;fantasy bag;different attributes;modularity;tasks;couplet completion;formality change;\u03bbwdec conditioning strengths;different tasks;predictors;\ufb01ne;wdec;limitations;strong performance;cclm"}, "97e8430fe01394ea9a49fd841d9aecdfc294a796": {"ta_keywords": "fuzzy rules;genetic algorithms;fuzzy reasoning;ultrasound images;myocardial heart disease;gaussian;classification;ultrasonic images;membership functions;classification rate;gdmfs;optimization;diagnosis;texture;gdmes;best case;training process;optimal coefficients;standard deviations;method;discrimination;ga;application;parameters;computer;set;results;gas;magnitudes;coefficients", "pdf_keywords": ""}, "33206a493e3519d27df968e98eb7fe6af14ef985": {"ta_keywords": "causal relationships;causal model;learning;human learning;incremental learning system;ai machine learning;occam;knowledge;free learning methods;similaritybased learning;memory;events;research;examples;explanation;processes;model;intensive methods;methods;contribution;lawrence erlbaum;evaluation;prospective;sequences;michael pazzani;review;variety;attempt;hillsdale;nj", "pdf_keywords": ""}, "89440a4cb27d17ced5d54bbe0f81f3477bf16404": {"ta_keywords": "minimum relative entropy discrimination;automatic speech recognition;kernel machine", "pdf_keywords": ""}, "27dafb0b6076e050c31ede8d3e0184ef3592b364": {"ta_keywords": "organic framework;electrodeposition;superior capacitive performance;efficient metal;metal;co", "pdf_keywords": ""}, "591ebe6dccb388d041623840db29a5e58824b4b0": {"ta_keywords": "underlying preference orders;conditional preference tables;preference variables;preference;uniform generation algorithm;preferences;large statistical bias;empirical testing;flipping length;graph structure;binary variables;social choice;nets;algorithm;several statistical cultures;new statistical evidence;graph;experiments;net;cp;lengths;time algorithms;maximum length;manner;minimal proof;generation;number;previous experimental work;result;literature", "pdf_keywords": ""}, "7f1a6c67d03de88b898271d52dd2e51907d5b615": {"ta_keywords": "natural language processing;semantic role labeling;dependency parsing;natural language analysis;relation extraction;relation representations;sentiment analysis;labeling spans;spans;span;disparate tasks;tasks;single task;semantics;relations;different tasks;sentiment;syntax;information content;aspect;single unified format;insight;architectures;specialized models;simple insight;output;many others;extensive experiments;performance;type", "pdf_keywords": "stronger contextualized representation models;natural language analysis capability;general language analysis datasets;natural language analysis;spans;bert;bertlarge;representations;tasks;uni\ufb01ed representational methodology;glad benchmark;different tasks;benchmark;testbed;spanrel model;uni\ufb01ed features;elmo;relations;datasets;holistic;brat format;output;uni\ufb01ed format;input;single modeling framework;labels;best performance;result;contrast;code"}, "a9c0ffc760f65ccaa99a08fc66b31653fd4a5bd7": {"ta_keywords": "organ donation;organ transplantation;organ donation program;transplantation;organ;donation;nurses;nurse;biological tissue;human body;treatment modality;health care fleet;dissemination;recipient;scooping review;commitment;awareness;success;india;pivotal role;status;dead person;change;knowledge;experimental procedure;people;right information;need;living;rapid strides", "pdf_keywords": ""}, "a03675379685d88c727bc985a323cc71d06f2514": {"ta_keywords": "discrete syntactic structure;structured generative;unsupervised dependency;syntactic structure;generative models;novel generative model;unsupervised learning;continuous word representations;gold pos annotation;efficient exact inference;speech;invertible neural projections;dependency;priors;invertible neural network;discrete latent variables;prior;tree;unsupervised fashion;marginal likelihood computation;multinomial parameters;markov;constraints;tasks;punctuation;part;model;pos;induction;difficult training condition", "pdf_keywords": "latent syntactic representation;latent syntactic structure;structured generative;syntactic dependencies;word embeddings;discrete syntactic structure;continuous word representations;embeddings;syntax model;observed embeddings;new generative model;novel generative model;dependency parse;markov structure;latent vectors;representation;new representation space;gaussian hmm;neural projector;markov;latent;example;neural network;new latent;invertible neural network;unsupervised fashion;projection;pos categories;simple space;tree"}, "7f817600b612aab6039dfba576ae8e8e7460d8f1": {"ta_keywords": "initial pronunciation dictionary;automatic speech recognition systems;pronunciation dictionary;bayesian learning;disjoint phonemic transcripts;word pronunciations;dirichlet processes;phone transcripts;textual data;words;wsj data set;text;word;context;appropriate vocabulary;specific domains;model;tasks;new framework;task;application;initial stage;area;ones;human levels;humans;performance;open question;work", "pdf_keywords": ""}, "60a9438c24847a949419e0350a61fc2a330e4a09": {"ta_keywords": "kernel clustering limitations;kernel clustering;many kernel clustering criteria;kernel methods;density biases;kernels;density mode isolation bias;clustering;real data experiments;data analysis applications;data inhomogeneity;broad spectrum;theoretical understanding;generality;example;findings;significant artifacts;disciplines;common class;means;conditions;past;solutions;power;principled solutions;principled solution", "pdf_keywords": "kernel clustering limitations;many kernel clustering criteria;clustering criteria;density equalization principle;density biases;mode isolation bias;continuous generalization;approximate optimization;gini criterion;data analysis applications;means objective;real data experiments;algorithm;bias;basic iterative approach;broad spectrum;means;standard lloyd;theoretical understanding;discrete case;disciplines;paper shows;past;solutions;breiman;section;signi\ufb01cant artifacts;cause;principled solutions;relation"}, "11db042ed2264f3ea1b8f20151adf725ec3461e8": {"ta_keywords": "neural network error surfaces;neural networks;partial training;training paths;local minima;error surfaces;weights;critical points;apparent convergence;critical point;weight space;loss;large movements;models;local optima;flat regions;nonconvex;random initialization;point;descriptions;symmetry;recent work;paper;researchers;evidence", "pdf_keywords": "neural network error surfaces;neural networks;partial training;training paths;error surfaces;mnist dataset;convolutional neural network;weights;iclr;layer;local minima;nonconvex;symmetry;random initialization;large movements;critical points;different random initialization;2d pca;weight space;apparent convergence;loss;workshop track;paths;\ufb02at regions;good ones;dropout;weight;feb;paper;space"}, "201b79be15b6b01e62a82b29ac4d30d3e6a11799": {"ta_keywords": "neural beamformer;speech recognition model;recurrent neural network;attention component;rnn;encoder;relative wer reduction;decoder;spatialized wsj1;transformer models;2mix corpus show;transformer;transformer architecture;channel;end models;reverberant case;masking network;models;whole sequence;tasks;aspects;end;self;computation;use;segment;order;work;methods;anechoic condition", "pdf_keywords": "speech recognition module;speaker speech recognition;end multispeaker asr;speech recognition model;lstms;attention layers;transformer models;encoder;transformer architecture;decoder network;transformers;decoder;rnn;channel;memory consumption;module;masking network;end;use;self;scenarios;conclusion;order;paper;time;consistent improvements;manner"}, "62606fbb3aa3ffb17c5427b3652c18a81425cd65": {"ta_keywords": "protein name extractor;annotated training data;extract gene;protein names;training data;labeled text;entity;biocreative challenge;gene;data;ner;difficult task;mouse;weakly;other sources;effort;performance;approach;paper;significant amount", "pdf_keywords": ""}, "99848c6424556bce427d621e89b6d05dac131910": {"ta_keywords": "crowdsourcing annotation;russian language;human intelligence task;crowdsourcing;lexical relations;different annotators;microtask;yandex;knowledge;microtask platform;words;toloka;crowd;negative answers;workers;relation;first dataset;mother tongue;positive ones;wisdom;age;direct answer;hit;pair;design;kind;layout;february;simple question", "pdf_keywords": ""}, "7a1bcf3c84607f7aeb0601658845ca2083059f43": {"ta_keywords": "nlvr2 dataset;mixmatch;language tasks;unlabelled samples;vision;input space;data;model;discreteness;more modifications;complexity;large amount;state;art;constraint;time;performance;limited literature;strategy;end", "pdf_keywords": ""}, "ef09dd6f5615e2b937d3f9dd555c2daafb4c4f4b": {"ta_keywords": "parallel programs;parallel virtual machines;java language;parallel virtual machine;common application programming interface;different computer architectures;javapvm;computer architectures;traditional pvm libraries;independent computers;traditional pvm library;java code;pvm;communication performance;multiple computers;message passing interface;fortran;different executable;programs;jpvm;architecture;libraries;such libraries;tradition pvm;mpi;single computation;performance;api;computations;machines", "pdf_keywords": ""}, "aa0d4f7cfa13758a02d248fd607547f045306519": {"ta_keywords": "person name recognizers;personal names;entity recognition;name repetition;informal text;email;recall;multiple documents;specific structural features;performance;methods;method", "pdf_keywords": ""}, "36db0616e59c8ac5e9ba8ded820ef6c969f068c1": {"ta_keywords": "contemporary art;southern california;art;time;guide;documentation", "pdf_keywords": ""}, "78f1eef6d79a129f59b977a5037f5fc9cc7fda90": {"ta_keywords": "peer review;improved peer;review processes;algorithmic toolkit;algorithms;ai venues;submissions;subjectivity;objectives;fairness;accuracy;robustness;challenges;results;paper;strategic behavior;ideas;goals;insights;survey;noise;variety;applications;ml;work;calibration;principled approach;issues;recent works;works", "pdf_keywords": ""}, "afdae523d420278670c30f45c015cc5860a0de22": {"ta_keywords": "adaptive gradient methods converge faster;deep neural networks;adaptive methods;sgd;minimizer;adam;sls generalizes;adagrad;kernel mappings;convex functions;binary classification;sls;parameterization;optimal rate;momentum variants;convergence;tasks;sps;constant step;converges;interpolation;search;empirical results;rate;line;other hand;violation;amsgrad;size;assumption", "pdf_keywords": "adaptive gradient methods converge faster;adaptive gradient methods;optimizers;convex loss functions;deep networks;stochastic line;kernel mappings;adagrad;generalization;parameterization;superior convergence;iteration;search;models;convergence;performance;convex problem;interpolation;practice;sls;step;binary classi\ufb01cation;\ufb01rst step;smooth;techniques;logistic regression;momentum;tasks;methods;variant"}, "656aedc681975c3c97b1764466832de537358150": {"ta_keywords": "acoustic model adaptation;hybrid automatic speech recognition;auxiliary feature based adaptation;sequence summary network;deep neural network;auxiliary features;auxiliary feature extraction module;decoder e2e models;available recognition tasks;encoder;auxiliary feature;unsupervised adaptation;end asr systems;e2e models;recognition performance;asr pipeline simple;adaptation;e2e model;adaptation scheme;dnn;input;models;asr;speakers;example;environments;systems;end;paper;part", "pdf_keywords": ""}, "2ccfa631708b78130b1ea1b8ae3c2b688caf3938": {"ta_keywords": "scheduling surgeries;surgery case durations;effective scheduling strategies;surgeries;heteroscedastic predictions;booking minutes;neural regression;surgery;booking;current scheduling techniques;minutes;scheduling collisions;large united states health system;disparate costs;heteroscedasticity;uc san diego health system;idle minutes;duration;uncertainty;risks;fundamental uncertainty;challenging task;costs;order;clinical environment;potential improvements;specific margin;terms;specific notion;case", "pdf_keywords": "scheduling surgeries;surgery duration;surgery case durations;neural heteroscedastic regression;heteroscedastic predictions;surgery records;booking minutes;neural regression;anesthesiology3 university;heteroscedasticity;minutes;booking;healthcare;idle minutes;machine learning;disparate costs;current scheduling techniques;models;scheduling collisions;ml;biomedical informatics2 department;large united states health system;clinical environment;data;costs;risks;stat;challenging task;speci\ufb01c uncertainty;fundamental uncertainty"}, "58777f0af009a225e315b7240db20ba545207702": {"ta_keywords": "computational complexity;complexity;complexity theory;computational reasoning;case complexity;uncertain information;aggregation systems;uncertainty;autonomous agents;artificial intelligence;elections;manipulation;insights;insight;susceptibility;research;terms;comsoc community;areas;broader impacts;rich literature", "pdf_keywords": ""}, "309fb4d4d0946ac746f352c13cd3be4e2cd86dae": {"ta_keywords": "bayesian approaches;acoustic modeling;practical speech recognition problems;speech recognition;maximum likelihood;related speech;machine learning;inference;statistics;generalization capability;heavy numerical computations;integrals;processing applications;most cases;applications;conventional approaches;expectations;paper;advantages;fields;review;other hand", "pdf_keywords": ""}, "ce17dab00ddd2c86da508fc0502247f9b18a570f": {"ta_keywords": "prominent voting rules;proportional approval voting;satisfaction approval voting;approval voting;approval ballots;multiple winners;representative winning set;computational complexity;computational aspects;single agent;agents;other agents;agent;rules;rule;group;intention;best response;np;set;many settings", "pdf_keywords": "computational complexity;proportional approval voting;approval voting rules;approval ballots;computational aspects;single agent;agents;other agents;agent;pav;rav;sav;group;winner;np;open problem;best response;variety;\ufb01xed set;detailed study;many settings"}, "1d1bbed89882ac1001b915ee73199a919aa0d13c": {"ta_keywords": "neural language model;vocabulary language modelling;training languages;universal linguistic knowledge;languages;several language;prior outperforms baseline models;most languages;human language;broad language;typological databases;parameter generation;posterior;distant supervision;networks;conditioning techniques;informative;laplace;concatenation;features;network weights;sample;shot;data;diverse sample;task;character;specific information;meta;question", "pdf_keywords": "universal linguistic knowledge;diverse training languages;new languages;languages;diverse languages;joint multilingual learning;language;level language;uninformative priors;typological features;unnormalizable priors;typological databases;shot regime;characters;neural network weights;universal;widespread \ufb01ne;data paucity;shot;random sequences;laplace approximation;sample;character;data scarcity;shot settings;several regimes;levels;superiority;results;tuning approach"}, "7b7f8fb08262fce3da64c09788fd4b595408e4e6": {"ta_keywords": "speech synthesis;mudulation spectrum;postfilter;hmm", "pdf_keywords": ""}, "d940e0192a6cc1ddd6288239b77b06e50f042114": {"ta_keywords": "end speech recognition;speech representations;supervised pretrained representations;speech data;automatic speech recognition;speech signal;pretraining;recognition performance;representations;end model archi;asr;training strategy;models;fidelity representation;available corpora;e2e;sota;eral;advanced end;untranscribed data;sev;self;end;general applications;progress;performance;wsj0;source;various tasks;current state", "pdf_keywords": "e2e speech processing toolkit;speech representations;automatic speech recognition;end asr;sslrs;recognition performance;end model architectures;asr;e2e;sota;advanced end;representations;models;available corpora;s3prl;training strategy;wsj0;toolkit;scripts;performance;end;wsj;espnet;systems;source;2mix;general applications;con\ufb01guratons;community;current state"}, "d5924c8cdef6270a955ba82c2b07a8282d869744": {"ta_keywords": "gesture predictions;gesture generation;gestures;freeform gestures;multimodal multiscale attention block;spoken language;acoustic cues;subword alignment;adversarial learning;language;explicit alignment;subword level;text;key challenges;importance;long tail;context;precision;learning relationships;aisle;balance;scale;need;user studies;art approaches;effectiveness;distributions;use;coverage;approach", "pdf_keywords": ""}, "b82e9b84cb639f6bb061c8a43b97986ecfec00ea": {"ta_keywords": "fast similarity queries;partite graphs;fast similarity;entities;dimensional representation;query response time;different datasets;comparable precision;web;task;dimensions;pic;specific baselines;small number;magnitude improvement;semi;approach results;orders;paper;terms;respect", "pdf_keywords": ""}, "ee33d61522fd70fa4e6470decbdac6c17f8b4fdb": {"ta_keywords": "neural speaker diarization;end speaker diarization;decoder based attractors;speaker subset;speaker activities;attractor calculation;multiple attractors;attractors;encoder;speaker condition;clustering method;speech;speakers;speakers conditions;decoder;mixtures;callhome;eend;unknown numbers;unknown number;network;sequence;der;attentive end;flexible number;eda;same number;method;vanilla sa;end", "pdf_keywords": "neural speaker diarization;end speaker diarization;speech mixtures;attractor calculation;speaker activities;encoder;multiple attractors;attractor calculation method;attractors;embeddings;speech;speakers;decoder;attentive end;sequence;eend;end;eda;network;same number;\ufb02exible number;art ders;sa;paper;method;state;ofthe;conditions;\ufb01rst;conventional self"}, "d6d2003d112e3d9d93edd4920436fe2fe879eb87": {"ta_keywords": "big text datasets;effective clustering methods;similarity matrix;scale text datasets;wise similarities;fast method;space;data points;best quadratic;family;pair;time;power;art;state;prohibitive cost", "pdf_keywords": ""}, "3b8b6f27a5df5dc2c231d0fa1e471887e4583466": {"ta_keywords": "citation networks;link prediction;academic biomedical publications;citations;link prediction technique;information extraction;genes;new genes;gene detection;previous coauthors;metadata;publication;information;databases;author;network;future;usefulness;paper;various baselines;something;various types;task", "pdf_keywords": ""}, "4bfc185dcc67b3eddfa059fc5446f4df844a0728": {"ta_keywords": "\u8a00\u8a9e\u7406\u89e3\u3068\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3", "pdf_keywords": ""}, "9635e3c008f7bfa80638ade7134a8fb0ef1b37e1": {"ta_keywords": "language model training;language models;language model performance;language model;tokenisation robustness;tokeniser uncertainty;tokenisations;tokeniser entropy;tokenisation;marginal likelihood;marginal perplexity;marginal perplexities;evaluation;sampling;samples;domain data;perplexity;results;different estimators;one;paper;implications;difference;manageable number;regard;approach", "pdf_keywords": "neural language models;loss language models;tokenisations;single tokenisation;tokenisation;multiple tokenisations;tokeniser entropy;language models;tokeniser;language model;german language models;input tokens;tokens;token;word types;besttokenisation;marginal likelihood;unique whitespace;english;open vocabulary;segmentation lattice;laura rimell deepmind;marginal perplexity;document;marginal perplexities;good predictor;input;entropy;type;evaluation"}, "3f2821dd40c12da560c89b9dad7f95cd4ad9354f": {"ta_keywords": "storage clusters;scale storage clusters;storage infrastructure;diskadaptive redundancy;pacemaker mitigates transition overload;production clusters;data redundancy;transition io requirement;disk failure rates;io load;disks;transition io;adaptive redundancy;redundancy schemes;disk;transition overload;world clusters;significant cost overhead;pacemaker;traces;future transitions;data layouts;substantial space;backblaze;transitions;roadblock;production systems;resilience;space;urgency", "pdf_keywords": "cluster io;hdfs;scale production clusters;diskadaptive redundancy;hadoop;production clusters;transition io load;storage systems;disk deployment;transition io requirement;transition io;disks;disk failures;total transition io;disk capacity;data redundancy;transition overload;pacemaker;failure data;pacemaker copes;traces;production systems;data layouts;ef\ufb01cient transitions;deployment pattern;data;backblaze;roadblock;primary takeaways;google"}, "ff6ddbd7ba59e0fd4a74748942083391d6e9a666": {"ta_keywords": "end information extraction;opera system;knowledge bases;information;isi;multiple media;hypothesis reasoning;results;cmu;ukrainian;english;russian;usc;paper", "pdf_keywords": ""}, "9fe09ca520cb7ce106e65b39c455777d18ec6efe": {"ta_keywords": "curated taxonomies;textual taxonomies;taxonomies;heterogeneous edge semantics;explicit supervision;taxonomic relatedness;edge semantics;arborist;taxonomy;structured knowledge;recall;nodes;taxonomic;new taxonomy;pinterest;embeddings;extensive evaluation;latent representations;several public datasets;node pairs;machine;task;mean reciprocal rank;actual parents;roles;parents;margin function;via;path distance;performance", "pdf_keywords": ""}, "ef4166a7fb2c40ca87b0ebb253e8ba1e80c09fd7": {"ta_keywords": "augmented discriminative feature transformation;speech separation;discriminative feature transformation;feature transforms;discriminative training;feature transformation;reverberation;various feature transformation;natural background speech;chime;noisy speech;art asr techniques;recognition challenge;home noises;arbitrary features;music;difficult task;challenge;model parameters;addition;task;state;paper;preliminary benefits;baselines;effectiveness;time;experimental results", "pdf_keywords": ""}, "5db0fa82c322bb7d9f60109294d088ff139eebf3": {"ta_keywords": "gan manifold;generative adversarial networks;denoising images;gans;gan;blur kernel;clean images;plausible images;real dataset;bias correction;latent vectors;dimensional latent vectors;images;bm3d;image space;noise variance;higher quality;latent vector;projection;image;quality;prior knowledge;signal processing;manifold;methods;method;nearest point;corrupted version;estimate;distances", "pdf_keywords": "generative adversarial networks;gans;gan;latent vector recovery;dcgan;latent code recovery;image denoising;deblur images;lowdimensional latent vectors;latent vectors;latent vector space;plausible images;best signal processing;images;sharpness;higher quality;recovery;psnr;projection;bm3d;versions;methods;method;knowledge;paper;subarna tripathi uc san diego;\ufb01rst empirical demonstration;conclusions;practice;attribute"}, "1d05e91b6d94f06439b2b41291a8dcc3d8064149": {"ta_keywords": "color clustering;image grid regularization;segmentation benefits;segmentation;kernel bandwidth;dimensional feature spaces;dimensional features;graph cuts;standard color model;wise feature;knn;fitting techniques;means approach;bound formulation;energy;adaptive bandwidth strategies;scalability;gini bias;means;properties;methods;general pair;alternative approach;standard model;extreme cases;effectiveness;fails", "pdf_keywords": ""}, "da1f22dd6d834e031eb733d2b70320f34ef9458f": {"ta_keywords": "pairwise comparisons;such pairwise comparison data;comparison graph;parametric ordinal models;preference elicitation;sharp minimax bounds;sporting competitions;qualities;standard minimax framework;peer;pairs;lower bounds;thurstone models;luce;models;others;optimal error;bounds;many domains;topology dependence;data;estimation;class;laplacian;terry;btl;topology;subset;form;spectrum", "pdf_keywords": "pairwise comparisons;ranking;parametric ordinal models;such pairwise comparison data;comparisons;preference elicitation;parametric models;thurstone models;sporting competitions;sharp minimax bounds;parametric idealizations;qualities;popular amazon mechanical turk;thurstone;selection;keywords;peer;inference;luce;models;btl models;others;utility;commercial crowdsourcing platform;elicitation paradigm;results;mturk;options;topology dependence;cardinal"}, "b07b124852f897823490db0a04ea6e411bb77f00": {"ta_keywords": "multilabel classification;binary classifier;binary classification;classifier;classifiers;optimal threshold;optimal thresholding;classifier outputs;best achievable f1 value;optimal f1 value;average f1 measures;threshold;f1 measures;f1 measure;precision;optimum;conditional probabilities;recall;class;harmonic mean;micro;decision;output;special case;instance;paper;context;success;new insight;relationship", "pdf_keywords": ""}, "b6502b61bf8f0332c6caa30198cff3619a9790aa": {"ta_keywords": "redundant requests;latency performance;optimal redundant;multiple replicas;redundancy;faster execution;multiple servers;average latency;storage system;service times;multiple processors;cluster;delay;computational task;additional copies;memoryless;high loads;negligible costs;request;load;data;policies;several recent works;jobs;system;instance;copy;rigorous analytical study;jobs results;removal", "pdf_keywords": "multiple replicas;storage system;redundant requests help;cluster;multiple servers;multiple processors;requests;computational task;in\ufb01nite capacity;several systems;such systems;buffer;computer sciences;system;instance;data;berkeley;request;paper;nihar;key features;california;model;compute;section;\ufb02exibility;several settings;university;kw1jjang;abstract"}, "b72c5236dacf2b958ebcf427d17a100bc54af504": {"ta_keywords": "attention network;automatic speech recognition;contextual block processing;rnns;contextual block processing method;neural networks;transformer encoder;naive block processing;local acoustic information;speaker attributes;transformer asr;layer;voxforge italian;block;new block processing method;transformer self;contextual inheritance mechanism;attention weight tendency;asr;additional context;global information;e2e;context;channel;aware inheritance mechanism;vector;end;evaluations;wall street journal;promising performance", "pdf_keywords": "transformer encoder;automatic speech recognition;attention network;contextual block processing;rnns;contextual block processing method;transformer asr;neural networks;transformer self;naive block processing;context inheritance;new block processing method;asr;voxforge italian;context;shinji watanabe2;model;novel mask technique;e2e;aware inheritance mechanism;promising performance;evaluations;end;yosuke kashiwagi1;alternative;systems;librispeech;abstract;wall street journal;eess"}, "6dfc2ff03534a4325d06c6f88c3144831996629b": {"ta_keywords": "visual commonsense reasoning;commonsense reasoning;new reasoning engine;necessary layered inferences;cognition networks;contextualization;recognition;movie scenes;adversarial matching;cognition;reasoning;rich annotations;challenge;machines;task;level understanding;vision systems;image;machine;minimal bias;actions;glance;order cognition;pixels;r2c;goals;instance;humans;new dataset;multiple choice qa problems", "pdf_keywords": "cognitionlevel image understanding;cognition networks;recognition;new reasoning engine;adversarial matching;necessary layered inferences;cognition;movie scenes;contextualization;computer vision systems;level understanding;commonsense understanding;visual data;reasoning;image;multiple choice qa problems;understanding;questions;novel qa assignment algorithm;new dataset;context;natural language passage;dataset creation;vcr;rationale;scale;grounding;r2c;world;new model"}, "df43f6ff7c66d39240235af3052be55222bef80d": {"ta_keywords": "mixture models;mixture distributions;mixture model;speaker clustering problem;elemental mixture distributions;mixture;variational bayesian;suitable sampling method;novel model estimation method;conventional sampling;hierarchical agglomerative methods;novel gibbs;gibbs;data structure;models;maximization algorithm;large bias;model;distribution;data;components;coarse;level;expectation;possible approach;component;kinds;deterministic procedures;method;approach", "pdf_keywords": ""}, "964293c1cb1b619eb9b474381d2ba60cf44fcc2d": {"ta_keywords": "facility map database;distribution facility management;distribution facility construction;mapping system;distribution line maps;distribution facilities;mapping system cost;mapping database;tokyo electric power company;maps;design system;facilities;automatic drawing reader;design;design jobs;recognition technique;tepc;planning;inputting;system;many jobs;maintenance;operation;development;manual digitizer input device;project;important feature;initial input;continued efforts;use", "pdf_keywords": ""}, "d389d8c2e15f9e9269c17fe6f960f70559eee840": {"ta_keywords": "parsimonious morpheme segmentation;unsupervised morpheme segmentation;morphemes;morphmine morphemes;enriching word embeddings;word embeddings;downstream language modeling task;morphmine;poor embeddings;text corpora;vocabulary words;words;infrequent words;languages;word;evaluations;hierarchy;parsimony criterion;level;human;variety;weak capabilities;quality;techniques;regard;experiments;paper;application;fewest number", "pdf_keywords": "unsupervised morpheme segmentation;morpheme segmentation;parsimonious morpheme segmentation;morphemes;morphmine morphemes;quality morphemes;quality candidate morpheme;enriching word embeddings;word embeddings;downstream language modeling task;language modeling;morphmine;\ufb01nest meaningful semantic granularity;input vocabulary;embeddings;mining tasks;language;word;individual word;segmentation;task;many text;evaluations;1ahmed el;tokens;model;kishky;champaign;level perspective;boundary identi\ufb01cation"}, "3d1318bc66d534eefac7c665fd7cc891fba27b87": {"ta_keywords": "\u65b0\u3057\u3044\u6280\u8853\u3068\u7814\u7a76\u306e\u53ef\u80fd\u6027;\u5c0f\u7279\u96c6;\u6a5f\u68b0\u7ffb\u8a33\u6280\u8853", "pdf_keywords": ""}, "33972d9e9a102f9388e5850d8aed3d1aefc9d2e5": {"ta_keywords": "argumentation quality;fallacious argumentation;argumentation scholars;computational argumentation;argumentation;argumentative discourse;fallacious arguments;serious games methodology;critical thinking;fallacies;nlp researchers;discussion;serious games;annotation;argotario;focus;resources;important skill;omnipresent;scalable approaches;nonexistence;importance;wrong moves;data acquisition;ability", "pdf_keywords": "computational argumentation;argumentation theory research;fallacious argumentation;argumentation;fallacy recognition task;argumentative discourse;argotario;serious games methodology;fallacies;critical thinking;annotation;computational linguistics research;game data creation;player interaction;platform;serious games;player;scalable approaches;important skill;gami\ufb01cation;resources;computer science;ubiquitous knowledge processing lab;software tool;data;iryna gurevych;qualitative criteria;educational aspects;active topic;features"}, "04138da3bac26f83a9d57152118d4cd5cc8c717d": {"ta_keywords": "similarity measure;similarity;search queries;different arbitrary queries;intelligent message threading;random graph walks;person name disambiguation;personal information management;adaptive graph;queries;random walks;email data;search;entities;such graphs;query type;alias finding;several learning techniques;walk;different relations;email message;persons;messages;graph;different tasks;person;links;other objects;instance;example", "pdf_keywords": ""}, "395aae6e7a79e5760457ca38e868acc970016230": {"ta_keywords": "table reasoning datasets;relational tables;attention transformer architecture;web tables;sparse attention;large tables;table;more rows;rows;tabular data;columns;memory;documents;novel transformer architecture;current accelerators;web;current transformer models;tokens;structure;heads;speed;challenge;mate;architecture;appropriate inductive bias;way;respect;work;new state;art", "pdf_keywords": "web tables;table structure;tabfact;textual data;tabular data;scale qa tasks;sqa;longer sequences;attention \ufb02ow;larger sequence lengths;inference;pointr;novel transformer architecture;points;structure;transformers;inductive bias;linear complexity;hybridqa;novel method;training;mate;section;practice;conclusion;phase framework;method;theory;result;state"}, "e07c2e66dab7b61091bb8a4ad132bf279c233027": {"ta_keywords": "citation prediction task;topic modeling framework;link prediction task;citations;topical similarity;citeseer data;citation;link structure;arbitrary link structure;lda models;mixed membership block stochastic models;lda model;bipartite graph;joint modeling;lda;baseline model;models;documents;unseen data;ideas;contents;text;different models;link;pairwise;erosheva;model;different data sets;plsa;subset", "pdf_keywords": ""}, "aeb4478619461ca25592e6d692f3591ec8c4091b": {"ta_keywords": "semantic collisions;paraphrase identification;nlp models;document retrieval;retrieval rank;similarity;texts;irrelevant document;filtering;collision;perplexity;response suggestion;many tasks;target query;other potential mitigations;gradient;example;approaches;art models;meaning;top;state", "pdf_keywords": "nlp models;nlp applications;semantic collisions;sentence retrieval;semantic collision;paraphrase identi\ufb01cation;unrelated text;vulnerabilities;extractive summarization;similarity;texts;attacks;document;benchmark datasets;input pairs;input;effectiveness;target model;query;tasks;conclusion;application;meaning;techniques;art models;different class;state;new class;work"}, "3a3fb140890dbba93290e358af700f9a5c8bcc7a": {"ta_keywords": "deep qa models;domain question answering;large corpus;gram machines;intensive ai tasks;natural language processing;gram machine;symbolic meaning representations;answer questions;deep neural networks;sentences;entire text;more knowledge;wikipedia;knowledge;millions;text size;qa;complexity;representative tasks;babi;practical tasks;end;ngm;scalability issue;web;question;novel;approach;life", "pdf_keywords": ""}, "2f780a18d44f4e3c5c4c74d4060b8dfd542a778d": {"ta_keywords": "sports commentator bias;racial bias;sports broadcasters;american football broadcasts;play commentary;broadcast transcripts;american football games;racial metadata;anecdotes;football;subjective analyses;drama;large corpus;prior social science studies;researchers;player;decades;team;conclusions;play;computational analysis;factors;phenomenon", "pdf_keywords": "sports commentator bias;racial bias;sports commentary;sports broadcasters;american football broadcasts;commentator sentiment;racial metadata;american football games;broadcast transcripts;play commentary;full game broadcasts;mass media;football;ncaa;transcripts;anecdotes;subjective analyses;social science studies;prior social science studies;drama;large corpus;national collegiate athletic association;player;researchers;analysis;conclusions;playby;decades;major category;team"}, "34fc6da7a88433478fd976fd0b9de3cf7134e652": {"ta_keywords": "automated commucation training system;multimodal information", "pdf_keywords": ""}, "df1d89f4ca9c20e2c6703cdbf26a62f2b50ac71c": {"ta_keywords": "stackelberg equilibria;stackelberg games;stackelberg equilibrium concepts;stackelberg equilibrium;stackelberg gradient dynamics;timescale learning dynamics;sum games;simultaneous gradient descent;stable attractors;only stable critical points;stable critical point;dynamics;continuous action spaces;games;hierarchical order;play;critical points;agents;convergence;conditions;nash;class;connections;paper;set;insight", "pdf_keywords": ""}, "02980e5ba847282b683a85e7a8862c6c1b6e0d94": {"ta_keywords": "di methyl phenyl amine;aqueous organic solvent;solvent interaction;solute;study", "pdf_keywords": ""}, "73aa33fd469b171d50c452c5e3fe0e9e03520520": {"ta_keywords": "iwslt ted asr track evaluation;naist english asr systems;confusion network combination;iwslt evaluation;outputs;english speech;text;first stage outputs;mllr;stt;cmllr;systems;subsystems;kit;second stage;unsupervised manner;vtln;stages;combination;ends;combinations;paper", "pdf_keywords": ""}, "c330ec2047d019d98233abb59d13b3256c662cc7": {"ta_keywords": "arbitrary structural causal model;counterfactual distributions;counterfactual queries;counterfactual query;causal diagram;same causal diagram;counterfactuals;polynomial programming;such polynomial programs;effective monte carlo;canonical scms;optimal bounds;experimental distributions;data;variables;qualitative knowledge;experimental data;arbitrary collection;model;arbitrary combination;canonical family;scms;finite domain;paper;scm;problem;form;solution", "pdf_keywords": "arbitrary structural causal model;counterfactual distributions;counterfactual probabilities;causal diagram;same causal diagram;unobserved states;arbitrary observations;discrete exogenous variables;partial identi\ufb01cation;observed variables;partial identi\ufb01cation problem;optimal asymptotic bounds;target;qualitative assumptions;experiments;experimental data;data;process;\ufb01nite samples;polynomial program;canonical family;variables;conclusion;arbitrary combination;scms;scm;paper;novel algorithm;\ufb01nite domain;values"}, "0a3caecce668731efe7abf37720793eed1fb951a": {"ta_keywords": "political information;tweets;twitter user;information sharing;social media;motivated reasoners;sentiment;political affiliation;social community;emotional reaction influences;sender;political contexts;emotional affect;accurate classifier;emotion;information;deliberative reasoning steps;precision classifier;behavior;people;message;prevalent way;interaction;paper;receiver", "pdf_keywords": ""}, "5bca90a331417402f5018f552e1a62656dd7fc5b": {"ta_keywords": "observed graph;symmetric stochastic block model;graph observation;corresponding community feature;edges;node;efficient algorithm;information;label;features;problem;sbm;theoretic limit;version", "pdf_keywords": ""}, "5166c0e04d77ac0f7969c49c0f8f18129a114198": {"ta_keywords": "clinical gait analysis;motion measurement system", "pdf_keywords": ""}, "205ff5dae21ca44c15d3b7d7a9febb7d84b47bc4": {"ta_keywords": "neural machine translation systems;multilingual models;language regularization;language regularization method;other adaptation methods;small lrl data;languages;explicit adaptation;language;bleu scores;seed models;bleu points;lrl;lrl settings;lrls;training;strategies;data;interest;novel;effective method;methods;paper;number;experiments;time;problem", "pdf_keywords": "neural machine translation systems;neural machine translation;multilingual modeling methods;language regularization;multilingual training;second similar languages;similar languages;new languages;new source language;resource language;small lrl dataset;languages;rapid adaptation;english;source modeling;training data;junjie hu language technologies institute;universal model;only parallel data;single monolithic model;lrl;slr;lrls;bleu scores;start scenarios;aug;novel method;start;graham neubig;interest"}, "488b1849dd81e63aae2cd327564077ae123c0369": {"ta_keywords": "absolute compression operators;communication compression;absolute compression;biased compression;optimal compressors;sgd;noise assumption;error compensation;arbitrary sampling strategy;convex problems;lsvrg;ec;rates;sahu et al;new analysis;analysis;\ufb01rst analysis;methods;class;ones;practical e\ufb03ciency;setting;error;powerful approach;al;issue;paper;certain sense", "pdf_keywords": "absolute compression operators;communication compression;absolute compression;biased compression;optimal compressors;optimization methods;sgd;convex problems;arbitrary sampling strategy;noise assumption;error compensation;neural networks;lsvrg;ec;marina;ras;mar;class;new analysis;methods;parameters;billions;analysis;control sciences;\ufb01rst analysis;powerful approach;1institute;millions;error;eduard gorbunov2"}, "4cd92a56dca741190e453b4229eb9851abf6944c": {"ta_keywords": "accelerated stochastic gradient descent;smooth convex stochastic optimization;new accelerated stochastic;stochastic optimization;stochastic gradients;accelerated gradient clipping;sgd;convex case;probability complexity;new complexity;sstm;noise;order method;method;special variant;gap;paper;theory;heavy;art results;state;case", "pdf_keywords": "smooth convex stochastic optimization;new accelerated stochastic;stochastic optimization;stochastic gradients;accelerated gradient clipping;probability complexity;order method;noise;mipt;sstm;hse;method;russia;eduard;theory;gap;oc;paper;oct;heavy;math;abstract"}, "40848b41ed8c9c255ecd8a920006877691b52d03": {"ta_keywords": "wild distribution shifts;distribution shifts;world distribution shifts;diverse data modalities;datasets;appropriate datasets;recent data collection efforts;machine learning;shifts;wilds;benchmark;artificial shifts;detail datasets;wildlife monitoring;wild;broad range;domain experts;substantial performance drops;poverty mapping;test sets;training;baseline models;ml community;test splits;evaluation metrics;challenges;appreciable performance drop;other applications;demographics;cameras", "pdf_keywords": ""}, "2e492af839e971d05592df1c76d4878908e1d4c0": {"ta_keywords": "factor graph grammars;hyperedge replacement graph grammars;factor graphs;single factor graph;factor diagrams;dynamic graphical models;graphs;tractable inference;product networks;fggs;standard inference techniques;fggs generate sets;finite variable domains;variable domains;models;generalization;variable elimination;fgg;case;finite sets;plate notation;general class;many situations;use;sum;infinite sets", "pdf_keywords": "factor graph grammars;hyperedge replacement graph grammars;factor graphs;tractable inference;graphs;fggs;substructure problems;inference;substructure;\ufb01nite variable domains;variable elimination;neural information processing systems;matrix inversions;hrgs;treewidth;example;formalism;rules;techniques;theorem;de\ufb01ning sets;many situations;satta;cost;34th conference;neurips;bilmes;habel;set;kreowski"}, "c66b59394f99d639b277a54ad357d20de30285bd": {"ta_keywords": "structured literature image finder;annotated text;biomedical literature;active learning;human labeling effort;images;text;literature;document;traditional latent topic;models;papers;image processing;figures;information;available searchable database;slif;structure;panels;mining;external databases;new ways;combination;innovative extensions;account", "pdf_keywords": ""}, "8fc728b71f9e92f91455f957f10c7e496cbe4772": {"ta_keywords": "entity mention;language model enhancement;entity;language model;semantic types;context sentences;distant supervision;context;dependent labels;training data;information;labels;noisy labels;specific context;benchmark datasets;models;model;art baseline;state;method;compatibility;issue;experiments;aims;problem", "pdf_keywords": ""}, "208e5c187e81f63024ece8e2003dbaef094703cb": {"ta_keywords": "repair bandwidth;distributed storage", "pdf_keywords": ""}, "7dadf1e4f6f7a6966d5f691c3707fe221038528b": {"ta_keywords": "maximizing fair allocations;utilitarianmaximal allocations;fair allocations;tractable fairness concepts;computing welfare;indivisible goods;allocations;utilitarian welfare;utilitarian social welfare;computational complexity;envy;computational problems;freeness;proportionality;utilities;agents;item;prop1;sum;problems;ef1;number;np", "pdf_keywords": "maximizing fair allocations;allocations;indivisible goods;computing welfare;utilitarian social welfare;algorithms;computational complexity;agents;utilities;problems;unsw sydney;sum;nicholas mattei;number;paper;sydney;xin huang;nsw;np;ariel;kiriat hamada;abstract;australia;\ufb01xed number;corresponding author;israel;halevi;haifa;ariel university;new orleans"}, "346081161bdc8f18e2a4c4af7f51d35452b5cb01": {"ta_keywords": "reasoning shortcuts;annotators;such creative questions;reasoning steps;required reasoning steps;questions;answers;wikipedia paragraphs;task;qa;steps;strategies;step;strategyqa;strategy;annotator population;potential strategies;priming;fundamental challenge;benchmark;humans;topic;current datasets;best baseline;data collection procedure;workers;question;adversarial filtering;accuracy;work", "pdf_keywords": "reasoning skills;reasoning steps;novel annotation pipeline;creative questions;strategy questions;boolean qa benchmark;knowledge skills;reasoning;crowdsourcing;knowledge domains;diverse strategies;strategyqa necessitates;strategyqa;strategy;step;wikipedia;simple language;experts;examples;decomposition step;challenging range;example;decomposition;conclusion;swers;geography;question;wide variety;authors;type"}, "76df9c90d5359585f5501a4da1af1078c32be6d7": {"ta_keywords": "open source ocr system;historical transcription;tesseract;historical printing processes;text;glyphs;generative probabilistic model;font structure;images;document;word error rate;google;documents;unsupervised system;art solutions;press era;relative reduction;task;state;process;commercial system;system", "pdf_keywords": "historical printing process;generative modeling approach;font structure;text;historical typesetting process;fonts;art baseline systems;generative process;underlying printing processes;unsupervised fashion;transcription;historical documents;documents line;layouts;images;art results;line;image;variation;single line;model;overall structure;noise;primary sources;conclusion;state;system;parameters"}, "88c3f221a6fc8aff014268b0efb5ff119ab40906": {"ta_keywords": "irony detection datasets;sensitive irony detection;irony detection;ironic tweets;emojis;emoji;online abuse;social media;classifiers;dataset analysis;harassment;augmentation;identification;important task;ubiquitous use;applications;structures;role;work", "pdf_keywords": ""}, "ce2d6de9cec4a6d135c32bb8d2d02bba09928b33": {"ta_keywords": "classifiers;large text categorization problems;categorization problems;classifier;classification;ripper;experts;sleeping;phrases;algorithms;machine;contexts;different ways;different notions;methods;context;different methods;combination;different criteria;differences;wide variety;presence;many other respects;number;absence;spite", "pdf_keywords": ""}, "393c5c96e73dd3a82c175f9ab1f6c083830d3b82": {"ta_keywords": "financial data;financial health;annual return;grade stock portfolio simulator;portfolios;deep neural networks;future fundamentals;select stocks;debt;backtester;companies;income;company;revenue;market average;standard factor model;industry;oracle;fundamentals;data;features;years window;retrospective analysis;factors;analysis;standard factor approach;insight;mlp;paper;periodic basis", "pdf_keywords": "stock market prediction;investment strategy;stocks today;investment;portfolios;future fundamentals;select stocks;stock;clairvoyant model;time series analysis;future \ufb01nancial reports;oracle;term success;standard factor approaches;lfm;simulations;factors;approach;standard factor approach;paper;new approach;retrospective analysis;simulation;discussion;respect;superiority"}, "e929c9b53c66d52ae5ea56f0dc2764aef4cc67f6": {"ta_keywords": "channel speech separation;reverberant speech mixtures;separation techniques;deep single;desirable synthetic overlap data;mixer;deep learning models;speech;studio interviews;corpora constructed;learning;datasets;oracle performance;environments;field conditions;multiple domains;significant gaps;robustness;field;performance degradation;evaluations;evaluation;dinner parties;analysis;need;procedure;important findings;end;great success", "pdf_keywords": ""}, "be28821d510a99ffce40cdcf6860302def8533ef": {"ta_keywords": "facility location games;strategic content providers;recommendation systems;content providers;mediators;facility location models;closest content;better social welfare;mediator;content;social welfare;optimal strategy profile;unique equilibrium profile;service;high social welfare;game;equilibrium profile;low social welfare;points;equilibrium;many users;semantic space;users;intervention cost;basic principle;contents;pursuit;modern applications;framework;conceptual contribution", "pdf_keywords": "recommendation systems;facility location games;strategic content providers;facility location models;mediator design;optimal social cost;mediator;game;better social welfare;technology haifa;unique pne;social cost;lime;users;4n;modern applications;mathematical model;pursuit;israel institute;technion;popular tools;contents;framework;moshe tennenholtz;conceptual contribution;kurland;tennenholtz;sep;work;itay rosenberg"}, "3d2dece28f566792b6dd3a190aa345fc30fee1ff": {"ta_keywords": "ground transportation networks;anaheim transportation network model;extra ground travel demands;traffic congestion;mixed integer linear program;vertiport selection;mathematical program;mathematical programs;global optimal solution;congestion;equilibrium constraints;ground vehicles;flight delays;travelers;nodes;hybrid air;vertiports location;aircraft;vertiports;mathematical model;capacity;areas;links;location;results", "pdf_keywords": "hybrid airground transportation network;ground transportation networks;ground transportation network;urban air mobility;optimal vertiport location;traf\ufb01c congestion;vertiport selection;hybrid air;vertiports location;transport;static traffic;static traf\ufb01c equilibria model;equilibrium constraints;vertiports;mathematical programs;urban areas;mathematical model;aerial modes;capacity;ufuk topcu;math;location;oc;mengyuan wang;concept;conclusion;mar;yue yu;mehran mesbahi"}, "eadd73c3e1c20d16e32ee8656c4f954603b37450": {"ta_keywords": "clarinetist videos;audiovisual dataset;onset detection;clarinet note onsets;complex auditory scenes;acoustic timed events;large musical ensembles;musicians;temporal pooling;3d convolutional neural network;stereo mixdown;visual information;audio domain;onsets;annotations;multiple streams;detection;dataset;vision;salient points;models;detail;understanding;world;knowledge;regions;preliminary experiments;coordinates;further research;approach", "pdf_keywords": "acoustic timed events;audiovisual sequences;acoustic events;independent audio sources;multimodal approach;clarinet note onsets;cnn model;detection;binary classi\ufb01cation approach;binary classi\ufb01cation;recall;vision;visual counterpart;precision;schechner;independent sources;joint optimization;barzelay;1multimedia computing group;sounds;technology;jun;netherlands 2vision lab;hyper;optimization algorithm;delft university;case study;netherlands;problem;parameters"}, "a4e937f0b6e0688f7f3c4fcaebbabefa4a36da85": {"ta_keywords": "neural vocoders;espnet2;art tts models;tts;espnet;tts performance;tts results;tts research;band e2e textto;training pipeline;end text;speech;toolkit;many new features;demos;unified python interface;e2e;models;recipes;art e2e;baseline samples;thefly;modeling;end;earlier version;inference;edge;unified design;quick means;extensions", "pdf_keywords": "second generation tts toolkit;tts toolkit;espnet2;tts techniques;espnet;tts;tts research;art tts models;speech recognition toolkits kaldi;toolkit;shinji watanabe5 1human dataware lab;end text;ryuichi yamamoto3;portability;e2e;speech;edge;source e2e;shinnosuke takamichi6;tomoki;yooncheol ju7;takaaki saeki6;asr;yusuke yasuda2;takenori yoshimura4;technology;end;jiatong shi5;scalability;hyundai motor group"}, "2135c44087e06a6d95d04ad0afa400e926d37944": {"ta_keywords": "large vocabulary continuous speech recognition;feature space maplr;feature space normalization;model parameter adaptation;maplr;adaptation data;corpus;normalization;structural maplr;posteriori linear regression;other conventional adaptation approaches;fmaplr;bayesian estimation approach;feature spaces;parameter estimation;adaptation;smaplr;posteriori;same prior distribution;csj;spaces;data;maximum;task;advantages;large amount;consistency;approach;small amount;experiments", "pdf_keywords": ""}, "99c80d608ba2aa638333f27bbe3f09cdc580a051": {"ta_keywords": "torchaudio;audio;speech processing domain;speech processing;machine learning applications;benchmarks;available implementations;implementations;source code;models;blocks;overview;development;document;version;engineers;design principles;september;python package index repository;objective;functionalities;various operations;researchers;shelf building blocks;clause license;deployment", "pdf_keywords": "torchaudio;source toolkits;art machine learning applications;speech domain;benchmarks;new projects;developers;github;development;overview;document;package structure;introduction;functionalities;design principles;recent years;many users;usage;structure;deployment;thriving community;state"}, "29bc6654abd34b2405f7a01341f790aed2aab9a4": {"ta_keywords": "storage codes;binary mds codes;mds codes;smallest repair;new piggybacking framework;explicit codes;codes;locality;repair;data;mds;node;stripe;multiple stripes;read;design framework;functions;other stripes;basic idea;constraints;small number;substripes;framework;important settings;maximum distance;smallest amount;download;solutions;rate;power", "pdf_keywords": ""}, "b35ad59ce9a3ea01a0980c90bc750273d1f99e7a": {"ta_keywords": "database integration;heterogeneous databases;statistical information retrieval;data integration system;most databases;name constants;local name constants;local names;domains;similarity;personal names;entities;appropriate global domain;names;normalization;several dozen web sites;integration;information;whirl;real world;space model;course numbers;vector;logic;previous work", "pdf_keywords": ""}, "04e0fb8b3bb06e1200288e6d2a17d55773e97504": {"ta_keywords": "location aware opportunistic bandwidth sharing;fair bandwidth sharing;dependent opportunistic bandwidth sharing;bandwidth sharing policies;dependent bandwidth sharing;cellular networks;cellular network;stochastic learning;mobile users;mobile;optimal policy;fairness;downlink users;single timescale stochastic approximation;higher data rate;channel variation;static users;algorithms;asymptotic convergence;favourable locations;location;algorithm;classes;static;popular notion;paper;idea;other times;literature;notion", "pdf_keywords": "location aware opportunistic bandwidth sharing;dependent opportunistic bandwidth sharing;aware opportunistic bandwidth sharing;optimal bandwidth sharing;dependent bandwidth sharing;cellular network;cellular networks;decentralized maximization;mobile users;mobile;sum throughputs;base station;downlink users;higher data rate;throughputs;static users;stochastic learning;data rate;optimal policy;channel variation;sum rates;long run average reward markov decision process;location;favourable locations;global problem;static;mdp;instantaneous data volumes;cell;algorithm"}, "016d83091a60a6de67ba2395c063967686043380": {"ta_keywords": "acoustic model adaptation;variational bayesian estimation;speech recognition;adaptation data;variational bayesian approach;word recognition;supervised adaptation experiment;vbec;parameter posteriors;conventional bayesian method;model structure selection;gaussian;posteriori;model;map;training;data;advantage;variables;method;conventional method;case;amount;small amounts;line", "pdf_keywords": ""}, "06708348b64e2e7b11a953389556c701bf3298da": {"ta_keywords": "language resources;evaluation", "pdf_keywords": ""}, "0098123efc851b67137c1028f7bac8d8bffbc8fd": {"ta_keywords": "pretrained language models;semantic parsing;language models;latent grounding;modeling language;syntactic structures;such labels;grounding capabilities;plms;token;human experts;concept;training;several downstream tasks;awakening approach;erasingthen;datasets;several techniques;empirical studies;few efforts;paper;power;recent years;approach;success;ability", "pdf_keywords": "pretrained language models;semantic parsing;language models;modeling language;novel weakly supervised approach erasing;learnable schema;auxiliary concept prediction module;human annotations;awaken latent grounding;latent grounding;novel weakly supervised approach;bert;slsql;inference;slsqll;schema;several downstream tasks;sql generation;oracle;awakening;sql task;text;plms;training procedure;summary;recent years;conclusion;dataset;abstract;level"}, "45f59bd3ef8e1d76474199c08c140675c04a728c": {"ta_keywords": "simultaneous gradient play;opponent anticipation;polynomial game;learning processes;agents;implicit conjecture;conjectures;fast conjecture;equitable solution;variational perspective;reactions;others;joint dynamics;techniques;conjectural variations;sum;future synthesis;rules;rotational components;framework", "pdf_keywords": ""}, "a13c580250af3644fe368b08a540f4ea65dac919": {"ta_keywords": "efficient compressive phase retrieval;phasecode algorithm;phasecode;sparse;graph codes;efficient algorithms;memory complexity;nonzero signal components;optimal time;graph;fourier;signal;algorithms;noisy scenarios;noiseless case;friendly measurement settings;extensive simulation results;measurements;fraction;novel family;framework;practical power;order;support", "pdf_keywords": ""}, "0b2e9e978898b9fb1116ea964c8c470086ceed87": {"ta_keywords": "informative depth cues;student features;computer vision;depth modalities;rgb;depth;spatial views;optimal feature aggregation;models;backbone strategy;teacher;module;dem;channel;bbs;datasets;novel bifurcated backbone strategy network;evaluation measures;superiority;bifurcated backbone strategy;sota;extensive experiments;complementary way;hot potato;art;measure;state;fundamental topic;approach;paper", "pdf_keywords": "informative depth cues;depth features;depth;rgb;student features;spatial views;multilevel features;backbone;different rgb;informative cues;backbone strategy;bifurcated backbone strategy network;channel;dem;powerful training;architecture;teacher;generalization ability;addition;bbs;module;future research;comprehensive analysis;order;ef\ufb01cient"}, "0b8dbc4a899c836fe2b1a213b9dc064cdf62fd63": {"ta_keywords": "explanations;explanation task;explanation accuracy;recent process comprehension benchmark;sentences;procedural text;effects;causal chain;effect;several strong baselines;original prediction task;events;passage;perturbations;perturbation;research;less rabbits;illness results;life cycle;rabbit;illness;rabbit population;modern systems;quartet;goal", "pdf_keywords": "recent process comprehension benchmark;explanations;explanation task;qualitative reasoning;qualitative effect;qualitative outcome;qualitative in\ufb02uence;sentences;such explanations;explanation accuracy;procedural text;effects;paragraphs;passage;effect;several strong baselines;life cycle;causal chain;rabbit;events;illness;arti\ufb01cial intelligence;points;rabbit population;multitask learning problem;input;perturbation;perturbations;1carnegie mellon university 2allen institute;abstract"}, "f07c5c540233b22f0ca154c80c713e2aed3c9606": {"ta_keywords": "adversarial losses;music generation;other gans;softmax trick;art music transformer;gan;long compositions;sequence generation;bert model;music;autoregressive models;new discriminative metric;models;autoregressive manner;musical structure;transformers;discriminator;classifiers;gumbel;nll objective;training stability;likelihood maximization;human evaluations;minute;negative log;sequences;sampling process;largescale;nll;likelihood", "pdf_keywords": ""}, "d15a7d00897f58a94def2a58c0cb0311851f2968": {"ta_keywords": "kaldi speech recognition toolkit;distant speech recognition;different speech enhancement measures;speech enhancement baseline;speech quality;speech distortion ratio;automatic speech recognition;speech processing communities;noisy asr;lstm;microphones;time delay;tdnn;neural network;channel track;asr;objective intelligibility measure;sdr;perceptual evaluation;mmi;new baseline system;term memory;challenge;real test;free version;mask estimation;stoi;simulation test;wer;addition", "pdf_keywords": "kaldi speech recognition toolkit;distant speech recognition;automatic speech recognition;speech processing;speech processing communities;speech enhancement baseline;different speech enhancement measures;speech enhancement;noisy asr;speech quality;speech distortion ratio;asr;lstm;recognition communities;term memory;sdr;time delay;tdnn;neural network;microphones;aswin shanmugam subramanian;new baseline system;mask estimation;szu;free version;challenge;mmi;language;lf;eigenvalue"}, "04b44c518b145be625ff270af56cfd2e37900137": {"ta_keywords": "aware speaker diarization;channel recordings;microphones;neural diarization;channel input;hybrid meetings;same loudspeaker;encoders;single neural network;multiple remote participants;utterances;transformer encoders;conventional eend;eend;model adaptation method;overlap;spatial information;datasets;comparable performance;spatio;recent progress;end;types;paper;method", "pdf_keywords": "channel recordings;transformer encoders;encoders;microphone settings;microphones;multichannel inputs;multichannel input;neural diarization;neural diarization method;conventional eend;eend;model adaptation method;better ders;nels;datasets;comparable ders;end;spatio;number;types;order;conclusion;paper"}, "a56dba9cabfc110df231051d7c9d6e439f6757dd": {"ta_keywords": "trainable pointwise pos taggers;domain adaptation situations;pos tagging;tagging;word segmentation;active learning;pos taggers;markov models;pos tags;training data;speech;target domain;domains;conditional random fields;general domain;sequence;domain;pos transition tendencies;japanese;predictors;stacking process;pos;data;pointwise;part;same domain;methods;method;state;paper", "pdf_keywords": ""}, "2ab9fd2be2bf82e0bbd558cc64c1c46728fc4f8a": {"ta_keywords": "multiscale adaptation;incremental adaptation;model adaptation;robust speech recognition performance;multiple time scales;multiple time scale evolution;large vocabulary continuous speech recognition experiments;original incremental adaptation scheme;incremental adaptations;single time scale;speech recognition;automatic speech recognition;macroscopic time scale;adaptation;temporal changes;language model;adaptation mechanism;acoustic model;multiscale properties;kalman filter theory;time evolution system;characteristic change;japanese lectures;model;posterior distributions;robustness;own dynamics;potential;decision process;importance", "pdf_keywords": ""}, "f17e182fcb7fbbff2257824174ed6f7df512a42b": {"ta_keywords": "end speech recognition;attention model;automatic speech recognition;connectionist temporal classification;joint decoding;complimentary acoustic information;heterogeneous encoders;attention;temporal resolutions;relative word error rate;separate ctc networks work;asr;memr;joint ctc;end;model;ctc;wer;network;architectures;different architectures;wall street journal;great success;wsj;effectiveness;parallel;reduction;work;framework;research directions", "pdf_keywords": "encoder ctc;encoder models;encoder;individual encoder;encoders;stream fusion;heterogeneous encoders;encoder end;cnn;rnn;separate ctc networks work;wise acoustic features;convolutional layers;ctc network;complimentary acoustic information;attention;memr model;joint ctc;end models;temporal resolutions;different architectures;end systems;vggbsltm;heterogeneous con\ufb01guration;content;end;wsj;level frame;relative improvements;blstm"}, "72b4ff7387223cf0398c298c3cc62ee07d9c0043": {"ta_keywords": "microsoft research sentence completion challenge;sentence completion;neural language models;dependency language models;gram language models;simple language models;syntactic dependency tree;semantic modeling task;lexicalisation;sentence;models;probability;highest accuracy;task;appropriate word;percentage points;paper;pair;approach;date;set", "pdf_keywords": ""}, "57fec656119e82b5e70b1a654f6d87d8c1137ef4": {"ta_keywords": "structured correspondence topic models;new structured probabilistic topic model;biological articles;biological literature;biological figures;automatic retrieval;biological information;information retrieval;literature figures;computational knowledge extraction;summarization;global captioned text;scholarly articles;efficient inference algorithm;other scientific contents;realistic figure generation scheme;scientific journals;images;informative part;gibbs;life science;figures;books;other graphical illustrations;visualization;major unsolved challenge;major source;elsevier grand challenge;typical figure;information", "pdf_keywords": ""}, "2797a36cd15b8c046683247995261546993c289d": {"ta_keywords": "speech recognition;dynamic variance adaptation;temporal speech;noise modeling;single channel enhancement;acoustic model;dynamic adaptive compensation;noise sources;conventional mllr;adaptation technique;spectral information;speech;recognizer;variance;features;gaussians;integration;temporal characteristics;time;mismatch;term;main components;presence;system;complementary elements;paper;approach", "pdf_keywords": ""}, "99bb811beb5d061d2b8fac5a1973b49cace93e2f": {"ta_keywords": "new topic model;current purchase logs;real purchase logs;item trends;consumer interests;consumer purchase behavior;purchase behavior;current inferences;trends;interests;past data;inference;prediction accuracy;model;changes;time;computational cost;memory requirement;terms;online nature;method;effectiveness", "pdf_keywords": ""}, "291b651654565cd88e4e56de5250219a71882a50": {"ta_keywords": "peer selection problem;accurate peer;peernomination;peers;peer;reliability weights;weighting scheme;inaccurate agents;prizes;weightedpeernomination;noisy assessments;aggregation problem;scores;assessors;strategyproofness;agents;algorithm;selection;overall accuracy;others;outcome;favour;winners;grants;condorcet view;group;information;best set;truth;way", "pdf_keywords": "peer selection;novel strategyproof peer selection algorithm;peernomination;reviewers;noisy assessments;weighting scheme;reweighting methods;weightedpeernomination;evaluation methods;selection;weighting;overall accuracy;accuracy;debiasing;noise models;agents;algorithm;quality;protocols;methods;populations;variety;noise parameters;novel methods;conclusion;suboptimal behaviour;several instances;paper;modular way;calibration"}, "9cf4609178e2739ed35f8d3e3d6efb7d5e2e1a41": {"ta_keywords": "traffic dynamics;traffic signal phase sequences;severe congestion;queue behavior;learned dynamics;anomaly feature;unstable eigenvalues;koopman operator approach;unstable behavior;signal phases;high queue lengths;congested condition;detection;long sequences;exogenous input;analysis;algorithm;accident;shorter green times;approach;longer green times;case study day;method;application;leg result;vice;feasibility;paper;promise;objective", "pdf_keywords": ""}, "74495e9735b601ce9060ac40ac27d196fdbf7462": {"ta_keywords": "storage;nodes;node;repair;codes;data;network;flexible class;flexible setting;flexible framework;constructive proof;cut;paper;existence;values;parameters;number;total amount;way", "pdf_keywords": ""}, "f75ba81828fd9d8c7fcba89dd98a0ee73d32dce6": {"ta_keywords": "mds distributed storage code;minimizes repair bandwidth;interference alignment;systematic nodes;miser code", "pdf_keywords": ""}, "58fd3001c88e9784b0794eef06cb7c0eab0d8747": {"ta_keywords": "picture synthesis systems;ontology;synthesis;ontology based approach;objects representation;system information resources;system components;text;approach;behaviour;uni cation;paper;possible veri cation;loose coupling", "pdf_keywords": ""}, "c9472731afe5fca98f362f49e26d17a9d5d0cc8e": {"ta_keywords": "interpretability;interpretability problem;machine learning suffers;machine learning algorithms;categorization procedures;machine learning;concepts;black box problem;particular technical features;human users;usefulness;formal definitions;conceptual framework;development;common response;problems;importance;terms;widespread agreement;existence;purpose;sense;situation;critical examination;adequate account;widespread adoption;paper;call", "pdf_keywords": "interpretability;interpretability problem;ubiquitous ml algorithms;ml algorithms;intelligibility;machine learning algorithms;usefulness;concept;machine learning;black box;black boxes;explicability;notions;algorithms;conceptual framework;philosophical discussions;ml;philosophy;only conceptual framework;introduction;technology;conversation;critique;maya krishnan1;development;broader discourse;abstract;vocabulary;transparency;coherence"}, "b103bb1dc05a48796a3ff0804c11909bf68db11b": {"ta_keywords": "token classification task;speculative language;biomedical text;sentence label;syntactic features;semantic content;classifier;sentences;syntactic dependency path;task;task2;task1;detection;token;uncertain information;words;cue;sentence;features;cues;performance;scope;score;paper;absence;existence;approach;order;proxy", "pdf_keywords": ""}, "83ac0851a8f6fa02f5db251b260f635907d7a01e": {"ta_keywords": "language navigation challenge;language navigation;navigator;frontier aware search;beam search;backtracking;local action decisions;tactical rewind;action;vision;natural language instruction;realistic image views;unseen environment;agent;entire trajectories;current approaches;global signals;location;room;r2r;art results;state;photo;general framework;self;unobserved environment;fast;source;ours balances;correction", "pdf_keywords": "captioning model;language navigation;asynchronous search;local action knowledge;decoder;trainable neural network function;textual description;optimal action sequence;progress;visual observations;global information;encoder;language;fusion;actions;seq2seq;vision;task;agent;partial trajectories;local knowledge;score;centric vision;room dataset show;intern;sequence;input;historical logits;information;most current approaches"}, "b02acb3d159b06b2319a164378e1e61c3983676f": {"ta_keywords": "complex query answering;complex queries;different queries types;queries;knowledge graphs;complex query;combinatorial generalizability;benchmark;cqa models;important reasoning task;operator systems;operators;different operators;datasets;cqa;normal forms;canonical choice;qa;new dataset;data;intersection;forms;effective pipeline;choices;code;paper;projection;detailed study;first time;times", "pdf_keywords": "complex query answering;knowledge graphs;query types;different queries types;queries;complex query;combinatorial generalizability;answer sets;dataset construction;cqa models;qa dataset;new dataset;datasets;models;cqa;important reasoning task;existential first;general framework;various normal forms;cse;complete framework;combinatorial space;related operators;model training;cqa checkpoints;qa;shenzhen;yangqiu song department;abstract;order"}, "eaa224ae5c969180503dda4972ab86d3a71c888c": {"ta_keywords": "polyphonic optical music recognition;optical music recognition;polyphonic datasets;end recognition;polyphonic omr;polyphonic passages;homophonic music;sheet music;encoderdecoder architecture;orchestral scores;piano;rnndecoder;image encoder;neural architectures;novel decoder models;end omr;flagdecoder;high accuracy;end;musescore forum;omr;task;empirical evaluation;workflow;novel formulations;type;second dimension;scale;previous work;formulations", "pdf_keywords": "polyphonic optical music recognition;polyphonic datasets;polyphonic music data;end recognition;polyphonic omr;rnndecoder;encoderdecoder architecture;novel decoder models;image encoder;flagdecoder;musicxml;common music notation formats;sheet music;end omr;musescore \ufb01les;datasets;end approaches;dataset;empirical performance;art performance;performance;end;output;musescore forum;input;omr;symbolic sequence;task;different architectures;scale dataset"}, "baad427b45ac691763fe3de4ea3ac1bffd3c74e3": {"ta_keywords": "political survey data;geographic party affiliation survey data;information visualization;partytracker;new visualization tool;partisanship;big data;multivariate dataset;social scientists;different demographic backgrounds;map;view;insights;tool;researchers;usability testing;time;users;many different aspects;people;expert review;important tool;general public;paper;effectiveness;age;interest", "pdf_keywords": ""}, "64280761641d8f1eb285165160bd96efac0bb5f5": {"ta_keywords": "deep bottleneck features;simultaneous speech;bottleneck features;speech interfaces;environmental recognition;deep neural network;environmental sounds;overall auditory environment;simultaneous recognition;recognition task;speech;dnn;dnns;utterance;tasks;respective noisy conditions;accuracy;location;input;actions;techniques;experimental evaluation results;framework;problem;method;study;possibility", "pdf_keywords": ""}, "2391e7446d47f681ad705c8e75d9d2ce1b92ad5f": {"ta_keywords": "corpus search tool annis2;corpus;new middle high german grammar;several earlier annotation efforts;high german texts;common annotation standards;annotation process;texts;rem project;high german;morphology;annis tool;rem;speech;diachronic investigations;hits tagset;rea;predecessors;tokens;zeldes;early middle;klein et al;results;records;ren;complete collection;middle;ref;cf;migrako", "pdf_keywords": ""}, "ff7e60b8d336aef5ed974609a63610641085177e": {"ta_keywords": "structured prediction tasks;machine translation;entity recognition;image captioning;specific reward;reward function;reward;rewards;maximum likelihood baselines;dependency parsing;bayes decision boundary;candidate outputs;synthetic data;likelihood updates;bayesian decision theory;bayes decision rule;maximum likelihood;raml;higher probabilities;distribution estimation;reference output;tree;task;distribution estimation method;distribution;real data;impressive empirical successes;work;candidates;novel theoretical interpretation", "pdf_keywords": "structured prediction tasks;structured prediction;image captioning;speci\ufb01c reward;reward;reward function;rewards;candidate outputs;corpus;maximum likelihood;speci\ufb01c evaluation metrics;synthetic data;distribution estimation;higher probabilities;iclr;raml;likelihood updates;level accuracy;dependency parsing;reference output;task;ml;eduard hovy language technologies institute carnegie mellon university;bayesian decision theory;distribution estimation method;theoretical interpretation;candidates;sentence;impressive empirical successes;novel theoretical interpretation"}, "4d991a83d6044b1aaed2c117b3d097ecd23cf6f4": {"ta_keywords": "speaker diarization;speaker diarization results;end neural diarization;speaker diarization problem;global speaker characteristics;local speech activity dynamics;attention weights;speaker;neural network architecture;neural network;real audio recordings;attention;term memory;speaker overlaps;diarization errors;end model;clustering;frames;self;eend method;network;next hidden states;end;eend;training;models;end simplicity;blstm;addition;simple", "pdf_keywords": "speaker diarization results;speaker diarization problem;end neural diarization;neural network architectures;neural network architecture;neural networks;neural network;eend method;attention;free training scheme;eend;permutation;self;end;novel approach;section;conclusion;excellent performance;different architectures;key"}, "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e": {"ta_keywords": "large dual encoders;dual encoder;dual encoders;dual encoder model;effective retrieval model;generalizable retrievers;retrieval tasks;ofdomain generalization;gtr;query vector;other domains;bottleneck;data;passage vector;domain;bottleneck layer;ablation study;ms marco;paper;final score;dotproduct;widespread belief;size;belief", "pdf_keywords": "shot retrieval benchmark;effective retrieval model;retrieval performance;generalizable t5 retriever;information retrieval tasks;dual encoder;dual encoders;dual encoder model;beir benchmark;domain generalization;encoder part;better generalizability;shot performance;ofdomain generalization;size bottleneck layer;bottleneck layer;gtr;\ufb01xed bottleneck;query vector;bottleneck;queries;beir;t5;dimension;many models;documents;passage vector;results;model size;art performance"}, "d18d8d364bb18d66924919feebb2e892ebe6761c": {"ta_keywords": "neural machine translation;traditional statistical machine translation;translation rule table;nmt output;nmt;best nmt outputs;nmt outputs;smt model;smt;standard phrase;forced decoding;traditional smt;phrase;search space;cost;fluency;main challenge;sake;algorithm;advantages;method;approach;adequacy", "pdf_keywords": "nmt translation;french translation tasks;translation accuracy;translation quality;translation system;translation model;best nmt outputs;strong nmt baseline;nmt;nmt output;nmt outputs;discrete lexicon features;nbest nmt outputs;different language pairs;smt model;phrase;english;large improvements;traditional smt;cost;pbmt;source sentence;tochinese;results;advantages;method;algorithm;conclusion;paper;path"}, "1b96b89d5b3ba444126cebefdfc665d3866f14f0": {"ta_keywords": "algorithmic hiring;modern hiring pipeline;fair outcomes;hiring;algorithmic decision making;fairness;machine learning models;fair treatment;site interview;automation;algorithms;broad challenges;decisions;value judgment;small decisions;models;role;processes;work;definitions;explainability;development;technologies;reality;literature;daily life;first screen", "pdf_keywords": ""}, "c888022dec626171d243d2a056709b9b053a0ed9": {"ta_keywords": "end speech recognition;noisy speech benchmarks;speech enhancement;microphone array signal processing;speech recognition;acoustic encoding network;noise suppression;multichannel end;conventional adaptive beamformer;neural networks;hidden markov models;attention;multichannel;end system;end framework;end;input;baseline;ami;midst;field;paper;paradigm shift;core technology;experiments;dominance", "pdf_keywords": "end speech recognition;end speech recognition objective;multichannel speech recognition;multichannel speech;speech enhancement;speech recognition;acoustic encoding network;microphone array signal processing;multichannel end;microphones;noise suppression;neural beamforming mechanisms;hidden markov models;recognition architecture;neural networks;decoder architecture;end asr objective;end training;recurrent encoder;end system;language modeling components;end;end framework;enhancement;joint optimization;asr objective;joint end;attention mechanism;overall inference;sd"}, "2526c510610c7220ecc56e6b08d09c4cbaf58c3c": {"ta_keywords": "honorific speech;automatic translating;correct honorifics;honorifics;appropriate honorific;anaphora resolution;japanese language;machine translation system;regular expressions;japanese;learners text;normal speech;automatic systems;correct subjects;proper form;japan;human;task;study;members;relationships;young generations;effectiveness;important role;use;situation;trouble;paper;mechanism", "pdf_keywords": ""}, "2a462e2b748d7e78f3af2621071265c1ad2683ea": {"ta_keywords": "dispatchable wind energy resource;optimal power flow problem;wind parks operation;wind parks;independent power producers;power system;ipp;operation;consideration;scale integration;modification;presence;paper", "pdf_keywords": ""}, "b61c9799f10e4de9cd222dfd8e423bbd950a7c44": {"ta_keywords": "extractive qa task;textual entailments task;extractive qa;natural language understanding;domain corpus;unanswerable questions;questions;idk questions;squad dataset;entity;competitive questions;text snippet;context;noncompetitive questions;information;idk phenomenon;rte;essential part;squad;progress;similarities;simple event;differences;types;sought;answer;recent work;extent;order;direction", "pdf_keywords": "current nlp systems;extractive qa task;extractive qa;rte dataset;rte data;idk questions;q2;yunmo chen;unanswerable questions;questions;squad;tongfei chen;training;top system;performance;major challenge;idk;considerable improvement;answer;use;benjamin van durme;particular type;john;case;seth ebner;domain settings"}, "4ebe5792fe2890590e7a5bf8ae0a29e0fb147ef9": {"ta_keywords": "semantic segmentation task;incomplete utterance;semantic segmentation;level edit matrix;formulation introduces edit operations;word;large attention;several public datasets;task;global information;prediction;scratch;extensive approach;paper;state;art performance;recent years;approach;problem", "pdf_keywords": "semantic segmentation task;semantic segmentation1;semantic segmentation;incomplete utterance;faster inference speed;edit operations;formulation introduces edit operations;large attention;languages;bene\ufb01ting;several datasets;level edit matrix;word;task;beijing;global information;extensive approach;scratch;prediction;contributions;jian;paper;parallel;beichen;china;model;iur;state;cl;\ufb01rst"}, "e6fe601c44835d3654131d0312d65227d3523373": {"ta_keywords": "structured text networks;text corpus;dependency parsing;similarity measure;syntactic relations;nodes;random walks;graph;learning;words;edges;particular task", "pdf_keywords": ""}, "5a4d4c0824b5e113c39105c71d42b93d3900d87e": {"ta_keywords": "crowdsourcing engine;entire crowdsourcing process;amazon mechanical turk;annotation process;annotation;semantic similarity assessment experiment;user worker interface;human workers;worker ranking;crowdflower;tasks;web service;answer aggregation;task allocation;software;functionality;computer platform;agreement assessment;mechanized labor;data persistence;micropayments;dependency injection mechanism;tier system;engine;replication;quality control;processors;database level;engine level;altruism", "pdf_keywords": ""}, "e2b6193a24cd6c9f736139aa66618d1b8bf2a60b": {"ta_keywords": "speech transcription tool;speech transcripts;sensitive transcription;efficient manual correction;transcript;transcription process;sesla transcriber;cost;time budget;tool;new tool;correction;parts;errors;skill;paper;starting point;situations;factor", "pdf_keywords": ""}, "fc848789b557a7581c51c79fd01897dc5aa7e8a8": {"ta_keywords": "novel model knowledge augmented transformer;answer prediction;knowledge retrieval;explicit knowledge integration;explicit knowledge;answer generation;multimodal task;encoder;knowledge;model predictions;decoder architecture;knowledge sources;largescale transformers;relevance;model;reasoning;interpretability;open questions;information;end;vqa;challenges;primary focus;ok;paradigm;parameters;additional benefit;approaches;kat;art result", "pdf_keywords": "explicit knowledge;novel reasoning module;structured knowledge bases;implicit knowledge;knowledge extraction;answer generation;knowledge;entities;conclusion;relevance;models;signi\ufb01cant improvement;encoderdecoder transformer architecture;tentative answers;novel methods;effective approach;step;vqa;clip model;kat;new prompts;evidence;relationships;art results;complementary role;paper;end;work;quality;state"}, "db729f2f55a92465cf88682ba7917621fd4c000b": {"ta_keywords": "tutor learning;teachable agent;student tutor;peer learner;students;explanations;learning;sim student;study;iterative system;engineering effort;computational model;explanation condition;improvement;self;apparent increase;effectiveness;prior study;effect;gain;system;results;problems;smaller number;same time;same amount", "pdf_keywords": ""}, "b2da0f022a48ebd10a23572b5310b7d7341b6448": {"ta_keywords": "", "pdf_keywords": ""}, "004ddf5a39a735d0f8ec7547629c2bee65eb1f93": {"ta_keywords": "peer reviewing;reviewer calibration;biases;peer review;reviewers;bias;such biases;scholarly research;statistical tests;tests;author identities;test;correlations;measurement error;wsdm conference;experimental setup;false alarm probability;results;scale experiment;high probability;tomkins et al;debate;zhang;certain groups;remarkable recent work;tomkins;model mismatch;presence;relevant variables;fact", "pdf_keywords": "statistical tests;false alarm probability;statistical procedures;biases;statistical test;bias;reviewer calibration;hypothesis;test;alternative experimental setup;measurement error;minimal assumptions;correlations;assumptions;novel experimental setup;relevant variables;high probability;type;control;model mismatch;aforementioned limitations;conditions;general framework;fact;principled approach;novel approach;mind;design;goal;issues"}, "1bd7d16340642948142d7608ef8f085d934d94a3": {"ta_keywords": "policy gradient methods;free optimization algorithms;unconstrained minimization;smooth objective function;continuous control tasks;convex functions;momentum version;heavy ball momentum;stp;smtp;point method;new complexity results;function evaluations;other methods;order method;numerical experiments;method;difficulty;other state;collection;art;problem", "pdf_keywords": "stochastic derivative free optimization method;unconstrained minimization;smooth objective function;heavy ball momentum;momentum version;new complexity results;point method;order method;convex functions;function evaluations;momentum;stp;smtp;peter richt\u00e1rik kaust;mipt;ranepa;bergou et al;method;rd;iclr;saudi arabia;el houcine bergou kaust;adel bibi kaust;feb;maiage;continuous control tasks;iitp ras;several mujoco todorov et al;eduard;russia"}, "db8376698c06d6a688a39bff0300780ef0383821": {"ta_keywords": "decentralized control method;local control unit;line manufacturing;boards;cardboard;liner;faced board;various stages;board;double wail;stage;pulses;lengths;length;medium", "pdf_keywords": ""}, "4b1555368fd2c5f1234eaac5e41296003481754a": {"ta_keywords": "durable deep eutectic electrolyte;deep eutectic electrolyte;stable electrolyte;lithium metal anode;oxygen battery;performance lithium;electrochemical stability;lithium;high ionic conductivity;generation energy storage systems;battery operation;litfsi;polar groups;high reactivity;high theoretical energy density;chemical;anions;cations;methylacetamide;nma;evaporation;dee formation;lob;dee;lobs;good compatibility;strong competitor;performance;environment;lack", "pdf_keywords": ""}, "005879e6587eb6e05f56c20d345f784ee84a44c4": {"ta_keywords": "generative dependency models;recurrent neural nets;language modeling;recurrent neural network;parsing;dependency syntax;new generative models;generative models;sentences;different languages;discriminative baseline;learner;structure syntax;models;trees;arabic;tree bottom;english;japanese;phrase;explicit independence assumptions;order;other top;performance;estimation problem", "pdf_keywords": ""}, "f61862b286c9e4894302faf716eedb0eb60a2f5f": {"ta_keywords": "newsgroup style conversations;conversational data;discussion forums;implicit thread structure;line discussions;thread structure;particular conversational goals;discussion;messages;presentation;structure;graph;relationships;data;data features;representation;connections;prior work;paper;contribution;specific subtopics;novel approach;collection;approach", "pdf_keywords": ""}, "20819855b9517c927a1262850146e525c8083fb4": {"ta_keywords": "human dialog data;spoken word sequences;dialog concepts;term memory;lstm;dependent lstms;lstms;dialog;utterance;lstm layers;sensitive lstms;speaker intentions;rnns;neural networks;dialog turns;hotel reservation task;label accuracies;agent intentions;words;context;logistic regression;sequences;sequence;sentence;human;concept tags;models;model;lr;performance", "pdf_keywords": ""}, "f74d4fa99ccedfea7a2662fe6944d99f34533912": {"ta_keywords": "fairness methods;multiple fairness constraints;adaptive classification thresholds;aware threshold adaptation;fairness;classification models;classification model output;privacy;demographic group;different demographic groups;classification model structure;machine learning;accuracy;model behaviors;group;optimization algorithm;optimality;attention;model output;confusion matrix;wide range;agnostic manner;probability distribution;method;rigorous theoretical analysis;applications;trade;different fields;convergence;same condition", "pdf_keywords": "adaptive classi\ufb01cation thresholds;fairness methods;multiple fairness constraints;fair classi\ufb01cation;aware threshold adaptation;classi\ufb01cation models;classi\ufb01cation model output;classi\ufb01cation model structure;fairness;fairness trade;demographic group;different demographic groups;machine learning;model behaviors;confusion matrix;group;model output;privacy;computer engineering;optimization algorithm;attention;1school;shi178;accuracy;pengyi shi2;management;taeuk jang1;purdue university;theoretical accuracy;wide range"}, "25fec1e150a273b3bec3655ace0ff6b97c338a96": {"ta_keywords": "matrix codes;storage systems;efficient repair;storage;code constructions;erasures;repair operations;nodes;code;reliability;codes;node;resilience;errors;reconstruction;bandwidth requirements;data;links;paper;product;class;respect;sufficient conditions;fundamental problem", "pdf_keywords": "storage networks;erasure capacity;multicast network;storage systems;storage;storage system;erasures;capacity;network;malicious adversaries;bandwidth requirements;codes;errors;tight outer bounds;optimality;paper;symbols;error;class;problem;\ufb01nite \ufb01eld fq;special case;presence;addition;occurrence;results;present paper lead;literature"}, "2875d6cac905c3dfec4c8a8e1d89a2a7e4d71d40": {"ta_keywords": "wireless distributed storage systems;storage codes;storage system;functional broadcast repair;partial failures;storage capacity;linear subpacketization;stored file;nodes;multiple partial failures;tex;broadcast messages;information flow graphs;free wireless channel;functional repair;local memories;repair;performance;admissible parameters;partial repair;inline;extension;scheme;data;formula;content;invariant conditions;cut;points;design", "pdf_keywords": "functional broadcast repair;full node repair;wireless distributed storage systems;multiple node failures;optimal functional repair;optimal storage;storage system;multiple partial failures;functional repair;repair;nodes;explicit storage;repair framework;broadcast setting;mbr point;bandwidth trade;communication technology;points;code construction;conference publication;electronics engineering;ntnu;suf\ufb01ciency;trade;conditions;problem;information security;technology email;electrical;interior point"}, "190865e2c3d4908ff20bf9a31f5a2773d6fec5cb": {"ta_keywords": "domain question answering;question retrieval;large text corpus;language models;open book approach;new qa system;knowledge base;text model;qa system;answer pairs;memory;qa;large memory;text;odqa;latent step;collection;answer;gener;pre;open;rea;prior systems;information;recent alternative;question;kb triples;good coverage;tionship;kb", "pdf_keywords": "question retrieval;retrievalbased qa system;answer corpus;retrieval;new qa system;qa pair encoder;new qa;large memory;complex queries;memoryaugmented transformer;compositional reasoning;qa;text model;qamat;batch memory;lower complexity training strategy;new task;answer pairs;task;better compositionality;text;retriever;knowledge;latent step;smaller datasets;training phases;question;model;performance;extended model"}, "4dc8ddef938699d0d8a0b685ad9f56d0b735a25d": {"ta_keywords": "concept learner;intensive inductive learning algorithm;learnability;alternative learning algorithm;learning system;learning algorithm;learning;perceptron learning algorithm;incremental abductive ebl;knowledge;background knowledge;abductive explanation;logical theory;ebl;model;cover;extension;littlestone;ia;article;previous work;performance;output;mistake;most other respects", "pdf_keywords": ""}, "5677d2b565c8265fef1693a9be861739cb01bf2f": {"ta_keywords": "whole large vocabulary speech recognition system;large vocabulary speech recognition systems;deep neural network;highest recognition performance;large computation;parallel computation;low word error rate;recognition systems;evolution strategy;cloud computers;training setups;compact model size;markov model;meta;parameters;evolution;training;system;evaluation;several components;appropriate configuration;process;components;designs;state;use;art;approach;effectiveness;result", "pdf_keywords": ""}, "3d2da57c2de69b02fa0fee5c12ace618718a3926": {"ta_keywords": "subcellular location image finder;stacked graphical model;images;base learner;captions;labels;text;image;graphical model;features;associating sub;journal articles;biology;sub;sentences;information;instances;slif;particular aspect;system;combination;scheme", "pdf_keywords": ""}, "d21a0e01514732f241b9c138eceb76ecaef17a27": {"ta_keywords": "better translation models;machine translation;active learning;extensive manual translation;professional translators;translators;short phrases;annotators;translations1;full sentences;informative examples;unlabeled data;statistical models;words;less effort;redundant segments;new methods;bleu score;experiments;previous work;method;mt;greater gain;pool;simulation;paper;problems;framework;same number", "pdf_keywords": ""}, "b4bc1a98eb79545f8da4385a6dfb643b0c62a07e": {"ta_keywords": "machine translation;simultaneous translation;complete parse trees;fluent translation;unseen syntactic constituents;target sentences;translation;syntax;smt;word order;japanese translation;current utterance;improvements;prediction;accuracy;latency;communication;short segments;more input;input;regards;method;mt;methods;degradations;paper;first experiments;experiments", "pdf_keywords": ""}, "425a4a9c0598e4101ca2f2b930f5c6986ce40a99": {"ta_keywords": "privacy regularization;differential privacy;privacy guarantees;privacy;joint privacy;regularization methods;serious privacy;neural language models;language models;training models;email correspondence;languagemodels;discriminator;memorization;user content;utility optimization;models;utility;users;training samples;novel triplet;joint optimization;utility degradation;popular choice;dp;use;terms;loss term;plications;high capacity", "pdf_keywords": "privacy regularization methods;differential privacy;privacy mitigation methods;novel privacy loss term;privacy guarantees;private model training;adversarial training;privacy;regularization methods;discriminator;language models;utility;models;users;joint optimization;utility degradation;novel triplet;certain cases;signi\ufb01cant costs;popular choice;terms;loss term;disparate impact;inclusion;dp;use;approach;higher level;work;extensive experiments"}, "4383e714f4535777ffb7b4f618d4ccede4b08bd3": {"ta_keywords": "multilingual allophone database;phonetic transcriptions;phonetic representations;international phonetic alphabet;allophones;allophone model;speech recognition models;phonemic representations;phonemic models;transcription task;transcription;phonemes;minority languages;languages;allosaurus;input language;language;allovera;ipa;speech;specific models;endangered;documentation;mappings;new resource;related technologies;technology;training;terms;implications", "pdf_keywords": "multilingual allophone database;allophones;allophone;allophone pairs;languages;minority languages;allophone model;phonemes;phonetic realization;language;phoneme symbols;phonemic models;phoneme;allovera;speech;transcription task;phones;new resource;mappings;villejuif;documentation;xinjianl;allosaurus;implications;canada;fmetze;cl;contents;endangered;aanastas"}, "c549b3f2d262efc1f68dfdd842174634f37519ed": {"ta_keywords": "incremental adaptation techniques;novel incremental adaptation framework;speech recognition;corrector adaptation;acoustic models;direct adaptation;indirect adaptation;acoustic model parameters;variant acoustic characteristics;incremental update;macroscopic time scale;macroscopic time evolution system;classifier parameters;time evolution system;speaker;kalman filter theory;transformation parameters;dozen utterances;changes;posterior distributions;predictor;mllr;corrector algorithm;linear regression;posteriori;noise source;variant characteristics;time;unified interpretation;set", "pdf_keywords": ""}, "40f4d7fe800810288a80f84cdb357a8f4c28e880": {"ta_keywords": "vision transformers;conventional cnn;vision transformer;cnns;cnn;convolutional neural networks;spatial dimension reduction;spatial dimension conversion;transformer architecture;computer vision tasks;spatial dimensions;transformer;transformers;channel dimension;object detection;image classification;dimension reduction principle;depth increases;novel pooling;language processing;architecture;alternative architecture;vit;robustness evaluation;role;several tasks;original vit model;application range;effectiveness;successful design principles", "pdf_keywords": "vision transformers;vision transformer;cnns;transformer architecture;cnn;convolutional neural networks;transformer;transformers;computer vision tasks;spatial dimensional transformation;convolution;spatial dimension reduction;new pooling layer;spatial dimension;spatial dimensions;strides;novel pooling;transformation;pooling;resnet;vit architectures;architectures;language processing;alternative architecture;generalization ability;design vit;engineering;model performance;vit;aug"}, "8a73eed98873d91086201f41c6e1f613fcdefe18": {"ta_keywords": "speech recognition;synthesized speech;enhanced asr;language model reward;attention context;asr;asr hypotheses;tts;model;babel;librispeech;self;training;main features;eat;domain data;hyper;results;parameter;performance gap", "pdf_keywords": "supervised speech recognition;language model reward;enhanced asr;tts models;sequence architecture;synthesized speech;asr;eat model;tts;asr hypotheses;model;training strategies;self;training;sequence;attention context;babel;jan;main features;eat;limited data;domain scenarios;domain data conditions;application;results;honza;librispeech;eess;technology;shinji"}, "42be8ed9973b3326a6e3d838c4742bc1d7704704": {"ta_keywords": "controllable speech modification;novel speech modification method;input speech signal;articulatory inversion mapping;acoustic production mapping;gaussian mixture models;articulatory parameters;statistical feature mapping;higher speech quality;statistical feature mapping technique;unobservable articulatory parameters;articulatory movements;articulatory;phonemic sounds;unmodified articulatory movements;manipulation method;inversion;manipulation;production mapping;gmm;gmms;system;paper;previous work;experimental results", "pdf_keywords": ""}, "7c0ada3511b05897fb4d75c5f657b5fbd953caa8": {"ta_keywords": "voter biases;reputation bias;social influence bias;biases;bias;different biases;social influence;position bias;vote aggregates;different impression signals;votes;voters;aggregate vote;reputation;impression;online platforms;initial votes;causal effects;candidate instruments;vote;stack exchange websites;empirical study;empirical literature;platforms;effects;validity;implications;content;ols;gold badges", "pdf_keywords": "quantifying voter biases;voter bias quantification;voter bias;voter biases;reputation bias;content quality;online platforms;biases;social influence bias;aggregate user feedback;different biases;vote aggregates;voters;votes;position bias;platforms;social influence;content;initial votes;empirical literature;reputation;user interface;implications;policy;si;instrumental variable approach;changes;use;fundamentals;types"}, "e79be3f9ce409f1a9b7084ef880298665e5212d0": {"ta_keywords": "aware contrastive loss;contrastive learning;video retrieval;video action segmentation;video retrieval benchmarks;video action step localization;aware cascade;efficient loss estimation;crosstask;content words;visual contents;cascade;activitynet;video;text;downstream tasks;token;text pair;function words;syntactic classes;verbs;consistent improvements;youcook2;words;vtt;nouns;hard negative examples;previous methods;novel techniques;taco", "pdf_keywords": "video action segmentation;simpler contrastive learning pipeline;video action step localization;video retrieval;video retrieval benchmarks;effective contrastive learning method;contrastive learning;activitynet;downstream tasks;video;aware cascade;crosstask;downstream speci\ufb01c tasks;uni\ufb01ed video;text alignment;text;token;contrast;cascade;multimodal understanding;consistent improvements;youcook2;vtt;taco;best performance;language;models;ef\ufb01cient loss estimation;public text;hard negative examples"}, "e40a5c25d39d0f9add6a26c82613cf29edbcccf5": {"ta_keywords": "channel eegs;user identification performance;grade eeg device;brain waves;dimensionality reduction technique;user identification;identification accuracy;machine learning techniques;ms erp epoch;classification algorithm;erp;p300 component;authentication;data;event;statistical significance;subjects;potential;experimental results;various different combinations;consumer;capabilities;variety", "pdf_keywords": ""}, "92bd9e8a83e82dbbcafd8cde4f5a42d7bb4a5859": {"ta_keywords": "statistical machine translation;language model adaptation;gram clustering;individuality;paraphrasing;characteristic words;longer contexts;speech;text;writer;\u96c5\u535a;various features;model;speaker;analysis;paper;smt;technique;method;previous work;effectiveness", "pdf_keywords": ""}, "d1d23675d2e65cd734f2955c10ec1028b1139b5b": {"ta_keywords": "training neural machine translation;neural machine translation;final translation accuracy;better translations;semantic similarity;disparate languages;evaluation metrics;bleu;english;human evaluation;metric results;optimization procedure converges;training;maximum likelihood estimation;reference;limitations;limited range;recent work;correct hypotheses;partial credit;output values;systems", "pdf_keywords": "semantic similarity;semantic similarity model;machine translation;similar translations;heavier semantic content;large external corpus;reference translations;paraphrase data;similarity;simile;discriminative nmt training;minimum risk training;bleu;metrics;words;reward;additional bene\ufb01t;sentence;new reward;simple alternative;matching;alternative;possible scores;distinctions;\ufb01ne;high accuracy;exact replacement;domain robustness;5simile;ding model"}, "a538a05864a23e2f80f9b003d5ecbdfb8025b954": {"ta_keywords": "twitter stance detection;target stance detection;stance detection;stance;unlabelled tweets;tweets;twitter;tweet;words autoencoder;feature representations;autoencoders;training data;specific training data;targets;task;semeval;target;none;favor;bag;goal;lack;test data;submission;large set;paper;university;sheffield;usfd", "pdf_keywords": ""}, "3376118362db3751cfbd88acd0c090b8a3897733": {"ta_keywords": "language models;semantic representations;complex words;example plm;subwords;improving bert;derivational morphology;meaningful input tokens;best generalization;generalization capabilities;new words;bert;plms;meanings;interpretations;route models;input segmentation;question;first study", "pdf_keywords": "semantic representations;wordpiece segmentation;subwords;bert;complex english words;meaningful input tokens;complex words;new words;derivational segmentation;best generalization;example plm;interpretations;meanings;english derivatives;serial dualroute models;input segmentation;plms;route models;tasks;model;delbert;question;\ufb01rst study;series;hypothesis"}, "1392df13a80a962057e979a294a850a50b7deb7e": {"ta_keywords": "efficient supervised language annotation;automatic annotations;word segmentation;natural language processing tasks;annotator;corpus;segmentation;natural language;confident labels;short segments;many uncertain labels;other segments;speech transcription;human supervision;supervision efficiency;segment;labels;correct labels;chunks;explicit cost;user models;same chunk;effort;user study;utility;confidence;cost;constrained optimization problem;baselines;contradictory objectives", "pdf_keywords": ""}, "8df3f3f72eb239eb212bd3fc929bd754ce2e03d6": {"ta_keywords": "protein interaction networks;protein interaction matrix;topic coherence;emergent topics;yeast protein;yeast biology literature;better topic coherence;proteins;yeast biology domain;protein;lda;relevant scientific articles;joint modeling results;joint modeling;topic;retrieval performance;papers;biologists;model;text;results;block;evaluation;approach;task;use;ability", "pdf_keywords": ""}, "aae3d5e24d02ae538030ef3995a86118c5323ae1": {"ta_keywords": "cluster storage systems;storage efficiency;ions;portability;disk;enhance programmability;reliability heterogeneity;heart", "pdf_keywords": ""}, "148bca569a0d2833f05df1297788f64bc6686fa8": {"ta_keywords": "modern nlp systems;nlp model;diverse tasks;temporal adaptation;domainspecific pretraining;tasks;task performance;temporal misalignment;task;pretraining;text data;time waits;social media;target time period;specific finetuning;news;science papers;data;time;study;work;years;reviews;suite;ubiquitous setting;end;model;different domains;multiple domains;effects", "pdf_keywords": "nlp model performance;language model generalization;modern nlp systems;domain adaptation;language model;important language domains;diverse tasks;temporal misalignment;temporal \ufb01netuning;temporal misalignment phenomenon;downstream tasks;task performance;tasks;task;interpretable metric;social media;time;news;\ufb01ve years;r\u00f6ttger;gpt2 models;downstream applications;performance;data;work;reviews;science papers;suite;different domains;study"}, "bb80f7d2269308c3e91da8c47b290645e9d3d7d5": {"ta_keywords": "rotation invariant latent factor model;poses;human poses;primitive human motions;activity classification;static poses;moveme discovery;invariant latent factor model;rotation;leeds sports dataset;movements;training data;dimensional projections;synthetic representation;various camera angles;training set;single frame;movemes;images;dynamics;sports;discovery;original feature space;manifold;bases;inference;main goal;set;applications;range", "pdf_keywords": "rotation invariant latent factor model;human poses;static poses;human motion;speci\ufb01c poses;invariant latent factor model;moveme discovery;synthetic representation;training data;dimensional projections;supervised learning tasks;rotation;leeds sports dataset;human actions;movements;e\ufb00ective rotation;dimensional bases;training set;twodimensional projections;primitive movements;dimensional manifold;activity classi\ufb01cation;movemes;single frame;representation;model;meaningful manifold traversal;original feature space;images;dynamics"}, "ed1da1abf0f50ca758e422fbd945f891b6cda690": {"ta_keywords": "recursive neural network paraphrase identification;dialog response retrieval;dialog retrieval;word representations;dialog;simple retrieval techniques;recursive autoencoders;user input query;sentences;representations;example;example matching;oov;words;sentence;oov cases;recursive structure;dynamic pooling;database queries;pair database;potential;arbitrary length;accuracy;interactions;same meaning;method;handling;previous methods;robustness;confusion", "pdf_keywords": ""}, "7596030e0ce7a8df2f43e6ba4e9de5fa4a19240f": {"ta_keywords": "stochastic extragradient methods;extragradient methods;gradient descent;stochastic gradients;vanilla extragradient;ascent schemes;extrapolation step;simple bilinear models;scale saddle;variable stepsize scaling;convergence speed;machine learning;exploration step;algorithms;convergence;point problems;stability;aggressively;update;staple;paper;other hand;basic premise;thanks;use", "pdf_keywords": "stochastic extragradient methods;double stepsize extragradient algorithm;stochastic gradients;vanilla extragradient;stochastic setting;sharp convergence rates;convergence rates;variable stepsize scaling;algorithms;exploration step;simple bilinear models;update step;numerical sequences;algorithm;convergence;cycles;aggressively;guan hsieh univ;method;scale;update;aggressive time;\ufb01rst attempt;lemmas;paper;yu;nov;other hand;oc;math"}, "0d1cd3baad7d0734c9bbb008a33e2d10846968cd": {"ta_keywords": "combinatory categorial grammars;grammar induction", "pdf_keywords": ""}, "739c2181f7894050a06b53b41ac5debe8ffc4829": {"ta_keywords": "stochastic gradient descent;several recent sde representations;stochastic differential equations;sgd;deep neural networks;such sdes;generalization bounds;gradient noise;sde;markov processes;generalization properties;capacity metrics;capacity metric;generalization error;driving process;trajectories;tail behavior;feller process;theoretical framework;rich class;wide range;important challenge;special case;hausdorff dimension;applications;theory;rigorous treatment;parameters;light;number", "pdf_keywords": "deep learning models;deep learning tools;fractal dimensions;stochastic learning algorithm;stochastic differential equations;capacity metrics;deep neural networks;sgd;capacity metric;such sdes;gradient noise;complexity;accurate metric;fractal structure;sde;generalization properties;uniform hausdorff dimension;sample paths;trajectories;generalization error;tail properties;feller processes;theoretical framework;process;rigorous treatment;broader context;theory;parameters;novel notion;several peculiar characteristics"}, "94f8ef5944ecbdd0350d406bf3a16a7f2dff7349": {"ta_keywords": "speaker speech recognition;field speech recognition tasks;2mix corpus show;mimo;novel neural sequence;spatialized wsj1;high word error rates;channel system;speech;sequence;seq2seq;above separation function;recognition;original seq2seq;curriculum;si;training;signals;end;best use;wers;performance;spatial information;model;systems;high quality;architecture;end approach;practical applications;other hand", "pdf_keywords": "speaker training data;speaker speech recognition;speaker speech recognition system;speaker speech recognition model;speaker data;speaker mixture;speaker asr;source utterances;sequence architecture;channel multi;speaker locations;utterance lengths;novel neural sequence;speech;sequence;neural end;microphone geometry2;wsj dev93;channel;mimo;seq2seq;wsj1;tosequence;2mix dataset;eval92;original seq2seq;training data;snr level;recognition;model"}, "ab193c05bc447f368565c1ff37064b1c517a750f": {"ta_keywords": "boltzmann exploration;thompson sampling;dialogue systems;common exploration strategies;exploration;learning;monte carlo samples;replay buffer;agents;neural network;few successful episodes;backprop;bayes;approaches;experiences;efficiency;new algorithm;algorithm", "pdf_keywords": "deep reinforcement learning;deep qnetworks;reinforcement learning;thompson sampling;bayesian neural networks;dialogue systems;bayesian neural network;monte carlo samples;agents;bbqn;agent;learning;exploration;ef\ufb01cient exploration;networks;amazon ai;selection;backprop;explores;bbq;user simulator;bayes;action;task;redmond;palo alto;pittsburgh;several areas;network;carnegie mellon university"}, "2b5d553cb2f298f36aff1a1519f7f2f6be4db5da": {"ta_keywords": "taxonomy expansion model;taxonomy expansion;node attachment prediction task;new concept terms;taxonomy expansion problem;query terms;many taxonomies;taxonomies;taxonomy;natural supervision;feature representations;important knowledge ontologies;expansion;prediction;multiple views;supervision signals;node attachment task;public benchmarks;steam;self;numerous applications;anchor pairs;accuracy;natural self;query;mean reciprocal rank;art methods;daily basis;practice;extensive experiments", "pdf_keywords": "taxonomy expansion model;taxonomy expansion;taxonomies;taxonomy;new concept terms;many taxonomies;taxonomy expansion problem;query terms;natural supervision;important knowledge ontologies;node attachment prediction task;supervision signals;expansion;learning framework;steam2;numerous applications;steam;yue yu;prediction;public benchmarks;yinghao li;jiaming shen;abstract;self;urbana;electronic science;champaign urbana;hao feng;extensive experiments;chengdu"}, "433b24d63146605d25c0c271062e129608462f03": {"ta_keywords": "nonlinear classification;plane subspace pursuit method;support vector machines;hidden markov models;dimensional features;kernel spaces;automatic speech recognition;linear models;original observation vectors;dimensionality;convexity;emission probability density functions;mixtures;training;log;novel method;paper;framework;goal", "pdf_keywords": ""}, "a0e0ce316ce0fdca2db61a52fdc7100e24906075": {"ta_keywords": "evolving data stream;ensemble outlier detector;evolving stream;streams;xstream;outlierness;outlier detection problem;stream;outlier dete;extreme streaming setting;feature;life datasets;ion;model updates;dimensionality;density;row;incoming update;granularities;space;art detectors;noise;modest space;time;algorithm;state;distance;scenarios;dimensions;3i", "pdf_keywords": ""}, "1a0d8dbd0252193abe9d64f72fc56cc1f05ed3eb": {"ta_keywords": "situational reasoning end task;structured situational graph;situational graphs;natural language;language model;situations;reasoning;iterative querying approach;st graphs;background knowledge;st graph;unexpected situations;models;curie;graph;relevant consequences;qa;wiqa;input;cloudy skies;points;accuracy;effects;method;hinder plant growth;hard subset", "pdf_keywords": "general situational reasoning framework;reasoning graphs;structured situational graphs;situational reasoning end task;structured situational graph;multiple reasoning tasks;situational graphs;situational reasoning;pretrained language models;natural language;\ufb01netuned language model;graph construction;curiea generation framework;st graphs;curie framework;background knowledge;st graph;automated metrics;curie;graph;situation;datasets;input;human evaluation;relevant consequences;components;wiqa;consequences;general framework;points"}, "8529af634b443427d87d62d64467d2f1adfc230f": {"ta_keywords": "malware communities;heterogeneous malware samples;malware samples;malware;unsupervised identification;modal features;standard unsupervised learning algorithm;possible threat actors;different threat actors;threat actors;unsupervised setting;feature vector;cybersecruity practitioners;possible features;analysis;best method;samples;characterization;method;important ramifications;research;results;better results;late integration;active area;early integration", "pdf_keywords": ""}, "8424dd233577e3bd3fbd7ecdfd8b4d442531a20e": {"ta_keywords": "hidden markov model;regression tree structure;speech processing;time series pattern analysis;regression parameters;gaussian clusters;adaptive training;variational techniques;bayesian treatment;tree;tree structure;likelihood;parameters;linear regression;hmms;gaussians;hmm;log;objective function;paper;hyper;sets", "pdf_keywords": ""}, "7b72f79015a0a5e06cc019bae78f268b16a8e659": {"ta_keywords": "discriminative training;sequence discriminative training;dnn model;low rank approximation;automatic speech recognition;deep neural networks;discriminative criterion;singular value decomposition;rank approximation;rank approximations;noisy speech;rank model;rank;model reduction;dnn;original dnn;dnns;svd;weight matrices;base model;high computational cost;sequence;number;order;performance;size;effective combination;parameters;application;effect", "pdf_keywords": ""}, "0ea90d783a76b7c119fb5471fc71b6bc2defa06d": {"ta_keywords": "efficient recovery;storage;storage system;minimum bandwidth setting;nodes;lower bounds;codes;individual node;data;efficiency;information;relaxations;paper;proof;rest;read;download;problem;converse result;picture;respect;model;amount;terms", "pdf_keywords": "matrix mbr code;storage system;storage;node recovery;mbr code;ef\ufb01cient recovery;nodes;individual node;other nodes;minimizing data;explicit codes;systematic nodes;productmatrix;node;recovery;relaxations;data;code;ef\ufb01ciency;aforementioned bounds;download;read;rest;brief overview;product;problem;apr;terms;modi\ufb01cation;amount"}, "2030551b2590fa70eb5132131e6627c93128f0a1": {"ta_keywords": "robust utility learning methods;parametric utility learning;multiple utility functions;utility functions;ensemble methods;utilities;generalized least squares;continuous games;occupant voting data;efficient behavior;inverse modeling;forecast;social game experiment;energy;occupants;ordinary least squares;feasible;mixture;probabilistic interpretation;players;bagging;new game;classical methods;method;data;cfgls;ols;new method;performance", "pdf_keywords": ""}, "b34f254083b012bafd9b5ebd6c27450b4213c984": {"ta_keywords": "captions;caption;standard information extraction methods;biomedical publications;scientific publications;extraction;image pointers;classification task;scientific knowledge;figures;information;image;references;understanding;recall;accurate tool;precision;important single class;part;excess;standpoint;methods;scheme", "pdf_keywords": ""}, "4a19211e077bc4ada685854245ba9fab381cbb06": {"ta_keywords": "relation extraction;information extraction;structured relation tuples;question answering;relation tuples;informal relation specifications;high quality relation triples;limited relation types;unstructured texts;qa4ie;common ie solutions;qa;ie baselines;novel ie framework;sentences;text;open ie systems;ie;flexible question;benchmark;results;approaches;system;framework;great improvements;order;weaknesses", "pdf_keywords": "question answering;machine reading comprehension;qa4ie;qa4ie framework;novel ie framework;novel qa;qa;previous ie solutions;ie baselines;ie systems;general ie;ie framework;high quality relation triples;sentences;document level;conclusion;above weaknesses;great improvements;benchmark;results;mrc;approaches;system;order;weaknesses;paper;\ufb02exible question;help;art approaches;area"}, "409280796e924bfe71421fe5bf4986bd3591ea72": {"ta_keywords": "similarity reasoning;short queries;purpose similarity metrics;common object identifiers;similarity;databases;world databases;typical queries;textual objects;exact matching;naive inference methods;database management system;answer substitutions;names;inferences;normalization routines;predicate;most web;query;whirl;plausible global domain;benchmark problem;tuples;data;list;information;text;type;sources;objects", "pdf_keywords": ""}, "4e3016617e5e254bafebcbd7e96c509f670bdd37": {"ta_keywords": "audio music performance synthesis;conditional generative audio model;speech synthesis;piano dataset;polyphonic inputs;new violin dataset;transformer encoder;recordings;music;deep performer;pitch accuracy;clear polyphony;decoder model;listening test;timbre;overall quality;harmonic structures;scores;model;novel system;competitive quality;text;baseline model;baseline;score;alignments;new techniques;noise level;conditioning;recent advances", "pdf_keywords": "audio music synthesis;polyphonic mixer;conditional generative audio model;unaligned musical scores;natural music performance;polyphonic inputs;musical score;synthesized mel spectrogram;audio waveform;synthesis model;mel spectrogram;music;pitch accuracy;timbre;encoder;clear polyphony;listening test;expressive timing;deep performer;decoder;stage system;alignment model;score;inversion model;model;baseline model;harmonic structures;conclusion;noise level;competitive quality"}, "2a39a4f2d18e376ef8a6e2f45416e7b87957481e": {"ta_keywords": "historical text normalization;other nlp tasks;task data;small datasets;more robust models;datasets;main finding;previous work;high variance;specific language;data;results;specific historical period;size;related problems;order", "pdf_keywords": ""}, "bd17620c6cb5ca97ef773499223d1509d123745f": {"ta_keywords": "machine learning scientist;jupyter notebooks;deep learning;interactive examples;source book;resource;code;math;sufficient technical depth;exposition figures;technical details;readers;runnable code;entire book;starting point;concepts;interactive discussion;practice;context;rapid updates;community;self;questions;ii;path;problems;attempt;forum;everyone;iii", "pdf_keywords": ""}, "a30f912f8c5e2a2bfb06351d4578e1ba3fa37896": {"ta_keywords": "code tokens;code comments;code semantics;code defect detection;code understanding;code snippet;code;programming languages;bimodal dual generation task;novel identifier;natural languages;identifiers;encoder;generation tasks;codet5;bert;identifier;decoder models;clone detection;token types;aware unified;understanding tasks;developer;better nl;tasks;nl;decoder transformer model;generation;unified framework;gpt", "pdf_keywords": "code comments;code tokens;code understanding;bimodal dual generation task;code semantics;encoder;code snippet;code;codet5;generation tasks;novel identi\ufb01eraware;better nl;token types;identi\ufb01ers;pl alignment;nl;comments;decoder transformer model;developer;tasks;pl;understanding;same way;uni\ufb01ed framework;special characteristics;model;user"}, "70bc4dc0bc72816773006c71b56fa5885c729caa": {"ta_keywords": "new neural music generation model;generative adversarial networks;convolutional gan based model;music;rock music;gans;track piano;musegan;generators;generating multi;track;convolutions;bars;rolls;model;discriminators;potential;user;demo paper;scratch;demonstration", "pdf_keywords": ""}, "78c9181abe18575925fbbb6e6d8c72d7bf90d06d": {"ta_keywords": "delay iot applications;decentralized mac protocol;qzmac;better fairness properties;low mean delay;wireless channel;zmac;delay;mean delays;central scheduler;hybrid mac design;contiki operating system;hybrid mac;protocols;6tisch communication stack;term fairness;crossbow telosb motes;reduced state information exchange;ezmac;mac;complete knowledge scheduler;networks;control signals;nodes;control;ism band;cc2420;optimality;minimum;system", "pdf_keywords": "qzmac;crossbow telosb motes;zmac;ezmac;6tisch communication stack;contiki operating system;hybrid mac;ism band;cc2420;simple extension;performance;test bed"}, "9bbdcc03d872987eef9165f4a63c3878a5b05189": {"ta_keywords": "text representation encoders;encode text sequences;deep lms;dense encoder;dense encoders;transformer language models;internal attention structure;single dense vector representations;efficient text comparison;text information;sentences;retrieval;dense representation;lm prediction conditions;lm;standard lms;novel transformer architecture;data;condenser;low data situations;passages;tunes;paper;use;key reason;prior research;lot;sophisticated techniques", "pdf_keywords": "condenser language model;sentence similarity tasks;sentence similarity;dense encoder;web search retrieval;retrieval;lm pre;contrastive learning;condenser;web search;suf\ufb01cient training;dense representation;lm prediction conditions;learning issue;novel transformer architecture;many sophisticated training techniques;tasks;new architecture;novel transformer;structure;architecture;improved performance;direct \ufb01ne;readiness;tuning;lightweight alternative;structural readiness;universal solution;paper;question"}, "2dd81061e0b11c828446f6a1843741ae51facbd2": {"ta_keywords": "slow neurons;neuron;synapse dynamics;biological neurons;convolutional architectures;cortical microcircuitry;networks;fast computation;expensive network relaxation phases;temporal substrate imperfections;standard benchmark datasets;physical realization;instructive signals;latent equilibrium;unified learning theory;slow components;network;vivo;stimuli;physical dynamical systems results;network depth;membrane potential;network output;detailed models;prospective energy function;phase;inference;timing mismatch;processing;successful learning", "pdf_keywords": "neuronal computation;analog neuronal systems;neuron;synapse dynamics;biological neurons;synaptic plasticity;neuron morphology;convolutional architectures;fast computation;networks;analog physical systems;membrane dynamics;cortical microcircuitry;temporal substrate imperfections;membrane potential;standard benchmark datasets;physical substrates;slow components;network;mechanisms;detailed models;network structure;latent equilibrium;model;momentum;prospective energy function;implementations;novel framework;successful learning;inference"}, "87f42406de084e60d2365adac8a159ed3e455856": {"ta_keywords": "streamspot;call flow graphs;stream;anomaly detection approach;graph sketches;cluster summaries;flagging anomalies;similarity;anomalous ones;graphs;nodes;clustering;heterogeneous graphs;normal browser activity;new similarity function;graph;edge;various attack scenarios;edges;real time;memory usage;vector representation;datasets;memory;fast;small delay;sketches;constant time;sketched version;performance", "pdf_keywords": "anomalous heterogenous graphs;ef\ufb01cient anomaly detection;streamspot;detects anomalies;anomaly detection approach;anomalous ones;typed graphs;streamhash;streaming;heterogeneous graphs;stream;nodes;fast memory;heterogenous ordered graphs;graphs;bounded memory;new clustering;incoming edges;new graphs;e\ufb00ective clustering;graph;clustering;memory consumption;edges;memory;shingling;real time;time updates;heterogeneity;representations"}, "4cc70dd760c2c8cfc0107921bade45fb5efe860e": {"ta_keywords": "knowledge graphs;recommender systems;latent factorization;art graph recommendation method;latent factor model;probabilistic logic system;probabilistic logic programming approach;large datasets;recommendations;more training data;dataset;graphlf;entities;graphs;start settings;generalization capabilities;content;typesim;types;yelp;model;graph;kg;important task;approaches;mix;paper;proppr;past;purpose", "pdf_keywords": ""}, "fa2125641578934de12d7f792b094ffcfdf82ee2": {"ta_keywords": "picture synthesis system;russian language processing;picture system;russian language;ttp system;stage processing subsystem;text;processing stage;natural language analysis subsystem;general purpose text;system architecture;design;subsystem;basic design ideas;paper;motivation", "pdf_keywords": ""}, "c818f9be503a1ed94f991a2949c29e3ee477e8b8": {"ta_keywords": "noisy speech recognition tasks;deep neural networks;stochastic representation;uncertainty training;deep neural network;enhanced feature vectors;probabilistic representation;input features;nonlinear activations;enhanced features;random interpolation coefficient;carlo approximation methods;gaussian mixture model;dnn;features;efficient monte;linear interpolation;uncertainty;expectation calculation;reverb challenges;stochastic process;distortions;training process;expectation;training;variations;asr;second chime;techniques;paper", "pdf_keywords": ""}, "da1d5dc331c2839dfc3e6a79ee17f3bdf2231a8b": {"ta_keywords": "entity list completion task;list extraction techniques;entity examples;query entity;billion triple dataset;list;complete set;recall;stage retrieval process;type match;relation;set expansion;partial set;seeds;types;seed;expansion;candidates;precision;valid uri;system;second stage;first stage;paper", "pdf_keywords": ""}, "eb28e82ca0bbc5d83e1cc07807da16874105d2fa": {"ta_keywords": "unsupervised semantic frame induction;frame induction problem;framenet;clustering;triclustering;verb class;triframes;triclustering problem;triadic data;dataset;generalization;graph;task;par;competitive methods;replicable benchmarks;document;supplementary materials;state;main paper;approach;art results", "pdf_keywords": ""}, "572535aff31c400578fdd75313c896c0650b2d4c": {"ta_keywords": "automatic speech recognition;entire multichannel speech enhancement;field asr;s2s asr module;conventional asr components;asr components;e2e asr;asr;beamforming;single differentiable neural network;neural extensions;reverb dataset;conventional pipeline methods;sequence;field applications;s2s model;dirha english dataset;s2s;better performance;talk;comparable performance;e2e;end integration;modules;end;focus;novel architecture;modeling;subnetwork;dereverberation", "pdf_keywords": ""}, "8495c1722e1f5107733c842839c2d298b9116921": {"ta_keywords": "conversational question answering;conversation history;conversational search;prepend history;bidirectional encoder representations;conversational question;bert;complicated attention mechanisms;history;transformers;new insights;convqa;history answer;major challenges;model;view;current question;seamless integration;concrete setting;general framework;impact;methods;different numbers;different settings", "pdf_keywords": "conversation history;conversational search;history selection;history modeling method;bidirectional encoder representations;conversational question;bert;better history;history;convqa model;history answer;large open benchmark;new insights;aspect;convqa;transformers;quac;view;first attempts;extensive experiments;results;model;effectiveness;seamless integration;approach;rule;effective approach;general framework;impact;concrete setting"}, "14f925098d57b0fa491a100fa73e52dbc764efa6": {"ta_keywords": "first fmri study;cognitive neuroscience;neurois;neuois;psychology;top mis journal;amcis;study;marketing;dimoka;sociology;economics;tam;icis;theory;paper;top international conference;isr;period;recent years;tool;clear track", "pdf_keywords": ""}, "32a2a8baf217d29f628d22d793cace95634f51d5": {"ta_keywords": "popular open source email client;mozilla thunderbird;real email users;email users;information leak detection;recipient recommendation;leak detection;usage patterns;user interface design;extension;user study show;implementation;address issues;interface;features;cutonce;algorithms;performance;impact;data;action;baseline methods;paper;solutions;such problems;large number;preliminary results", "pdf_keywords": ""}, "1092da11519fe8427c8113b16a012f34f4a3fb6b": {"ta_keywords": "differential privacy;data privacy;privacy;fairness metrics;several ethical concerns;fairness;deep learning;biased predictions;learning;dutch datasets;empirical interplay;learning model;bank;accuracy;researchers;adult;experiments;measures;issues;work;unprecedented success", "pdf_keywords": "federated learning meets fairness;federated machine learning;privacy;di\ufb00erential privacy;sensitive attribute;sensitive attributes;training data;fairness;dp guarantee;training process;training timesteps;aggregator;machine learning lab;dp;agent;abstract;survey;communication;desirable criteria;networking systems;mourad;future directions;hyderabad;sankarshan damle;information technology;aug;otrok;international institute;phases;wahab"}, "ed913bed529d6bb7beac3b6086a853698abf627d": {"ta_keywords": "digital home assistants;field speech recognition;speech processing;spoken language interface;key speech processing algorithms;microphone array processing;quality speech synthesis;free speech interaction;speech;reliable wake;interaction detection;signal processing;sophisticated statistical models;hands;signal enhancement;heterogeneous training data;fetched technology forecasts;device;technologies;machine;ubiquitous commodity today;language;tutorial article;futuristic science fiction;major advancements;commands;dereverberation techniques;end;word;distance", "pdf_keywords": ""}, "914626e2e13bd42a5f06c28ff02ba7c428e81ff1": {"ta_keywords": "ionosphere;thermosphere;disturbances;complex system;modeling;elucidation", "pdf_keywords": ""}, "e829ee7fe48f4b1e451378b6a21470b2f86c0aa6": {"ta_keywords": "explicit erasure code;erasure code;pir algorithms;pir algorithm;perfect privacy;explicit codes;privacy;erasure;linear storage;pir;precise capacity;capacity;algorithms;data;requisite data;lower bounds;high reliability;information;extra bit;download;additional bit;paper;systems;small factor;respect;necessity;metric;investigation;size;user", "pdf_keywords": ""}, "31603b3339f4da5bdc6b7de4231bd1ddfb32a50a": {"ta_keywords": "neural controlled differential equations;neural ordinary differential equations;irregular time series;temporal dynamics;backpropagation;multivariate time series;rnn;subsequent observations;models;datasets;trajectory;memory;observations;ode;ordinary differential equation;efficient adjoint;differential equation;model;empirical studies;state;general setting;previous work;initial condition;mechanism;solution;attractive option;art performance;range;fundamental issue;problem", "pdf_keywords": "neural ode framework;neural odes;continuous time analogue;backpropagation;time time series models;similar ode models;adjoint backpropagation;neural cde;rnn;universal approximator;continuous data;neural cdes;continuous analogue;multivariate time series;differential equation model;memory;speedups;model;resnets;training proecedure;resnet;energy;observations;additional theoretical results;ef\ufb01cient adjoint;previous work;vector \ufb01eld;general setting;new class;conclusion"}, "5f563da2843e005c4b236f7889e7a22631b53210": {"ta_keywords": "conference peer review;reviewer quality scores;citation count;tier conference publications;quality scores;subjective element;reviewing process;individual researchers;quality;neurips experiment;inconsistency;real conclusion;papers;experiment;impact;community;paper;correlation;variation;suggestions;years;origin;function;notion", "pdf_keywords": "conference peer review;reviewer quality scores;quality scores;machine learning conferences;eventual citation impact;citations;citation count;scoring process;poor papers;good papers;google research;conference;neurips experiment;papers;accepted papers;inconsistency;paper;experiment;impact;process;summary;correlation;signi\ufb01cant overhaul;number;cambridge;variation;years;abstract;sep;university"}, "dd5e54b08b2c1520d179e88cd524e9bd4fe1f6ab": {"ta_keywords": "regularization strength;optimal transport;regularization;ot distances;sample complexity;first sample complexity;maximum mean discrepancies;finite samples;measures;mmd;probability measures;approximation error;sample size;sds;respective densities;optimizers;regularizer;sobolev;machine learning;tradeoff;ot;quantities;dimension;extremes;variant;rkhs;gap;terms;operations;maximization problem", "pdf_keywords": "empirical sinkhorn divergences;regularization parameter;\ufb01rst sample complexity;interpolation property;convergence theorems;sds;approximation error;sgd;optimizers;rkhs;rkhs ball;sobolev;measures;scaling;recent papers;maximization;mmd;kernel;computation;reformulation;ii;expectation;better use;ot;constant;inverse;iii;door;bridge;paper"}, "8b192503f119a0b0cc30ef5179a00f231c20fb93": {"ta_keywords": "fake event epochs;event datasets;events;observable events;historical dependencies;negative evidence;fitting tasks;conditional intensities;prediction;tasks;log;model;time;sequences;likelihood;underlying parametric form;art baselines;line;various types;state;work;numerous domains;introduction;method", "pdf_keywords": "relevant neural baseline neural hawkes process;modeling event stream data;modeling event sequences;fake event epochs;model multivariate event data sets;deep neural networks;model \ufb01tting tasks;dimensional attentions;benchmark model \ufb01tting datasets;gems;observable events;gem class;recent model;underlying intensity functions;model;negative evidence;log;art baselines;art models;pgem;modeling power;mei;nhp;state;neural method;other state;paper;subramanian;introduction;order"}, "0ca2575a1ef73930dc2abe205b44e079eadc426c": {"ta_keywords": "tolling schemes;multiple lanes;traffic flow;lane road example;theoretic lane;adjoint method;local decision;pdes;new macroscopic model;nonlinear system;model;drivers;multiple populations;behavior", "pdf_keywords": ""}, "b5991b1018bb89b053a2c8229248f97956391bb5": {"ta_keywords": "iterative pronunciation learning;acoustic model adaptation;automatic speech recognition;pronunciation lexicons;pronunciation variations;acoustic data;native speech;multiple candidate pronunciations;grapheme;phoneme;standard asr systems;linguistic experts;asr;iterative estimation procedure;speech;accuracy;word;average improvement;conversion;g2p;new ones;performance;occurrence frequency;hand;degradation;method;work;design;various levels;time", "pdf_keywords": ""}, "b19cba7bfe318c69d5e62f8322cb5d75228452f4": {"ta_keywords": "scale language models;nlp benchmarks;rank hypercomplex adapter layers;parameterized hypercomplex multiplication layers;language models;trainable parameters;task performance;weights;specific weight matrices;compacter layer;rank optimization;tasks;compacter;models;tuning;efficient low;task;model;rank;billions;adapters;millions;scale;parameters;resource settings;matrices;top;separate copy;better trade;ideas", "pdf_keywords": "scale language models;language models;nlp benchmarks;trainable parameters;rank hypercomplex adapter layers;memory footprint;task performance;parameterized hypercomplex multiplication layers;compacter;fewer parameters;compact;rank optimization;tuning;tasks;sebastian ruder deepmind;tuning method;adapter layers;better performance;ef\ufb01cient adapter layers;scale;extensive experiments;adapters;top;weight \ufb01ne;ideas;standard \ufb01ne;recent advances;data;better trade;\ufb01ne"}, "3ba013b8b56646d66aac8472fb90a5c029ef55a0": {"ta_keywords": "learned dynamics;differentiable surrogate;standard numerical solvers;solution trajectories;differential equations;neural networks;dynamics;time cost;additional objective trades model performance;order derivatives;training progresses;remedy;encourages", "pdf_keywords": "speed regularization;standard numerical solvers;neural networks;differentiable surrogate;solvers;solution trajectories;series modelling tasks;regularization order;differential equations;matthew james johnson google brain;solver order;models;speed;training progresses;density estimation;dynamics;time cost;vector institute;various models;order derivatives;supervised classi\ufb01cation;performance;jacob;time;tradeoff;paper;jesse;encourages;university;remedy"}, "26299d5fdc5137291dc6a091573b3d18aba1d1c2": {"ta_keywords": "multilingual bert;multilingual models;multilingual model;entity recognition;new language;diverse languages;nlp applications;resource languages;xlm;shot;strong baseline method;main goal;mad;competitive results;adapter;novel invertible adapter architecture;addition;framework;representative set;question;art;state", "pdf_keywords": "target language adaptation similar;monolingual models;multilingual model;target language;multilinguality;diverse languages;new language;languages;source language;arbitrary tasks;tasks;adapts;task domain;taskspeci\ufb01c \ufb01ne;adapter weights;mlm;modular framework;novel invertible adapter architecture;unlabelled data;invertible adapters;new adapter variant;strong baseline method;tuning;code;robustness;strong performance;mad;addition;effective baseline method;\ufb01netune"}, "cce8cf3d7f45113a4cba984b878802a5b16d5967": {"ta_keywords": "monotonic statistical machine translation approach;style transformation", "pdf_keywords": ""}, "77ce1b8d425b7538c21ce0be976ee24a58e797c1": {"ta_keywords": "discriminative nmf;channel source separation;2nd chime speech separation;discriminative nmf criterion;nmf basis functions;discriminative training;discriminative objective functions;source signals;previous nmf approaches;reconstruction basis functions;nmf;mixture;mixtures;novel multiplicative update algorithm;optimization;source;distortion ratio;recognition challenge task;coefficients;significant gains;respect;objective;direction;application;popular approach;task;efforts;paper;results", "pdf_keywords": ""}, "5e8c52ddbd3581320f7e536b7cd10d7263b81eb2": {"ta_keywords": "unsupervised grammar induction algorithm;representation learner;intelligent agent developers;feature predicates;intelligent agents;human learning;prior domain knowledge;artificial intelligence;less human knowledge engineering;intelligent behavior;simulated student;agents;representations;representation;simstudent;cognitive science;efficient algorithm;understanding;world;paper;set;goal;past", "pdf_keywords": ""}, "4481244de2cc0c55d91cebbb152eec79a76386f3": {"ta_keywords": "innovative flip chip assembly process;compression bonding method;nm logic device;logic device;3d integrations;reliable 3d;high temperature storage test;non conductive film;3d structure;effective assembly;300h pressure cooker test;reliability test items;memory die;logic die;organic substrate;tsv integrations;high reliability;lpddr3;cu pillar;underfill material;\u03bcm bump pitch layout;thickness;new technology;substrates;accelerated stress test;cycle temperature cycling test;logic;high density;high humidity test;gb", "pdf_keywords": ""}, "d26254cf3ec537f37708afaaf7f5a76a7922d4a2": {"ta_keywords": "statistical machine translation;hierarchical phrase;basic hierarchical phrase;word pairs;reorderings;contiguous words;source words;statistical models;helpful word;sentence;word;models;different distances;information;bleu points;previous work;average time;system;paper;method;series", "pdf_keywords": ""}, "10e221c7d4636703c5c97b54f53b1cb57c25f3a6": {"ta_keywords": "unregularized linear networks;importance weighting;linear networks;importance weighting alters;gradient descent converge;learned model;regularization methods;networks;weights;reinforcement learning;loss function;early stopping criteria;indefinite training;synthetic data;training;many algorithms;usefulness;causal inference;max margin solution;stochastic;policy evaluation;theoretical tools;separable data;key ingredient;theorists;direction;data points;theoretical findings;ii;broader applicability", "pdf_keywords": ""}, "6dfecb5915e8b10841abe224c5361bbda7100637": {"ta_keywords": "morphological parsers;parsers;parser;entity detection;morphological segmentation;humanitarian need detection;oromo languages;tigrinya;multiple output representations;word gloss;english word;representations;lemmatization;input;state paradigm;rule;other systems;rapid development;paradigm;linking;ease;combinator;integration;cost", "pdf_keywords": ""}, "73e401dead436aabd0cd9c941f7b13bfdeda9861": {"ta_keywords": "nonconvex optimization algorithms;gradient communication mechanisms;communicationefficient training;lazy aggregation;lazy aggregation literature;new efficient methods;point compressors;theoretical communication complexity;communication;compressors;efficient;static compressor choice;practical efficiency;art error feedback mechanism ef21;training;training process;top;better theory;class;aim;theoretical foundations;state;approaches;general approach;advantage;methods;art;new class;approach;number", "pdf_keywords": "nonconvex optimization algorithms;gradient communication mechanisms;communicationef\ufb01cient training;point compressors;lazy aggregation;communication;training;igor sokolov kaust;advantage;ilyas fatkhullin eth ai center;better theory;feb;elnur gasanov kaust;zhize li kaust;new class;eduard gorbunov;abstract;ef\ufb01cient;eth zurich"}, "1c2c9e5d0588599516a78adda1fe3935dc5ae5d7": {"ta_keywords": "derivative free play;convex games;efficiency estimate;monotone games;unconstrained optimization;efficiency guarantee;improved rates;target accuracy;distance;method;influential work;note;bravo et al;solution", "pdf_keywords": ""}, "311381feeb6346bfcb2ba622bd8f713261a4075d": {"ta_keywords": "comment ranking;collaborative documents;document revision;user comments;edit anchoring tasks;edits;edit anchoring;specific edit actions;related tasks;comments;document;document context;multiple authors;track;deletions;additions;relationship;paper;crucial step;network;user;architecture;management;evolution;flux;profusion", "pdf_keywords": ""}, "efcdb62b59e4dfb3f51b53850a81d6149ec3dfc8": {"ta_keywords": "interpretable machine learning;iml methods;iml;target use cases;broad use cases;use cases;useful diagnostics;relevant methods;technical objectives;methods;researchers;taxonomy;workflow;consumers;step workflow;level goals;progress;vision;field;panacea;need;years;sides;variety;complete version;significant gap;current gaps", "pdf_keywords": "interpretable machine learning;iml methods;iml community;ml community;useful diagnostics;broad use cases;target use cases;better practices;use cases;3determined ai;researchers;concerns;testing;step;discussions;diagnostic vision;various stakeholders;consumers;key principles;paper;widespread adoption;need;\ufb01eld;path;goal;variety;gap;sides;panacea;disconnect"}, "null": {"ta_keywords": "hierarchical clustering;quality hierarchies;link prediction;hierarchies;tree;real world graphs;novel probabilistic model;markov chain theory;graphs;sampling divergence;graph;quality metrics;end optimization;continuous relaxation;quality;model;efficient end;strong results;connections;dasgupta cost;tsd;relaxed versions;task", "pdf_keywords": ""}, "42fc352a0db1e742b0248a02b812db4aaf7b2cd3": {"ta_keywords": "autoregressive neural machine translation;neural machine translation;alternative training algorithms;autoregressive nmt;energy;mle training;lower energy;task measure;training objective;mle;task measures;reranking;higher bleu score;bleu score;nmt;models;beam;model assigns;maximum likelihood estimation;computational efficiency;model;nmt support;output;samples;observation;discrepancy;ebr;distribution;mismatch;stability", "pdf_keywords": "autoregressive neural machine translation;neural machine translation;energy ranker;reranking;alternative training algorithms;autoregressive nmt;mle training;lower energy;energy;mle;different energy;marginal energy model;english tasks;germanenglish task;joint energy model;task measure;target sentences;english task;higher bleu score;task measures;maximum likelihood estimation;computational ef\ufb01ciency;models;german task;nmt;bleu score;transformerbased nmt;performance;romanianenglish;model assigns"}, "740afdd1619d797145b056877865f941891e6a65": {"ta_keywords": "dynamic pricing pilot study;loss minimization;loss function oracle;parking rates;sfpark;algorithms;novel algorithms;real world data;geometric decay process;\ufb01xed decision;prices;data distribution;target occupancy;decision;information;environment;epoch;example;time;improvement;maker;same underlying principle;action;problem;setting;paper;length;institution", "pdf_keywords": "loss minimization;order stochastic gradient methods;dependent risk minimization;loss function oracle;\ufb01rst order gradient oracle;geometric decay process;optimal points;novel algorithms;algorithms;\ufb01xed decision;iteration complexity;dynamic environments;epoch;dynamic setting;decision;data distribution;time;information;maker;action;rates;geometrically;logarithmic factors;environment;same underlying principle;april;length;paper;setting;abstract"}, "b9c026ab6e161a0f8c4b4db82ee8ad10792084cc": {"ta_keywords": "electrolaryngeal speech enhancement;el speech enhancement;voice conversion;statistical voice conversion;voice conversion method;noise reduction;el speech;laryngectomees;noise reduction method;acoustic parameters;natural voices;electrolarynx;electrolaryngeal;speech;el;noise;excitation parameters;spectral subtraction;excitation;spectral parameters;intelligibility;spectral;conversion;device;naturalness;method;hybrid method;significant improvements;degradation;latter method", "pdf_keywords": ""}, "066f2023b2b5ba5df61dc193c205785fa5e73fed": {"ta_keywords": "kernel clustering;kernel clustering criteria;optimization kernel cut algorithm;data partitioning;segmentation;regularization;regularization objectives;new linear kernel;spectral bounds;continuous solvers;joint energy;combinatorial move;gap;code;general methodologies;many applications;complementarity;popular methodologies;work;practical problems;integration;making;such terms;main focus;literature", "pdf_keywords": ""}, "9578679e028777dd709881f938114aa59fbbf481": {"ta_keywords": "probabilistic record linkage community;string distance metrics;information retrieval;entity names;fast heuristic string comparators;matching methods;distance metrics;java toolkit;tfidf weighting scheme;different metrics;distance scheme;different communities;winkler string;jaro;token;name;hybrid methods;task;source;edit;number;method;hybrid scheme", "pdf_keywords": ""}, "ab627ba77dced941f9f45eeaee17bc6644308d89": {"ta_keywords": "collective classification;collective classification method;act classification;classification;email messages;classification algorithm;speech acts;email;maximum entropy models;local classifiers;certain relational features;dependency;network;sequential correlation;commitment;words;new text;same thread;request", "pdf_keywords": ""}, "3429d0529d3e77f9e4606f13b2d252d5d964abad": {"ta_keywords": "web;information;issues", "pdf_keywords": ""}, "66b83f0801d0c2d4194ff60c5ef9c754b51ce521": {"ta_keywords": "interpretable image segmentation;learnable noise masks;image segmentation models;segmentation;deep neural networks;ct scans;pancreas;dnns;explainability techniques;noise;images;occlusion sensitivity;regions;cam;grad;quality;downstream model performance;decision;critical applications;method;new method;myriad", "pdf_keywords": "interpretable image segmentation;image segmentation models;learnable noise masks;deep neural networks;segmentation;ct scans;dnns;interpretability model;algorithmic biases;explainability techniques;pancreas;occlusion sensitivity;predictive models;models;images;regions;model performance;noise;cam;decisions;downstream model performance;grad;useful tool;quality;munich;introduction;jan;importance;downstream performance;decision"}, "568efa8d71d8f2a086c8debcdf547e7053269021": {"ta_keywords": "intelligent toy enhanced learning;digital game;ieee fourth international conference;digitel;takamatsu;japan;march", "pdf_keywords": ""}, "4f0d485cbcde840533f23f0c8b0f3fa1ca2d74df": {"ta_keywords": "transductive linear bandit problem;transductive linear bandits;linear bandits;combinatorial bandits;drug discovery;transductive;measurement vectors;sequential experimental design;confidence;cost;noisy measurements;books;availability;recommender systems;goal;items;vivo;example;sellers;lab;more esoteric titles;set;form;probability;practitioner;safety reasons;paper;setting;compounds;unknown vector", "pdf_keywords": "transductive linear bandits;transductive linear bandit problem;linear bandits;sample complexity;superior algorithm;previous algorithms;transductive setting;information theoretic;dependent lower bounds;alba algorithms;algorithm;sequential experimental design;ml;goal;instance;problem scenarios;experiments;set;evaluation;number;range;arms;logarithmic factors;form;paper;jun;abstract;probability;noisy measurements;rage"}, "7b19e6540c786b80a3615a8ae2ef706242a1fa5b": {"ta_keywords": "noisy compressive phase retrieval problem;compressive phase retrieval problem;robust compressive phase retrieval;sparse complex signal;phasecode algorithm;measurement matrix;sample complexity;graph codes;additive noise;linear scheme;sublinear scheme;ith row;noise;paper;schemes;ith measurement;set;regime;sub;high probability;architecture;presence", "pdf_keywords": "noisy compressive phase retrieval problem;robust compressive phase retrieval;compressive phase retrieval problem;phasecode algorithm;sparse complex signal;sparse;graph codes;computational complexity;sublinear scheme;sample complexity;additive noise;linear scheme;yi;\ufb01rst scheme;computer sciences university;ith row;electrical engineering;schemes;noise;paper;kangwook lee;wi;dongyin;dong yin;ramtin;set;kw1jjang;kannan ramchandran department;jun;ith measurement"}, "a0cbaf59f563580f68523ab6839a436e38b6db18": {"ta_keywords": "multilingual neural machine translation;resource neural machine translation;multilingual corpus;multilingual data;resource language;minimal training;languages;bleu improvements;sampling;nmt;data selection;training;target;tcs;neubig;training loss;distribution;data;paper;experiments;hu;significant gains", "pdf_keywords": "multilingual neural machine translation;resource neural machine translation;helpful multilingual data;multilingual data;multilingual mt;multilingual corpora;resource language;xinyi wang language technologies institute;target sentence;languages;nmt models;sampling;data selection;ef\ufb01cient data selection framework;graham neubig language technologies institute;nmt training;several source sentences;strong baselines;nmt;lrl mt model;sampled data;training objective;target;training;source sentence;data;training time;bleu improvements;neubig;formulation"}, "105146a7872835a52c8c5c55a3aae62c5d8852a1": {"ta_keywords": "transliteration;machine translation;additional lexical processing steps;tokenization;naive alignment methods;lexical processing;distant language pairs;many alignment strategy;target language;target languages;morphological analysis;character strings;translation;arbitrary substrings;many aligner;white spaces;strings;words;single transduction;transduction;correspondences;character;word;phrase;accuracy;comparable results;sparsity issues;par;improvements;accuracies", "pdf_keywords": ""}, "9d10bbd21f475d500c3a7e24052e02596e052e2e": {"ta_keywords": "neural network speech recognizer;speech recognition;gram language models;neural networks;huge recognition vocabulary;gaussian mixtures;jlaser;speech;small corpora;many applications;recent research;article;state;art approach;statement", "pdf_keywords": ""}, "36d193c7a9523f55f9fe5ffd0730f248c241f5c7": {"ta_keywords": "peer review;other sociotechnical intelligent systems;fairness;bias;unfairness;scholarly research;empirical studies;aaai tutorial;challenges;open problems;aaai;domain;tutorial;part ii;number;several problems;solutions;backbone;urgent need;part", "pdf_keywords": ""}, "8b0f27bb594b1eaaf493eaf1e2ee723a2b0a19ad": {"ta_keywords": "natural language inference;commonsense inference;new challenge dataset;adversarial filtering;adversarial way;commonsense;adversarial set;nlp research;harder challenges;bert;dataset examples;goldilocks;new task;machine;piano;text;hellaswag;event description;models;wrong answers;key insight;art models;difficulty;data collection paradigm;discriminators;construction;humans;woman;af;complexity", "pdf_keywords": "nlp progress;adversarial \ufb01ltering;adversarial way;language generation;adversarial set;adversarial filtering;commonsense reasoning;nlp research;harder challenges;robust models;dataset examples;new testbed;discrimination;models;dataset;goldilocks;training distribution;insight;benchmarks;art models;machine;articles;discriminators;key insight;wikihow;text;data collection paradigm;af;humans;wrong answers"}, "de7d0c87794c3de6f8ab2c753ecc398c18c26631": {"ta_keywords": "grammatical specification;morphological agreement;descriptive grammar;language documentation;grammars;automatic extraction;standard annotated data;expert annotations;languages;language;readable format;universal dependencies project;raw text;morphosyntactic phenomenon;concise;rules;agreement;indispensable step;framework;pass;machine;preservation;steps;paper;core;process;gold;promising results;interest;world", "pdf_keywords": "morphological agreement;grammar sketch;descriptive grammar;language documentation;grammars;morphosyntactic phenomenon;particular language;languages;automatic extraction;language;documentation;1language technologies institute;readable description;rules;abstract;concise;agreement;universal dependencies project;unique characteristics;understanding;creation;adithya pratapa1;preservation;yulia tsvetkov1;indispensable step;aditi chaudhary1;framework;graham neubig1;human;zaid sheikh1"}, "b709da495f15a4a9c1173192ecd755d1697dedf0": {"ta_keywords": "reading recommendation system;personalized reading recommendations;saccharomyces genome database;online recommendation system;recommendation tasks;collaborative filtering approaches;citation history;rich context information;reading;query languages;citation;information;traditional content;literature;biology;research;random walk;pcrw;history;users;approaches;rapid growth;other input;approach;degree;experiments;restart;problem;different subareas", "pdf_keywords": ""}, "bef4548a43fca8a7410734e4200157d50e257a29": {"ta_keywords": "automatic speech recognition;speech processing;adaptive span self;language modeling;asr tasks;attention;end asr;input sequence length;natural language processing;whole input sequence;asr;input sequence;transformers;layer;selfattention;many tasks;memory cost;window;future;head;network;key components;window size;position;end;past contexts;art performance;paper;technique;state", "pdf_keywords": ""}, "dad121213a17c6cc977d2298c7a9927639ca58e6": {"ta_keywords": "auditory filter;loudness compensation;impairment simulation;audiogram;approximation", "pdf_keywords": ""}, "9f832bdcbc9d9566f7ab07b7455364bee62086fb": {"ta_keywords": "statistical machine translation;python source code;source code;preferred source code;code;difficult code;tool pseudogen;natural language;pseudogen;new generators;smt framework;english;smt;tool;generation;paper;workings;understanding;way;users;detail", "pdf_keywords": ""}, "f79361dda56ee755fc56ab83cf0d9f12d42b2d5e": {"ta_keywords": "pairwise comparisons;optimal ranking;ranking;pairwise;comparison probabilities;computational efficiency;several orders;algorithm;order;optimal method;items;computation time;prior work;underlying matrix;theoretical guarantees;copeland;number;btl;robust;contrast;data;attractive features;value;speed;information;parametric model;magnitude;goal;conditions;constant factors", "pdf_keywords": "copeland counting algorithm;pairwise comparisons;counting algorithm;spectral mle algorithm;algorithm;copeland method;comparison probabilities;pairwise;pairwise probabilities;optimal method;copeland;order;several orders;computation time;computational e\ufb03ciency;lower bounds;btl model;optimality;underlying matrix;number;btl;performance;theoretical guarantees;method;simplicity;prior work;items;contrast;goals;cop51"}, "092687dc06b0b264a524c6d4ea151780ba85a02a": {"ta_keywords": "nonverbal communication training;autism;autistic traits;communication skills;social skills;utterances;communication difficulties;social signals;multimodal computer;training tool;social;audio modalities;ability;context information;social stimulus;socialization scores;training;presentation;testing context;modality;temporal context;effectiveness;computer;aq communication;experimental evaluation;effect;results;nd;significant relationship;correlation", "pdf_keywords": ""}, "2d8d51d483a50c6fbf16a0cc120465539f4055da": {"ta_keywords": "microblog text;microblog posts;microblog post;different languages;other languages;languages;twitter;multilingual study;larger character sets;information;tweet;entropy;japanese;much information;strong correlation;more information;quantitative fashion;character;space;single post;authors;results;theoretic approach;criterion;paper;question;order", "pdf_keywords": ""}, "27ad78b72c3fb77a117b15855008b65e838314e8": {"ta_keywords": "paper index", "pdf_keywords": ""}, "51b2dd5cbec02f016c6fa716705ede9b3846a410": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "3e86ecbd41ab55b90d3b45601aeb15d2e5c1c8f8": {"ta_keywords": "balanced knockout tournaments;tournament;draws;optimal draw;sports competitions;draw;particular player;elections;polynomial time;computational problem;algorithm;memoization;player;winner;natural cases;decision;outstanding open problem;general problem;making;results;np;problem;number;previous approaches;common formats", "pdf_keywords": ""}, "7580df14bf01438e7174bbff260508a39a44df84": {"ta_keywords": "explicit erasure codes;such sparse codes;storage codes;optimal codes;fast encoding;sparse generator matrix;storage;codes;generator matrix;system constraints;matrix;sparsity;mds;repair;standard counterparts;desirable properties;speedup;separable;pm;distance;general classes;times;systematic form;problem;product;construction;typical parameters;factor;transformation;maximum", "pdf_keywords": "optimal systematic distributed storage codes;explicit erasure codes;erasure codes;optimal codes;minimum storage;storage systems;fast encoding;storage;lower storage;replication;explicit code construction;sparse generator matrix;optimal repair;maximal reliability;nodes;original data;uncoded form;repair;node;reliability;maximal \ufb02exibility;data;pm codes;sparsity;mds;desirable properties;california;separable;systematic property;place"}, "92fc770721e95249f8db01c5019d1cc4cf79ff00": {"ta_keywords": "natural language query system;standard command query language;hubble space telescope proposal selection;query program;sentence processing;hubble space telescope;proposal selection process;english subset language sentence;keyword phases;knowledge domain;tacos;tacos design;system;particular attention;implementation methods;use;terms;order;maintenance;flexibility;detail;greater flexibility;user;single reaction;addition", "pdf_keywords": ""}, "6c5144872c259611dceb32fe4e4486a6865e6c42": {"ta_keywords": "robust speech recognition;noise suppression problem;extended kalman filter;residual component decomposition;suitable parameter estimation technique;residual signal;bias component;residual component;noise;em algorithm;estimation;bias factor;decomposition;frame;component;components;bias;role;paper;problem;other hand", "pdf_keywords": ""}, "cf6352c789ab51320fa7ca9b1440c685b57fd769": {"ta_keywords": "speech activity detector;speaker segments;speaker activity;microphone recordings;xvector embeddings;inaugural dihard diarization evaluation;wideband microphone data;diarization;bayesian refinement;variational;inaugural dihard challenge;lessons;best system;task;johns hopkins university team;new task;unscored collars;best performing;jhu team;domain data;researchers;variety;experiences;paper;end;typical practices;difficult conditions", "pdf_keywords": ""}, "2e1a1588955a8a64ec618b3cc04be961ed0cb59c": {"ta_keywords": "phase oligothiophenes;excited state energy;transfer learning;transfer learning models;oligothiophenes;state energies;polymers;p3ht;state energy distributions;optoelectronic properties;crystal;oligomers;training data;tddft calculations;experimental absorption spectra;neural networks;machine learning;short oligomers;sufficient training data;chemistry;transferability;hexylthiopnene;transfer;data;solution phases;ml;remarkable progress;data scarcity issue;average error;difficulty", "pdf_keywords": ""}, "9237d6efc603465765e80eb5ca1268c2bd7b5c24": {"ta_keywords": "machine translation;language generation systems;language generation tasks;linguistic labels;sentence accuracies;holistic comparison;salient differences;comparison;compare;generation;tools;salient characteristics;probabilistic models;holistic analysis;words;tool;system improvement;histograms;log likelihoods;source side data;grams;results;analysis;counts;systems;mt;accuracy;system;further analysis;new types", "pdf_keywords": "other language generation systems;language generation systems;machine translation;language generation tasks;holistic comparison;source tool;comparison;compare;language technologies institute;holistic analysis;tool;results;systems;multiple system outputs;zi;analysis;mt;abstract;conclusion;junjie hu;developer;graham neubig;john wieting;xinyi wang;danish pruthi;yi dou;main use case;paul michel;paper;sep"}, "a6336fa1bcdeb7c84d2c4189728f0c1b2b7d0883": {"ta_keywords": "recurrent neural networks;recurrent networks;sequence learning;lstm;rnns;term memory;neural networks;time series prediction;handwriting recognition;sequences;powerful learning models;scale learning;musical information retrieval;image captioning;inputs;brnn;connectionist models;long context window;network;model;language translation;video analysis;parallel computation;tasks;standard feedforward;network architectures;nodes;recent years;cycles;performance", "pdf_keywords": "recurrent networks;recurrent neural networks;sequence prediction tasks;image captioning;natural language;sequences;representations;neural networks;powerful learning models;input;translation;references;output;performance metrics;number;present review paper;survey;decades;selective survey;historical perspective;last year;goal;papers;art;subsections;new domains;research;state;primary research;explication"}, "7b7416c90e8d3fc9ad5c9fb3923a638f69294ed7": {"ta_keywords": "natural language understanding tasks;large text corpus;entity mention;mention memory;domain knowledge;factual knowledge;factual information;many disparate sources;corpus;entity;memory;several entity;internal memory layers;knowledge;wikipedia mentions;information;multiple sources;dense vector representations;intensive tasks;qa benchmarks;tome;transformer;input passage;source;transformer model;single transformer model;strong performance;claim veri\ufb01cation benchmarks hover;domain question;model", "pdf_keywords": "large text corpus;text corpus;memory attention layer;mention memory;textual information;entity mention;corpus;language model;attention;mention encodings;internal memory layers;retrieval results;external memory;dense vector representations;factual knowledge;entity;entire vkb;information;passage mentions;vkb;knowledge;tome;input passage;collection;transformer model;transformer;novel;source;model;baselines"}, "8be39979cb2eb1aeaba15b57e1e4bc712eb962cb": {"ta_keywords": "paragraph embeddings;paragraph reconstruction;sentence content task;paragraph;downstream classification tasks;input paragraph;downstream classification accuracies;better generalization ability;sentence identity;art paragraph;classification;sentence;words method;basic linguistic property;benchmark datasets;faster training;objective;simplicity;simpler bag;models;paper;single vector;terms;zhang et al;state;method;trouble", "pdf_keywords": "encouraging paragraph embeddings;powerful paragraph embeddings;paragraph reconstruction;long paragraphs;semantic similarity;paragraph;many nlp applications;text classi\ufb01cation;document retrieval;better generalization;downstream classi\ufb01cation tasks;art paragraph;sentence identity;relatedness;classi\ufb01cation;benchmark datasets;downstream classi\ufb01cation accuracies;encoder;decoder model;cnn;information;reconstruction objective;faster training;simple objective;data;paper;models;simplicity;objective;terms"}, "f9ee690d223beac6d893aedae13c09dbf0fb694e": {"ta_keywords": "semantic verb clustering;dirichlet process mixture models;natural language processing;particular clustering solution;nlp;constrained dpmms;evaluation measures;dpmms;pairwise constraints;task;qualitative evaluation;approaches;highlights;light;work;method;practical application;addition;benefits;use", "pdf_keywords": ""}, "7354b87a1b4c99ccd9cf25b7314927ced8b156f7": {"ta_keywords": "interactive writing assistant;controllable writing assistants;language models;creative writing task;author intent;author specifications;language model;text;specific rhetorical directives;crowdsourced evaluations;author preference;assistant;intent;language;tags;description;assistance functionalities;users;input;scale user study;particular sentence;form;liking;advances;baseline methods;quality;tune;iga;outputs;contrast", "pdf_keywords": "interactive writing assistant;text generation;rhetorical instructions;explicit rhetorical directives;author speci\ufb01cations;coherent text;text;sentence fragments;author;assistant;interactive web demo;participants;intent;language;feedback;edits;conclusion;keywords;self;model;paper;advances;iga;means;\ufb01ne;new approach;behavior;help"}, "0f395654e69cd2e063a6ef221fb66fb46e68cefd": {"ta_keywords": "truthful classifiers;training classifiers;thebox classifiers;classifier;specific classifier;hierarchical ensemble;incentive;features;bad test scores;certain feature values;characterization;agent;data;simpler alternative;machine;credit approval;specialized hill;true distribution;hc;mincut;techniques;applications;college admission;data problem;behavior;climbing procedure;such contexts;twist;convergent;problem", "pdf_keywords": ""}, "60dd53fca1f538fabe18e4d6a9326b2f40e358dd": {"ta_keywords": "latent dirichlet allocation;statistical topic models;variational em algorithm;various sized document collections;parallel implementations;variational em;lda;implementations;dramatic improvements;scalability;unsupervised fashion;attractive framework;model;speed;version;experimental evaluation;work;ups;setting", "pdf_keywords": ""}, "084ddb77fce5a7f0b6418ef4e38dbb1bedf4ae78": {"ta_keywords": "el speech enhancement;several el speech enhancement methods;intelligible el speech;el speech;statistical voice conversion;proficient laryngectomees;laryngectomee;single laryngectomee;speech;excitation sounds;statistical excitation prediction;electrolarynx control;electrolarynx;el;listenability;face conversation;electrolaryngeal;statistical f0 prediction;excitation;other speakers;statistical prediction;mechanical excitation;excitation parameters;improved naturalness;direct control method;method;device;methods;proficiency;f0 patterns", "pdf_keywords": ""}, "5b2c5eeea9ac8f26908b9dfc8fd0a2d0e7aa5bb1": {"ta_keywords": "deep lstm;lstm;adaptive beamforming networks;recurrent neural network;field speech recognition;robust speech recognition;recent deep learning breakthroughs;acoustic model;beamforming;timevarying room impulse responses;microphones positions;reverberant conditions;term memory;multichannel;filter coefficients;units;baseline systems;architecture;real evaluation set;absolute gain;source;system;set;dynamic nature;challenging problem;paper;time", "pdf_keywords": "deep lstm acoustic model;deep lstm;lstm;recurrent neural network;adaptive beamforming network;acoustic model;adaptive beamformer;acoustic feedback;timevarying room impulse responses;microphones positions;term memory;real development set;real test data;real development;network;simulated development set;architecture;joint training;real test;table;best system;senone labels;test;baseline system;single channel signal;source;set;dynamic nature;absolute gain;result analysis"}, "d38b686b8b68d0b91b294fd8a55ac7dea191706f": {"ta_keywords": "guided neural abstractive summarization;neural abstractive summarization models;summarization framework;coherent summaries;external guidance;guidance;general framework;strategies;different types;gsum;different kinds;input;output;paper;previous studies;several different varieties;faithfulness;experiments", "pdf_keywords": "guided neural abstractive summarization;abstractive summarization models;summarization model;popular summarization datasets;summarization framework;text summarization;coherent summaries;different summaries;external guidance;summaries;highlighted sentences;sentences;faithful summaries;neural;guidance;abstractive methods;summary;extractive methods;highlighted sentence;abstract;novel words;other datasets;models;suitable words;different types;general framework;different kinds;addition;dataset;gsum"}, "e114618157e025ed17b7e45684d67becd34a14f3": {"ta_keywords": "high dimensional gaussian distributions;distribution learning;total variation distance;tight functional approximations;mixtures;mixture;gaussians;sample complexity;tight lower bounds;lower bounds;statistics;characteristic function;theory;connection", "pdf_keywords": "single gaussian total variation bounds;gaussian mixtures;dimensional mixtures;total variation distance;single gaussian results;mixtures;component variance;gaussians;new lower bounds;generalization;lower bounds;components;new tv distance;analogous results;dimensional setting;pairs;variance;pair;component;largest gap;main contribution;dimensional result;direct analysis;characteristic function;guarantees;complex analytic tools;wealth;applications;conclusion;function"}, "3ed91aae1038b8b0130fb3974060a50b10de1345": {"ta_keywords": "field automatic speech recognition;accurate speech recognition;automatic speech recognition;deep learning;spoken language interface;digital home assistants;microphones;acoustic beamforming;recognition accuracy;machine recognition;signal enhancement;speech;traditional signal processing;end asr engine;source separation;front end;asr;multicondition training;significant improvement;algorithms;far;technological breakthroughs;distance;field;attention;adaptation;industry;tutorial article;prominent application;effective solutions", "pdf_keywords": "speech enhancement;unsupervised spatial clustering;microphone array;neural mask estimator;spatial clustering;deep clustering;spatial clustering approaches;mask estimation;microphone channels;neural network;spatial cues;sound;technique;phase;particular class;direction;level differences;approaches;methods;advantages;tages;tf bin;integration;information;following;respect;section \ufb01rst"}, "addd2d86d19c1e7c8854e827fb2656a50c250440": {"ta_keywords": "summarization models;aspect annotation;summarization;such summaries;wikipedia articles;aspects;domain aspect;sentiment;section titles;text;several straightforward baseline models;sources;product features;reviews;dataset;key challenges;opinions;article;results;domain;boundaries;proper pronoun handling;different domains;sensitive events;large differences;efficient analysis;task;direction;research;type", "pdf_keywords": "summarization models;aspect annotation;summarization;summarization task;aspect identi\ufb01cation;wikipedia articles;domain aspect;several straightforward baseline models;section titles;sources;key challenges;multidomain aspect;proper pronoun handling;sensitive events;abstractive models;article;dataset;challenges;results;boundaries;task;different domains;research;models;consistent explanation;scale dataset;direction;time;unique variety;paper"}, "0c3c4c88c7b07596221ac640c7b7102686e3eae3": {"ta_keywords": "biomedical research question answering;pubmed abstracts;pubmedqa instance;pubmedqa;biomedical research texts;first qa dataset;novel biomedical question;qa;quantitative contents;long answer bag;research questions;research article title;questions;biobert;conclusion;dataset;word statistics;research question;long answer;baseline;improvement;preoperative statins;single human performance;best performing model;task;atrial fibrillation;corresponding abstract;context;question;coronary artery bypass grafting", "pdf_keywords": "biomedical research question answering;biomedical qa dataset;pubmed use questions;pubmed abstracts;biomedical research texts;expert annotations;pubmedqa;novel biomedical question;qa;research questions;quantitative contents;questions;dataset;\ufb01rst qa;articles;contexts;reasoning;titles;substantial instances;abstract;pittsburgh;task;paper;qiao jin university;zhengping liu university;cl;xinghua lu university;sep"}, "b7731a9b9142a6deb132e99bc55ddbe458a537a6": {"ta_keywords": "online moment selection;average treatment effect estimation;causal graph;data fusion problems;data sources;causal effect;multiple data sources;structural assumptions;algorithms balance exploration;optimal action;probabilistic model;confounders;researchers;instrumental variables;current estimates;moments;mediators;moment conditions;source;best action;part;interest;step;very moments;functional;framework;subsets;variables;oms;time", "pdf_keywords": "online moment selection;ef\ufb01cient online estimation;vietnam era draft lottery dataset;selection strategies;causal effects;data fusion problems;dataset;probabilistic model;causal effect;multiple data sources;algorithms balance exploration;structural assumptions;asymptotic regret;researchers;current estimates;source;moments;methods;moment conditions;effectiveness;infant health development program;ihdp;etc;mse;etg;functional;distinct subset;best action;variables;framework"}, "3ea5468e6d3007a94d4318932d7778693526145c": {"ta_keywords": "resource allocation controller;dynamic resource management;dynamic resource management mechanism;dynamic resources management mechanism;area grid computing;parallel computing;delay compensator;computing resources;conventional cluster computer systems;transient state performance;transfer delay;simgrid simulator;available resources;drm;dc;resources;control theory;network;time simulations;smith predictor;control;high steady state;site;jobs;sites;main feature;paper;issues;theoretic approach;amount", "pdf_keywords": ""}, "97906df07855b029b7aae7c2a1c6c5e8df1d531c": {"ta_keywords": "traditional nlp pipeline;classical nlp pipeline;semantic roles;linguistic information;coreference;pos tagging;pipeline;bert;bert rediscovers;level representations;information;ner;level decisions;localizable way;step;model;network;sequence;such model;steps;regions;qualitative analysis;basis", "pdf_keywords": "many nlp tasks;deep language models;classical nlp pipeline;traditional nlp pipeline;bert network;semantic roles;semantic abstractions;training corpus;language processing;semantic structure;coreference;text encoders;bert rediscovers;sentence;hierarchical information;pos tagging;task suite;consistent ordering emerges;weights;ner;edge;step;cumulative scoring;ian tenney1 dipanjan;aug;model;conclusion;sequence;abstract;1google research"}, "e31a3f52890dcb68f596020e45f8c9718b700466": {"ta_keywords": "logic programming;technical communications;proceedings 37th international conference", "pdf_keywords": ""}, "77c98b45c95121fc2a3d2ab4906fc00364cf381c": {"ta_keywords": "speech separation;joint training;recognition;stage;scratch", "pdf_keywords": ""}, "11a28f9e6fb6581d0a01428dd27a3fb649454395": {"ta_keywords": "chymotryptic hydrolysis;cyclopropylamine;chymotrypsin;diphenylcarbamyl chloride;tryptic hydrolysis;enzymatic behaviour;active enzyme;trypsin;hydroxylamine;hydrolysis;additional general acid;ethylamine;substrate activation;ph;specific substrates;tryspin;reaction;substrates;postulated chemical basis;hypothesis;agee;mep;dep;effect;ethyl;curve;rate;findings;maximum;formation", "pdf_keywords": ""}, "6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4": {"ta_keywords": "transferable visual models;imagenet;object classification;computer vision datasets;sota image representations;natural language supervision;training examples;action recognition;caption;videos;predetermined object categories;art computer vision systems;other visual concept;dataset;image;tasks;instance;supervision;shot;accuracy;text;ocr;performance;data;localization;set;internet;geo;scalable way;usability", "pdf_keywords": "sota image representations;computer vision datasets;visual concepts;caption;action recognition;videos;images;shot transfer;dataset;tasks;natural language;image;object classi\ufb01cation;text;downstream tasks;ocr;raw text;performance;broader source;localization;model;reference;geo;supervision;internet;\ufb01ne;scratch;ef\ufb01cient;new ones;scalable way"}, "de0e1f9980afa7949df64d53b8ae7a2f59c55579": {"ta_keywords": "large stylelabelled corpora;style transfer;controllable style transfer;shot style transfer;sentence pairs;annotations;paraphrases;indic languages;automatic evaluation suite;stylistic difference;sentences;formality transfer;indian languages;target style;human evaluations;languages;input sentence;inference;shot;datasets;content;dataset;code;output diversity;further research;art;better performance;prior literature;such low resource setting;task", "pdf_keywords": ""}, "1d79d055cf9711944f14e1388a9d054cbe81ddd0": {"ta_keywords": "discriminative language models;text corpus;confusion models;different language models;supervised training examples;sentences;negative examples;syllable;baseline asr system;sample selection strategy;perceptron algorithm;similar results;hypotheses;word;variant;error distribution;half;phone levels;training;various granularities;strategies;best performance;work", "pdf_keywords": ""}, "8cfd299be05bf3df91e0bf656a7e2fb973056350": {"ta_keywords": "acoustic language similarity;speech synthesis tasks;language family classification;language similarity approach;speech processing systems;speech processing;speech recognition;resource languages;languages;resource systems;resource data;gap;digital divide;data;part;hundreds;lack;vast majority;effectiveness;compelling way;approach", "pdf_keywords": "acoustic language similarity approaches;speech synthesis tasks;acoustic language similarity approach;downstream crosslingual speech recognition;speech synthesis;monolingual neural tts models;speech data;speech recognition;different indic source languages;language family classi\ufb01cation;acoustic approach;features;\ufb01ve;usefulness;distinction;ones;contributions;additional information;section;wealth;effectiveness;approach;following"}, "3ba26e897d0085ecd8cb695e1728a083f9227447": {"ta_keywords": "speech recognition;teki shuho ni motozuku onsei ninshiki", "pdf_keywords": ""}, "8f6763b339363216794f48895b9381d1a7caa88c": {"ta_keywords": "learning dynamics;overall learning dynamics;player bilinear games;lq games;quadratic costs;payoff matrices;individual player;robustness;noisy environments;disturbances;gradient;action coordinates;imposes constraints;players;constraints;disturbance;unobservable subspaces;such players;actions;player;respect;coordinate;subset;applications;letter", "pdf_keywords": "learning dynamics;player gradient;gradient disturbances;quadratic games;coupled dynamical systems;arbitrary disturbances;input disturbance;gradient;quadratic costs;single structured dynamical system;disturbances;individual player;disturbance;noisy environments;robustness;cost coupling structure;bance;graph;lillian ratliff2;action;techniques;frequency;paper;effects;theoretic conditions;respect;applications;conclusion;oct"}, "51e5e7093e0183feab61b00ca6c3df61cd8c46de": {"ta_keywords": "discriminative language modeling;gram language models;machine translation;strong baseline english cts system;phrase tables;baseline recognizer;phrasal cohorts;best list output;reference text;best lists;asr output;wer reduction;perceptron algorithm;results;training;half;methods;largest gains;paper investigates;experiments", "pdf_keywords": ""}, "9d03a125a9568af8af3fae5091752017d6abe59e": {"ta_keywords": "protein name extraction;entity recognizers;unlabeled auxiliary data;extractors;classifiers;feature hierarchies;biological publications;related domains;features;problem domain;tasks;hierarchy;data;more resources;train;dropping;test data;dependencies;techniques;problems;transfer;complex relationships;situations;stable regularities;better answers;other regularities;shifts;thesis;different aspects;problem", "pdf_keywords": ""}, "7cbb56da008163df09d254f85b7165f11389f298": {"ta_keywords": "natural language argument;argument reasoning comprehension;reasoning comprehension;neural networks;correct warrant;accuracy;premises;task;warrants;fact;external knowledge;topic information;opposite claims;complexity;premise;random accuracy;candidates;many approaches;dataset;principle feasibility;claim;instances;reasons;results;computational approaches;analysis;goal;paper;inclusion", "pdf_keywords": ""}, "3f16887a8e5c81aea554c7a266b08ea70dd2aa9a": {"ta_keywords": "cooperative behaviour;cooperative environments;cooperative setting;rewards;social incentives;additional rewards;unfair allocation;recent reinforcement learning studies;competitive behaviour;other agents;agents;qmix;social interests;mixed environments;algorithms;tomixed environments;barocco;common goal;conflicts;interplay;art algorithms;mechanism;decisions;prevalent approach;interwoven components;coma;such state;extension;issue", "pdf_keywords": "mixed multiagent environments;critic frameworks;social incentives;incentives;social component;mixed environments;qmix;behavioural aspects;environments;social welfare functions;algorithms;training;qualitative advantages;techniques;advantages;effectiveness;term approach;broader set;barocco;actor;methods;capability;crucial novelty;algorithm;meta;paper;coma;applicability;wider range;extension"}, "a6aed0c4e0f39a55edb407f492e41f178a62907f": {"ta_keywords": "contextual text attention;automatic research assistant;attention networks;paperrobot;graph attention;paper abstract;comprehensive background knowledge graphs;incremental draft generation;papers;new paper;paper;deep understanding;new ideas;scientific ideas;future work;large collection;memory;conclusion;abstract;links;background kgs;key elements;human;entities;title;input title;target domain;kgs", "pdf_keywords": "contextual text attention;incremental draft generation;automatic research assistant;comprehensive background knowledge graphs;graph attention;attention networks;paper abstract;paperrobot;new paper;papers;future work;paper;new ideas;deep understanding;english literature search;scienti\ufb01c ideas;background kgs;novel data;retrospective review;memory;large collection;conclusion;results;entities;pubmed;abstract;links;input title;pathways;embase"}, "5695847f8ffbb3da078842c3683ef74175eb59e5": {"ta_keywords": "japanese speech synthesis preserving speaker individuality;speech synthesis;speech synthesis method;synthetic speech;prosody correction method;voice conversion;speaker individuality;japanese speakers;incorrect phonetic sounds;phonetic sounds;speaker;english speech;erj;prosody;japanese;english proficiency level;native listeners;english;partial correction;performance;effectiveness;hmm;degradation;read;naturalness;effects;issue", "pdf_keywords": ""}, "37a0f28f6aa41028e64d0440001ff525d67c1305": {"ta_keywords": "efficient allocation;constrained round robin algorithm;constrained round robin;allocation;flexible algorithm;algorithm;reviewers;fairness;papers;envy;assignment;welfare requirements;welfare requirement;oracle;system designer;welfare;welfare level;fair;freeness;crr;order;strengthening;item;higher degree", "pdf_keywords": "allocation process;allocation;constrained round robin algorithm;e\ufb03cient allocation;feasibility constraints;ef1 allocations;fairness concerns;\ufb02exible algorithm;agents;fairness serum;crr algorithm;welfare requirement;reviewers;target welfare;welfare;assignment;fair;crr;system designer;ef1;papers;unsw sydney;rm;goals;nicholas mattei;chinese university;abstract;um;tastes;xin huang"}, "7bdb04ba2da682e4c0b19b5d61e999d648826edd": {"ta_keywords": "low complexity algorithms;complexity;additive noise;algorithms;measurement vector;forward algorithm;algorithm;graph;noisy setting;measurements;small constant;ck measurements;wi;simplifying assumptions;components;high probability;framework;large fraction;message;problem", "pdf_keywords": ""}, "d8c1eb86cc4546e4355ed368d8400d7640926cee": {"ta_keywords": "many constrained clustering algorithms;nonparametric bayesian hierarchical model;clustering method;new deterministic clustering algorithm;posterior inference;clusters;observed data;probabilistic model;noisy side information;efficient gibbs;data sets;side information;tvclust;data instance;constraints;empirical studies;information;algorithm;consensus;side;rdp;inclusion;extension;model;means;conditions;paper;work;variance asymptotics;additional property", "pdf_keywords": "view clustering;latent clustering structure;nonparametric bayesian hierarchical model;probabilistic model tvclust;nonparametric bayesian model;new deterministic clustering algorithm;clustering method;probabilistic model;observed data;noisy side information;side information;tvclust;data instances;information;rdp;data;consensus;sources;constraints;side;section;model;paper;blum;method;variance asymptotics;means;mitchell"}, "fe0ec764813fbcb6b6fd77d82188e81826088103": {"ta_keywords": "discriminative training;sequential pattern recognition problems;automatic speech recognition;minimum classification error;objective functions;strings;maximum mutual information;conventional objective functions;modified joint probabilities;novel generalizations;minimum phone;important function;word error;comprehensive relationship chart;analysis;difference measure;sum;common approaches;novel unified view;negative exponential;term;modifications;approaches;observations;valuable results;paper;central component;wide variety;investigation", "pdf_keywords": ""}, "659b476a10b0e676a031b1b17ebfe405c1904227": {"ta_keywords": "end speech processing toolkit;date speech processing experience;end speech recognition experiments;speech enhancement;voice conversation;speech separation;speech translation;espnet;speech;sequence modeling;advanced data augmentation;various benchmarks;sequence;tts;text;vc;applications;generic sequence;transformer;se;recent development;end manner;end;denoising;academia;project;recipes;various industry scales;technologies;dereverberation", "pdf_keywords": "espnet project;whole espnet project;espnet update;espnet;end speech processing toolkit;kaldi speech recognition toolkit;chin huang6;performance improvements;new features;shinji watanabe1;recent development;recent advances;shigeki karita11;naoyuki kamo10;jing shi13;5human dataware lab;2airudit;xuankai chang1;eess;automation;chinese academy;wangyou zhang12;broadened applications;tomoki;wen;yosuke higuchi7;frameworks;hirofumi inaguma9;end;chenda li12"}, "f02948f2976991bb76419775f303c27fc8afb7b5": {"ta_keywords": "text classifiers;classification problems;idf weighting;ripper rule;filtering;generalization performance;large training sets;keyword;rules;examples;algorithm;methods;significant generalizations;tf;method;traxiitionm ir;type;new method;sets;problems;small number", "pdf_keywords": ""}, "62a5b47def8d21825d06f7407a505ff0b64ecb1a": {"ta_keywords": "semantic parsing;semantic parsing framework;natural language paraphrase;paraphrasing;free grammars;ambiguous input;ambiguous input string;grammar;input sentence;ungrammatical input;search queries;synchronous context;formalism;meaning representation;original input;representation;output;verification;new method", "pdf_keywords": ""}, "05b0c768ecd4a82e486923e83250ddd53bacbf67": {"ta_keywords": "pruning algorithms;nn search;wise linear approximation pruning;pruning rule;short indexing time;accurate retrieval;dimensional non;space;tree;wise linear approximation;data;trigen;approaches;piece;parts;hybrid;rule;rules;methods;case study;low;adaptations", "pdf_keywords": "metric pruning rule;pruning algorithms;wise linear approximation pruning;pruning rule;dataadapted pruning rule;trigen algorithm;nn search;moderate dimensionality;wise linear approximation;trigen;piecewise linear approximation;tree;modi\ufb01ed trigen;data;hybrid approach;eric nyberg2;approaches;piece;cases;hybrid;vp;carnegie mellon university;case;rules;abstract;ir;low;leonid boytsov1;case study;pittsburgh"}, "1d938731dfad31c09b2f58c365f630c640f2ca1a": {"ta_keywords": "efficient text classification;active learning;strongest active learning;better label efficiency;label efficiency;many natural language processing;language models;training framework;unlabeled data;nlp;label;training baselines;aware active self;training;al;lms;model performance;self;al methods;specific al algorithm;tasks;prior work;data;uncertainty;satisfactory performance;extensive experiments;new framework;tuning;researchers;potential", "pdf_keywords": "pretrained language models;active annotation;strongest active learning;annotations;data annotation;language model;many nlp tasks;unlabeled samples;pseudo labels;text classi\ufb01cation datasets;unlabeled data;training baselines;label ef\ufb01ciency;regionaware sampling strategy;label noise;training;model self;memory bank;active self;data;self;model;strong performance;active \ufb01ne;lkkong;\ufb01netuning;uncertainty;actune;active plm \ufb01ne;may"}, "ae82f831bda5681edfe40ec15de4e9d2096ea92f": {"ta_keywords": "lexical entailment;entailment;asymmetric similarity measure;multiple context vectors;contexts;single context vector;vector space models;latent vector representation;words;senses;tiered clustering;word;narrower term;supervised approach;classifier;broader term;algorithms;representation;approaches;different approaches;high scores;subset;effects;extensions;work;problem", "pdf_keywords": "clustering word senses;lexical entailment techniques;word senses;lexical entailment;entailment;natural language processing;senses;clustering;clustering techniques;multiple context vectors;contexts;asymmetric similarity measure;words;word;supervised approach;sense;broader term;narrower term;latent vector representation;many tasks;conclusion;algorithms;better results;classi\ufb01cation decision;effort;classi\ufb01er;appropriate algorithm;improvement;results;high scores"}, "8c9069641876d025c66ab6800939c278b07f60a3": {"ta_keywords": "topic hierarchies;document hierarchies;document hierarchy;topic taxonomies;document graphs;bayesian generative model;document collection;specific topics;general topics;explicit hierarchy;taxonomy;document;documents;practical groupings;graph data sets;levels;observed data;top;bottom;experiments", "pdf_keywords": ""}, "423044220d9642a2d5839cfb19e32171e8a16a83": {"ta_keywords": "reward model;bandits;satiation dynamics;modeling satiation effects;greedy policy;rewards;initial reward;satiation;recommender systems;many goods;user preferences;enjoyment;algorithms;consecutive exposures;generalization;model;exposures;dynamics;algorithm;same item;time;arm;invariant linear dynamical system;offline data;general setting;psychological research;parameters;work", "pdf_keywords": "bandits;stochastic satiation dynamics;optimal time;satiation dynamics;dependent policy;bilinear program;explore;plan;estimate;invariant linear dynamical systems;algorithm;eep;time;unknown parameters;arms;system;work"}, "be0ad0710bfb09f6c875dd6cd834ac643713c93d": {"ta_keywords": "", "pdf_keywords": ""}, "4a0f96bb17836b4c4d6e19627f176fba8fe05127": {"ta_keywords": "state dc circuit breakers;circuit breaker;limiting circuits;relay protection;relay sensitivity;dc distribution network;current variation;circuit;timing scheme;breaking;state loss;hefner model;closing process;simulation modeling;low sensitivity;theoretical analysis;application accuracy;problems;effect;same time;principle;input", "pdf_keywords": ""}, "1d5d170670889bd82364fbcc594dadcb5481e9e4": {"ta_keywords": "neural machine translation;narrow domain translation tasks;translation examples;nmt translation;translation pieces;alternative retrieval;target sentences;source sentences;sentence pairs;translation time;recall;phrases;nmt;appropriate translation;search engine;input sentence;frequency words;sentence;words;source sides;similarities;repetitiveness;accuracy;bleu points;simplicity;speed;process;difficulties;implementation;respect", "pdf_keywords": "neural machine translation;nmt encoding;retrieved translation pieces;nmt model;nmt model structure;translation pieces;nmt;target sentences;sentence pairs;value memory;sentence pair;source sentences;recall;phrases;sentences;frequency words;appropriate translation;3language technologies institute;input sentence;real input sentence;search engine;words;nara institute;training;masao utiyama1;jingyi;communications technology;test time;information;computational cost"}, "f32c67daa6a93281bd8645fc2fa423dca67aea00": {"ta_keywords": "various assignment algorithms;conference peer review;assignment algorithm;fairness objective;review quality;statistical accuracy objective;reviewers;review process;peer;objective comparison;sharp minimax analysis;score model;assignment;disadvantaged paper;review;statistical accuracy;fairness;incremental max;total quality;papers;accuracy;objective;flow procedure;experiments;paper;inherent difficulty;novel experiment;contrast;ground truth;correct recovery", "pdf_keywords": "reviewer assignments;assignment algorithm peerreview4all;least quali\ufb01ed reviewers;various assignment algorithms;reviewer;review process;peer;objective comparison;min fairness posits;multiple candidate assignments;review;score model;sharp minimax analysis;algorithm;fairness;quality;accuracy;experiments;max;\ufb02ow network;incremental execution;paper;novel experiment;construction;crucial issues;ground truth;context;inherent di\ufb03culty;absence"}, "827e0def212f6834d615e4f3f25b55fe27f6460d": {"ta_keywords": "novel semantic verb relation scheme;sensitive semantic verb relations;annotations;sensitive verb relations;entailment relations;semantic information;crowdsourcing;centric propositions;agreement scores;relations;large dataset;new large dataset;context;report;several quality measures;specific context;domain;scaling", "pdf_keywords": ""}, "d8ad713ffde54d0a837e6a9cab4e70739d649d41": {"ta_keywords": "dialog response retrieval;dialog retrieval;recursive neural network paraphrase identification technique;word representations;dialog;recursive autoencoders;recusive autoencoders;word representation;user utterance;retrieval techniques;previous dialog;example matching;representations;example;robust example;different word;dynamic pooling algorithm;pair database;oov cases;database;\u7b2c5\u56de\u5bfe\u8a71\u30b7\u30b9\u30c6\u30e0\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0\u304a\u3088\u3073\u4e00\u822c;same meaning;good response;potential;structure;good performance;robustness;confusion;approach;paper", "pdf_keywords": ""}, "f45c777b29e0a00f7b1e1f33daa751853015724a": {"ta_keywords": "acm fellows;acm honors;industry liaison officer;acm sigai;award officer;many ai researchers;ethics officers;autonomous agents;intelligence;officer positions;intelligent user interfaces;computer systems;machine learning;robotics;knowledge representation;planning;other awards;human language technologies;knowledge discovery;computer vision;annual activity report;scope;search;study;june;cognitive modeling;order;realization;constraint programming;last year", "pdf_keywords": ""}, "1f7fb2c16e51f207eb1816f4f3fc3e1649c364f0": {"ta_keywords": "robust speech recognition;data simulation mismatches;microphone;environment;analysis", "pdf_keywords": ""}, "83f648f01d858d02b20f9327bebb1d5e91d0b6a9": {"ta_keywords": "speech recognition error;weighted finite state transducer;automatic speech recognizers;minimum transition error training;transition error minimization;discriminative optimization;crf training;differenced mmi methods;linear classification process;state transition errors;several sophisticated training methods;mmi;network optimization;crf;networks;maximum mutual information;optimize;wfst;training technique;accuracy;framework;paper;several methods;processes;variants", "pdf_keywords": ""}, "099346e2837c53ded931d98135edbb261039764a": {"ta_keywords": "computational social choice;political polarisation;political scientists;decision makers;artificial intelligence research;group decision;algorithms;democratic process;economists;polarization;many sociologists;compromise;computer science;research agenda;general research proposals;representation;provable guarantees;desirable properties;proportionality;historians;machine;possibility;matter;results;tools;paper;divergence;many cases;design;turn", "pdf_keywords": ""}, "cbdccaa4a5bceaae190f78b1ac0a0cf47391968d": {"ta_keywords": "platforms;curation;creators;creation;microcontent;algorithms;distinction", "pdf_keywords": ""}, "09fcc7ed1f867bcf9133ab12065ee7366cfaa652": {"ta_keywords": "efficient fault tolerance;checkpointing;fault tolerance;erasure coding;dlrm training system;future dlrms;memory;erasure;ecrm;large dlrms;dlrms;recovery;consistency;failures;training;recovers;servers;time overhead;dlrm parameters;dlrm size;significant training;overheads;tables;systems;use;larger overhead;pauses;model;tens;promise", "pdf_keywords": "recommendation model training;recommendation models;erasure coding;fault tolerance;ef\ufb01cient fault tolerance;dlrm training system;erasure;future dlrms;dlrms;scale dlrm training system;ecrm;deep;learning;users;apr;server failures;content;key tools;xdl;internet scale;promise;superior alternative;source;results;potential;alibaba;introduction;abstract"}, "8d939637b3a5ecf681130619cd35f295dbb9db03": {"ta_keywords": "venous thrombosis;aptt levels;snps;aptt;vt risk;healthy patients;odds ratio;independent sample;susceptibility;patients;risk;kng1;rs9898;rs710446;effects;sample;vt;rs2731672;association;controls", "pdf_keywords": ""}, "0bcd8210e9b90b33ab8467b94fd9b9511aad0f86": {"ta_keywords": "best performance ump system;ubiquitous multiprocessor;pipeline processing architecture;ump network;whole ump system;ubiquitous processors;ump system;pervasive application development;ump;high performance;network transmission speed;performance evaluation;performance;network;percomp;computers;parallelism;data size;user task;transmission;technologies;great progress;important rule;feature;experience;daily life;research;previous work;method", "pdf_keywords": ""}, "cece2d2f7cc38a512325122401f8aa658121b80e": {"ta_keywords": "deception detection accuracy;deceptive conversation partner;deceptive conversational partner;deception;intelligent dialog strategy;dialog system;several dialog strategies;telltale signs;humans;actions;questions;task;other hand", "pdf_keywords": ""}, "4bc9d6596069c9277b57a7ee1e1127d231f28663": {"ta_keywords": "highest scoring parse tree;outside recursive autoencoders;unsupervised parsing;outside recursive autoencoder;single tree encoding;possible binary trees;single tree;trees;soft dynamic program;deep inside;diora;hard argmax operation;beam;vector averaging approach;sentence;chart;drozdov et al;mixture;cell;paper;variant;errors;issue", "pdf_keywords": ""}, "dbb4035111c12f4bce971bd4c8086e9d62c9eb97": {"ta_keywords": "most graph learning models;scale graph machine learning;graph convolutional networks;citation networks;social networks;global poverty;poverty research;mobile phone networks;mobile phone datasets;node labelling;countries;algorithms;benchmarks;computational tools;relations;vast majority;different prediction tasks;myriad ways;people;algorithm;use;art;tasks;broader set;study;state;method;sudden relevance;applications;rapid expansion", "pdf_keywords": "citation networks;convolutional network;mobile phone datasets;different mobile network datasets;convolutional neural networks;poverty research;graph;benchmark datasets;citation labeling tasks;mobile phone subscribers;poverty line;benchmarks;countries;international development community;structured data;west african country;node labelling;different prediction tasks;east african country;algorithms;paper;citeseer;use;tasks;gender;south asian country;technology;art;method;broader set"}, "8376b18a4dd228ea4c33d606b32b081cee9bf80a": {"ta_keywords": "free smooth stochastic convex optimization;stochastic optimization problems;smooth convex function;accelerated method;noisy observations;free algorithm;stochastic nature;unconstrained problem;derivative;complexity analysis;noise;first part;pairs;function values;parts;values", "pdf_keywords": "free convex optimization;free optimization problems;gradient descent step;better complexity bounds;unconstrained optimization problems;complexity bounds;optimization community;gradient;complexity;mirror descent step;point feedback;new algorithms;algorithms;point feedback situation;norm;proximal setup;inexact function values oracle;point setup;ardfds;decision variable;ones;progress;analysis;line;dimension;paper;degree polynomial;community;method;traditional choice"}, "1e5b826ddf0754f6e93234ba1260bd939c255e7f": {"ta_keywords": "best translation quality;nat models;existing nat models;nat model;nat;knowledge distillation;autoregressive models;distilled data;autoregressive model;training data;generation speed;better performance;performance;substantial improvements;accuracy;complexity;optimal complexity;capacity;data sets;systems;output data;output tokens;sequence;several approaches;large gains;strong correlation;variations;findings;success;technique", "pdf_keywords": "autoregressive machine translation;traditional neural machine translation;german translation benchmark;best translation quality;autoregressive models;autoregressive baseline;nat models;graham neubig1 language technologies institute;knowledge distillation;nat model;autoregressive fashion;nat;nat student models;generation speed;iclr;models;standard wmt14;nmt;theart performance;carnegie mellon university1 facebook ai research2;performance;substantial improvements;output tokens;target token;sequence;at model;optimal dataset complexity;sequences;complexity;tokens"}, "41d4763792db8ea420efcfbd112a55deec971fee": {"ta_keywords": "commonsense knowledge;encyclopedic knowledge;wordnet;common knowledge;wikipedia;knowledge;entities;open data;principled experiment;mediator;real world scenarios;systems;types;marriage;different situations;proposal", "pdf_keywords": ""}, "4cc97c3858b558b4fa80ad73a894fcc7df841114": {"ta_keywords": "fairness definitions;fairness objectives;fairness;fairness trade;fair model;confusion tensor;traditional confusion matrix;predictive performance;data attributes;tensor;accuracy;different notions;several inherent trade;agnostic characterization;data;theoretical impossibility results;wider range;model;offs;single model;agnostic way;several types;object;trade;work;elements;practitioners;perspective;diagnostic;observation", "pdf_keywords": "group fairness incompatibilities;group fairness notions;group fairness;fairness objectives;linear fairness functions;fairness notions;group fairness trade;fairness;confusion tensor;different groups;predictive performance;attributes;confusion matrix split;tensor;attribute values;several optimization problems;individuals;real datasets;accuracy;systematic characterization;majority;loss;general diagnostic;abstract;class;model;fact diagnostic;use cases;several scenarios;offs"}, "72d89aa7cd77c3f22a667f2b0707758eb8d52a7a": {"ta_keywords": "aware translation models;aware machine translation models;human translators;professional translators;ambiguous translations;pronoun disambiguation;context words;contextual information;contexts;context;french dataset;right attention;ambiguous words;lexical characteristics;attention scores;attention strategy;new english;scat;words;alignment;questions;several questions;model;agreement;depth analysis;paper;degree", "pdf_keywords": "aware translation models;professional translators;random context words;ambiguous translations;context words;pronoun disambiguation;other ambiguous discourse phenomena;anaphoric pronoun translation;target context;other language pairs;attention;context;contrastive evaluation;right attention;source context;full context;ambiguities;english;french translation;new english;french dataset;ellipsis;different tasks;scat;analyses;par;usage;similar user studies;model performance;other types"}, "d170bd486e4c0fe82601e322b0e9e0dde63ab299": {"ta_keywords": "adaptive softmax;neural language modeling;adaptive embeddings;popular character input cnn;adaptive input representations;billion word benchmark;model words;input;perplexity;characters;models;output layers;lower number;improvement;grave et al;parameters;result;experiments;several choices", "pdf_keywords": "adaptive word representations;adaptive softmax;character input cnns;adaptive input embeddings;input word representations;neural language modeling;adaptive input representations;neural language;word inputs;character inputs;additional dropout regularization;michael auli facebook ai research;output layer factorizations;adaptive input;input;higher accuracy;strong character;alexei baevski;models;different input;output;comparison;grave et al;tail projection;abstract;paper;feb;cl;ca;menlo park"}, "3d3f01feee0dd3eea22e390c80deaadc6f11eb9a": {"ta_keywords": "end speech recognition;end speech recognition system;automatic speech recognition systems;convolutional neural network;encoder;neural network;word error rate;cnn;casual conversations;multichannel end;decoder;sound input;multichannel;single channel end;mmi tdnn;noises;text;everyday environments;multiple speakers;attention;devices;end;output;lf;best baseline;system;presents difficulties;experimental results;performances;study", "pdf_keywords": "kinect microphone arrays;binaural microphone pairs;deep models;rnn layers;single channel end;cnn layers;tracks;single channel model;end models;end model;array track;lm;model;gpu;wer;multilevel lm;environment asr;end;extension;performance;word;limitations;cells;absolute reduction;character;challenge;strength;respect;size"}, "b2fd7297f7681f9e3ea860cecf1ec97b2cc8ccc3": {"ta_keywords": "destination therapy ventricular assist device patients;tobacco cessation;international survey;results", "pdf_keywords": ""}, "ff783c4709a095cc581534fec58ef9515613ebc9": {"ta_keywords": "catastrophic forgetting;continual learning;forgetting;remembering;memory;visual model explanations;replay buffer;model explanations;explanations reduce;simple novel training paradigm;prior tasks;explanations;consistent improvement;example;tasks;predictions;training time;buffer;explainability;rrr;decisions;evidence;right reasons;model;performance degradation;various cl approaches;previous work;shot settings;goal;cl", "pdf_keywords": "incremental learning;gradient class activation mapping;guided backpropagation;continual learning;backpropagation;vanilla backpropagation;shot class;model explanations;imagenet100;other memory;memory;saliency maps;smoothing gradients;experience replay;consistent improvement;cam;rrr;popular benchmark datasets;various popular explanation methods;shot settings;regularization;cifar100;overall accuracy;iclr;smoothgrad;grad;ucsd birds;tasks;earlier decisions;cil"}, "f2e7598464a0b9376771ffc4ba243233ee12c677": {"ta_keywords": "lexical sememe prediction;chinese sememe knowledge base;minimum semantic units;various nlp tasks;sense knowledge bases;word sense;vocabulary words;human languages;sememes;chinese characters;external context information;multiple sememes;external context;internal character information;linguists;words;frequency words;chinese;concepts;hownet;meaning;large margin;art baselines;novel framework;advantage;robust performance;framework;methods;state;issue", "pdf_keywords": "lexical sememe prediction;sememe prediction framework;chinese sememe knowledge base;internal character information;sememe embeddings;sememe prediction;character filtering;external context;external information;internal information;frequency words;character;world dataset;word;models;art baselines;hownet;novel framework;large margin;spcse;robust performance;robustness;spwcf;csp;framework;effectiveness;paper;state;methods"}, "48b18bf5c9cad0e4c36b2d885f380c5c637e1a09": {"ta_keywords": "disentangled representations;optimal conditional priors;conditional prior;generative model;disentanglement;auxiliary observed variables;regularization;prior distribution;latent space;unsupervised setting;latent variables;inductive biases;models;input observations;novel vae;information;data;model;theoretical guarantees;metrics;theoretic principles;art methods;state;recent developments;aistats;literature;respect;superior performance;experimental results", "pdf_keywords": "generative model;disentanglement methods;superior disentanglement performance;novel generative model;disentanglement;disentanglement metrics;conditional prior;identi\ufb01ability;regularization;idvae;novel vae;input observations;experimental protocol;vae;information;datasets;theoretical guarantees;latent variables;most experiments;tangible improvements;optimality constraint;metrics;superior performance;uni\ufb01ed notation;art approaches;theoretic terms;art competitors;contributions;detailed overview;state"}, "ee5dc631a682696a4704b742ea087e8abb5df897": {"ta_keywords": "unsupervised speech recognition tasks;synthesized speech;enhanced asr;language model reward;attention context;asr;asr hypotheses;tts;training;main features;babel;eat;self;domain data;cycle;framework;performance gap;librispeech;consistency algorithm;results;hyper;parameter;paper;major benefits", "pdf_keywords": ""}, "162c3cf78af48ddf826ec76a1a3767a88a730170": {"ta_keywords": "\u4e00\u822c", "pdf_keywords": ""}, "c8a5d05cb741b3448ec4106d2006ae24a7a401b4": {"ta_keywords": "latency streaming asr;asr networks;sequence transducer models;automatic speech recognition;latency regularization;training transducer models;asr;rnn;transducer models;word error rate;transducer;frame probability prediction;level emission regularization;sequence probability;fastemit;convnet;sequence;emission delay;constrained alignments;level emission regularization method;late penalties;wer;alignment;various end;end;transformer;degrading quality;conformer;level optimization;hypothesized word", "pdf_keywords": "sequence transducer models;latency streaming asr;automatic speech recognition;latency regularization;asr networks;training transducer models;transducer models;frame probability prediction;level emission regularization;transducer;asr;voice search test;word error rate;fastemit;emission delay;sequence probability;300ms latency reduction;constrained alignments;level emission regularization method;rnn;better accuracy;late penalties;sequence;convnet;wer;alignment;various end;hypothesized word;end;transformer"}, "9918ea4b68e90e1257953b6f2665b2ce29f2bc8b": {"ta_keywords": "speech enhancement;3d ambisonic microphones;l3das22 challenge task;l3das22 challenge;deep neural network;beamforming result;dnns;linear beamformer;second dnn;first dnn;linear beamformers;dnn;waveform;channel wiener filter;complex spectral mapping;challenge baseline;distortion;extra inputs;challenge;losses;magnitude;estimation;evaluation set;espnet;combination;signal;submission;paper;se submission;core", "pdf_keywords": "beamforming enhancement;3d ambisonic microphone format;complex spectral mapping;linear beamformers;target speech signal;beamformer;iterative pipeline;deep neural network;channel wiener \ufb01lter;dnns;dnn;linear;ineube framework;tcn;architecture;denseunet;approach;miso con\ufb01guration;method;core;study"}, "30109a213aa10765486c676ecfa511db227ab543": {"ta_keywords": "neural machine translation;shorter sentences;sentence length;nmt toolkits;nmt;nmt training;longest sentence;corpus;processing speed;training;padding;empirical study;length;efficient computation;models;disparate strategies;essential step;previous work;efficiency purposes;amount;fact", "pdf_keywords": "neural machine translation;minibatch creation strategy;nmt models;training corpus;many nmt toolkits;language pairs;nmt toolkits;batches;nmt training;nmt;training examples;neural networks;largescale machine learning;larger operations;models;satoshi nakamura2 1ntt communication science laboratories;disparate strategies;training;sorting;modern computation architectures;recent implementations;jun;simple shuf\ufb02ing;ntt corporation;strategies;empirical study;parallelism;japan science;yusuke;standard practice"}, "5e6acc5c73f22c2dbbb4910f656a03cf40a2fe15": {"ta_keywords": "pac", "pdf_keywords": ""}, "03e62d5f0265608c6ebdebba0870131b056b79a6": {"ta_keywords": "online harms;harmful online content;harmful content;content moderation;harm mitigation;harm;online social media platforms;harms;harassment;severity;policy;practices;experiences;prioritization frameworks;research;theoretical framework;approaches;prioritization;policies;policy settings;empirical understandings;deeper understandings;frameworks;understandings;framework;theory approach;participants;efforts;activities;interviews", "pdf_keywords": "harmful content online;harmful online content;online harms;harmful content;content moderation;content moderation work;online social media platforms;harm mitigation;harm;social media users;harms;severity;empirical understandings;research;policy;theoretical framework;practices;prioritization;experiences;frameworks;framework;relationships;understandings;approaches;theory approach;experts;efforts;rich data;proliferation;participants"}, "33ce3cd897a3473973f338c154f3fe5c1175643c": {"ta_keywords": "open predicate query language;virtual knowledge bases;open predicate relations;large knowledge bases;different kb reasoning tasks;opql;relation mentions;structured supervision;language model;external memory;virtual kb;vkb;reasoning;text;kbs;prior vkb methods;tasks;recommendation;question;improvements;widerange;lm;domain question;way;industry applications;set;method", "pdf_keywords": "open predicate query language;opql;distant kb supervision;open predicate relations;different kb reasoning tasks;virtual knowledge bases;virtual knowledge base;multiple opql operations;conjunctive reasoning;external memory;qa task;prior vkb methods;language model;differentiable reasoning operations;studied qa task;neural lm;text models;effective vkb;novel vkb construction method;vkb;art vkb methods;reasoning;distant supervision;kb;less supervision;tasks;lm;improvements;text corpus;supervision"}, "b00bc4dcce60e7c631a23d60894e51001de1c630": {"ta_keywords": "ebola virus glycoprotein;ebola virus gp;viral infectivity;vesicular stomatitis virus;most filoviruses;glycoprotein cleavability;antibodies;neutralizing antibodies;endothelial cells;viruses;proteolytic processing;epithelial cells;infectivity;cell types;vsv pseudotype system;cell tropism;secretory gp;pseudotype system;amino acid substitutions;greater affinity;gp cleavage site;vsv;sgp;acylation;gp;detection;strain;strong tropism;activity;functional properties", "pdf_keywords": ""}, "2583e7e279e2969493c3290c8f300ab32da40bf9": {"ta_keywords": "entity mentions;current entity candidate generation methods;language knowledge base;plausible candidate entities;resource languages;resource xel;transfer learning methods;language texts;referents;xel datasets;language kb;mentions;resource counterparts;resource;gold candidate recall;mention;resources;languages;xel;target;resource scenarios;kb entries;candidate generation;list;source;kb;improvements;task;art baselines;performance", "pdf_keywords": "entity mentions;current entity candidate generation methods;language knowledge base;entity;wikipedia anchor;lowresource xel;entity name;previous xel candidate generation models;referents;language texts;real world xel datasets;resource;string matching model;common sources;language technologies institute carnegie mellon university;xel;other datasets;mentions;mention;target;theart candidate generation model;sources;kb entries;baseline model;candidate generation;kb;methodological improvements;improvements;source;mismatch"}, "0bb30ed3340d2c34fe9f37c5002929bc5f458c23": {"ta_keywords": "other biomedical relation extraction tasks;protein relation datasets;biomedical text;bidirectional encoder representations;ary relation extraction;biomedical relation statement;bert architecture;biomedical literature;lstm;term memory;bert;attention;relations;graph transformer;gene;extraction task;neural network;neighbor tokens;ary relation;multiple sentences;benchmarking results;attention mechanism;graph;mining approaches;datasets;disease;transformers;current token;results;gnn", "pdf_keywords": "other biomedical relation extraction tasks;protein relation datasets;bert architecture;bidirecti onal encoder representations;bert;graph transformer;independent biomedical benchmarks;attention mechanism;pubmed abstract;benchmarking results;datasets;cdr datasets;novel model;novel architecture;transformers;whole text;architecture;key information;response;prediction;neighbor;improvements;accuracy;inte;f1;significant improvement;other state;measu;art;work"}, "9bbc8ca94810e8a21e4a6a55a5913c5b0b6c787f": {"ta_keywords": "line speech transcription;initial automatic transcript;smaller utterances;respeaking word error rate;speech;correction efficiency;typing;respeakers;respeaking;traditional respeaking methods;supervision;confidence;costs;detailed experiments;results;effect;method;terms", "pdf_keywords": ""}, "7e0570f498a5de4f2a861546d4e67ba208f71d12": {"ta_keywords": "speaker recognition benchmark;art dnn speaker recognition;speaker recordings;microphone state;diarization system;field;performance gap;evaluation design;degradations;challenging artifacts;interactions;tasks;paper;results;research;goal", "pdf_keywords": ""}, "1410f7d9470a24fb4055c6685c2dda758b9d995f": {"ta_keywords": "evolutionary game theory;dynamic agents;evolutionary learning dynamic;sum games;chaotic coevolution;archetypal game;static games;static game;recurrent orbits;evolve;games;agents;network generalizations;sum competition;online learning;replicator;competitive settings;possible initializations;conservation laws;theoretic flavor;time analogue;populations;initial conditions;artificial divide;behavior;multiplicative weights;theoretic setting;current population mixture;regularities;poincare", "pdf_keywords": "polymatrix games;static polymatrix games;sum polymatrix game;sum games;dynamical systems;network generalizations;new systematic game;games;replicator dynamics;arbitrary network;agents;theoretic graph;game;environment dynamics;theoretic analysis;general framework;models;concept;broad class;player;class;time;input time;novel reduction;population;preliminaries;background material;de\ufb01nitions;application;problem"}, "e8e62a80c7355bcf5dbc9fabafff4025e00cf540": {"ta_keywords": "combinatory categorial grammars;novel nonparametric bayesian model;plausible lexicons;languages;pos;text;induction;state;number;art performance", "pdf_keywords": ""}, "4ef46d5daf6a7a9536e2ebe3c7aa2296bffcf43e": {"ta_keywords": "unsupervised pos tagging;unsupervised markov models;speech tagging;infinite hmm;pos tagging;unsupervised part;ihmm inference algorithm;dirichlet;yor processes;states;pitman;ihmm;hmm;wall street journal;previous work;number;implementation;problem", "pdf_keywords": ""}, "467b14cc8337dd7efe1d374f9a7feb90ae9d2c12": {"ta_keywords": "articulatory controllable speech modification;direct waveform modification;gaussian mixture models;evaluation", "pdf_keywords": ""}, "63a604942f1238e9678aebd697a2379981e9a20a": {"ta_keywords": "tutor learning;teaching simstudent;tutor;students;computer agent;simstudent;line learning environment;peers;social factors;effect;others;tutees;research progress;ample evidence;factor;various contexts;problem;cost;area", "pdf_keywords": ""}, "db392858262b17aa9c8ff8659738f68fbf832ebe": {"ta_keywords": "abstract syntax tree;code completion;programming languages;structural language modeling;structural language models;programming language;arbitrary code;source code;code snippet;strict syntax;code;tree;program;neural model;ast paths;conditional probabilities;expressions;structure;target node;probability;ast;nodes;kinds;slm;vocabulary;task;restriction;piece;product;previous techniques", "pdf_keywords": ""}, "040a1abdbef2a0e087a586d719259c32c95bfc78": {"ta_keywords": "dialog management task;planning;full policy optimization;linear probabilistic model;optimal action;free grammars;like log;system actions;reward;pomdp;log;propagation inference step;context;belief;system;model;same objective function;line estimation;variable spaces;rich features;linear counterpart;hand;rule;experiments", "pdf_keywords": ""}, "e1a20480e4168d58deec743035b7ff02720672d7": {"ta_keywords": "end speech recognition;lstm rnn;open vocabulary recognition;connectionist temporal classification;automatic speech recognition;language models;mandarin;character lms;hmm systems;open vocabulary end;hybrid attention;chinese tasks;characters;end asr;word lms;languages;long sequences;word level;japanese;small alphabet;character;linguistic constraints;recognition accuracy;lm;lms;asr;english;end;ctc;art dnn", "pdf_keywords": ""}, "a13d9c8e5a2fc028ad597e2bd46a9c60aca0ede4": {"ta_keywords": "speech synthesis system;synthetic speech;expressive speech synthesis;speech input;prosody modification method;prosody modification;input speech;speech inputs;prosodic mismatches;hmm state alignment;prosody;own voices;target speaker;model adaptation;text;original functions;alignment;appropriate unit;f0 patterns;degradation;quality;hmm;naturalness;duration information;duration;propose method;correction;order;information;user", "pdf_keywords": ""}, "d26a7a86013b3be57acc0f5df73393cab7c302d9": {"ta_keywords": "deterministic particle methods;iterative stochastic path;pde solvers;optimal interventions;planck equations;control methods;nonlinear backward partial differential equation;deterministic particle;logarithmic gradients;deterministic framework;sdes;forward probability;diffusive systems;pde;fokker;necessary controls;hjb;grid;bellman;hamilton;shot;jacobi;equation;terms;solution;scores", "pdf_keywords": "deterministic particle methods;stochastic simulations;stochastic monte carlo;forward probability \ufb02ows;planck equations;optimal interventions;particle number;logarithmic gradients;deterministic framework;particles;euler integration;particle;pde solutions;fokker;sample paths;feynaman;methods;euler;odes;maruyama;method;pice;kac formula;approach;shot;controls;small number;terms;performance;scores"}, "73c401e29cb83157bc6dfb33d5ce4364a7d2731b": {"ta_keywords": "shot image generation;shot model;large source domain;realistic images;diversity information;target domains;relative similarities;correspondences;instances;source;extensive results;previous methods;differences;work", "pdf_keywords": "gans;batch statistics adaptation;shot model;tgan;adaptation;source model;corresponding images;minegan;large source domain;target domains;relative similarities;target domain;diversity information;similarity;correspondences;noise vectors;target;samples;intermediate layers;model;distributions;pairwise distances;source;instances;distribution;extensive results;notion;scale;same objective;process"}, "4702bfd200ceb6de126a60afb4db9da5c413476e": {"ta_keywords": "speech estimate;acoustic score distribution;speech enhancement algorithm;uncertainty propagation;asr accuracy;dnn baseline;deep neural networks;acoustic model;acoustic scores;residual noise;noisy environments;chime database;approximate propagation methods;asr performance;observation uncertainties;dnn;uncertainty;estimate;distortion;speech;layers;monte carlo sampling;propagation;activation function;variance;distribution;nonlinearities;measures;unscented transform;piecewise exponential approximation", "pdf_keywords": ""}, "b946ce2c3405969bf615bedc623845b0d3d9b010": {"ta_keywords": "end transformer automatic speech recognition;transformer encoder;attention network;automatic speech recognition;decoder layers;neural networks;transformer self;local acoustic information;speaker attributes;transformer;attention;attentions;novel mocha training;entire input sequence;asr;e2e;online end;end;additional context;inference algorithms;channel;self;aware inheritance mechanism;peaky;context;multiple heads;vector;residual connections;block;block processing method", "pdf_keywords": "online transformer decoder;contextual block processing encoder;transformer encoder;transformer decoder;online e2e asr system;automatic speech recognition;attention network;end transformer;transformer self;neural networks;asr;previous transformer;online end;e2e;conventional chunkwise approaches;shinji watanabe2;block processing method;alternative;end;eess;yosuke kashiwagi1;context;emiru tsunoo1;promising performance;wsj;systems;evaluations;toshiyuki kumakura1;japan 2johns hopkins university;mocha"}, "3ad287cf3b17cb109bf991731d2c0dcf8b7db2b1": {"ta_keywords": "morphological tagging;superior tagging accuracies;universal dependencies treebank;neural factor graph models;tag sets;languages;resource languages;factorial conditional random fields;resource language;tags;neural network representations;training data;transitive relationships;neural network potentials;surface forms;paper;model;lrl;overlap;model pairwise;hrl;lrls;expressive power;information sharing;previous work;assumption;same family;performance;superficial differences;method", "pdf_keywords": "morphological tagging;universal dependencies treebank;superior tagging accuracies;morphological analysis;syntactic traits;neural factor graph models;languages;neural network representations;annotations;tag sets;syntactic properties;language;tags;resource languages;resource language;neural networks;transitive relationships;graphical models;graham neubig language technologies institute;factorial conditional random \ufb01elds;training data;neural network potentials;tokens;code;novel framework;surface forms;model;paper;word;overlap"}, "27e1dbe9f7c71cd6cc1b0357f49aef497e572d09": {"ta_keywords": "statistical machine translation;source code;code understanding;natural languages;python statements;english;smt;human effort;less human effort;framework;method;paper;experiments;demand production;relationship", "pdf_keywords": ""}, "1abd1efae8c3849e28de926e52d166b7800965a1": {"ta_keywords": "aggregating incomplete ranked lists;graph embeddings;incomplete rank lists;deep neural representation vectors;preference aggregation;deep neural representation learning;recommendation systems;deepaggregation;layer graph;aggregation;nodes;edges;computational social choice;ties;web search;collection;algorithm;preference;alternatives;input;recent advances;information;literature;paper;fields;set;first time;problem;new approach;techniques", "pdf_keywords": ""}, "d513a3583bd168ee341ce3b26d54a4e4096da471": {"ta_keywords": "archival storage systems;mds queues;mds queue;data storage systems;storage;insightful scheduling policies;latency performance;hot data;analysing latency performance;cold data;redundant requests;latency;mds codes;improved reliability;data;performance;extensive simulations;codes;monte carlo methods;paper;key metric;lower bounds;use;knowledge;theory;theoretical analysis;term;benefits;first analytical results;lens", "pdf_keywords": ""}, "1d634d645bfe0b289fd6a2a0d9210b2a04c9237b": {"ta_keywords": "private stochastic gradient descent;private nlp models;private learning;large deep learning models;private training approaches;sgd;learning;strong nonprivate baselines;example gradients;nlp tasks;high computational overhead;memory saving technique;dp optimization;sized corpora;large performance drops;hyperparameters;dependent performance degradation;models;dimensional models;performance drop;text;computational challenge;model;conventional wisdom;large transformers;dp;empirical results;tuning;layer;dimension", "pdf_keywords": "private stochastic gradient descent;private learners;large language models;performant dp language models;large deep learning models;privacy budgets;language models;language generation tasks;nlp tasks;sgd;sentence classi\ufb01cation;learning;high computational overhead;training objective;models;hyperparameters;baseline dp optimization algorithm;strong differentially;appropriate hyperparameters;examples;strong performance;downstream task objectives;dp;performance;thousands;abstract;large performance drops;text;percy liang1;suite"}, "5ee580fba44c6efb2a9b06f4c62de6b053db7784": {"ta_keywords": "peer review;empirical risk minimization;reviewers;lp losses;loss functions;criteria scores;computational social choice;different reviewers;loss function;aggregate mapping;final recommendations;community;desirable values;novel paper;novelty;paper;key challenge;disparate mapping;extensive experiments;erm;choice;major source;matrix;ground truth;vectors;whole;absence;class;handful;specification", "pdf_keywords": "community aggregate mapping;peer review;aggregation;aggregate mapping;reviewer;criteria scores;community;ijcai review data;subjectivity;machine learning;empirical risk minimization;visualizations;social choice theory;recommendations;opinion;mapping;acceptance decisions;preferences;discussion;data;research;interpretations;various criteria;approaches;paper;subsequent modeling;erm;approach;use;issue"}, "45dcccef42ed09cfd2babb630c117e95136b35d1": {"ta_keywords": "popular dialogue state tracking benchmarks;example dialogue;universal dialogue systems;dialogue dataset;dialogue;seq2seq modeling;large language models;schema representations;schema elements;schema;descriptions;semantics;apis;prompt format;short examples;out benchmark;task;better generalization;minimal supervision;service developers;critical challenge;demonstrations;similar effort;multiple do;model;show;mains;stronger performance;maintenance;multiwoz", "pdf_keywords": "popular dialogue state tracking benchmarks;dialogue dataset;large language models;natural language descriptions;single dialogue example;schema representations;example dialogue;state annotations;schema representation;dialogue history;semantics;out benchmark;schema;schema elements;sota dst models;apis;sgd training data;descriptions;new apis;benchmarks;seq2seq modeling;sdt models;dataset;better generalization;more data;sdt;short examples;description;service developers;variations"}, "6b9c3f82a0c0fd62f8ae527126b118890cfd452d": {"ta_keywords": "grammatically biased learning;logic programs;explicit antecedent description language", "pdf_keywords": ""}, "1b06fe6ca5f4404e68b066cdea1a74a36e3e0e13": {"ta_keywords": "egocentric manipulation data;robot success detection;robot;objects;unseen objects;success detection;action outcomes;encode prior geometry;nesting objects;classification accuracy;images;static object data;task baseline;performance;end pipeline;shape;model;language expressions;static data;end;absolute gain;pairs;hours;reason;size information", "pdf_keywords": "robot action outcomes;egocentric manipulation data;human annotations;natural language object;robot;action outcome detection;egocentric camera data;egocentric data;egocentric camera images;object ot;robot manipulates;end cnn;objects;unseen objects;object pairs;static vision;detection success;object;object og;vision;linguistic information;language data;task accuracy;language;unimodal ablation analysis;modality;observations;models;dataset;fig"}, "4cb3275ec95f4ad407f153aa9dc2d527bc2744e5": {"ta_keywords": "speech synthesis system;speech synthesis technologies;speech synthesis;synthetic speech;synthetic speech parameters;speech input;input speech;controllable hmm;own speech;specific target speaker;speech;prosody;target speaker;original functionality;text;interfaces;modules;system;last module;duration;determined duration;great demand;hmm;creative activities;f0;users;paper;popularity", "pdf_keywords": ""}, "34c9e3152c9a14af711994230d8a3909daeaa7cf": {"ta_keywords": "empirical risk minimization;loss functions;lp losses;loss function;peer review;aggregate mapping;computational social choice;community;reviewers;desirable values;novel paper;novelty;research paper;erm;axioms;key challenge;paper;ground truth;extensive experiments;class;matrix;standard class;vectors;choice;specification;absence;whole;extension;framework;handful", "pdf_keywords": ""}, "46f88a062df05673ae0731aa17f9f9cc9d3e87bf": {"ta_keywords": "cross sections;flows", "pdf_keywords": ""}, "c4e83bfddb38642debb31097501aec8768f9020e": {"ta_keywords": "acm sigai student essay contest;ai researcher;artificial intelligence technologies;several prizes;chat;500usd", "pdf_keywords": ""}, "f5813bb0b398007cae10ffdddeab221d4b9b0dc7": {"ta_keywords": "pumped storage power station;dynamic simulation technology;characteristics;research", "pdf_keywords": ""}, "27de5fb45af9799ed0020c978fe3a3080c60401e": {"ta_keywords": "morphokinetic annotations;embryo;convolutional neural networks;lapse videos;time", "pdf_keywords": ""}, "bab35e88a510938d22cb28f2ecc6f6e189c3d8ea": {"ta_keywords": "arabic speech recognition;modular systems;human;end", "pdf_keywords": "arabic asr;arabic speech;native speaker performance;linguist performance;dialectal datasets mgb3;arabic language;e2e asr;dialects;modular hmm;dnn asr;e2e performance;e2e transformer;\ufb01rst e2e transformer;new dataset;absolute wer gap;hsr;performance;human performance;machine;data size;head;wild2;challenges;mgb5;results;modular system;private data;average;lay;comprehensive study"}, "0132cb4384c3a6402353d8f349f8dd450d8ea4a2": {"ta_keywords": "historical spelling normalization;deep neural network architecture;language processing;normalization algorithms;texts;variant spellings;high german;historical documents;annotated data;diverse set;character level;task;early new;model;abundance;suitability;lack", "pdf_keywords": "term memory networks;spelling normalization;historical spelling normalization;term memory model;sequence labeling task;diverse corpus;lexical resource;normalization tool norma;additional normalization data;normalization accuracy;deep neural network architecture;texts;diverse dataset;high german;training data;crf baseline;norma tool;task;norma;crf;dataset;tagger;tokens;character level;additional data;character;early new;future work;bollmann;performance"}, "39e734da43eb8c72e9549b42e96760545036f8e5": {"ta_keywords": "machine comprehension datasets;qa dialogs;dialogs;dialog context;art reading comprehension architecture;model dialog context;short excerpts;wikipedia text;freeform questions;questions;reference models;quac introduces challenges;text;quac;context;dataset;student;teacher;crowd workers;detailed qualitative evaluation;results;question;number;sequence;total;state", "pdf_keywords": "dialog context;qa dialogs;model dialog context;art reading comprehension architecture;dialogs;wikipedia articles;context;reference models;questions;information;text;quac;strong neural baseline;section text;large scale dataset;sections;allen institute;results;student interaction;dataset;question;number;ofthe;student;paper;cl;conclusion;aug;form;roles"}, "68b3905c2f82814294631f2ce29d5be4165e6b1f": {"ta_keywords": "wireless relay nodes;relay nodes;impromptu multihop wireless network;relay node;optimal policy structures;light traffic regime;transmit powers;impromptu deployment;packet source;nodes;random length;packet;sink node;maximum power;deployment;sum power;typical parameters;policies;objective;known distribution;sink;overall system;performance;linear combination;step;measurements;measurement;numerical results;links;line", "pdf_keywords": "countable state space;computational complexity;total cost mdp;wireless relay nodes;state space;sum power objective;stochastic monotonicity;threshold policies;simulation estimate;random length;measurement based impromptu deployment;memory requirement increases;\u03b3r;max;lemma;in\ufb01nite horizon;value iteration;action;deployment failure probabilities;sum;space;asyou;power case;known distribution;deployment;problem;same model;dimension;person;mar"}, "dc8ebb6d9908542ae474dc2b21bfb6a14216f678": {"ta_keywords": "large multilingual translation models;competitive translation results;translation systems;pmi corpus;gpu;top submission;bleu points;leaderboard;single gpu;memory;compute optimization;maximum;metrics;latest advances;standard baselines;hours;work;shortcomings;constrained setting", "pdf_keywords": ""}, "010df54445ab5f47582eb668dc3488a3e46b55d3": {"ta_keywords": "unsupervised hidden markov model;generative models;tag;simpler model;additional context;duction;art;state;approach;work;first results", "pdf_keywords": "unsupervised neural hidden markov models;unsupervised hidden markov model;hidden markov models;speech tag induction;generative models;topic models;unsupervised systems;speech induction;variational inference;downstream nlp applications;speech tags;variable sequence model;neural networks;tag induction;incomplete data likelihood;grammar induction;encode morphosyntactic information;simpler model;single latent;mcmc;language;hmms;additional context;amsterdam 3google brain;daniel marcu1 kevin knight1 1information sciences institute;part;tag;em;sep;southern california 2informatics institute"}, "90b9d19af75c86f42865052c21305c70f884b5fe": {"ta_keywords": "selfish routing game;congestion costs;network congestion;multicommodity routing networks;urban transportation networks;congestion;favorable network conditions;dynamic pricing policies;uncertain users;equilibrium behavior;uncertainty;costs;multicommodity;prices;cost;inefficiencies;policy;different estimates;users;user;usual notion;perception;drivers;multiplicative factor;efficacy;light;face;results", "pdf_keywords": ""}, "124385efee78010a4408329dffea4798f5a1ad47": {"ta_keywords": "simultaneous speech translation;translation unit segmentation;translation timing;speech translation;conventional speech translation systems;translation systems;translation process;language pairs;pause boundaries;similar word order;linguistic information;translation;target languages;phrase table;input utterance;less delay;delay;large delay;languages;input sentence;sentence;more word;information;points;work;end;source;relationship;probabilities;methods", "pdf_keywords": ""}, "0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42": {"ta_keywords": "ground truth label representations;segmentation networks;soft labels;ordinal regression;deep neural networks;image quality ranking;categories;classification problems;monocular depth estimation;shelf classification;horizon line regression;intraclass;age estimation;metrics;natural order;relationships;encoding;metric penalties;variety;network architecture;specialized approaches;different network architectures;respect;explicit modification;adapts;different scenarios;approach;effective method;purpose method", "pdf_keywords": "la softmax;segmentation networks;ground truth label representations;image quality ranking;interclass distance;soft labels;monocular depth estimation;categories;horizon line regression;metrics;ordinal regression;distance metrics;metric penalties;parameter discretizations;class vector;traditional classi\ufb01cation problem;different classi\ufb01cation;classi\ufb01cation problems;specialized approaches;age estimation;robustness;shelf classi\ufb01cation;relationships;different network architectures;plethora;continuous domains;variety;competitive results;section;art results"}, "59f3e3cad309eb4965d67773d68bc2f91b2e376f": {"ta_keywords": "highland puebla nahuatl speech translation corpus;access speech translation corpus;endangered language documentation;speech translation;machine translation;automatic speech recognition;highland puebla nahuatl;machine learning tools;el audio;languages;el;documentation;central mexico;els;glottocode high1278;asr;mt;thousands;paper;processing;end;21st century;st;verge;aspect", "pdf_keywords": ""}, "2ac98a28fdae4c01a89f09393c736e72445a4c4e": {"ta_keywords": "speech recognizer;dynamic variance adaptation;cluster", "pdf_keywords": ""}, "da660ca9e6fedefe815e305efd0dcd3bf9b4bb60": {"ta_keywords": "relation extraction;relation extraction process;entity recognizers;large knowledge bases;entity filters;distant supervision paradigm;limited distant supervision;architect names;many relations;relation;supervision;recent approaches;completion years;few instances;world applications;substantial amount;application;performance;approach;seed instances;average precision;points", "pdf_keywords": ""}, "2078d466766b6876d73ac1981392fa8bd2b9520d": {"ta_keywords": "optimize paper bidding;peer review", "pdf_keywords": ""}, "dcac1abd2ae5af180e51994a9c8334a6de915765": {"ta_keywords": "biased compression operator;compensated sgd;sgd;arbitrary compressions;constant learning rate;loss functions;convex objectives;quantization;variance reduction;convergence guarantees;convergence rates;gradient differences;full gradients;exact optimum asymptotically;arbitrary sampling;updates;ec;unified analysis;new variants;expectation;feedback;general scheme;variants;diana;workers;error feedback;state;different variants;paper;methods", "pdf_keywords": "converging error compensated sgd;compensated sgd;sgd;arbitrary compressions;updates;di\ufb00erent variants;yandex;ec;variants;dmitry kovalev kaust;kaust;sirius;dmitry makarenko mipt;uni\ufb01ed analysis;oct;peter richt\u00e1rik kaust;saudi arabia;oc;math;framework;eduard gorbunov mipt;russia;paper;error;abstract"}, "6a9394e5d49c1251c0fb6d7fb0c0813d26c6a907": {"ta_keywords": "shot parsers;semantic parsing benchmarks;semantic parsers map;canonical utterances;stronger paraphrasers;shot learning;natural language utterances;improved grammars;canonical examples;synthetic canonical examples;laborious annotation efforts;utterances;meaning representations;training examples;linguistic diversity;real user intents;training data;grammar;efficient learning methods;language;logical gaps;programmatic patterns;data;geo;ones;programs;gaps;such models;world user;strong performance", "pdf_keywords": "semantic parsing benchmarks;shot parsers;semantic parsers;automatic paraphrasing;shot parser;stronger paraphrasers;improved grammars;more expressive grammars;idiomatic language patterns;idiomatic synchronous grammars;realistic utterances;real user intents;canonical examples;synthetic canonical examples;language gap;language;datasets;logical gaps;ef\ufb01cient learning methods;programmatic patterns;data;geo;gaps;ef\ufb01cient;lms;ones;world user;domains;domain;strong performance"}, "5446a8bbadc2ba2c575353b257f26abae27b3b2a": {"ta_keywords": "user comparisons;recommendation systems;user preference;user preferences;relative attractiveness;comparisons;localizing items;lowdimensional space;different items;items;lifting approach;novel convex;users;ideal point model;point;user;context;model;representation p1;paper;method;set;delta distancing;common problem;problem", "pdf_keywords": ""}, "f49ccfb32aad8e6893e8cbb037c1282572fe6e21": {"ta_keywords": "deep testing methods;various adversarial samples;adversarial samples;adversarial attacks;dnn models;dnn systems;deep neural networks;model mutation testing;dnn;higher diversity;vulnerability;cifar10 validate;models;lack diversity;detection;model;graph characteristics;software engineering;ggt;confidence;real applications;number;mmt;wide application;graph;effectiveness;efficiency;different kinds;initial experiments;respect", "pdf_keywords": ""}, "62dc7bdae6700c4409e6d9773d6ecb5c0fab75a4": {"ta_keywords": "approximate dictionary searching;dictionaries;indexing methods;russian dictionaries;natural language datasets;retrieval;frequent words;art indexing methods;string identifiers;taxonomy;indices;clueweb09 collection;comparative analysis;sequence;synthetic english;strings;update;auxiliary information;field;direct methods;methods;article;important cases;solutions;understanding;state;primary goal", "pdf_keywords": ""}, "02aebef93baeef3396f3cb4468a7054067f190c6": {"ta_keywords": "matching entities;canonical entities;entities;nonparametric bayesian approach;entity;structured database;name structure;schema;accurate database;references;text;raw text;fields;empirical evaluation;only supervision;tasks;prototype examples;sensible model;approach;iii;ii;method;advance;set;number", "pdf_keywords": ""}, "f262ef2f50dfcaf07dc6598f22fb9b2470b37cf1": {"ta_keywords": "dynamic span graph allow coreference;confident entity spans;information extraction;several information extraction tasks;nested span entities;dynamic span graphs;span enumeration approach;span graphs;span representations;coreferences;relation type confidences;relation types;nodes;graphs;ace dataset;graph;confidence;significant f1 score improvement;general framework", "pdf_keywords": "relation extraction tasks;relation detection tasks;entity recognition;multiple information extraction tasks;general information extraction framework;contextualized information;global contextual information;joint entity;relations;coreferences;dynamic span graph framework;wet lab protocol corpus;general framework dynamic graph ie;span representations;several datasets;richer span representations;datasets;tasks;many domains;domains;scienti\ufb01c articles;framework;news;scierc;wet lab;experimental protocols;diverse range;paper;code;dygie"}, "36906613dcef29263afe711f128da1fc916cbbee": {"ta_keywords": "connectionist temporal classification;corpus;long sequence data;gaussian kernel;attention;efficient training;training data;frame indexing technique;invariant kernel;kernel function;shift;benchmarks;asr;gaussian;accuracy;windowing techniques;ctc;csj;relative position information;queries;short segments;tedlium;length mismatch;self;keys;new architecture;mismatch;architecture;variant;significant improvement", "pdf_keywords": "recognition performance;encoder;long sequence data;asr model;asr;corpus;gaussian kernel;kernel structure;attention;kernel function;connectionist temporal classi\ufb01cation;frame indexing technique;ctc;shift;benchmarks;accuracy;gaussian;csj;length mismatches;windowing techniques;conventional masking;relative position information;queries;training;sa;keys;novel structure;signi\ufb01cant improvement;testing data;tedlium"}, "9a334566b79bc6c6906e2b5285d5ea50b9b99479": {"ta_keywords": "adversarial feature learning;meaningful representations;machine learning;controllable invariance;representations;specific predictions;representation;particular task;optimal equilibrium;certainty;uncertainty;task;detrimental variations;trait;game;data;content;detrimental factor;great interest;problem;specific factor;paper", "pdf_keywords": "adversarial feature learning;adversarial learning;representation learning;meaningful representations;representation;invariant representation;minimax game;learning;typical discriminative models;benchmark tasks;better generalization;discriminator;bias;encoder;controllable invariance;variation;predictor;detrimental variations;feature;machine learning;particular task;feature space;tasks;players;free classi\ufb01cation;independent image classi\ufb01cation;predictions;language;abstract;intuitive interpretation"}, "939dfa4dec88ca167e6572904c4ad2fcbf726f48": {"ta_keywords": "wasserstein gradient;euclidean gradient flow;edgeweights converges;gradient flow;gradienttype potential;scalar entropy;graphons;such large graphs;exchangeable particle systems;probability measures;continuum limits;continuum limit;various optimization problems;maximal slope;infinity;curve;limit;several natural functions;field interaction;examples;suitable function;homomorphism functions;applications;space;detail;size;set;host", "pdf_keywords": "edgeweights converges;graphons;such large graphs;continuum limits;euclidean gradient \ufb02ow;scalar entropy;gradient \ufb02ow;gradienttype potential;discretization;continuum limit;exchangeable particle systems;maximal slope;mathematical justi\ufb01cation;curve;several natural functions;limit;algorithm;homomorphism functions;suitable function;space;examples;che16;in\ufb01nity;\ufb01ner;set;size;method;detail;results"}, "c377bf3ae52dee4075c1e807de9c5579d553de22": {"ta_keywords": "nl dialogue systems;automatic dialogue systems;dialogue;speech analysis;spoken language generation;speech processing;speech;speech recognition;corpora;texts;text;talks;parsing;transcription;multimodal techniques;language resources;semantic processing;topics;tagging;16th international conference;main topics;recognition;conference;classification;synthesis;pilsen;tsd;applications;papers;modelling", "pdf_keywords": ""}, "ea71f5f59727b63b8912c6db097ba811da41bf5b": {"ta_keywords": "deterministic particle;nonlinear systems;stochastic;systems modelling;quantitative biomedicine;theoretical computer science;berlin;germany department;potsdam;technical university;germany centre;university;december;birmingham;marchstra\u00dfe;united kingdom", "pdf_keywords": "coupled stochastic kuramoto oscillators;precise stochastic control frameworks;deterministic \ufb02ow control;brownian bridge dynamics;adaptive evolution;adaptive landscapes;kuramoto phase oscillators;forward density evolves;deterministic particle \ufb02ows;synchronisation control;stochastic;nonlinear systems;optimal dynamical interventions;diffusive systems;evolver;synchronising \ufb01nite;controls;optimal interventions;state transitions;networks;continuous culturing;molecular phenotypes;cell culture growth;size networks;arti\ufb01cial selection protocols;str;novel methodological framework;framework;liebknecht;platforms"}, "5a26eeda7c2ca58c2d56f1d580fbbae9eb1a19cd": {"ta_keywords": "approximating pdes;dimensional pdes;small neural networks;elliptic pdes;deep networks;neural networks;coefficient networks;pde;boundary conditions;input dimension;dimensionality;parametric complexity bounds;dirichlet;solution scale;parameters;polynomial dependence;coefficients;volume;solutions;representational power;size;parameter counts;paper;dependence;domain;solution;recent experiments;curse", "pdf_keywords": "small neural networks;approximating pdes;deep networks;dimensional pdes;gradient descent;neural networks;neural network architecture;parametric complexity bounds;linear elliptic pdes;coe\ufb03cient networks;elliptic pdes;input dimension;dimensionality;andrej risteski machine learning department;pde;solution scale;volume;size;parameters;boundary conditions;appropriate hilbert space;laplace;iterates;partial di\ufb00erential equation;dirichlet;solutions;polynomial dependence;representational power;poisson equations;parameter counts"}, "7647a06965d868a4f6451bef0818994100a142e8": {"ta_keywords": "aware neural language models;word embeddings;raw texts;model training;conll03 ner task;novel neural framework;efficient training;language model;extra annotation;level knowledge;benchmark datasets;abundant knowledge;key knowledge;specific knowledge;task;additional supervision;transfer;most transfer;sequence;example;character;concise model;word;f1 score;different components;study;efficiency;previous methods;extensive experiments;techniques", "pdf_keywords": "sequence labeling model;sequence labeling framework;effective sequence labeling framework;lstm;transfer learning;language model;neural framework;level knowledge;raw texts;wordlevel;sequence;task;selfcontained order information;knowledge;crf;level layer;lm;architecture;character;same character;study;conclusion;ef\ufb01cient way;paper;fashion;setting"}, "e65676b43338e914ad77afd0fd6ce4bef87943a1": {"ta_keywords": "novel statistical singing voice conversion;converted singing voice waveforms;converted singing voice;singing voice characteristics;natural singing voice;singing voices;arbitrary source singer;arbitrary target singer;voice timbre;statistical conversion process;source singer;speech quality;conversion model;differential gaussian mixture model;target singers;singer identity;direct waveform modification;conversion accuracy;target singer;vocoder;vocoderbased framework;differential spectral feature;spectrum differential;waveform domain;modeling errors;conventional svc;traditional gmm;spectra;signal;gmm", "pdf_keywords": ""}, "d29d33f3b92b447d6011606be41b64439a1da088": {"ta_keywords": "contextual bandit algorithm;behavior constrained thompson sampling;online exploration;online rewards;constrained policy;online learning;novel online agent;observed behavioral constraints;behavioral constraints;reward feedback;reward;exploitation;agent;additional constraints;constraints;exogenous constraints;online setting;ai systems;policy;teacher agent;priorities;regret;actions;daily life;decisions;guide;ethical principles;observation;real world data;novel extension", "pdf_keywords": "contextual bandit algorithm;behavior constrained thompson sampling;online exploration;constrained policy;online learning;novel online agent;observed behavioral constraints;behavioral constraints;teaching agent;online recommendation;reward;online decision settings;exploitation;agent;constrained behavior;teacher agent;constraints;exogenous constraints;policy;several possible actions;online setting;regret;examples;behavior;decisions;observation;clinical trial;movie;guide;treatment"}, "721d7c82b80f14246d353251837e1711824a9e60": {"ta_keywords": "reverberation;convolutional beamformer;reverberant scenarios;weighted power minimization distortionless response;eigenvalue decomposition;matrix inverse operation;dereverberation module;reverb show;simultaneous separation;2mix corpus;novel frontend architecture;speech;frontend;wsj1;dereverberation;wpe;different frontend architectures;prediction error;propagation algorithm;end approaches;end;wpd;model;module;original wpd;performance;new formulation;conventional methods;paper;successful applications", "pdf_keywords": "reverberant speech;speech dereverberation;speech model;speaker;beamforming;2mix corpus;spatialized wsj1;end asr;previous mimo;uni\ufb01ed dereverberation;e2e;novel frontend architectures;uni\ufb01ed frontend;recognition;separation;end;promising performance;conclusion;applications;powerful method;paper;section;results"}, "a45c3120c077994409093771077a2d16f77674c5": {"ta_keywords": "efficient transfer learning methods;text classification benchmarks;machine translation;tuning methods;modifications;text summarization;transfer;less parameters;tasks;modification;new parameter;models;language understanding;efficient fine;strong performance;parameters;model;previous methods;design elements;parameter;comparable results;unified view;model size;recent work;important design choices;unified framework;tune;design dimensions;art parameter;different approaches", "pdf_keywords": ""}, "62d17b6f6ad77fd71ef9954c7784700d5e316f1f": {"ta_keywords": "privacy;differential privacy;privacy concerns;language models;data sanitization;natural language;popular data protection techniques;language model;private lives;protection methods;text;phrases;data;content;context;narrow assumptions;social norm;broadness;meaningful notion;real life;identities;training sets;paper;sensitivity;ability;expectations;nature;mismatch", "pdf_keywords": "human privacy norms;common privacy defenses;respect privacy;privacy;di\ufb00erential privacy;private information;data sanitization;popular data protection techniques;language data;language models;training language models;natural language;protection methods;narrow assumptions;social norm;complexity;broadness;context;meaningful notion;discussion;claims;paper;challenges;humans;decisions;section;summary;mismatch;parallels"}, "211a6838b9550d227ce81d0bec542ec5b70e290b": {"ta_keywords": "unseen politicians;complete historical voting records;official voting records;voting patterns;voting record;past votes;future votes;politicians;knowledge base;prediction;neural network composition;roll call votes;key political decisions;external knowledge;united states congresspeople;news text;models;accuracy;freebase;prior system;unigram features;records;empirical evaluation;prior state;relations;individuals;multiple sources;office;augmentations;prior work", "pdf_keywords": ""}, "cf9fa9ebbefab1877aa7a501c888a8a618c31abb": {"ta_keywords": "sentiment polarity;political blog posts;comment polarity;blogs;blog post;negative collective opinion;topics;community;polarity;comments;posts;content;readers;computational methods;buttons;context;specific models;issues;techniques", "pdf_keywords": ""}, "42605dca59a3aafe2e5b33741a98dad9ba117395": {"ta_keywords": "entity similarity;useful search system;personal email collections;graph walk performance;similarity metric;person name disambiguation;personal information management;enron corpus;graph walk results;reranking;similarity;search queries;search;personal information;other semistructured domains;finite random graph;other corpora;walk;relations;alias finding;persons;messages;pim domain;task;terms;graph;tool;threading;term;features", "pdf_keywords": ""}, "2a94fa0de804b5efaae1a66f50c3ea96539c46b8": {"ta_keywords": "dialog example database;goal dialog system;human conversation examples;conversational agent;best dialog example;drama conversations;drama television;database design;filtering;human;design;challenging design issues;current user query;aim;users;proper system response;examples;collection;fashion;time requirement;number;experiments;paper", "pdf_keywords": ""}, "d0895dccd61c567034d197eecfa5d7d59332061f": {"ta_keywords": "minimum storage regenerating;minimum bandwidth regenerating;regenerating codes;storage codes;traditional erasure codes;distributed storage;efficient repair;nodes;matrix construction;msr code;codes;code;network;matrix framework;node;mbr;mbr points;optimal exact;msr;new product;first constructions;data;simpler description;explicit constructions;paper;product;other parameters;values;knowledge;class", "pdf_keywords": "storage codes;regenerating codes;distributed storage;storage network;mbr codes;msr codes;storage;msr code;matrix construction;matrix framework;codes;nodes;mbr points;mbr point;bandwidth;bandwidth tradeoff;msr;optimal exact;msr point;ieee;network;additional constraint;regeneration;node;system parameters;feasible values;repair;simpler description;data;other parameters"}, "ffe6d7573bb2c4fbfac0cc474804b5b1734a1179": {"ta_keywords": "contextual bandits framework;contextual bandits;constrained online movie recommendation;reward feedback;behavioral constraints;rewards;ai systems;novel online system;constraints;online setting;additional constraints;priorities;decisions;actions;feedback;daily life;guide;observation;preferences;ethical principles;regulations;extension;criteria;set;many cases;values;domains;significant impact", "pdf_keywords": ""}, "40fc6e46f2921be346eacff86ce765ff5b28fbdd": {"ta_keywords": "bitcoin inverse perpetual swap contracts;inverse perpetual swap contracts;bitcoin exchange rate;bitmex funding correlation;granger causality;bitcoin derivative;margin funding interest rates;futures;market trend;heteroskedastic nature;funding rates;causal relationship;bitmex;implications;predictive tool;relationship;results;paper", "pdf_keywords": "bitmex funding rate correlation;bitcoin inverse perpetual swap contracts;bitcoin exchange rate;inverse perpetual swap contracts;granger causality;margin funding interest rates;heteroskedasticity;funding rates;bitmex exchange;futures;bitcoin derivative;heteroskedastic nature;market trend;causal relationship;rate;predictive tool;predictive model;technology manipal;implications;manipal institute;computer science;conclusion;communication technology;relationship;preprint;information;sai srikar;december;engineering;paper"}, "f7c9521dcd80127d6d4a72fb407e81a9c518ae8d": {"ta_keywords": "inductive learning;intensive inductive algorithms;intensive induction algorithms;induction algorithms;induction process;induction;free algorithms;good concept definitions;new algorithms;effective concept definitions;concept definitions;knowledge;current knowledge;relevant knowledge;single general approach;transformational framework;examples;computation;preliminary work;possibilities;plethora;frameworks;point;tentative problem;problem;number;space framework;integration part;quality;range", "pdf_keywords": ""}, "737aff546a9112127d7a13a5b835e27a6e1e935e": {"ta_keywords": "masked language model;conditional masked language model;automatic speech recognition;term memory networks;autoregressive transformer;input speech;decoder input tokens;deep transformers;kaldi asr system;asr;special mask tokens;audio;unmasked context tokens;mandarin;tokens;aishell;confident predictions;cmlm;example;japanese;network;english;fmlm;speedup;csj;librispeech;performance;frameworks;strategy;state", "pdf_keywords": ""}, "39fdea1c34832f9bb1644bff81f53fb8ce6b2679": {"ta_keywords": "machine learning;icml;finland;helsinki;fifth international conference;june;proceedings;twenty", "pdf_keywords": ""}, "b58e80ad8c6e6844c41535080ccbdef06bce3b6e": {"ta_keywords": "3d house simulator;autonomous agents;room layouts;rooms;dynamic environment;house configuration;new house;navigation;common household activities;objects;chalet;environment;actions;tasks;vision;appliances;manipulation;closeable containers;language;challenging domain;range;support", "pdf_keywords": "cornell house agent learning environment;3d house simulator;interactive house environment;environment logic;objectoriented programming constructs;implementation details chalet;visual reasoning;navigation;instruction;chalet;environment;unity;education purposes;objects;language;manipulation;partial observability challenges;level;awalsman;2the community version;awbennett;sep;question;washington;support;dkm;report;aaron walsman"}, "b0efb62aa2a435704a3412d592e73faf6be5ecea": {"ta_keywords": "semantic representations;character intentions;linguistic features;relationship categories;simple sentiment polarities;characters;relationships;narrative;inference;raw text;models;latent states;data;modeling;model;sequences;various cues;dynamic phenomenon;goals;paper addresses;large quantities;rich sets;techniques", "pdf_keywords": ""}, "8b48c55808636a52699b38869df3eba9c8b999d9": {"ta_keywords": "statistical voice conversion;silent speech interfaces;time voice conversion;silent speech communication;alaryngeal speech;laryngectomees;speech;whisper;dsp;portable devices;devices;practical use;implementation;body;laptop pcs;technology;time;sufficient computational resources;methods;approach;enviromments;resources;report", "pdf_keywords": ""}, "a0b47c7162d1a3b04b27e27c9fadd2eabc4dab0e": {"ta_keywords": "statistical machine translation system;translation systems;iwslt2012 evaluation campaign;ted talk tasks;decoder;ted task;languagepairs;experiment management system;naist;moses phrase;tasks;domain data filtering;minimum bayes risk;mert;comprehensive comparison;multitude;techniques;focus;total;issues;paper;work;common base", "pdf_keywords": ""}, "c3f9c1f702d0c3b35b99502674757b3d8e7dd352": {"ta_keywords": "crosslingual speech synthesis;speech synthesis;synthetic speech;synthesized target speech;speech preserving speaker individuality;voice conversion;synthesized speech waveform;foreign language speech;phonetic correction method;natural speech;prosody correction method;unnatural prosody;speaker individuality;phonetic characteristics;native japanese speakers;target languages;prosodic;pronunciation;dictation test;model adaptation;english speech;native text;target speaker;unvoiced consonants;spectrum replacement;linguistic systems;mother tongue;hidden markov model;naturalness;new approach", "pdf_keywords": ""}, "89b2a1dc68a7232bc3c68eb4b3e597f99755f7fe": {"ta_keywords": "textual compositionality;words representations;qanta learns word;text classification methods;matching text;quiz bowl;recursive neural network;sentences;factoid question;string matching rules;trivia competition;previous rnn models;questions;rnn;tasks;qanta;entities;such input;level representations;dataset;bag;reason;phrase;model", "pdf_keywords": ""}, "0025b963134b1c0b64c1389af19610d038ab7072": {"ta_keywords": "learned preference function;web search engine;metasearch;search experts;preference judgments;ordering;binary preference function;preference functions;specific query expansion strategy;ordering problem;first learns;hedge;algorithm;instances;instance;feedback;freund;things;combination;statements;line algorithm;domain;schapire;np;experimental results;problem;form;effect;conventional means;stage approach", "pdf_keywords": "\u00f6\u00b9 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8;\u00f9\u00f4\u00f6\u00fa\u00b5\u00ba \u00f6\u00ef\u00f2 \u00f3\u00f9\u00f4\u00f2\u00f8 \u00f8\u00f8;\u00e1\u00f2\u00f8 \u00f6\u00f2;\u00f8\u00fb\u00f3\u00b9 \u00f3\u00f6 \u00f6\u00bd;\u00f8\u00fe \u00f3\u00f2;\u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8;\u00f6\u00f8\u00f2 \u00f1\u00f2\u00f1\u00fe;\u00f3\u00f2\u00f8 \u00f2\u00f8\u00b9;\u00b9\u00fa \u00f0\u00f9;\u00f2\u00f3\u00f8 \u00f6\u00f0;\u00f0\u00fd \u00f3\u00f9\u00f2;\u00fc\u00f4 \u00f6\u00f8\u00ba;\u00f2\u00f3\u00f8;\u00f3\u00f4\u00f8;\u00f8\u00fb\u00f3 \u00f3\u00f6;\u00f6\u00f8 \u00f3\u00f0;\u00f8\u00f3;\u00f8\u00f8\u00f6 \u00f9\u00f8;\u00f0\u00f9;\u00f3\u00f2 \u00f3\u00f9\u00f0;\u00f3\u00f8 \u00f1\u00f3;\u00f6\u00f8;\u00f3\u00f8;\u00f3\u00ec\u00f8;\u00e6\u00f3\u00f8;\u00f2\u00f3 \u00f4\u00f6 \u00f3\u00f6 \u00f2\u00f3\u00fb\u00f0;\u00f8\u00f9\u00f8;\u00f2\u00f8\u00ba;\u00f0\u00ba;\u00f9\u00f4\u00f8"}, "448406c38e739695b926d112b2b7aebd4e840322": {"ta_keywords": "speaker diarization information;speaker diarization;time conversation analyzer;group meetings;online manner;estimation;asr;arrival;signals;information;system;method;insertion errors;doas;goal;paper;directions", "pdf_keywords": ""}, "06431546c21d7c2528aaa170c2e1078e0a82d12e": {"ta_keywords": "multilingual models;other transfer languages;many target languages;target languages;transfer language;question answering tasks;resource languages;english;future benchmark designs;shot systems;multiple classification;shot;surprising performance;tuning;models;mt5;zero;immediate impact;primacy;set;mbert;data;study;success;finding;practical solution;need", "pdf_keywords": "standard multilingual benchmarks;other transfer languages;target languages;multilingual models;dominant transfer language;languages;dominant source language;effective source language;question answering tasks;english;shot benchmarks;transfer;zeroshot;tuning;empirical evidence;shot;advance;study;current literature;mt5;\ufb01ne;machine;strong candidates;experiments;mbert;most settings;multiple classi\ufb01cation;effective choice;main research question;set"}, "7570afa31c68e24fce1342b7d67c591787219bc1": {"ta_keywords": "extractive summarization;generating wikipedia;summarizing long sequences;english wikipedia articles;neural abstractive model;decoder;sequence transduction;long sequences;salient information;source documents;abstractive model;article;only architecture", "pdf_keywords": "generating wikipedia by summarizing;wikipedia article text;english wikipedia articles;multidocument summarization;wikipedia articles;decoder models;english wikipedia;wikipedia;sequence transduction model;decoder;wikipedia topic;source documents;reference text;longer input sequences;long sequences;strong baseline models;article;long input;output examples;supervised machine;neural network;rnn;abstract;iclr;task;conference paper;transformer encoder;conclusion;abstractive framework;input"}, "4f9a4afc0ba500d839f7ee245513af9b87add8be": {"ta_keywords": "visual similarities;modal discrimination;audio feature spaces;contrastive learning;contrastive learning defines;good representations;audio;similarity;positive instances;positives;video;downstream tasks;learning approach;negative samples;negative sets;individual instances;self;multiple instances;vice;recent work;significant gains;method;definition", "pdf_keywords": "crossmodal similarity;audio representations;modal similarity;video representations;visual similarity;related videos;avid task;visual representations;contrastive learning;visual instance discrimination;contrastive learning framework;facebook ai research;videos;multiple audios;avid;audio;audio instances;align video;video;task;cma;multiple variants;manner;self;larity;new insight;discussion;addition;work;recent advances"}, "2fb54dfcb1a62deac6565e82f2a87919d33074da": {"ta_keywords": "optimal methods;convex functions;lipschitz", "pdf_keywords": ""}, "5aa3c6ab6cc55c24bab224505e8ad5a4d9863706": {"ta_keywords": "attention mechanisms;historical text normalization;attention;several novel encoder;training encoder;decoder;decoder architectures;phoneme dictionary;auxiliary data;grapheme;high german;task;different texts;training data;models;mtl;lot;performance;architecture;early new;such problems;state;art;ways;problem", "pdf_keywords": ""}, "86db47e228167439f15ee320a8a81d386f529a0c": {"ta_keywords": "environment manipulation tasks;natural language instructions;environment manipulation;same generative language model;language model;language;environments;agents;scene;tasks;various environments;environment;experimental tasks;alchemy;pretraining strategy;remarkable improvements;lemon;execution;prior knowledge;propara;general framework;art results;huge space;unified approach;effectiveness;tangrams;new state;work;experimental results", "pdf_keywords": "environment manipulation tasks;same generative language model;lem tasks;environment manipulation;language model;language;different lem tasks;scene;tasks;environments;lemon;better controllability;experimental tasks;various environments;environment;execution;alchemy;remarkable improvements;pretraining strategy;interpretability;parts;prior knowledge;signi\ufb01cant improvements;general framework;art performance;effectiveness;art results;tangrams;propara;paper"}, "2842c21e879ee581aa50704817454f21b539fc69": {"ta_keywords": "opinion detection;opinionated tweets;sentiment;linguistic research;language preference;hindi;neutral sentiments;unique tweets;multilingual societies;indian users;english bilinguals;preferred language;language;twitter;languages;classifiers;english speakers;emotion;opinion;speech transcriptions;preference;small groups;expression;dewaele;participant interviews;data;speakers;such studies;study;end", "pdf_keywords": ""}, "a010b3aa83d7d80e52c84d5f239f940eb33df904": {"ta_keywords": "automatic speech recognition;speech corpora;acoustic input;end asr;separate encoders;large text datasets;traditional acoustic input;external lm;end architecture;input;symbolic input;asr;attention;mmda architecture;new end;mmda;training;decoder parameters;end;seamless mixing;architecture;addition;need", "pdf_keywords": "data augmentation scheme;new data augmentation scheme;multilingual training;encoder;language models;unsupervised language;language model;multilingual systems;target languages;supplemental text data;end asr performance;other languages;training data;decoder;shallow fusion baselines;decoder model parameters;text data;asr;training;decoder act;mmda;data;vanilla mmda;speech;psda;modest improvements;psda variants;\ufb01gure;nmt;performance"}, "f784ab218692364b9c8a1f8064809e4524116f3a": {"ta_keywords": "decentralized datasets;byzantine attackers;byzantine;sybil attacks;byzantine tolerance;deep learning;training algorithms;volunteer computing;novel protocol;learning;such peers;peers;protocol;server;training;image classification;algorithms;computational resources;communication efficiency;redundant communication;marginal communication;updates;theoretical bounds;train;hardest problems;efficiency;language modeling;resistance;many independent parties;work", "pdf_keywords": "deep learning workloads;training protocol;byzantine attackers;byzantinetolerant;novel protocol;training;nonconvex losses;convergence bounds;strategy;communication ef\ufb01ciency;work;problem;novel;scale"}, "2dd1504d54f8d7e01e1323a9f876f35bb86356da": {"ta_keywords": "agent preference models;demand mobility services;intelligent transportation technologies;incentive policy;transportation;particular incentive policy;road network;agent;transportation authority;monetary incentives;city planners;simulation framework;altruistic behavior;commuters;deep learning models;travel;models;car;travel time;share options;data;city;disutility;bike;level disutility;addition;effectiveness;approach;framework;residents", "pdf_keywords": ""}, "c9d65eee1b5df8ccda87c024b88e1b620099b316": {"ta_keywords": "unrestricted natural language commands;natural language commands;robots;robot;testable algorithms;neural architectures;instruction sequences;unrestricted language;meaningful training data;context;architectures;human;complex goal configurations;blocks;communication gap;humans;blocks world;instructions;framework;problem", "pdf_keywords": ""}, "f6db40e1f0477d27a34240b2e11d6893b9e85b7b": {"ta_keywords": "affordable air purifier;air purifiers;hazardous air quality conditions;filters;pollution;wildfires;climate change;optimal time;many affected people;people;users;issues;response;amount", "pdf_keywords": ""}, "9a36d6b76b3b223aa877b4243e5fdfe5c998689e": {"ta_keywords": "electromagnetic pump;magnetohydrodynamic simulation", "pdf_keywords": ""}, "3f59122d4cac12f27ad6ae379deefd9f3fa81f29": {"ta_keywords": "robot;interpretable plans;robots;agent;future;language command;language;intermediate goals;human instructions;command;prospection;representations;motions;action;key feature;execution;real world;sequence;consequences;horizon;order;framework;work", "pdf_keywords": "interpretable plans;natural language commands;high level plan inference;robot;planning;end plan inference;natural language;plans;scenes;language;raw sensory data;language command;sensory input;raw sensor observations;raw sensor input;prospection;representations;task;intermediate goals;dreamcell architecture;level execution;model;level controller modules;execution;future world states;component;framework;nature;crowd;sequence"}, "0b2ff02ab23e5c9910b98fb87c4d58045dbe89ce": {"ta_keywords": "reverberant speech recognition task;reverberation time estimation;reverb challenge;reverb;deep neural networks;discriminative training;gaussian mixture model;single channel dereverberation method;art asr techniques;direct sound;sound;various feature transformations;best performing system;different feature;relative improvements;various environments;challenge;system combination approach;systems;environment;state;addition;real test sets;different types;baseline;approaches;effectiveness;experiments", "pdf_keywords": ""}, "d72a1579074a1a2bc500f257474144b1957d5166": {"ta_keywords": "coded computation;computation framework;neural network inference;neural networks;computing systems;computation;machine learning;computation approaches;learning;slowdowns;localization;inference tasks;image classification;major workload;production services;speech recognition;resilience;impart resilience;evaluation results;recent advances;high resource;accurate reconstruction;failures;challenges;work;limited subset;unavailable results;applicability;potential;careful use", "pdf_keywords": ""}, "c5141ed9ed785a6a1df61b36883e6dfa19a59ff7": {"ta_keywords": "channel speech separation;separation performance;building corpora;corpora;robust models;mixer;speech;datasets;many modern applications;standard methods;single;multiple domains;realistic applications;data;current source;bulk;shortcomings;field;date;research;wide variety;multiple conditions;value", "pdf_keywords": "channel speech separation evaluation;speech separation performance;standard speech separation technologies;speaker speech regions;speaker segmentation;separation performance;realistic conversational speech;synthetic overlap datasets;source separation technologies;utterances;corpus selection;utterance;mixer;mixture lists;dataset creation;additional datasets;datasets;level permutation invariant training;data cleanup;corpora;algorithmic generation;training;performance;main components;evaluation;data;quality;shortcomings;standard methods;analysis"}, "77000dba4b0638bb8f4222efcd731e040938c846": {"ta_keywords": "driver prediction;vehicle task performance;vehicle interface;vehicle hmi;user actions;prediction methods;intentions;interaction;information;complex controls;capability;access;terms;trend", "pdf_keywords": ""}, "ab8be9e585e599db99d8451e63a2311d88ff9293": {"ta_keywords": "memory caching systems;memory cache clusters;production caches;world cache workloads;value cache clusters;workloads;memory;modern web services;twitter;several workload analyses;production traces;different workloads;latency;ideal replacement strategy;production systems;data;research;tb;use cases;hundreds;example;more write;large number;unique temporal patterns;simulations;fifo;work;business logic;effectiveness;understanding", "pdf_keywords": ""}, "c612905cffc5a9aa9f0d8ac7ce1fd17f90413dab": {"ta_keywords": "argumentative dialogue;attention model;discussions;neural architecture;successful arguments;sentences;reasoning;argument;opinion holder;view;view forum;interaction encoding;parts;evaluation;posthoc analysis;content;challenger;model;components;reddit;several baselines;interplay;change;vulnerable region detection;unsuccessful ones;oh;goal;relationship", "pdf_keywords": "argumentative dialogue;computational linguistics;argumentation;attentive interaction model;interaction;human language technologies;attention model;interaction encoding;opinion holder;interplay;neural architecture;argument;interaction encoding help;viewpoint;reasoning;view;model;architecture;abstract;conference;apr;conclusion;identi\ufb01es parts;association;north american chapter;content;yohan;year;relationship;gap"}, "5547eff5376c56358be56f8bcc3a4b6ce4600bb5": {"ta_keywords": "recent robust automatic speech recognition;robust speech processing;robust asr;general asr toolkits;own robust asr systems;deep learning toolkits;end asr toolkits;speech enhancement;asr applications;language model toolkits;major toolkits;toolkits;asr;microphone array;end toolkits;available tools;features;such tools;language;platform;source location;aim;real environments;functions;license;emergent end;community;functionalities;techniques;information", "pdf_keywords": ""}, "f430c43018f17cabccd3a2e9258aff3da508afe1": {"ta_keywords": "unknown word detection;eye gaze features;svm;foreign language", "pdf_keywords": ""}, "4b34a4cc5bc9defb0f530d61f9b0f843071e227c": {"ta_keywords": "menstrual hygiene;excessive vaginal bleeding;hygienic method;blood stains;menstrual period;prevalence;binary logistic regression;women;protection;delivery;lower risk;evidence;study;significance;assessment;square analysis;india;conclusion;effects;chi;important prognosticator;results;objectives;addition;strong association;percent;high focused states", "pdf_keywords": ""}, "39025112f6a40d8aae38f2e966bb27cbc35ea25d": {"ta_keywords": "research showcase;cmu", "pdf_keywords": ""}, "0db557c4315b1e08ef65ff15b96eb7630014bf72": {"ta_keywords": "unnecessary utterance detection;dialogue system intervene;unnecessary utterances;typical automatic summarization method;topic shifts;discussion;word frequency;digressions;features;evaluation;detector;method;performance;paper", "pdf_keywords": ""}, "09a169c853e24b3a5196eefeab4c94eaac744cda": {"ta_keywords": "political ideology detection;political annotations;recursive neural networks;recursive neural network;sentiment analysis;sentence level;political position;wordlists;ideology;rnn;language;subsentential elements;compositional aspect;phrase;syntax;words;sentence;bags;task;text focus;importance;inspiration;framework;recent work;techniques", "pdf_keywords": ""}, "3a72f1346f3cd41e14b45c7fba5259bc77357ed4": {"ta_keywords": "recursive logic programs;ary recursive clauses;learnability;linear recursive clauses;recursive calls;linear recursive clause;depth determinate program;program classes;natural generalization;boolean dnf;depth determinate clause;pac;constant locality;programs;depth determinate;depth;unbounded number;class;valiant;model;companion paper;paper;negative results", "pdf_keywords": "recursive programs;depth determinate programs;recursive calls;linear recursive clauses;depth determinate program;single linear recursive clause;linear recursive clause;recursive clauses;learnability;computational learning theory;program classes;secure cryptographic schemes;computational limitations;boolean dnf;depth determinate clause;programs;depth;di erent classes;cult learning problems;constant locality;single nonrecursive clause;unbounded number;class;restrictions;equivalent;open problem;dnf;prediction;problems;analytic methods"}, "b62d63580b81a2cbb20c3c1593dd62d118e4cb07": {"ta_keywords": "natural language specifications;semantic example selection;code generation;natural language descriptions;constrained semantic decoding;target language;target similarity tuning;language models;syntax;samples programs;language model;code;contextual logic;valid programs;smcalflow programs;rich constraints;programs;shot examples;examples;prediction accuracy;lite visualizations;tst;world languages;csd;training bank;general framework;codex;framework;sql;models", "pdf_keywords": "programming language constraints;reliable code generation;code generation;world programming languages;constrained semantic decoding;target language;valid programs;language model;natural language descriptions;code;token vocabulary;samples programs;world languages;smcalflow programs;prediction accuracy;constraint;codex;general framework;framework;implementation errors;examples;output validity;synchromesh;tst;csd;lite visualizations;sql;output;vega;models"}, "af85c67a1f30f8359be1091234118492b511a088": {"ta_keywords": "\u7b2c6\u56de\u96c6\u5408\u77e5\u30b7\u30f3\u30dd\u30b8\u30a6\u30e0;\u8a00\u8a9e\u7406\u89e3\u3068\u30b3\u30df\u30e5\u30cb\u30b1\u30fc\u30b7\u30e7\u30f3", "pdf_keywords": ""}, "cd9e1eac4c93a314254cf8a8682ed5f01b6a808f": {"ta_keywords": "accurate neural reasoning;deeper language understanding;knowledge base;neural retrieval;neural approaches;natural language processing;accurate logical reasoning;memorization;logical reasoning;nlp;answering;remembering;compact sketch structure;facts;generalization;generalizations;novel kb;kb;plausible;specific information;model;question;triples;scheme;approach;new mechanisms;set", "pdf_keywords": "emql;qe methods;qe systems;relational operators;relational \ufb01ltering;qe system;previous qe schemes;deductive reasoning;new qe scheme;prior qe method;qe;expressive set;neural module;kb completion;entity sets;kbqa system;neural retrieval;downstream task;benchmarks;natural language kb question;\ufb01nd entities;kbqa;prior state;relation;knowledge;previous methods;answers;task;metaqa;generalization"}, "9712ebfbc4f86c68403f64918463edad3e553ac6": {"ta_keywords": "dynamic sensor subset selection;dynamic sensor activation;centralized tracking;active sensor selection;sensor networks;stochastic approximation;efficient tracking mechanisms;tracking;cyberphysical systems;stochastic process;global optimality;learning;algorithms;internet;algorithm;gibbs;energy;distribution;process;unknown parameter;high performance;methods;case;things;order;time;key theoretical result;cases;numerical results;efficacy", "pdf_keywords": "optimal dynamic sensor subset selection;dynamic sensor subset selection;sensor networks;dynamic sensor activation;centralized tracking;inactive sensors;active sensors;tracking;stochastic process;cyberphysical systems;energy constraint;network;algorithm;internet;process;preprint version;oc;time;arpan chattopadhyay;apr;things;problem;fundamental problem;herein;math;work;urbashi mitra"}, "873dff010c00f0601d6939324929eeabb1ddbd6e": {"ta_keywords": "secret sharing;secure multiparty;separate secure message transmissions;several cryptographic protocols;sneak;secret;protocols;dealer;shares;general network;direct communication links;network;hop neighbors;key management;communication;algorithm;participants;randomness;considerable coordination;shamir;threshold;participant;computation;node;paper;identities;existing methods;important component;solutions;amount", "pdf_keywords": "secret dissemination;secret sharing;sneak algorithm;secure multiparty;sneak;general communication network;secret;several cryptographic protocols;network;shares;dealer;dealer condition;algorithm;ef\ufb01cient algorithm;key management;general networks;computation;threshold;network topology;communication cost;participants;nihar;onehop neighbours;node;paper;independent interest;lower bounds;shamir;identities;ii"}, "35cb2b9febada179689724c78dfe31d9fa3f74c4": {"ta_keywords": "windows azure storage;local reconstruction codes;cloud storage system;storage;erasure;prior codes;coding;repair reads;data fragments;codes;store;data;fragments;paper;access;lrc;os;customers;significant reduction;important benefits;new set;duration;limitless amounts;number;ability;time", "pdf_keywords": "modern storage codes;local reconstruction codes;shorter codes;low overhead durable storage;erasure;solomon code example;storage;data fragments;codes;reconstruction cost;low read latencies;implementation;small examples;important design decisions;reed;fragments;description;lrc;paper;design goals;properties;production;better trade;new set;number;section;concept;de\ufb01nition;addition;offs"}, "35c6bdab35e8fd4e982302b5270da3c8098c58b1": {"ta_keywords": "natural language instructions;compositional instruction following;novel subgoal compositions;modularization;challenging instruction;sequence approaches;modular architecture;diverse subgoals;modular networks;subgoal modules;sequences;subgoal type;specific subgoal type;modules;sequence;generalization;training;environments;benchmark;instructions;alfred;approach;segment;standard", "pdf_keywords": ""}, "32feca141fce06c6588b4014d27953a3fc25f19b": {"ta_keywords": "language model;physical commonsense knowledge;natural language;language;natural language summaries;linguistic form;text;knowledge;piglet;world dynamics;literal symbolic representation;text approach;physical interactions;interaction;unified model;objects;model;dynamics model;interface;lm alternatives;sentence;humans;english sentence;glass cups;meaning;time;plastic ones;result;experimental results;100x", "pdf_keywords": "language grounding;symbolic interaction;physical interaction grounding;language model;language transformers;physical commonsense knowledge;language;language form;grounding;linguistic form;natural language;physical interaction;representation;piglet;interaction;knowledge;concept level;agent;arti\ufb01cial intelligence;neuro;pigpen;world dynamics;3d world;model;explicit model;dynamics model;new environment;meaning;world;sense"}, "d9c2242e3aa17db649c92d7d4db46509f3d203db": {"ta_keywords": "constrained upper confidence reinforcement learning;upper confidence reinforcement learning;constrained markov decision processes;stochastic decision problems;auxiliary cost constraints;reward function;cost functions;transition kernel;constraints;reward;decision maker;policy;ucrl;priori;probability;settings;paper;class;respect", "pdf_keywords": "constrained upper con\ufb01dence reinforcement learning;constrained markov decision processes;upper con\ufb01dence reinforcement learning;safe reinforcement learning;optimal stochastic policy;constraint costs;auxiliary cost constraints;optimal policy;constraint satisfaction;robust linear programming1;stochastic decision problems;constraints;ucrl algorithm;classical ucrl2 algorithm;learning process;reward;cmdp;rewards;costs;guarantees;transition kernel;policy;ucrl;goals;decision;uncertainty;algorithm;computer engineering;priori;value"}, "b990517fbbf4499861d7aa00407b0422874ab990": {"ta_keywords": "interpreters;interpreter;interpreter performance;untranslated terminology;interpreting;accurate translation;translation;language;simultaneous interpretation;translation error;speech;interpretation;difficult terminology;tools;intelligent computer;word;cai;task;terms;proper names;greatest challenges;strenuous task;numbers;other entities;number;specific features;time", "pdf_keywords": "untranslated terminology prediction;ted talk corpus;terminology tagger;source speech;untranslated terminology;simultaneous interpreters;interpreter;new manual annotations;annotated data;talk subset;terminology;svm;tagging model;simultaneous interpretation process;streaming asr;words;text;tagger;speaker;feature extraction;word;features;model training;task;speci\ufb01c features;interpreting interface;window;si;couple baseline models;section"}, "fb38451ff87254ac1ff15e79154ef958b4efb6a6": {"ta_keywords": "other sequential structured prediction models;practical neural networks;structured networks;deep learning;recurrent networks;neural networks;nlp applications;syntax trees;multilayer perceptrons;sequence tagging;structured nns;parsing;net models;nlp researchers;simple classification models;cnn;graph formalism;nlp;compositional architectures;structured output spaces;sequence transduction;algorithm states;complex algorithm states;advanced patterns;practical implementations;sequences;sequence;code;toolkits;prediction problems", "pdf_keywords": ""}, "e2d770b9ab691753a7ec1eb439185303118c8455": {"ta_keywords": "multilingual artificial intelligence agent assistant;multilingual ai agent assistants;natural language processing technologies;translation layer;language;human agents;language barriers;customer support;maia;edge machine learning;it lisbon;unbabel;inesc;human quality;collaboration;id;cmu;project;cutting;paper;time", "pdf_keywords": ""}, "c8f78575bfb642b2dab6ed542a683ade9527c17d": {"ta_keywords": "algorithmic decisions;kidney transplants;online mechanisms;fairness;algorithms;tissue authority;strategyproofness;robustness measures;decisions;organ;axiomatic properties;deceased patients;patients;efficiency;donations;sided market;real world data;experiments;waiting list;complex algorithm;simple mechanism;blood types;consideration;other mechanism;empirical analysis;new mechanism;stability;properties;responsibility;lives", "pdf_keywords": ""}, "4cc07c367e4a1f932e159678ef711e1802edf49f": {"ta_keywords": "spoken language understanding;decomposable tasks;decomposable task;speech processing skills;utterances;benchmarks;end evaluation;robust test sets;end architectures;actionable comparisons;insightful comparisons;end systems;test sets;performance gaps;similar performance;end model;original test sets;natural language;models;competitive end;test;future model development;different architectures;performance differences;abilities;coordinate ascent;heldout speakers;split;end;framework", "pdf_keywords": "spoken intent prediction;intent prediction;speech recognition;nlu subtasks;decomposable tasks;similar intents;semantic processing abilities;snips datasets;end modeling approaches;popular benchmarks;task;datasets;challenge splits;end model;snips;new test splits;new phrasings;good slu model;various end;models;splits;asr;original test splits;end;snips smartlights;level utility functions;accuracy differences;model;performance differences;weaknesses"}, "8fa6b06cb96e5ae98dfff1c50f6940ef43af223f": {"ta_keywords": "storage system;erasure codes;lower storage overheads;disk io;data replication methods;additional storage;data centers;erasure;new erasure;efficient data reconstruction;warehouse cluster;unavailable data;same fault tolerance;degraded reads;latency;faster recovery;data;io;higher reliability;reconstruction;workloads;time traffic;hitchhiker;network bandwidth;computation time;codes;facebook;network traffic;machines;reed", "pdf_keywords": ""}, "1941f5b053ccc80fa44980d38ac074145591b4ec": {"ta_keywords": "semantic sentence embedding;sentence embeddings;encode natural language sentences;latent semantic vector;bilingual data;bilingual generative transformer;monolingual data;parallel sentences;such embeddings;deep latent;sentences;translation pair;specific latent vectors;semantic sentence;semantics;language;variational probabilistic framework;simple word overlap;source separation;similarity;vectors;divergent properties;models;priors;difficult subsets;evaluations;closeness;good indicator;space;variable model", "pdf_keywords": "latent semantic embedding;encode monolingual sentences;bilingual generative transformer;latent semantic vector;common semantic latent vector;sentence embeddings;english inference net;semantic sentence encoding;encode natural language sentences;bilingual data;monolingual data;semantic inference net;semantic variation;deep generative model;french inference net;deep latent;linguistic variation;parallel sentences;inference networks;english decoder;speci\ufb01c latent vectors;such embeddings;sentences;semantic sentence;latent variables;semantics;translation pair;french decoder;variational probabilistic framework;generative process"}, "553028f7f7c850371379c621e40d7d00e75303a6": {"ta_keywords": "multilingual models;modern multilingual models;multilingual representations;multiple languages;resource languages;languages;language;negative interference;meta;generalization;text;pronounced benefits;learning treatment;universal structures;positive transfer;layers;specific layers;benefits;performance;new directions;potential cause;results;findings;parameters;recent work;manner;phenomenon;hopes;observations;specific parameters", "pdf_keywords": "multilingual models;bilingual models;monolingual model;language models;similar languages;individual language;language similarity;languages;other languages;speci\ufb01c language lg;language;natural language tasks;training corpus;corpus size;knowledge transfer;purpose representations;downstream tasks;negative interference;model capacity;model;parameter similarities;gradient con\ufb02icts;lg;gradient;advances;other hand;speci\ufb01c modules;range;shot;variety"}, "1606dc1e966ad59dd96dc8e74722dca06b1f1a58": {"ta_keywords": "evolutionary causal matrices;educational neuroscience;educational interventions;term outcomes;markov chain", "pdf_keywords": "different mean participation ratio;participation ratio;simulation program;participation rate;intervention studies;educational interventions;educational intervention outcomes;longitudinal trend;interventions;longitudinal outcomes;study;term outcomes;prediction results;different trajectories;simulations;term effectiveness;computer simulation model;educational psychology;longitudinal influences;voluntary service participation rate;prediction model;tst;tmt;anova;comparisons;tmc;educational neuroscience;computational model;students;first figure"}, "e3480d9395e692833b722b2e957d51139985f310": {"ta_keywords": "question classes;question types;challenge questions;example macaw;language models;macaw;qa;purpose qa systems;challenge300;generative question;topics;unifiedqa;suite;good answers;strong performance;response;t5;answer;shot;training setup;inputs;choice options;insights;community;addition;wide variety;angles;variety;outputs;question", "pdf_keywords": "example macaw;macaw;challenge questions;shot qa system;speci\ufb01c tasks;highest precision;challenge300;strong performance;shot performance;training data;several other large language models;topics;strong starting point;shot;answer;suite;t5;uni\ufb01edqa;choice options;tuning;inputs;addition;wide variety;angles;question;various limits;parameters;further \ufb01ne;community;outputs"}, "6d19d73909ffaa6c94cae6a2535ed52d138cb63b": {"ta_keywords": "dialog management system;dialog corpus;dialog system;appropriate dialog corpora;human conversation examples;twitter conversations;conversational agent;multi domain chat;appropriate dialog;trigram conversation turn;conversation;semantic similarity analysis techniques;movie scripts;twitter data;semantic similarity;chat;raw movie scripts;drama script files forms;database design;human subjective evaluation;aim;small user study;filtering approach;real human;content;ebdm;cosine similarity;raw movie;users;current user query", "pdf_keywords": ""}, "d1678032a9eee94ec0a9c54fb008e1addc7213d4": {"ta_keywords": "robust utility learning framework;robust utility;utility functions;energy efficiency;occupant voting data;least squares;heteroskedasticity inference;ordinary least squares;utility;social game experiment;social game;energy;efficient behavior;estimator variance;game;smart;constrained feasible;occupants;data;ols;performance;method;improvement;classical methods;cfgls;loop;closing", "pdf_keywords": ""}, "33cd5965745dc2e8bb8d0400d0b3c18d4e6369d4": {"ta_keywords": "memory caching systems;memory cache clusters;production caches;world cache workloads;workloads;memory;modern web services;production traces;several workload analyses;twitter;different workloads;latency;large scale analysis;ideal replacement strategy;production systems;more write;tb;data;use cases;research;hundreds;simulations;example;unique temporal patterns;large number;work;business logic;fifo;effectiveness;understanding", "pdf_keywords": ""}, "0b79cb7fe16aa8b99d521989f39e49034394f701": {"ta_keywords": "human computation;human computation systems;crowdsourcing marketplaces;identity verification tasks;ai;human intelligence;captchas;artificial intelligence;online gamers;recaptcha;tasks;esp game;games;algorithms;online content;computation;hci;enjoyable game;computational problems;users;machine learning;optical character recognition;monetary rewards;ocr;programs;research area;purpose;goals;books;workers", "pdf_keywords": ""}, "61cd4ffdaf2c0daa3d432ff9fecdd064d6e72886": {"ta_keywords": "fol reasoning;reasoning ability;commonsense inference;language models;logicnli;target fol reasoning;many nlu tasks;bert;reasoning;nli;interpretability;lms;order logic;fol;xlnet;benchmark;robustness;generalization;accuracy;diagnostic method;weaknesses;possible applications;perspectives;style dataset;roberta;widespread interest;future exploration;significant performance;experiments;work", "pdf_keywords": "logical natural language inference;order logical reasoning ability;certain interpretable fol reasoning ability;best fol reasoning ability;order logic;natural language processing;fol reasoning;natural language;sensible fol reasoning;commonsense inference;fundamental logics;reasoning forms;logicnli;computational linguistics;reasoning;language models;fol;novel benchmark;benchmark;order;many nlu tasks;ai institute;facts;first;fols;abstract;conference;simple paradigm;diagnostic method;traceability"}, "a829d65de0cc19da49ad6b4a294dd31545aed2bb": {"ta_keywords": "jstor;journal;researchers;information technology;trusted digital archive;profit service;economic statistics;scholarship;scholars;business;use;access;content;productivity;tools;students;more information;new forms;wide range", "pdf_keywords": ""}, "bc5e4b9fb3a40057df4994354a403202218d53a6": {"ta_keywords": "program transformations;probabilistic parser;human programmers;initial correct declarative program;dynamic programming;nlp literature;program;heuristic search procedure;semantics;algorithms;substantial improvements;search;mental search;transformations;initial program;running time;efficiency;many trees;many speed;predictions;laborious process;sequence;instance;practice;system;such problems;set;simple metric;work;end", "pdf_keywords": "program transformations;monte carlo tree search;dynamic programming;optimal asymptotic runtime;faster algorithms;probabilistic parser;initial correct declarative program;algorithms;program;heuristic search procedure;transformations;running time;many trees;semantics;beam search;predictions;sequence;ef\ufb01ciency;instance;such problems;simple metric;end;metric;set;error"}, "ab17c315f7ee4fe69fde2f3d8ae0e30e4e2f3a2b": {"ta_keywords": "long document;complex documents;document information;document;different qa tasks;documents;dochopper;text;short passages;long sections;next query;qa;hierarchical part;step;compact neural representation;query;information;complex questions;datasets;systems;different parts;novel behavior;new model;art results;question;state;contrast", "pdf_keywords": "query embeddings;iterative hierarchical attention;query vectors;retrieval;answering complex questions;long documents;query vector;step attention;navigation;conversational qa;document section;documents;compact neural encoding;neural representations;section;document;questions;query;context;iterative process;complex questions;dochopper;model;information;different levels;new model;input;different parts;second hop;ruslan salakhutdinov school"}, "e54ffc76d805c48660bb0fd20019ca82ac94ba0d": {"ta_keywords": "low dimensional task representations;trainable parameters;lower intrinsic dimension;intrinsic dimensionality;language models;intrinsic dimension;gradient descent algorithms;strong regularization;generalization bounds;generalization;full parameter performance levels;language understanding tasks;language model fine;dimension;larger models;tuning;full parameter count;roberta model;compression;datasets;low data regime;examples;example;millions;model;full space;parameters;hundreds;mrpc;thousands", "pdf_keywords": "low dimensional task representations;minimal description length;natural language tasks;generalization bounds;average description length;nlp tasks;intrinsic dimension framework;description length;intrinsic dimension;intrinsic dimensionality;different nlp tasks;dimension;generalization;compression;full parameter count;few parameters;model parameter count;compression framework;pre;tasks;new interpretation;task;models;large set;same tasks;interpretation;model;practice;process;downstream \ufb01ne"}, "2a82a16bdb793dc388391be57d6424f0d5090513": {"ta_keywords": "rankings;peer reviews;updates scores;scores;review;review process;peer;score;synthetic datasets;information;papers;baseline;iclr;conference;suitable interfaces;methods;judicious use;data;interfaces;standard procedure;inef\ufb01ciencies;challenges;principled approach;arbitrariness;area chairs;method;ii;different ways;approach;\ufb01nd", "pdf_keywords": "rankings;quantized scores;peer reviews;peer review;scores;score;reviewers;yichong xu microsoft cognitive services research;baselines;review;performance;baseline;yusha liu carnegie mellon university;aarti singh carnegie mellon university;dequantization;synthetic datasets;iclr;papers;bre;conference;data;synthetic dataset;algorithm;paper;section;abstract;method;apr;ir;thurstone model"}, "188fd1373aefdbf564e90a76fed43e1b8b7052dc": {"ta_keywords": "ntt communications science laboratories open house;report", "pdf_keywords": ""}, "69e2d1f5374918111432fae23212c2759b1357c2": {"ta_keywords": "pairwise ranking;sequential ranking algorithm;active ranking;noisy pairwise comparisons;ranking;pairwise comparisons;comparisons;luce models;pairwise probability matrix;little statistical advantage;counts;algorithm;popular parametric modeling choices;confidence intervals;tight lower bounds;items;pair;parametric models;number;thurstone;guarantee;data;bradleyterry;past work;context;set;point;logarithmic factors;structural properties;means", "pdf_keywords": "sequential ranking algorithm;btl pairwise comparison model;ranking;pairwise comparison probabilities;full ranking;comparisons;probabilistic model;parametric models;e\ufb03cient algorithm;sample complexity;several prior works;algorithm;thurstone models;popular btl;btl parameter vector;counts;items;performance analysis;common parametric assumptions;number;pair;logarithmic factors;data;paper;mg15;hun04;section;point;con\ufb01dence intervals;basis"}, "926d827aef568ed97431a7845c9a8138930c80fd": {"ta_keywords": "social sharing behavior;political information;affective responses;affective reactions;group sources;information;outgroup sources;messages;people;experiments;studies;evidence;subjects;paper;link", "pdf_keywords": ""}, "9b534639bcadc9ad232b338e760c523a4d74c8de": {"ta_keywords": "grammar descriptions;linguistic exploration;language experts;such descriptions;linguistics;descriptions;autolex;human evaluation;language learners;language;manual creation;sentence construction;evaluation;linguists;automatic framework;deep understanding;phrase;word;own terms;bias;principles;method;hand;own complex systems;help;consumption;whole;error;fraught process", "pdf_keywords": "automatic syntactic analysis;syntactic analysis;grammar descriptions;linguistic exploration;phrase construction;treebanks;language experts;linguistic phenomena;syntax;concise descriptions;automatic feature extraction;word formation;semantics;sentence construction;automatic framework autolex;descriptions;automatic framework;language;morphology;extract rules;language learners;linguists;autolex;languages;phrase;human evaluation;description;multilingual adaptation;evaluation;extract features"}, "987c5ad75d5092bed03e9f523aec00dc43bc17e4": {"ta_keywords": "urban air quality;road network density;road area occupancy;air quality;road traffic;peak congestion delay index;bus emission reduction;road parameters;bus network density;road network planning;bus route planning;traffic jams;gwr model;intersections;remote sensing;aerosol;intersections number;intersection number;gwr;regression;local spatial changes;geographical;aod;impacts;jinan;correlation;correlation r2;areas;optical thickness;pcdi", "pdf_keywords": ""}, "89c2b3bfcc309ce16c85d2ab0c8cac5295400715": {"ta_keywords": "sequential learning;entropy learner;arbitrary base learner;learning algorithm;sequential stacking;nonsequential base learners;sequential tasks;sequential partitioning problems;learners;labels;crfs;identical labels;nearby examples;performance;long runs;scheme;method;problems", "pdf_keywords": ""}, "9b263129548dc09369e8bc34560fe5bb6047fcee": {"ta_keywords": "greek electricity market;scheduling;simulator;real time schedule differences;real time dispatch;market dynamics;natural gas transportation system;participant schedule deviations;market participants;key market operations;market outcomes;natural gas system constraints;participant decision strategies;uncertain stochastic outcomes;greek regulatory authority;bids;wholesale market;energy;dynamics;relevant time scales;software package;variability;design;available capacity;day;modules;interactions;implementation;loads;several interacting modules", "pdf_keywords": ""}, "9333d372ad3887e02029d2eab0dbc0c0478582c7": {"ta_keywords": "speech tagging;unsupervised learning methods;unsupervised part;natural language processing tasks;context evaluation;annotated data;learning;evaluation;evaluation paradigm;case study;methods;model;research;way;development;reasons;popular area;primary advantage;account", "pdf_keywords": ""}, "35b376ad9e03e5e0b930c53a48817bfb5703108d": {"ta_keywords": "neural machine translation models;text style transfer task;semantic similarity metrics;parallel corpora;automatic metrics;strong baselines;input texts;supervised models;human evaluation;metrics;content;training strategies;training;model;system outputs;experimental results;effectiveness;preservation;lack;potential weaknesses;efficient strategies;methods;significant gains;most cases", "pdf_keywords": "neural machine translation models;automatic evaluation metrics;text style transfer;semantic similarity metrics;semantic similarity metric;content reward;text;automatic metrics;human evaluation;content;input texts;content preservation;strong baselines;reward functions;input text;same basic semantics;literature;ef\ufb01cient reward;training;metrics;input;preservation;effectiveness;\ufb01ne;conclusion;different style;model;signi\ufb01cant gains;paper;robustness"}, "c96970cfb1c13ae6dccc30de482ce6b0d4414f2b": {"ta_keywords": "predicate invention;predicate invention based;new predicates;predicate;logical theory;structure;structured sparsity;previous strong baselines;learning;subroutine;rules;soft version;group;parameters;soft pi;scale tasks;hard pi;pi;version", "pdf_keywords": ""}, "4fee3d5d476568deb971768f8a5191eb627309d0": {"ta_keywords": "differential nash equilibria;game dynamics;game jacobian;continuous games;local equilibria;stability;equilibrium;optimization landscape;games;dynamics;instability;different learning rates;gradient;players;game;player;robustness;vector field;agent;quadratic numerical range;rates;rotational components;advantage;variation;numerical example;general costs;points;paper;method;sufficient condition", "pdf_keywords": "differential nash equilibria;learning dynamics;game dynamics;game jacobian;continuous games;gradientbased dynamics;stability;stable points;sum games;optimization landscape;potential games;games;equilibria;symmetric components;robustness;nash;symmetric component;quadratic numerical range;timescale separation;player;agents;numerical example;\ufb01xed points;rotational components;variations;vector \ufb01eld;rates;important trade;method;spectrum"}, "5df0b8b80aecda1efdebac5d1ab7bcf94a88c68f": {"ta_keywords": "downstream nlp tasks;contextualized word embeddings;biomedical embeddings;embeddings;language models;downstream task models;entity;feature extractors;better encoding;elmo;relational information;biomedical version;nearest neighbor analysis;lms;additional sequence;type;visualization;significant improvements;additional information;biobert;layers;bioelmo;domain;experiments;paper;superiority", "pdf_keywords": "biomedical contextual embeddings;pubmed corpus;biomedical corpus;biomedical citations3;domain corpus;noncontextual biomedical w2v;biobert representations;recent abstracts;biomedical ner;pubmed;embeddings;bioelmo2;nli;bioelmo;biobert;bioelmo8;bert;tokens;medline;complicated downstream models;tokens9;elmo;domain;moen;tasks;outperforms;speci\ufb01c version;ananiadou;database;access"}, "5930efbf01efa8944258b1c0f7349111702f779e": {"ta_keywords": "corpora annotations;nlp applications;annotation modules;natural language processing;nlp community;shelf nlp tools;corpus;annotators;nlp;text representation;popular corpora;syntactic tasks;library cogcompnlp;feature extraction;reader module;python interface;extensive suite;datasets;language;text;sister project cogcompnlpy;features;language constructs;training machine;modules;module;search;components;data;considerable engineering effort", "pdf_keywords": ""}, "44268b5a208e8f48a5883bb12e3e80a13101e752": {"ta_keywords": "serum baseline creatinine level;congestive heart failure;acute kidney injury;contrast agent;heart failure;contrast;elevated levels;hfref;hf;range ef;hfpef;severity;elective pci;aki;hfmref;risk factor;ef;natriuretic peptide;ejection fraction;risk factors;levels;ci;\u03bcmoi;nt;patients;incidence;administration;association;classification;increase", "pdf_keywords": ""}, "96ed7a7da69d654668b35b50344debd44e87c1a1": {"ta_keywords": "resource contextual topic identification;language topic classification;topic identification;topic id;variable topic shifts;unstructured audio;audio instance;contextual dependencies;universal acoustic modeling;speech;translation lexicons;resource languages;sequential segments;segments;english;segment;world;cascade;large improvements;low;general purpose method", "pdf_keywords": "language topic classi\ufb01cation;contextual modeling;topic identi\ufb01cation;topic id performance;contextual model;recurrent neural networks;recurrent neural network;topic id;context segments;rnn;low resource languages;context;translation lexicons;common phonemic representation;resource languages;language;many languages;universal acoustic modeling;universal acoustic models;lorelei languages;emergent incidents;attention;universal phone set asr;english;index terms;program framework;darpa lorelei;dependencies;independent models;challenges"}, "b9c3e87bc09c4c6167a03a835c30b1c23bef7a40": {"ta_keywords": "contextual embeddings;knowledge bases;novel bert;stronger generalization;bert;kbqa models;generalization;kbqa model;training examples;questions;dataset;quality dataset;enormous space;scale kbs;grailqa;levels;data;first time;true user distribution;key role;question;scale;model;addition;combination;evaluation settings;development", "pdf_keywords": "contextual embeddings;generalizable question answering;stronger generalization;compositional generalization;shot generalization;novel bert;generalization;bert;kbqa models;highquality kbqa dataset;novel compositions;unseen schema items;kbqa model;questions;prior models;schema items;kbqa;training distribution;quality dataset;grailqa;good margin;models;levels;training;evaluation;key role;diverse characteristics;graphq;model;competitive performance"}, "05b6be9aec266072669f6f287a846637eedf19b5": {"ta_keywords": "nematode communities;nematode community;alien plant invasion;soil;microbial community;experimental warming;global warming;warming;nutrient availability;microbes;underground food webs;resource stoichiometry;invasion;canada goldenrod;simpson index;diversity;chao1;interaction;structure indexes;basal index;study;results;interactive effects;maturity;findings;changes;most studies;function;shifts;functioning", "pdf_keywords": ""}, "449310e3538b08b43227d660227dfd2875c3c3c1": {"ta_keywords": "deep neural network models;neural network;continuous normalizing flows;hidden layers;depth models;generative model;ode solver;hidden state;differential equation;derivative;constant memory cost;input;network;box;internal operations;speed;training;output;data dimensions;maximum likelihood;discrete sequence;access;numerical precision;new family;evaluation strategy", "pdf_keywords": "neural ordinary differential equations;latent ode model;series latent ode experiments;deep neural network models;recurrent neural network;residual networks;box ode solvers;deep learning;neural networks;generative latent function time;latent variable models;generative modeling;automatic differentiation;extrapolate time series;series model;series modeling;new models;model component;learning;density estimation;optimal control;jacobian products;depth depth;adjoint method;general integration;depth;data;vector;time;vector institute"}, "ab1e5a3c5521b6204dc7c6f1fa72b88000bc30ee": {"ta_keywords": "answering engine;centric question answering;qa system;answering;qa;voice assistants;challenge set evaluation;questions;search engine;correct answers;passages;significant community attention;languages;pipeline;performance;users;components;systems;interfaces;user;question;real world;considerable sources;upstream noise sources;variety;error", "pdf_keywords": "google speech;speech recognizer;speech recognizers;translation engines;translation systems processing queries;qa engine;keyboard interfaces;google text;qa systems;data augmentation;synthetic noise generators;query repair;speech;interface noise;synthetic keyboard;natural noise decrease accuracy;queries;qa;natural asr errors;synthetic noise;interfaces;interface types;noise;other languages;keyboards;text;different accent;benchmark;english;interface errors"}, "5f609f252d8815c5fb660d83c0dc71af21ecf65d": {"ta_keywords": "known keywords;noun phrases;event monitoring;keywords;twitter;many event;social activities;words;text data;many nps;sudden spikes;feature vector;training data;specific broad category;knowledge;nps;sports;aspects;results;behavior;subsequence;np;author;politics;base;sample;boundaries;systems;method;frequency", "pdf_keywords": ""}, "33c691ca050e1806d44c08e55e63fcd7e555899a": {"ta_keywords": "negative classifier;classifier;unlabeled mixture;binary classification;unlabeled sample;positive class;unlabeled data;unlabeled;pu classification;pu learning;positive sample;negative sample;negatives;learning;positives;proportion estimation;positive;dedpul;analog;proportions;latent instances;cheap postprocessing procedure;predictions;method;objectives;pu;paper;current state;experiments;choice", "pdf_keywords": ""}, "a8ea980b63deaf1404cd9f539a575b4e7135466e": {"ta_keywords": "parity models;parity model;erasure coding;parm;storage;decoder;neural network;erasure;speech recognition;resourceefficient resilience;efficient resilience;prediction;localization tasks;median latency;hard copies;copies;image classification;resilience;data unavailability;resource;classroom use;predictions;queries;same median;use;systems;communication systems;applicability;system;part", "pdf_keywords": ""}, "fb7caddac20dca012f48c90b2e1e2383f7185051": {"ta_keywords": "interpretability tools;misuse interpretability tools;interpretability;data scientists;visualizations output;ml models;interpretml implementation;tools;qualitative themes;machine learning;mental models;contextual inquiry;trust;researchers;tool designers;findings;results;social science literature;machine;common issues;implications;gams;survey;end;shap python package;participants;use;practitioners", "pdf_keywords": "interpretability tools;author keywords interpretability;introduction machine learning;interpretml implementation;machine learning;shap python package;data scientists;ml models;blackbox models;computing;user studies;centric evaluation;criminal justice;humancentric evaluation;healthcare;gams;education;glassbox models;ml;context;public policy;use;conclusion;user;everyday lives;building;domains"}, "b1d8c868e1d6d4980ee2f8c50e6fc5e4e7027ca2": {"ta_keywords": "person narration;story continuation accuracy;character relationships;story continuation;modeling character relations;dialogue;dialogue transcripts;other characters;characters;critical role dungeons;personas;character;persona;stories;role;game dungeons;language;relationships;story;strong baselines;models;dragons dataset;end;dragons;people;ablations;bailey;evidence;series;pair", "pdf_keywords": "automated storytelling;person narration;modeling character relations;story continuation accuracy;character relationships;story continuation;dialogue;dialogue transcripts;storytelling;characters;other characters;character relation;text generation;character;complete stories;personas;persona;term memory;stories;critical role dungeons;language;role;interactive computing;story;models;relationships;creativity;strong baselines;game dungeons;end"}, "e785441f5ccd6e4e29b3123e61121df5c65b88f7": {"ta_keywords": "variational autoencoder;deep latent variable model;inference network;variational learning technique;strong autoregressive baselines;neural inference network;inference lag;vae training;vae;basic vae;approximate posterior mimics;vaes;gradient methods;latent variables;image benchmarks;posterior collapse;latent variable;model;new model components;posterior;marginal data likelihood;model update;likelihood;degenerate local optimum;previous work;observation;large amount;true posterior;practice;collapse", "pdf_keywords": "variational autoencoders;variational autoencoder;lagging inference networks;deep latent variable model;accompanying variational learning technique;variational learning technique;strong autoregressive baselines;inference network;deep latent;inference lag;image benchmarks;vae;vae training;posterior collapse;latent variable;effective training algorithm;vaes;basic vae training;model;training dynamics;welling;variable model;collapse;perspective;text;novel training procedure;iclr;observation;likelihood;jan"}, "f7a2f2ae829545ee992a2214b3600cf914544e22": {"ta_keywords": "cognitive tutor;intelligent tutoring systems;cognitive skills;student modeling;human students;cognitive model;simstudent;students;agent;significant programming;machine;tools;demonstration;novel problems;evaluation study;paper;correct behavior;second use;errors;author;problems;building block;performance;current implementation;time", "pdf_keywords": ""}, "9112be1801598125d463febb96a525227c32acc1": {"ta_keywords": "deep neural network;automatic differentiation;new structured loss functions;speech recognition;convolutional wfst layer;traditional convolution;state transducers;handwriting recognition;level representations;latent decomposition;word pieces;phrases;graphs;prior knowledge;operations;wfsts;algorithms;encoding;replacement;training time;drop;interior;separation;turn;exploration;framework;experiments", "pdf_keywords": "convolutional wfst layer;deep neural network;differentiable wfsts;traditional convolution;automatic differentiation;state transducers;level representations;wfsts;prior knowledge;awni hannun;training time;differentiable;data;model;jacob kahn;interior;drop;replacement;abstract;finite;framework;oct;vineel pratap"}, "4cf633d0893a1d3af97723ce1f2fae33c2a30043": {"ta_keywords": "relational classification;open information extraction;knowledge bases;similar relations;redundant relations;entity pairs;relations;similarity;exact similarity;softmax classification;fact distribution;conditional probability distributions;negative sampling;models;sampling;various tasks;competitive models;divergence;open ie;good approximation;approach;mistakes;effective method;method", "pdf_keywords": "knowledge bases;similarity;similarity score;fact distribution;entity pairs;relations;entity pair space;conditional distributions;human judgments;metric;intelligent technology;ai;arti\ufb01cial intelligence;technology;human judgment;computer science;pairs;leibler;divergence;carnegie mellon university;computational ef\ufb01ciency;beijing;department;systems institute;state key lab;abstract;tsinghua university;kullback;experiments;kl"}, "9f1059006e4ba303f8945114eddadd50d58a9f3e": {"ta_keywords": "soft symbolic database;neural query language;knowledge base query language;large knowledge bases;tensorflow;soft kb;neural models;kb access rules;many ai tasks;query templates;prior knowledge;learning systems;modern gradient;only differentiable operators;kbs;example;facts;information;framework;text;form;confidences;hand", "pdf_keywords": "neural query language;knowledge base query language;soft symbolic databases;large knowledge bases;soft symbolic database;query language;queries;neural models;query templates;many ai tasks;soft kb;tensor\ufb02ow;kb access rules;symbolic kb;neural model;new kb access rules;nql;inductive logic programming;prior knowledge;learning methods;kbs;kb;learning systems;data;alex hofer google;modern gradient;facts;differentiable operators;information;only differentiable operators"}, "02b932416751674dc25353620a1df4b53c3a5f6f": {"ta_keywords": "phonemic transcripts;spoken dialogue systems;automatic speech recognition;phoneme sequence;speech interface applications;asr transcript;linguistic annotations;speech translation;target transcript;natural language processing;audio data;linguistic information;speech;asr system;nlp;sequence model;audio;asr;grapheme;sequence;pipeline approaches;transformer;training targets;tags;pos tag;part;pos;methods;method;access", "pdf_keywords": ""}, "811531c959b0543a8e7abe1e827770e36b96f817": {"ta_keywords": "level emphasis estimation;level emphasis transfer;translation systems;emphasis translation;target language;speech;level emphasis;emphasis;words;languages;conditional random fields;word;objective evaluation;listening test;s2s;hsmm;human subjects;linear regression;lr;crfs;system;paper;global;new components;various technologies;result;problem", "pdf_keywords": ""}, "6c34b7b0441bff66cce2418d36acfd9776ad7bd2": {"ta_keywords": "rule learning systems;ective rule induction;large noisy datasets;machine learning proceedings;noisy datasets;benchmark problems;large samples ripperk;training examples;rule;algo rithm ripperk;algorithm;examples;error rates;bench mark problems;twelfth international conference ml;thousands;diverse collection;hundreds;modi cations;irep;paper;respect;num ber;number", "pdf_keywords": ""}, "d723630c585aa0e4084fdd6e71bc6586cfa30e9d": {"ta_keywords": "joint pause prediction;pause information;syntactic information;pauses;only syntactic information;consecutive words;prosodic information;manual annotation;syntax;such joint models;latent variables;data;latent;baseline;dependency;tree;more data;variable model;sufficient data;model;same data;addition;points;paper;measure;decision;further gains;problem;larger quantities;experiments", "pdf_keywords": ""}, "81bc64ce5553798c058f25fe5bd537d4bed67aed": {"ta_keywords": "qd luminescence;organometallic chemical vapour deposition;emission energies;xas;inxga1;dots;excited state separations;qds;pyramidal recess patterns;fabrication;narrow pl lines;state;mev", "pdf_keywords": ""}, "a8c62c42509c45a708ba477b603ee3fb81c77056": {"ta_keywords": "false news detection;false news detection approaches;false news;social media;news posts;wide dissemination;fnews;competition;participants;different approaches;further propagation;significant negative effects;society;performance;time;development;order", "pdf_keywords": "false news detection problem;news image detection;news text detection;falsenews;fnews;false news;subtasks;e\ufb00ective visual features;features;global features;early fusion integrates features;deep network;multiple modalities;di\ufb00erent modalities;modalities;e\ufb00ective fusion approaches;late fusion;representations;di\ufb00erent approaches;participants;performance;e\ufb03ciency;competition;limited research;integration;classi\ufb01cation decision"}, "44775500a5380be3776e876aedc43921d42d8de9": {"ta_keywords": "urban mobility data;massive urban mobility data;urban dynamics;urban activities;rich urban dynamics;urban states;hidden markov model;activity patterns;whole city;urban region;temporal dynamics;state transition;general hmm;state;distinct daily rhythms;states;limited states;interests;emergence;novel time;reliable data;people;semantics;population;region;different time slots;recent works;pois;sshmm;type", "pdf_keywords": ""}, "470bfbde1dc0ed6ca989957dcd551213720657c0": {"ta_keywords": "neural machine translation;machine translation systems;parses;syntax nmt;explicit syntax;syntax;dependency trees;grammatical understanding;translation;attention mechanism;semantic knowledge;decoder;knowledge;structure;nmt;model;information;performance;fluency;types;systems;burden;question;benefits;way;recent work;issues", "pdf_keywords": "structured self attention encoder;syntactic structure;attention;latent structures;target syntax;target decoder;latent trees;decoder;target language;semantic objective;soft structured representation;syntax;interpretability;strong baseline;representations;obj boy;source sentence;encoding;model;quantitative attachment accuracy;subj;structures;new nmt model;summary;verb;noun girls;trees;alignment;signi\ufb01cant improvements;qualitative look"}, "bc494b9c6d9602a69b76ab9ea0e95d348a2fce19": {"ta_keywords": "summarization research;summarization;summary assessment;multiple annotators;salient content;summaries;highlights;manual evaluation;highlight;source document;other evaluation approaches;human judges;less evaluation;neural network;datasets;substantial progress;reference;comparison;novel approach;recent advances;task poses;difficulty;novel;approaches;differences;highres;system;systems;scale;multiple systems", "pdf_keywords": "extreme summarization dataset;summarization research;document summarization;highlight annotation;abstractive summarization methods;summarization;referenceless evaluation;summaries;pointer generator networks;salient content;highlight;multiple annotators;reference bias;manual evaluation;evaluation;summary;less evaluation;source document;quality judgments;reference;example;substantial progress;aware convolutional networks;crowd;datasets;topic;abstract;xsum;neural network;jun"}, "e2ffd0ea7aa9cebaafba4afaee3cbe78070c8aa2": {"ta_keywords": "state triphone hmms;speech recognition;variational bayesian estimation;isolated word recognition experiments;variational bayesian approach;bayesian prediction classification;bayesian framework;model selection;speech;high recognition performance;maximum likelihood approach;vbec;appropriate model structure;vbec framework;mdl criterion;bic;paper;data;conventional methods;small amounts;advantage;asymptotic assumption;insufficient amounts;principle", "pdf_keywords": ""}, "3321c947a4a399803592f26879927e58f587fd74": {"ta_keywords": "algorithmic risk assessment instruments;criminal justice;several recent crowdsourcing works;judicial decisions;predictive performance;offender;decision makers;participants;scrutiny;behavior;predictions;likelihood;researchers;key findings;human interactants;laypersons;tools;potential;survey;most cases;impact;inequity;vignette study;rais;factors;time;rai;most studies;seconds;paper", "pdf_keywords": "felony offenders;black offenders;felonies;incarceration;white offenders;offenders;arrest;higher false positive rates;misdemeanors;risk estimates;charges;separate logistic regression models;blacks;risk;trust;higher influence;likelihood;predictions;prs;influence;rate;overall rates;participants;ogs;average probability;self;comparison;rai;types;use"}, "0554246ebb6c53e88d7ac2aabf0c96a91ad500a0": {"ta_keywords": "strong speech enhancement capability;speech enhancement;domain speech enhancement model;speech recognition performance discrepancy;speech recognition models;channel conv;tasnet;beamforming model;channel;good performance;joint training;real data;simulation;frontend;great potential;simulation conditions;integration;time;world scenarios;several approaches;many experiments;real;insightful investigation;various strategies;approaches;paper;experiments;gap;conditions", "pdf_keywords": "channel speech enhancement on;domain speech enhancement;strong speech enhancement capability;speech enhancement;speech recognition performance discrepancy;speech recognition models;chime4 corpus;channel conv;deep learning;audio;tasnet;signal processing;beamforming model;domain models;models;performance;acoustics;domain multi;new paltz;ieee workshop;overall performance;joint training;real data;simulation;simulation conditions;applications;arti\ufb01cial intelligence;beam;chinese academy;institute"}, "c2bd176f8f9c84f9ba52ffb8f8bd4e9299c0f0cf": {"ta_keywords": "general nonparametric quantile regression methods;nonparametric quantile regression;multiple quantile regression approach;parking data;prediction;price tracks;generic data sets;gefcom2014;algorithms;wind;juban;scikit learn style python;approach;ohlson;methods;kolter;poirier;maasoumy;detail;paper", "pdf_keywords": ""}, "a9a7058b39768ece13608e31341cfb16c4faf2c3": {"ta_keywords": "fair machine learning;fair machine;fairness;fair world;misguided policies;consequential decisions;political philosophy;ideal worlds;ideal thinking;predictive framework;policy;government;naive applications;decisions;justice;predictions;predictive modeling;ideal theory;algorithms;utility;various decision;ideal approach;various statistical parities;shortcomings;machine;deviations;hopes;broader troubles;parities;researchers", "pdf_keywords": "algorithmic fairness;algorithmic injustice;political philosophy;fair machine;machine learning;algorithms;such normative prescriptions;criminal justice;misguided solutions;critical discussion;burdens;impossibility results;hiring;ideal theorizing;allocation;apparent shortcomings;social services;numerous sensitive domains;ideal approach;broader troubles;challenges;literature;models;introduction;ml;reinterpretation;social bene\ufb01ts;future work;harms;paper"}, "156323f4d87af6cf105c97bf29d324c9e3bc8f92": {"ta_keywords": "speech translation;speech synthesis;machine translation;translation evaluation measure;translation quality;automatic speech recognition;minimum error rate training;previous joint optimization methods;asr system;joint optimization techniques;word error rate;joint optimization;asr;optimization;hybrid optimization method;relaxed algorithm;algorithm;batch margin;computational cost;pairwise;wer;mt;features;empirical comparison;best combination;addition;ss;bleu points;mira;st", "pdf_keywords": ""}, "3cd4797725ca9cf954946ed5309e15ebab80b92a": {"ta_keywords": "multimodal conditional image synthesis;unimodal conditional image synthesis approaches;experts generative adversarial networks;conditional image synthesis frameworks;experts gans;multimodal user inputs;gan;single modality;unimodal setting;multiple input modalities;poe;images;high quality;user inputs;art;style reference;diversity;training scheme;text;segmentation;empty set;limitation;subset;product;framework;practicality;state", "pdf_keywords": "multimodal conditional image synthesis;multimodal conditional image synthesis model;unimodal conditional image synthesis approaches;prior multimodal synthesis work;multimodal discriminator architecture;gan approach;single modality;conditional inputs;landscape images;input modalities;multiscale;images;coco;modalities;poe;image;discriminator;segmentation;style reference;art;datasets;text;celeba;conditions;mmpd;experts;conclusion;ms;proprietary dataset;arbitrary subset"}, "365e049ecb7299cc6925483127f2f2123a97c35f": {"ta_keywords": "change point detection problem;novel kernel learning framework;kernel selection algorithms;kernel selection;kernel change;time series cpd;auxiliary deep generative models;abrupt property changes;auxiliary generative model;time series;kernel;benchmark datasets;point detection;cpd;test power;sample test;traditional parametric approaches;distributions;emergence;simulation studies;comparative evaluation;insufficient samples;kl;fewer assumptions;paper;other state;approach;task;art methods;success", "pdf_keywords": "deep kernel parameterization;new kernel learning framework;kernel learning framework;novel kernel learning framework;time series cpd;deep kernel parametrization;kernel change;deep generative models;abrupt property changes;auxiliary generative model;rbf kernels;time series;kernel;kernel twosample;rnns;cpd;change;points detection;point detection;test power;latent space;iclr;data;points;different realworld applications;auxiliary generator;kl;sample test;ml;auxiliary"}, "464a75c05a5ce709fc515a2577b43acc8e3d45ce": {"ta_keywords": "complete inference chain;250k manual explanatory relevancy ratings;explanatory completeness;knowledge base;explanation regeneration;future improvement;shared task;relevance;task data;textgraphs;subtask;task;questions;instantiation concentrates;baseline methods;facts;participants;ndcg;large chains;performance;edition;previous editions;use;question;significant room;gaps;end;system;correct answer;large set", "pdf_keywords": ""}, "a6e61164e7b385cec0e12093bc270eafd3ef1dbc": {"ta_keywords": "activity recognition method;unlabeled acceleration sensor data;sensor data;activities;training data;recognition method;similar users;participants;good recognition accuracy;end user;other users;user;physical characteristics;information;height;gender;effectiveness;hours;method;paper;advance", "pdf_keywords": ""}, "d7c1bdafb51fe1a757604f9daeaea812f124320f": {"ta_keywords": "technology forecasting systems;technology forecasting;russian patent databases;russian government contracts;information retrieval system pipeline;data sources;government contracts;technology trends;latent semantic analysis;citation indexes;word2vec;technology;different technologies;trends;government;other languages;research;patterns;english;fundamental research;future state;production;interest;multidisciplinary field;most countries;global ones;grade systems;new possible parameter;order;parameter", "pdf_keywords": ""}, "fba7c0a51a6301ca4086a5ce59b1f13af9acad7f": {"ta_keywords": "japanese morphological analysis;partial annotation;structured predictors;tagging;active learning;structured approach;japanese ma;structure information;structure;learning;domain data;same feature;accuracy;pointwise approach;current state;method;art;lack;use;combination", "pdf_keywords": ""}, "5d07db93e6fbd9e10713a2f372131c777077062d": {"ta_keywords": "deep quantization;automatic deep quantization;deep reinforcement learning framework;quantization;dnn computation;deep networks;heterogeneous bitwidth assignment;proximal policy optimization;bits;bitwidths;releq;bitwidth;minimal accuracy loss;network encodings;layers;neural networks;reinforcement learning approach;storage;speed;large space;significant accuracy loss;computation;arduous manual effort;large variety;quality;possible assignment;questionable utility;sample efficiency;storage costs;end", "pdf_keywords": ""}, "e63e1db25f33162cc6e498f983dc3f6e10c9867e": {"ta_keywords": "speech separation benchmarks;conventional speech separation;speaker extraction;speech separation;complex speech recordings;speaker information;speech sources;speaker;conditional chain model;extraction;sequence model;speakers;sequence;whole observation;model;information;observation;variable numbers;comparable results;better adaptability;common strategy;conditions;method;prior studies;problem;identities;work;experiments", "pdf_keywords": "speech separation;speaker diarization;aim speaker extraction;speaker information;accurate speaker identity information;speech recognition;audio recordings;speaker;long recordings;multiple speakers;speech sources;speech;speakers;different speakers;more speakers;conditional chain model;short overlapped segments;extraction task;further downstream usage;independent tasks;toextraction pipeline;separation problem;inference;probabilistic chain rule;real scenes;common chain model;processing;conditional probability;base model;model"}, "c3d2c60e70cad17ea37cb116ab30e1239405dbdd": {"ta_keywords": "global \u79d1\u5b66\u6280\u8853\u7dcf\u5408\u30ea\u30f3\u30af\u30bb\u30f3\u30bf\u30fc", "pdf_keywords": ""}, "6a730aff0b3e23423a00cb3407eb04e7f6e83878": {"ta_keywords": "statistical machine translation;moses machine translation system;word alignment;variational bayes;ibm models;em algorithm;bayesian approaches;such bayesian technique;overfitting;model parameters;prior probabilities;bleu score;overall performance;performance;terms;amount", "pdf_keywords": ""}, "c06410ce8f9b1c941115d6d96780794e66b27eac": {"ta_keywords": "novel incremental adaptation framework;incremental adaptation techniques;fast incremental adaptation;large vocabulary continuous speech recognition;utterance update;speech recognition;adaptation;macroscopic time evolution system;line adaptation;acoustic models;variant acoustic characteristics;acoustic model parameters;bayesian detection;japanese broadcast news;environmental changes;posterior distributions;changes;real time;acoustic characteristics;700k vocabulary size;utterance;speakers;noise sources;variant characteristics;time;styles;such time;paper;various factors;result", "pdf_keywords": ""}, "68167af17980a14ed5fa2514e61d76d5a6a9bed7": {"ta_keywords": "pandemic vaccine conversation;conspiracy theories;social media posts;fake news;legitimate sources;external articles;traditional news;news;scientific messaging;coronavirus;public health responses;narratives;twitter;misinformation;articles;distinct narratives;information;content;external content;information vacuum;spread;government;novel methodology;resources;february;types;specific analysis;time;lack;june", "pdf_keywords": "pandemic vaccine conversation;vaccination discussion;social media posts;conspiracy theories;legitimate sources;fake news;external articles;social media;future public health messaging;social media activity;scientific messaging;coronavirus;news;article content;misinformation work;twitter;traditional news;misinformation;public health responses;articles;similar external content;narratives;multiple social media platforms;distinct narratives;information;external content;content;information vacuum;source;origin source"}, "4a96b2b33786301d59670fa647f99e3dd807abb8": {"ta_keywords": "multiagent learning algorithms;stable nash equilibrium;continuous games;agents;equilibrium;desirable equilibria;learning path;individual gradient;stochastic settings;convergence guarantees;games;gradient;unbiased estimator;deterministic settings;neighborhood;numerical examples;oracle access;class;vector field;analysis;insight;distortion;effects", "pdf_keywords": ""}, "d9b458d39e0912524032887aaaf922f0e950f0c1": {"ta_keywords": "aware superpixel segmentation;unsupervised convolutional neural networks;edge", "pdf_keywords": ""}, "76f9f4bf8d97de5e95d2fd9dd8b50041524fb1cc": {"ta_keywords": "joint knowledge embeddings;entity alignment;knowledge graph completion performance;joint semantic space;entities;dimensional semantic space;semantic distance;wikipedia links;alignment performance;relations;realworld datasets;alignment;baselines;external information;small seed;various kgs;costly manual feature construction;parameter sharing method;novel approach;favor;significant improvements;paper;process;method;methods;experiment results", "pdf_keywords": ""}, "476ff888fe3917f92b221c522ffb7bfaa4e1861b": {"ta_keywords": "conversational question answering;functional conversational search systems;conversational search;information retrieval;retrieval;reranker component;reranker;conversational question;orconvqa;retriever;answers;large collection;quac;response;reader;candidate;end system;dataset;recent research approaches;answer;further step;end;research;ultimate goals;regularization effect;evidence;transformers;passage;model performance;limitation", "pdf_keywords": "functional conversational search systems;retrieval;reranker component;large collection;reranker;retriever;conversational question;orconvqa;answers;reader;quac;history;end system;system components;substantial improvement;end;evidence;dataset;transformers;regularization effect;system;further step;research;model performance;limitation;setting"}, "b169c4b6c23efe8cbd4dc29eb97939cbcfba0f28": {"ta_keywords": "persuasive dialogue systems;persuasive dialogues;dialogue participants;most common dialog acts;dialogue acts;dialogue;persuasive power;persuasiveness;persuasion;utterances;recent dialogue literature;annotated corpus;persuader;argumentation;passive actors;salesperson;professional salespeople;corpus;speaker;information exchange;actions;customer;satisfaction;framing;particular product;factors;subjects;listener;effective predictors;real humans", "pdf_keywords": ""}, "65d3575b1c380b1bcc14ec69ccf6989c04be9493": {"ta_keywords": "asynchronous graph algorithms;semantic web graph;graph algorithms;collect programming model;collect framework;semantic;graphs;many algorithms;signal;unconnected data sets;programming models;algorithms;graph;abstraction;asynchronicity;various algorithms;various relevant algorithms;web;prototype signal;programming model;computations;data;infrastructure;collect;new knowledge;scalability;collect adaptations;paper;example;elegant way", "pdf_keywords": ""}, "cf7e8f47ad1c57738dc586109dcf28a22ab67b72": {"ta_keywords": "optimize paper bidding;conference peer review;many bids;peer review;popular baselines;bids;ordering;bidding process;requisite bids;reviewers;local optimality guarantee;reviewer;baselines;sequential arrival;algorithm;papers;paper;iclr;relevant items;synthetic data;applications;real data;list;systems;various real world complexities;items;experiments;users;number;system", "pdf_keywords": "optimize paper bidding;ordering;peer review;sequential arrival;applications;users;items;number;ai;user;washington;jul;tanner fiez university;lillian ratliff university"}, "adc273bd25ab1e2a66543f23c7a801af0dd80e5b": {"ta_keywords": "speaker diarization;simultaneous speech recognition;automatic speech recognition;speaker embeddings;challenging dialogue recordings;channel dialogue recordings;short sample utterance;speaker overlap ratio;speaker;diarization error rate;target speaker;speech;word error rate;recordings;target speakers;speakers;asr;estimation;wer;iterative method;sample;der;use;ts;ii;method;limitation;target;obvious drawback;technique", "pdf_keywords": "speaker diarization;speaker embeddings;simultaneous speech recognition;challenging dialogue recordings;channel dialogue recordings;monaural dialogue recordings;automatic speech recognition;short sample utterance;acoustic models;target speaker;speaker;speaker overlap ratio;speech;target speakers;recordings;speakers;diarization;estimation;naoyuki kanda1;kenji nagamatsu1;asr;shota horiguchi1;iterative method;yusuke fujita1;ts;shinji watanabe2;sample;ii;target;1hitachi"}, "b20cadef0c59e80f7dfdf825b07442619d920fd5": {"ta_keywords": "recurrent neural network language model;connectionist temporal classification;automatic speech recognition;decoder architecture;vectorized beam search;rnnlm;efficient beam search techniques;spontaneous japanese datasets;multiple utterances;beam search;encoder;asr accuracy;corpus;attention;vectorized hypotheses;asr;gpus;significant speedups;speedup;gpu;batch;cpu;ctc;algorithms;vector;librispeech;matrix operations;scores;end;multiple hypotheses", "pdf_keywords": ""}, "16326359081a42c0b254ee6be39824fd2db07e48": {"ta_keywords": "pivot translation;pivot language model;target translation models;high translation accuracy;language pairs;pivot;translation time;translation;third language;triangulation stage;triangulation method;parallel data;target model;data;novel approach;additional information source;source;paper", "pdf_keywords": ""}, "336ee50043b916c9e932338c02fd1abc87a6e849": {"ta_keywords": "compositional generalization;learning analytical expressions;compositionality;cooperative neural modules composer;cognition;analytical expressions;cognitive argument;hierarchical reinforcement learning algorithm;variable slots;solver;memory;symbolic functions;neural model;end manner;great ability;work;model;previous works;challenges;benchmark scan;end;experiments;refreshing view", "pdf_keywords": "compositional generalization;compositionality;language compositionality;learning analytical expressions;cooperative neural modules;cognition;expressions;analytical expressions;symbolic functions;memory;ai;variable slots;essential intellective capability;solver;above analytical expressions;unstructured sentences;abstract;composer;architecture;known parts;neural model;intrinsic connection;human beings;zeqi;beichen;yan;work;paper;beijing;gao"}, "89ba434b30a3f1b61bcbcf917842899fe3d2eea4": {"ta_keywords": "linguistic individuality transformation;statistical machine translation;dialogue systems;speech;individuality;spoken language;function words;text;manual evaluation;speaker;tm construction techniques;writer;types;various features;smt;system;method;step;creation;effectiveness;paper;limited set;technique;degree", "pdf_keywords": ""}, "63a35d8822a042f6d6cd919fd5d3c9e94df6ee18": {"ta_keywords": "supervised change point detection;unsupervised change point detection methods;novel change point detection framework;change point detection;change point detection performance;dimensional change point detection settings;true change point instances;change point instances;change points;sparse metric;changes;feature selection;ground metric;real world sequences;sinkhorn divergences;information;supervision;sample tests;consequence;methods;experiments;online manner;windows;kinds;kind;method;interpretation", "pdf_keywords": "supervised change point detection;online change point detection;novel change point detection framework;change point detection;true change point instances;change points;changes;learning sinkhorn divergences;complex sequential data;features;ground metric;sinkhorn divergences;metric;interpretable maps;information;supervision;sample tests;approaches;consequence;abstract many modern applications;online manner;methods;kinds;framework;interest;kind;yao xie;paper;feb;february"}, "00717c695e4a33318fe5655e2b69e1ba8b61f981": {"ta_keywords": "deep learning systems;ieee automatic speech recognition;several language models;rnnlm;naist asr system;speech;official challenge;acoustic models;text system;system weighting approach;rank;gram;training data;score function;english;challenge;overall training quality;understanding workshop;dnn;score;naists contribution;combination;premiere;normal system combination strategy;system combination experiments;better performance;sizes;mfcc;fbank;paper", "pdf_keywords": ""}, "ba201da15899e78629ee5471e8d336b6b2eb7279": {"ta_keywords": "routing models;transportation networks;considerate routes;public transit;traffic congestion;mobility decision support systems;mobility services;congestion;matsim simulator framework;urbanization;communities;algorithms;demand nature;simulation analysis;riders;nashville;individual utility;major cities;predictions;such services;effects;paper;tennessee;different levels;rate;adoption;overall efficacy;effect;penetration;case study", "pdf_keywords": "routing models;considerate routes;transportation networks;traffic congestion;mobility services;matsim simulator framework;urbanization;communities;social ratio;algorithms;simulation analysis;riders;level performance;nashville;rate;different levels;improvement;low penetration;tennessee;predictions;paper;penetration;effects;overall efficacy;adoption;system;case study;chinmaya samal;results;effect"}, "0af2ff552ab0555914dee90ccfae18297b2792c9": {"ta_keywords": "discriminative speaker embeddings;speaker identification component;discriminative training;channel audio recordings;deep network model;speaker overlap;end diarization models;local convolutional network;diarization performance;meetings;end diarization;loudspeaker playback;speakers;diarization methods;meeting data;diarization;attention module;real acoustics;global networks;traditional clustering;libritts datasets;librispeech;model;multitask transfer;final evaluations;global self;several components;libricss;second stage;end", "pdf_keywords": "global speaker modeling;attention network;speaker detection module;speaker identi\ufb01cation component;end diarization models;speaker classi\ufb01cation;attention module;diarization performance;end diarization model;attention;speech;local convolutional network;complexity self attention;diarization;convolutional neural network;meetings;auxiliary task;neural network;stage end;sequential architecture;embeddings;speakers;multitask transfer;global discriminability;datasets;global network;tdcn;local features;dynamic mixing;end"}, "12f3bc02d649645fa8734977e28b0ac839e56371": {"ta_keywords": "congestion constraints;allowable congestion;curbside parking resources;parking scarcity;curbside parking;queues;such queues;congestion;available servers;convex optimization problem;available server;price control;network;single node;occupancy;such networks;network subject;constraints;customer rejection;block;conditions;theoretical insight;relationship;faces;view;new kind;lack", "pdf_keywords": "queue network;parking resources;allowable congestion;queue;e\ufb00ective future parking policies;parking;queues;parking data;such queues;congestion;convex optimization problem;network topology;network;single node;price control;occupancy;customers;such networks;ine\ufb03cient spatial utilization;service;available server;constraints;san francisco;mission district;ners;modeling;conditions;drivers;application;view"}, "b7637d1148da569d2211b5dd9851bca82c6aac43": {"ta_keywords": "dynamic parser;dependency parsing;parsers;dynamic feature selection;feature computation;features;feature templates;faster framework;sentence;exhaustive search;graph;speed;accuracies;full set;decisions;edges", "pdf_keywords": "dependency parsing;dependency parsers;order parsing;dependency graph;belief propagation;standard static feature selection methods;few feature templates;dynamic feature selection algorithm;feature computation time;feature templates;word input sentence;graph;many features;other graph;selection;order;edge;decent accuracy;accuracy;approximations;smith;paper;speed;cases;section;conclusion;eisner;approach;use"}, "5f8d2da91a6c4b9dd079ccb2706c31bda14ef320": {"ta_keywords": "audio captioning;joint speech recognition;automatic speech recognition;clean speech wall street journal corpus;monaural speech recognition systems;audiocaps;speech enhancement;aac tasks;background noises;better model interpretability;art asr;robust models;joint modeling;asr;aac methods;aac;tasks;train noise;background;end;improvements;extensive experimental evaluation;holistic understanding;advantages;several approaches;multiple levels;methods;state;field;traditional approaches", "pdf_keywords": "audio captioning;effective audio representations;audio events;automatic speech recognition;dual output decoding;encoder;task modeling;dualdecoder framework;decoder frameworks;various e2e transformer frameworks;aac tasks;asr;art asr;raw textual information;better model interpretability;wasr;video streaming;joint modeling;tasks;transformer;television broadcasting;aac;aac methods;waac;end;holistic understanding;several applications;temporal structure;extensive experimental evaluation;advantages"}, "298b72096b8a770b0cdb263dd53cf2463b8a1a1d": {"ta_keywords": "deep language models;causal inference;dimensional text representation;embeddings;dimensional embeddings;causal adjustment;text documents;text;effects;example;observational data;paper;aspects;outcome;features;theorem;treatment;key insight;subject;quality;chance;acceptance;method adapts;challenge;values", "pdf_keywords": "causal topic model;suf\ufb01cient document embeddings;causal bert;topic modeling;lowdimensional document representations;suf\ufb01cient embeddings;causal estimation;causal identi\ufb01cation;causal estimation problems;causal effects;modern text representation;language modeling;text documents;gender label;text;semisynthetic data;bert;representations;paper acceptance;suf\ufb01cient information;paper;ef\ufb01cient estimation;effect;questions;contributions;methods;post popularity;theorem;estimation procedure;modern tools"}, "ffa07e4d7c8fade2ded5ffeea7265d22d8a0c0ab": {"ta_keywords": "3d constructionlovers;3d construction methods;lidar;generative neural network;convolutional neural network;models;neural networks;cnn;image processing;model;images;gan;light detection;model performance;ground truth;expensive furniture;hausdorff distance;ranging;ideal tools;independent network;cost;best result;numerical understanding;difference;easy way;gain;essential steps", "pdf_keywords": ""}, "41e49fd3af628f1c8201942a659769f7cc21d812": {"ta_keywords": "ssl algorithms;ssl algorithm;semi supervised learning;unlabeled nodes;novel graph;ssl;label distribution;node;graph;labels;seed nodes;label information;distinct labels;smaller memory footprint;data structure;art graph;min sketch;algorithms;sketch;mad;space complexity;similar performance;time complexity;paper;count;structure;10x speedup;large number;similar savings;state", "pdf_keywords": "semi supervised learning;ssl algorithms;label distribution;novel graph;ssl algorithm;scaling graph;labels;graphs;nodes;graph;ssl;art graph;node;data structure;smaller memory footprint;min sketch;edges;william cohen machine learning department carnegie mellon university;sketch;datasets;algorithm;algorithms;mad;paper;runtime improvements;signi\ufb01cant memory;count;similar performance;millions;similar space reduction"}, "3bfa808ce20b2736708c3fc0b9443635e3f133a7": {"ta_keywords": "graph neural networks;nodes;other gnn types;popular gnns;gnn;gnns;bottleneck;edges;node;incoming edges;gcn;neighbors;training data;gin;structured data;relationships;models;squashing;hyperparameter tuning;paper;messages;inherent problem;information;mechanism;art results;elements;state;additional weights;practical implications", "pdf_keywords": "gnn models;gnn;additional gnn;gnns;popular gnns;gcn;bottleneck;ggnn;neural networks;incoming edges;graph;theoretical lower bounds;limitation;gin;gat;training data;hidden size;range problems;range signals;squashing;long path;adjacent layer;tuning;inherent problem;paper;problem radius;additional weights;new explanation;messages;problem"}, "9ab3622b3a801b90907f3ee399f881764db05d06": {"ta_keywords": "consensus filtering;online stochastic gradient descent;linear attack;multiple agent nodes;attack detection probability;agent nodes;agent node computes;stochastic approximation;kalman;sensor observations;multiple sensors;sensor observation;external attacker;attacker;algorithms;gaussian noise;optimization technique;stochastic process;neighboring nodes;estimate;convexity;linear dynamics;estimates;tucker;constraint;lagrange;karush;kuhn;kkt;convergence", "pdf_keywords": "online linear attack algorithm;popular linear attack scheme;attack algorithm;linear attacks;linear attack;stochastic gradient descent algorithm;novel attack scheme;attack scheme;attack schemes;attack design algorithm;attack detection probability;simultaneous perturbation stochastic approximation;timescale stochastic approximation;attacks;noisy gradient estimate;estimation;kalman;attacker;estimators;online learning;deception attack;kkt equations;spsa algorithm;kuhn;kkt;karush;optimization;consensus \ufb01lter;estimates;kcf"}, "f2e544c5333125ee30c1c34b08936b6ef87c97dd": {"ta_keywords": "dnn based spoken language systems;speech recognition;spoken language processing systems;deep learning research;evolutionary algorithms;neural network research;neural network;language systems;language processing;implementations;tuning;automated development;dramatic performance improvements;various novel models;system;parameters;art implementations;example;applications today;effort;research areas;wide range;basic concepts;previous state;chapter;recent revival;forefront", "pdf_keywords": ""}, "ecfac0d377db229d58bc88698ad3bfd4b384ef37": {"ta_keywords": "argument mining;automatic argument identification;annotated arguments;peer reviewing;scientific publications;review dataset;high review workload;arguments;extensive empirical evaluation;reviewers;review process;editors;reviews;senior researchers;modern research;different computer science conferences;new peer;publication decision;peer;findings;process;relevant parts;decision process;cases;models;various use;interest;community;high quality;assistance", "pdf_keywords": "argument mining;new argument mining;annotated arguments;arguments;review dataset;reviewers;extensive empirical evaluation;review process;reviews;extensive evaluation;peer;editors;new peer;different computer science conferences;conclusion;publication decision;different stances;applicability;community;relevant parts;new dataset;identi\ufb01cation;assistance;approach;different actors;work;state;art am techniques"}, "6ec6fa4e34200e13d80ee79b95d1cc6ec0f6b424": {"ta_keywords": "interactive dialogues;natural language interaction;embodied agents;robots;conversation;human spaces;tasks;household tasks;teach;chat;task;environment;follower;simulation;commander;coffee;questions;understanding;dataset;instructions;breakfast;complexity;additional information;ambiguity;correct mistakes", "pdf_keywords": "interactive dialogues;human dialogs;agent task completion;agent task completion benchmark;dialogue messages;dialog;task communicates;extensible task de\ufb01nition framework;dialog history;tasks;intelligence challenges;teach data;task execution;language grounding;robot;natural language;teach sessions;intelligence;agents;actions;follower models;household tasks;teach;simulated environment;models;benchmarks;execution;environment;commander;simulation"}, "51b0609155e3a63afd1dd7dcc3034a5950f90ee0": {"ta_keywords": "audit model predictions;influence audits;influence model predictions;feature influence;direct influence;proxy features;influence;model outcomes;classifier being;black box models;dataset;representations;experiments;data;individual outcomes;level outcomes;training;theory;show;aggregate;mechanism;extensive research;test data;respect;individual;need;explicit computation;single point", "pdf_keywords": "fairness audit;multidimensional indirect in\ufb02uence audits;indirect in\ufb02uence audits;gender feature;in\ufb02uence audits;feature in\ufb02uence;individual outcomes;dataset;proxy features;gender;race;representation;data types;representations;indirect in\ufb02uence problem;classi\ufb01cation;level outcomes;regression;aggregate;classi\ufb01er;individual;data set;image data;independent factors;experiments;variation;theory;idea;techniques;direct in\ufb02uence problem"}, "1a27c23453d3f718d854ac4b57dcf3e81ac51aa8": {"ta_keywords": "active learning persist;active learning;active learner;active learners;annotation;datasets;dataset;transferability;training;models;model development;different models;data;model;underlying model;examples;findings;particular model;practice;worse performance;use;new technology;uncertainty;rounds;rapid pace;paper;cases;high cost;implications;benefits", "pdf_keywords": ""}, "9c403ca58853fbb223f6e9fce446bb638f291692": {"ta_keywords": "named entity recognition task;entity mention annotations;materials science procedural text;new annotation approach;scientific nlp;consistent annotations;entity mentions;information extraction models;annotation speed;material science synthesis;new corpus;material science synthesis procedures;procedural texts;materials;other entities;new label inventory;accurate labels;domain experts;mentions;training data;recipes;tokens;procedures;promising domain;proper modeling;fundamental challenge;operations;new ways;consistency;ms", "pdf_keywords": ""}, "33e5e4b079535957d1275497f8870ea57762a03d": {"ta_keywords": "sentence attackability;attackable sentences;attackability;online arguments;argumentation;attacks;sentences;arguments;proposition types;machine learning models;external knowledge source;sentence;relevant characteristics;tone;characteristics;content;laypeople;useful information;several baselines;findings;reasons;scale analysis", "pdf_keywords": "attackable sentences;sentence attackability;persuasion dialogue;attackability;argumentation;online arguments;arguments;sentences;attacks;proposition types;argument;machine learning models;relevant characteristics;tone;external knowledge source;laypeople;characteristics;sentence;content;appropriate points;important skill;introduction;useful information;task;several baselines;kialo;\ufb01ndings;reasons;future directions;performance"}, "81dfa45c568d7c1d9771ba2a1f07dad96558cff6": {"ta_keywords": "hidden markov kernel machine;hidden markov models;gaussian mixture models;conventional hmms;sequential pattern classification;mixture emission pdfs;phoneme classification;nonlinear classification;sequential pattern classifier;mixture models;sufficient nonlinear classification performance;kernel methods;novel classifier;emission probability density functions;gaussian;sequential data;hidden states;emission;observed vectors;pdfs;maximum likelihood;maximum mutual information procedures;overfitting;hmms;gmms;transition;paper;local optima;application;extension", "pdf_keywords": ""}, "be12a8d9ddb12c9ed292430c38d50093191dd442": {"ta_keywords": "fuzzy graph clustering;equidistant nodes clustering;soft clustering algorithm;synset induction;nodes;natural language processing task;algorithm;community;enc;core;assumption;paper;steps;limited number", "pdf_keywords": ""}, "90db4ddb08df23a4c587e6136e66cb388311473b": {"ta_keywords": "symbolic learning methods;collaborative learning system;several learning methods;several different learning methods;classifiers;classifier;filters;direct transfer;transfer;features;collaborative fashion;other users;users;documents;data;diverse set;new user;poor performance;initial training phase;more conventional evaluation settings;stability;system;effect;problem;way;case;setting;distribution", "pdf_keywords": ""}, "d409ff05d70f7b9787baf6431a84a178ad726e8d": {"ta_keywords": "novel inverse reinforcement learning;agent architecture;constrained environments;soft constraints;agents;constraints;agent;constraint;human decision making;actions;demonstrations;state features;knowledge;environments;total reward;objectives;cognitive model;emergency;human;novel system architecture;irl;traffic rules;life scenarios;trajectory length;mdft;addition;humans;offs;states;speed limit", "pdf_keywords": "inverse reinforcement learning;novel inverse reinforcement learning;constrained markov decision processes;human decision making;unique agent architecture;soft constraints;general constraint;constraints;constraint;agents;grid;decisions;actions;demonstrations;state features;environments;cognitive model;initial demonstrations;novel orchestration technique;mdft;color;objectives;human;decision;altman;capability;blue;irl;framework;superior expressive power"}, "f16c0699a873b0209a370e8e6301b0189785c614": {"ta_keywords": "constrained dirichlet process mixture models;dirichlet process mixture models;verb clustering;active learning approach;active learning;constraint selection;links constraints;sampling;instances;supervision;task;must;uncertainty;links;work;form;recent work;cannot", "pdf_keywords": ""}, "363eb288abf76f7ab52d7789b30399b4b909dd5a": {"ta_keywords": "optimal bribery schemes;traditional bribery problem;bribery;candidate set;voters;computational complexity;combinations;cartesian product;variables;agents;preferences;cp;nets;domains;parameters;set;compact way;account;several issues;setting", "pdf_keywords": ""}, "0d6a4e45acde6f47d704ed0752f17f7ab52223af": {"ta_keywords": "human demonstrations;hierarchical tasks;level language generator;natural language instructions;unseen tasks;such demonstrations;actions;reinforcement learning;human instructions;few demonstrations;level descriptions;natural language;agent;action trajectories;interpretable behaviors;grid world;automatic decomposition;language;level policy;step;generalization;humans;dataset;shot setting;model;form;approach;sequence;use", "pdf_keywords": "reinforcement learning;hierarchical tasks;human demonstrations;reward reinforcement learning setting;unseen tasks;reinforcement learning approach;level language generator;grid world;few demonstrations;human instructions;natural language instructions;such demonstrations;ef\ufb01cient learning;natural language;language;level policy;generalization;humans;hierarchical model;dataset;world;iclr;abstract;data;model;paper;shot setting;complex;valerie chen;conference paper"}, "88b66f705a329da8292e7b8aa4bfe26de4759cfa": {"ta_keywords": "phrasal inversion transduction grammar alignment techniques;accurate machine translation;machine translation;translation model;substring alignment;translation;character strings;several language pairs;mt framework;mt;strings;uncommon words;transformation;words;phrase;word;character;systems;results;evaluation;result;concept;paper;problem", "pdf_keywords": ""}, "a901185ee0710770420044cace33003109d478e3": {"ta_keywords": "rating systems;rating system;ratings;discriminate quality;answer labels;market participants;feedback form;rate;quality;true underlying quality distribution;online labor market;questions;platform;platforms;levels;design;systems;numeric interpretations;choices;results;relative importance;manner;study;principled manner;trial;convergence;signal;additional question;meaning;theoretical framework", "pdf_keywords": "designing informative rating systems;informative rating system;rating system designs;rating systems;rating system;rating scale;standard numeric rating systems;ratings;large online labor platform;online labor market test;online labor market;answer choices;market participants;verbal descriptions;baseline designs;scale design;question phrasing;designs;quality;design;information;choices;model;framework;data;optimization;platforms;\ufb01eld test;hoc choice;evidence"}, "ee9f40f1c1e77b0b39b6e4a158208614fb4995c0": {"ta_keywords": "urban anomaly detection;urban anomaly;urban anomalies;urban datasets;urban big data;urban sensors;anomalies;prediction frameworks;environment data;surveillance cameras;data;event records;trip records;comprehensive survey;state;populations;trajectory;property;algorithms;survey;life;social media;diverse devices;issues;loss;machine;various types;early stage;great value;cdrs", "pdf_keywords": "urban anomaly analytics;urban anomaly detection;urban anomaly analysis frameworks;urban anomalies;environment anomaly detection;urban big data;big urban data;urban data;urban datasets;individual anomaly;urban sensors;environment anomaly;traf\ufb01c anomaly;urban areas;unexpected crowds;surveillance cameras;environment data;data;primary data source;event records;prediction problem;trip records;recent years;trajectory;algorithms;social media;comprehensive survey;survey;kinds;state"}, "5bcbc4554a68b38ff4a22b848fb0817b809608b2": {"ta_keywords": "evaluation", "pdf_keywords": ""}, "c159725940750adbad262ac946ce161bb68e41b5": {"ta_keywords": "automatic speech recognition;connectionist temporal classification;rnn;e2e asr;reverberant tasks;various asr benchmarks;attention;sequence models;art e2e asr results;simple model training;asr;dynamic convolutions;sequence;conventional hidden markov model;dynamic convolution;e2e;convolution;e2e model;transformer;alternative architecture;end;art transformer;joint training;better performance;self;performance;lightweight;architectures;state;computational order linear", "pdf_keywords": "automatic speech recognition;e2e asr;rnn;various asr benchmarks;reverberant tasks;attention;asr;convolutional layer;e2e;dynamic convolution;convolution;asr experiments;e2e model;connectionist temporal classi\ufb01cation;models;performance;better performance;alternative architecture;art transformer;self;joint training;end;architectures;state;various corpora;introduction;test sets;computational order linear;frequency axis;techniques"}, "ec6499842d3e51b7dda94f5d0620d6df5c1a1b6d": {"ta_keywords": "speech technology;unwritten language;speech subsystems;unwritten languages;speech;utterance;text;computer interaction;information retrieval;representations;images;intermediate representation;line shopping;building systems;meaning;work;aim;instance;results;need;sufficiency;case;standard combination;others", "pdf_keywords": ""}, "55faed1fbb1575ffa2609bdc4490586e30df441a": {"ta_keywords": "automatic translation evaluation metrics;machine translation evaluation metrics;machine translations;translation results;qa accuracy;knowledge bases;clqa accuracy;qa systems;language;clqa;metric;information source;qa;manual analysis;few major languages;questions;systems;data;topics;data set;words;result;investigation;variety;question;factors;paper;frequency;relationship", "pdf_keywords": ""}, "e52115834ac7a529b1f4a7769dd538f143cf3eea": {"ta_keywords": "general erasure codes;erasure codes;reed solomon codes;piggybacking codes;achievable repair bandwidth;repair schemes;codes;storage;low repair;optimal constructions;several impossibility results;piggybacking;complexity;low substriping;desirable properties;general characterization;limitations;characterization;subcategories;framework;certain parameters;separation", "pdf_keywords": "erasure code repair schemes;general erasure codes;code repair schemes;piggybacking codes;scalar mds base codes;general linear codes;linear repair schemes;mds array codes;reed solomon codes;repair schemes;codes;optimal constructions;achievable bandwidth;several impossibility results;general characterization;low substriping;impossibility results;piggybacking;characterization;node;style;subcategories;subcategory;certain parameters;framework;contributions;order;regime;conclusion;separation"}, "777d7b4141c9ce163de99b747e94c8d1db12e11e": {"ta_keywords": "interpretable privacy;deep learning inference;perturbation maximization method;service provider;cloud;accurate prediction;gradient;service;services;provider;prediction model;models;input feature space;consumers;input;entire raw data;machine;more information;many cases;order;small portion;respect;execution;problem;decision making;subset;work", "pdf_keywords": ""}, "89e53f116ef732d0abe81ee2218fa862ddc5ddce": {"ta_keywords": "speech translation systems;end speech processing toolkit;speech translation;machine translation;automatic speech recognition;espnet;speech functions;benchmark datasets;speech;quick development;data pre;text;feature extraction;pipelines;models;new project;training;reproducible results;recipes;wide range;end;st;current state;single framework;art performances", "pdf_keywords": "speech translation systems;toend speech processing toolkit;speech translation;espnet;machine translation;automatic speech recognition;speech functions;benchmark datasets;speech;toolkit;text;quick development;feature extraction;data pre;new project;pipelines;training;recipes;wide range;sep;end;st;single framework;abstract"}, "6d654bab72d062d91f731331f16ea01d7cac0812": {"ta_keywords": "narrative tropes;gender bias;tropes;trope;societal biases;genderedness;popular media;narrative elements;literature;gender;archetypal characters;tvtropes dataset;media;topics;television;popular reception;occurrences;types;film;creator;plot arcs;analysis;relationship;repository;study;online user;use;work", "pdf_keywords": "tropes;trope usage;gender bias;trope;genderedness;genre;literature;narrative patterns;gender;female instances;tvtropes dataset;characters;tvtropes;goodreads;popular media;topics;author;television;women;occurrences;imdb;tv;media;contexts;creator;dataset;metadata;male;evil genius;types"}, "e79d1206292bc5e67ba19737d87d4b2ea4a37105": {"ta_keywords": "subword tokenization module;latent subword representations;separate rigid subword tokenization algorithms;subword tokenization end;candidate subword blocks;subword;natural language processing;noisy text datasets;charformer;characters;deep transformer model;gbst;inductive bias;soft gradient;generalization ability;byte level;english glue;competitive byte;level baselines;block scoring network;par;models;adaptation;part;position;model;new model;series;art models;paper", "pdf_keywords": "subword tokenization;subword tokenization module;based subword tokenization;separate rigid subword tokenization algorithms;latent subword representations;latent subwords;novel lightweight tokenization method;natural language processing;level representations;fast character transformers;multilingual variants;characters;charformer;deep transformer model;generalization ability;iclr;character;soft gradient;strong character;gbst;gradient;compositionality;byte level;end learning;level baselines;adaptation;english;various datasets;fashion;data"}, "4cdd533963d8fb21fbf4bb3487bf6a6d60e14e93": {"ta_keywords": "cell image segmentation;robust cell image segmentation;accurate cell image segmentation results;segmentation;cell images;oral mucosal cell images;segmentation experiments;segmentation method;improved markov random field;micronucleus cell;markov;chinese restaurant process model;clusters;binuclear cell;random field;mrf;nucleus;map;posteriori;crpm;data;advance;paper;method;preprocessing;criterion;experimental results;size;maximum;number", "pdf_keywords": ""}, "396e942542904dd32d0d70daa39613e5a27cc059": {"ta_keywords": "collective classification methods;collective classification;graphical learning;large graphs;online learning;efficient inference;learning;iterative inference;graphical models;datasets;class labels;dataset;learning procedures;instance;class;instances;iterative optimization;memory;minimal memory;group;training time;memory cost;less time;domains;sample problems;cost;pass;paper;accurate results;problem", "pdf_keywords": ""}, "d7851e80f6072991bc99e2157f05515564f894f4": {"ta_keywords": "online discriminative training method;structured adaptive regularization;adaptive regularization;multiclass classification;phoneme conversion model;binary classification;overfitting;margin infused relaxed algorithm;phoneme error rate;g2p conversion task;robust grapheme;weight vectors;datasets;dataset;learning problem;g2p conversion;web;aggressive weight update method;outlier;collective knowledge;evaluation;mira;terms;paper;current example;approach;time;art approach;problem;current state", "pdf_keywords": ""}, "254491f0d981fb5d796c374287d439d8d1967088": {"ta_keywords": "cardiometabolic risk;vitamin;clinical trials;adolescents;children;effect;markers;analysis", "pdf_keywords": ""}, "e68762a32ec91587d9761030fc75a8f5ee71c45b": {"ta_keywords": "topic tracking model;mixture language model adaptation;accurate latent topic estimate;latent dirichlet allocation;unsupervised topic;speech recognizer;mixture modeling;unsupervised adaptation;speech recognition;topic;confusion network;recognition errors;recognition output;input;best input;model;uncertain observations;selection variable;recent approaches;extension;purpose", "pdf_keywords": ""}, "e66ade4e28d9f401277194ed8feea5c6e9f18253": {"ta_keywords": "terrorist organizations;terrorist groups;operational similarity;similarity patterns;operational repertoires;clusters;tactics;groups;similar behaviors;diversity;intelligence monitoring;patterns;attacks;targets;organizations;yearly repertoire;weapons;novel computational framework;co;actionable insights;last decade;temporal consistency;events;activity;overall activity;year stability;dynamics;sets;year;factors", "pdf_keywords": "active terrorist organizations;terrorist organizations;terrorist groups;terrorist behaviors;terrorism;weapon networks;operational similarity;tactics;political violence doi;operational repertoires;similar behaviors;groups;intelligence monitoring;diversity;targets;modal tactic;clusters;attacks;organizations;sociology;patterns;modal networks;target;operational heterogeneity;yearly clusters;multi;actionable insights;weapons;novel computational framework;social research"}, "82c4be27b0803c08c56bba4352669c1230a3ea19": {"ta_keywords": "storage networks;storage nodes;error resilient mbr exact repair regenerating codes;minimum repair;storage;storage capacity;bandwidth adaptive;exact storage capacity;exact repair;repair;low cost data reconstruction;codes framework;total repair;node failures;helper nodes;data reconstruction;codes;network;erroneous nodes;mbr;efficient methods;upper bound;simultaneous extensions;flexible parameter;schemes;setup;paper;fundamental limits;dimakis et al;case", "pdf_keywords": "repair regenerating codes;regenerating codes;storage networks;minimum repair;node failures;error resilient mbr;bandwidth adaptive;different repair procedure;exact repair;repair;erroneous nodes;mbr codes;helper nodes;storage;data reconstruction procedure;data reconstruction;codes framework;storage capacity;mbr;exact storage capacity;network;on m5s3g4;ef\ufb01cient methods;d1;runtime;simultaneous extensions;helpers;test;\ufb01eld size fq;natural extension"}, "4c42d6412c080fef23ad95b4469efe9cf321ae5d": {"ta_keywords": "automatic speech recognition;unpaired speech;speech;text data;text modalities;asr;text;sequence;librispeech corpora;losses;tts;models;derive training procedures;such models;data;data quantity;extensive results;end;high performance;wsj;terms;recent surge;interest;large quantities;impact;such techniques;consistent gains;techniques;reason;method", "pdf_keywords": "unpaired speech;seq2seq asr systems;rnn language model;librispeech corpus;asr performance;speech;text modalities;text data;text;librispeech corpora;extensive results;pipeline loss;shallow integration;performance;competitive results;data quantity;information;wsj;end;additional gains;impact;terms;consistent gains;new approach;techniques;paper;conclusions;section;experimental analysis;work"}, "a714ca5254fb3cd7b06ead36d026c4eb154a7134": {"ta_keywords": "class discrimination;disparate learning processes;disparate treatment;unfairness;fairness;disparate treatment protocol;disparate impact;algorithmic decision;disadvantaged group;prejudice;law;proportional representation;nonsensitive features;notions;policy;same legal status;legal status;regularizer;arguments;normative point;learning algorithm;algorithms;dlps;characteristic;input;treatment;processes;forms;favor;ii", "pdf_keywords": "algorithms exhibit treatment disparity;treatment disparity;purposeful treatment disparity;algorithms exhibit impact disparity;class discrimination;impact disparity;such policy judgments;impact parity;nonsensitive features;utility;outcomes;policy desiderata;dlps;cautionary insights;other features;practical consequences;group membership;keen understanding;accuracy;algorithms;suboptimal trade;world datasets;awareness;experimental results;subgroups;technical solution;members;ii;historical context;iii"}, "69320030be096e78380a097810554b648e7409c0": {"ta_keywords": "bayesian speaker;conventional bayesian information criterion;approximate bayesian approach;preliminary speaker;timit database;dpmm;algorithm;bic;uo;parameters;computational cost;method;analytical solution;robustness;changes;paper;terms;conventional one;results;experiments", "pdf_keywords": ""}, "0639cbb07ec3e03de7c8c1d828a90049c92cf5df": {"ta_keywords": "orthorhombic perovskites;mn4;srsno3;asno3;spectroscopic properties;crystal field strength;casno3;ion;mn;luminescence;phonon line;bond distance;sr;deviation;transition;energy;value;significant parameter;dq;aim;comparative study;paper", "pdf_keywords": ""}, "62924cef027a66a75b5465ebb7a926c06f95790f": {"ta_keywords": "adversarial approaches;adversarial algorithms;relaxed distribution alignment;domain adaptation;target distribution;target encodings;real datasets;distribution;training;domain;standard domain;source;target error;test data;asymmetrically;precise assumptions;new approach;empirical benefits;limitations;algorithm;approach;terms;common problem", "pdf_keywords": "adversarial domain adaptation;relaxed distribution alignment loss;adversarial learning objectives;adversarial training;relaxed distribution alignment;relaxed distribution matching losses;adversarial algorithms;label distribution shift;latent space distributions;relaxed alignment;source target;good target domain performance;data distributions;source domain;negative class;exact matching;real datasets;positive class;target;target domain;target performance;domain performance guarantees;empirical results;better classi\ufb01cation;model;figure;new distance;standard domain;new approach;assumptions"}, "9b5cf607f9cd3eb5ef47d3597bb9360ea6034264": {"ta_keywords": "peer review system;peer review;unfairness;wsdm audience;biases;various computer science conferences;researchers;submissions;academia;subjectivity;challenges;dishonest behavior;many open problems;tutorial;insightful experiments;systemic challenges;matthew effect;computational techniques;miscalibration;entire career trajectory;source;problem;noise;significant impact;issue;prevalence;number", "pdf_keywords": ""}, "9a7a4f125d8016e0fad9f6f5e9e0bca4e38b0784": {"ta_keywords": "scalable probabilistic logic;probabilistic logic programming;stochastic logic programs;probabilistic logic;scalable inference;parameter learning;pagerank algorithm;efficient learning;structure discovery;inference;weight learning;gradient descent;database;queries;graphs;parallel stochastic;slp;efficient first;proppr;small graph;order theories;order;framework;paper;size", "pdf_keywords": ""}, "684e712f59f11d2bdc98be4c210824ab9e6f11f4": {"ta_keywords": "transferable relational graphs;modern deep transfer;generic latent relational graphs;word embeddings;different embeddings;unsupervised learning;generic feature vectors;convolutional features;glove embeddings;elmo embeddings;graphs;specific rnn;downstream tasks;unlabeled data;other tasks;free units;pixels;dependencies;task;image;data units;vision;language;units;words;pairs;scale;possibility;work;glomo", "pdf_keywords": ""}, "22655979df781d222eaf812b0d325fa9adf11594": {"ta_keywords": "hop question answering;qa systems;factoid comparison questions;answers;qa;knowledge schemas;113k wikipedia;hotpotqa;facts;questions;complex reasoning;key features;reasoning;new dataset;answer pairs;datasets;dataset;explanations;diverse;relevant facts;documents;level;necessary comparison;strong supervision;reason;sentence;predictions;existing question;question;new type", "pdf_keywords": "factoid comparison questions;latest qa systems;diverse natural language;knowledge schemas;qa systems;reasoning ability;qa;113k wikipedia;questions;facts;various entity properties;reasoning;key features;relevant facts;hotpotqa;conclusions;necessary comparison;test systems;documents;explainable predictions;new dataset;text;answer pairs;task;intelligent systems;level;dataset;strong supervision;models;predictions"}, "0f726fcd676baff957574b223b99fd84163ebe6e": {"ta_keywords": "stacked graphical learning;graphical learning;traditional machine learning methods;many relational datasets;graphical models;base learner;relational data;relational template;graphical model;other related instances;social networks;real world data;instance;dependencies;instances;hyperlinked web pages;algorithm;citations;features;scientific literatures;other methods;performance improvement;predictions;thesis;performance;thesis proposal;kind;approach;recent work;scheme", "pdf_keywords": ""}, "4dfa9de9b3b2b222ddbdda934975bf608b8e1fda": {"ta_keywords": "collaborative dialogues;collaborative conversations;dialogue systems research;group conversations;conversation;group dialogues;dialogues;chatbots;deliberation cues;deliberation;annotated data;novel annotation schema;14k utterances;user engagement;constructiveness;cognitive task;restaurant bookings;interlocutors;usefulness;training classifiers;delidata;dataset;systems;available dataset;end;research;area", "pdf_keywords": "deliberation utterances;collaborative conversations;group dialogues;deliberation dataset;annotated corpus;conversation;deliberation cues;14k utterances;dialogues;conversational dynamics;novel annotation schema;group deliberation;annotation schema;corpus;scienti\ufb01c project meetings;task performance;cognitive task;people;dataset;study groups;available dataset;data collection platform;delidata;contexts;panels;key elements;future analysis;wason card selection task;end;work"}, "bdf6ad58338279634d647447751442db8a6e2f77": {"ta_keywords": "neural network error surfaces;neural networks;error surfaces;partial training;training paths;local minima;weights;critical points;vast continuous regions;apparent convergence;weight space;critical point;large movements;flat regions;models;loss;local optima;equal loss;nonconvex;random initialization;descriptions;point;symmetry;recent work;paper;researchers;evidence;existence", "pdf_keywords": ""}, "88051a6dce3b67541d8096647da2f6d31daa9e9a": {"ta_keywords": "latent relation language models;knowledge graph relations;knowledge graph information;language models;entity spans;language modeling performance;relations;entities;appropriate relations;text;document;words;context;word;joint distribution;posterior probability;model;lrlms;paper;empirical improvements;qualitative analysis;class;attractive properties;number;previous approach;experiments;ability", "pdf_keywords": "latent relation language models;conditional language modeling tasks;knowledge graph relations;language models;knowledge graph information;knowledge graph;baseline language model;entity spans;relational information;language modeling performance;posterior relation probability;entities;relations;nlp;appropriate relations;context;text;latent variables;document;conditional lms;words;word;posterior probability;spans;model;joint distribution;empirical improvements;core model class;paper;lms"}, "bc33c151a375d30d85a99d4e269185bad360b7bf": {"ta_keywords": "semitransparent organic photovoltaics employing;color neutrality;ternary strategy;optical engineering;simultaneous enhanced device efficiency;synergy", "pdf_keywords": ""}, "72ae4bba9aaa30dfba45f6e7e076952a76e2d751": {"ta_keywords": "conversational model;ubuntu dialog corpus;party conversations;traditional lstm model;lstm;language generation model;language model;term memory;language model perplexity;participant role;participants;context information;interaction;context;response;different architectures;model;long;paper;experiments;method", "pdf_keywords": "conversational language model;conversation models;conversational model;conversation model;language model;response generation;lstm;party conversations;term memory;topic features;participant role;role information;role factor;different roles;role factors;context information;neural network model;global context;context;different word distribution;topic;response;electrical engineering;interactive computing;models;model;summary;yi luan1;network architecture;different architectures"}, "9b52f250376e07c2caddb5f43b8db8b2f300bb51": {"ta_keywords": "big social data analysis", "pdf_keywords": ""}, "fd8b33299ce6ca81ce54e7d2de555a1a96ca96f1": {"ta_keywords": "speech recognition;automatic speech recognition;structured discriminative models;gram language models;discriminative approaches;structured sequence data;natural language processing;hidden markov model;acoustic models;generative classifiers;asr;machine learning;nlp;label sequences;class posteriors;sentences;acoustic waveform;observation sequences;bayes rule;overview;task;sequential nature;systems;hmm;possible future approaches;research areas;approaches;current literature;article;recent work", "pdf_keywords": ""}, "457e1c9476f08fa2c253982e3effcb364487073e": {"ta_keywords": "naist english speech recognition system;iwslt", "pdf_keywords": ""}, "b80ce55fbb4aa427439009985c0ce28a34324dc6": {"ta_keywords": "antenatal clinic;nutritional supplements;pregnantwomen;intake;assessment", "pdf_keywords": ""}, "e23c5dafc718f9e55ccf7729ce2d2834b650540a": {"ta_keywords": "speaker clustering systems;bayesian speaker;dirichlet process mixture model;nonparametric bayesian manner;structured utterance;speaker;novel speaker;utterances;speakers;method;number;conventional method;accuracy;case;data", "pdf_keywords": ""}, "773e752ab6dc04b43aaf984bcbdd4895c9ab8c2f": {"ta_keywords": "large vocabulary continuous speech recognition;large vocabulary continuous speech recognition task;timit phoneme recognition;discriminative training;gram models;linear classifier;acoustic models;hidden markov models;perceptron algorithm;training method;wfst;wfstbased;sequential multiclass data;minimum phone error;structured data;conventional information source models;additional linear models;small task;dimensions;paper;scores;scale;arcs;performance;graph;number;process;improvement;difficulty;previous study", "pdf_keywords": ""}, "510aef8370d82c4c4ec50de0f645f34f11e549a7": {"ta_keywords": "recall protein entity recognition;dictionary hmms;dictionary information;semicrfs;datasets;conditional random fields;large hmm;crfs;entities;dictionary;normal crfs;phrases;features;standard training methods;maximum entropy;hmms;task;highest overall performance;results;most interest;new approaches;maxent;performance;extension;new methods;variations;effective use;variants;measure;application", "pdf_keywords": ""}, "7ddddea393c2cd70fe716e2dfc5d77daf58449c0": {"ta_keywords": "person content influence;influence;misinformation researchers;twitter;misinformation narratives;upstream alters;granger causality;digital marketing;alters;ego;impact;large audiences;alter;president donald trump;multiple topics;topics;single alter;people;topic;different magnitude;person;different scope;magnitude;platforms;canaries;case study;alter framework;novel method;fold;coal mine", "pdf_keywords": "twitter;social network analysis;social media;social networks;person content in\ufb02uence;granger causality;person in\ufb02uence;person;donald trump;ego;alters;alter;posts;president donald trump;topics;people;discussion;time delay;key alters;richard kuzma et al;keywords;in\ufb02uencers;richard kuzma;introduction;in\ufb02uence;\ufb01nding;si;novel method;paper;mainstays"}, "1890775da6ba2627a5d6c17a639e2dca7cdc388d": {"ta_keywords": "everyday environments", "pdf_keywords": ""}, "ccad27088b9098de4eaca8dc449b18766db4b3ab": {"ta_keywords": "paraphrase generation;paraphrase generation problem;unsupervised style transfer;paraphrase data;style transfer;paraphrases;style transfer systems;world style transfer;modern nlp;language models;diverse styles;attribute transfer;semantic properties;sentiment;style;semantics;sentence;large dataset;input;tuning;inputs;task;simple methodology;outputs;systems;system;paper;depth analysis;meaning", "pdf_keywords": "style transfer evaluation;diverse paraphrasing;unsupervised style transfer;paraphrase generation problem;style transfer;simple unsupervised style transfer method;output paraphrases;effective style normalization;paraphrase data;paraphraser;art style transfer systems;syntactic diversity;semantic preservation;diverse styles;language models;corpus;new sentence;new benchmark dataset;baseline;tuning;summary;critique;contributions;par;task;level aggregation metric;level aggregation;prior work;metrics;\ufb01ne"}, "703a8252585948a96f5815025f7f03d68033b8bf": {"ta_keywords": "dialog agents;agent;reinforcement learning;api environment;bots;supervised training;play;communication strategies;building collaborative;game;human;human corpora;self;theoretic equilibrium finding;task;approaches;empirical results;user;paper", "pdf_keywords": "dialog self;reinforcement learning;reinforcement learning methods;agent;bot;action strategies;bots;dialog;play;game;api environment;strategies;communication strategies;tasks;learning scheme;communication;dialog problems;full rewards;self;task;approaches;main challenges;scratch;theoretic equilibrium \ufb01nding;empirical results;methods;user;introduction;paper;data sparsity"}, "fa6c76d466fef633df51745bad85e991c371622c": {"ta_keywords": "everyday environments;special issue;guest editorial", "pdf_keywords": ""}, "41a47363d261459c594525ef330e5fccaa8518a0": {"ta_keywords": "authorship attribution accuracy;authorship attribution;author;writing style;dataset characteristics;datasets;features;document;useful features;individuals;conclusions;analysis;effectiveness;different types;art;preferred topics;previous studies;relationship;approaches;study;extension;task;approach;problem;conditions;prior state", "pdf_keywords": ""}, "98e6197e21ae530cd33eeff144ee556c5cf91dc8": {"ta_keywords": "cognitive tutors;simulated student;cognitive modeling;cognitive model;intelligent authoring environment;cognitive scientist;human domain expert;training session;programming;demonstrations;study;agent;detailed demonstration;machine learning;training problems;testing;machine;impractical levels;sample solutions;ambiguities;author;search complexity;interpretation;aim;difficulties;end;ambiguity;days;goal;order", "pdf_keywords": ""}, "af679d69fcc1d0fcf0f039aba937853bcb50a8de": {"ta_keywords": "softmax attention;linear attention functions;dense attention methods;nested attention mechanism;attention operation;sequence modeling tasks;neural machine translation;attention mechanism;rank attention;traditional attention mechanism;context sequence modeling;language modeling;long sequences;memory complexities;additional sequence;strong baseline methods;luna;other efficient sparse;adequate contextual information;space complexity;extensive evaluations;benchmarks;input;scale pretraining;length;efficiency;transformer;output;time;paper", "pdf_keywords": "linear uni\ufb01ed nested attention;linear uni\ufb01ed nested attention mechanism;regular softmax attention;softmax attention;linear attention functions;nested attention mechanism;attention functions;second attention function;luna attention;sequence modeling tasks;neural machine translation;\ufb01rst attention function;context sequence modeling;luna models;downstream task \ufb01netuning;language modeling;luna;memory;strong baselines;sequence;luna layer;input sequence;packed sequence;space complexity;models;extensive evaluations;benchmarks;linear uni\ufb01ed;speed;\ufb01netuning"}, "682e69be87f181edcf71800b54083595874d4ec6": {"ta_keywords": "speaker trait prediction;related speaker traits;hierarchical models;such hierarchical models;personality;neural networks;hierarchical structure;artificial intelligence;speaker;subtasks;networks;task hierarchies;predictions;learning;inference;smaller subtasks;model;social science communities;additional features;task;final task;ability;relationship;intermediate objectives;simple trick;method;great interest;wide variety;problems;work", "pdf_keywords": "ternary persuasiveness prediction;multimodal late fusion accuracy;related speaker traits;speaker traits;novel neural architecture;ternary persuasiveness classi\ufb01cation;persuasiveness;task hierarchy;hierarchical structure;neural network;intermediate tasks;better classi\ufb01cation performance;hierarchy;intermediate layers;classi\ufb01cation performance;speaker;trust;models;multiple modalities;content;social media;stack;objectives;intense emotion;\ufb01nal task;information;youtube;performance;novel algorithm;multimedia"}, "7c8314e6138ce968f3b9f3bc55d5461ffbbec4aa": {"ta_keywords": "tourism route;genetic algorithm;optimization;research", "pdf_keywords": ""}, "97883f37c62b4b0e52cdc31dea1a375597db3804": {"ta_keywords": "network quantization;binary masks;deep neural network;mask;filters;masks;multiple tasks;catastrophic forgetting;learning;tasks;fixed network;new task;task;underlying network;network;least overhead;sparsification;certain weights;ability;low overhead;capabilities;piggyback;network parameter;performance;bit;work;prior work;good performance;concepts;single", "pdf_keywords": "convolutional network;imagenet;basic fully convolutional network architecture;popular imagenet;semantic segmentation;pixelwise segmentation;image classi\ufb01cation;natural image domain;networks;conv1_1 segmentation;deconvolutional layer;human sketches;\ufb01xed backbone networks;datasets;densenets;resnets;network architectures;network;conv1_1 classification;multiple network architectures;layer;classi\ufb01cation tasks;piggyback masking;multiple datasets;piggyback masks;wikiart paintings;backbone network;separate network;classi\ufb01cation backbone;\ufb01xed weights"}, "e4c8447e56fc9cc3867087748acc4b259b9efe19": {"ta_keywords": "coreference relations;several text comprehension tasks;recurrent neural networks;external linguistic knowledge;explicit memory;cnn;linguistic knowledge;memory;text;external knowledge;entity information;directed acyclic subgraphs;representations;document;sequence;distant elements;benchmarks;model;babi;such graphs;graph;edges;explicit signal;lambada;art results;new state;ability;analysis", "pdf_keywords": "text comprehension tasks;several text comprehension tasks;coreference relations;model coreference;recurrent neural networks;comprehension models;rnn framework;rnn;recurrent units;cnn;linguistic relations;text;explicit memory;encode \ufb01ne;representations;entity information;symbolic knowledge;tokens;tasks;mage;document;model;benchmarks;babi;best results;conclusions;lambada;new state;such graphs;ability"}, "be8d6a8d3dfe87a4d9171f25bf9a18d502498756": {"ta_keywords": "fuzzy graph clustering;global graph clustering;semantic frame induction;semantic class induction;watset meta;synonymy graph;distributional thesaurus;synset induction;watset;frame induction;nodes;input graph;algorithm;computational complexity;sense;dependency triples;computational analysis;domains;variety;competitive results;ambiguity;approach;intermediate representation;applications", "pdf_keywords": ""}, "bd1cf4279d834699db871e1451d289c49ff2b6de": {"ta_keywords": "many step charts;dance platform;dance dance revolution;screen step charts;raw audio track;new step chart;level audio features;popular rhythm;music;step placement task;steps;convolutional neural networks;spectrograms;charts;video game;chart difficulty;chart;song;synchronization;task;ddr;players;goal;standardized packs", "pdf_keywords": "musical onset detection;onset detection;recurrent neural network;cnn baseline;level audio features;deep learning methods;deep neural networks;conditional lstm;convolutional neural networks;cnn;convolutional neural network;statistical language modeling;rnn;step placement;step selection;ddr choreography algorithms;step placement task;subtasks;spectrograms;consecutive time slices;generative model;steps;datasets;performance evaluations;effective pipeline;gram;insights;best model;window approaches;information"}, "cf46ecac1cb1bdae153be2b909ff3e313034ac9e": {"ta_keywords": "social skills training tools;social skills training aid;social skills;communication skills;communication difficulties;contextual differences;contextual information;communication;context;sensory modality;modality;seconds context;elucidated characteristics;effect;types;computer;people;paper;number;results;trouble;objective;experiments;reasons;variety", "pdf_keywords": ""}, "ef59f05a30972742a714b8903848e4b5dfc5cdaf": {"ta_keywords": "interpretable machine learning;actionable taxonomy;use cases;technical objectives;cases components;iml methods;taxonomy;researchers;methods;evaluation;tool;consumers;iml;types;step workflow;interest;level goals;work;field;foundational work;foundation;lack;gap;connections;significant gap", "pdf_keywords": ""}, "9b9ee9a25fc4d9f8ad22c2923c49b8d5d0b83356": {"ta_keywords": "hypernymy extraction;synonyms;hypernymy relationships;unsupervised sense representations;wiktionary datasets;embeddings;synsets;aware relationships;sets;respective languages;sense;gold standard datasets;english;standard hearst patterns;evaluation;method;paper", "pdf_keywords": "hypernymy extraction task;noisy ambiguous hypernyms;distributional semantics;disambiguation;hypernyms;synonyms;wiktionary datasets;hypernymy relationships;embeddings;synsets;unsupervised way;aware relationships;gold standard datasets;russian;sets;respective languages;unsupervised method;english;hearst patterns;sense;standard hearst patterns;input database;postprocessing;evaluation;substantial performance boost;scale database;study;denoising;method;experiments"}, "923ddc71f8a453c7995e97b0681a674224a5fc09": {"ta_keywords": "machine translation error analysis;machine translation;manual error analysis;error analysis;mt errors;human translators;error selection methods;translations;errors;mt output;accuracy;mt;machine;references;systems;methods;few methods;various methods;method;differences;efficiency;framework;work", "pdf_keywords": ""}, "407eacc5ade80b54126c300b57b81f4b4f411487": {"ta_keywords": "professional human translations;professional human translation;machine translation;language translation;reference translations;human evaluation;english news translation;quality;linguistic context;machine parity;raters;evaluation design;chinese;human;errors;weaknesses;best practice;recommendations;number;empirical investigations;creation;field;availability;investigation;finding;choice;degree;past years;set", "pdf_keywords": "machine translation system outputs;professional human translators;translations;reference translations;human mt evaluation;english translations;professional human chinese;raters;machine parity;linguistic context;quality;output;such outputs;strong mt system;aspects;alternatives;use;conclusion;reference;best practice;recommendations;empirical \ufb01ndings;methods;creation;paper;potential issues;\ufb01rst;availability;special focus;choice"}, "4bf1ea102e1eb1246929bb77c11ebbd6b6d27500": {"ta_keywords": "text generation;sparse prototypes;entire training corpus;novel generative model;strong language modeling performance;prototypes;prototype retrieval function;prototype selection;variational inference;prototype;prototype selection distribution;generation;certain sentence attributes;prototype support;semantics;syntax;sentence;output text;sparsity;different granularity;library;test time;paper;methods;result", "pdf_keywords": "generative models;novel generative model;sparse prototypes;language models;amortized variational inference;text generation;language modeling;learnable prototype retriever;strong language modeling performance;sparse prototype;natural language processing;sparse prototype support;nlp;prototype selection;prototypes;certain sentence attributes;prototype;semantics;text;sentence;previous prototype;welling;syntax;marginal data likelihood;model;different granularity;sparsity;output text;lms;log"}, "93a55f3341aa70bb42c0f76b112e2e8da27b3df2": {"ta_keywords": "ebdm dialogue system;dialogue system;dialogue;dialogue acts;entrainment analysis;entrainment;response selection;lexical level;lexical choice;ebdm;example selection;effect;similar manner;structural level;users;results;previous works", "pdf_keywords": ""}, "bed0452305633791340f80cb0be02f46e4a34b0d": {"ta_keywords": "voice conversion challenge;voice conversion;end speech processing toolkit;input speech;voice;automatic speech recognition;transcriptions;speaker identity;conversion similarity;sequence baseline;speech;seq2seq models;sequence;source end;seq2seq;asr;tts;espnet;models;model;vc;text;official evaluation results;target;system;systems;top;community;terms;promising ability", "pdf_keywords": "voice conversion challenge;voice conversion;e2e speech processing toolkit espnet;end speech processing toolkit;input speech;voice;sequence baseline;automatic speech recognition;transcriptions;sequence;speech;seq2seq;asr;tosequence;tomoki toda1;vcc;tts;baseline system;models;chin huang1;model;vcc20;vc;opensource end;espnet;text;shinji watanabe2;tomoki hayashi1;target;eess"}, "ce97452d031a1a156212f038bab6f47a51575236": {"ta_keywords": "conversational speech;stances;new annotated corpus;stance;prosodic features;much stance;stance strength;sentiment analysis;best classifiers;classifiers;subjectivity;way recognition;text;word unigram features;most common class assignment;polarity;taking activity;negotiations;taking;significant attention;strong accuracies;speaker spurts;activities;style;behavior;binary detection;common class assignment;national budget;decision making;meeting", "pdf_keywords": ""}, "995f4e670c0cdcd5afdef08719c2528a682bff05": {"ta_keywords": "end speech translation model;better intermediate automatic speech recognition;autoregressive transformer asr decoder;asr decoder;high translation quality;end speech translation;comparable translation quality;decoder states;language model;asr;fast md model;connectionist temporal classification;nar hi;autoregressive hidden intermediates;nar;ctc outputs;ctc;na\u00efve md model;teacher;training;mask;outputs;parallel hi;gpu;speed;md;cpu;corpora show;intermediates;fast", "pdf_keywords": "end speech translation model;better intermediate automatic speech recognition;asr decoder;autoregressive transformer asr decoder;high translation quality;end speech translation;comparable translation quality;decoder end;decoder states;asr;language model;fast md model;nar hi;nar;fast multi;parallel hi;ctc outputs;md model;gpu;outputs;mask;cpu;ctc;speed;md;fast;fastmd;model;overall task;hirofumi inaguma1"}, "e2198b039ee5bfa233cf06e65f26a9f3233ada9f": {"ta_keywords": "dialogue act entrainment analysis;dialogue act selection;dialogue participants;switchboard corpus;dialogue act;specific dialogue acts;dialogue;word selection;speech;entrainment hypotheses;entrainment;same speaker;word choice;different speakers;different parts;word;novel measures;patterns;different points;findings;previous studies;user profile", "pdf_keywords": ""}, "29da62b3f8aed3fe98b3f02bbfd436dd8e65a532": {"ta_keywords": "optimal csma;throughput;wireless networks;protocols;protocol;real networking scenarios;symmetric channels;extreme contention aggressiveness;message passing;synchronization;low service;nodes;terminals;utility;flows;performance;custom implementation;theoretical guarantees;promising approach;first comprehensive evaluation;experimental evaluation;methodical approach;paper;evaluation;experimentation;state;example findings", "pdf_keywords": ""}, "4264599665522594d9ecb521dd2e1d002e85a961": {"ta_keywords": "fair matchings;common paper matching algorithms;novel local fairness formulation;local fairness formulation;paper matching;valid matching;peer review process;matchings;fairness;fairflow;reviewer workloads;reviewers;fairir;submissions;new algorithms;papers;algorithms;paper;venues;rounding technique;respect;order;compromises;group;critical problems;loads;sufficient expertise;thousands;relaxation;formulation", "pdf_keywords": "fair matchings;local fairness constraints;novel local fairness formulation;local fairness formulation;competitive fairness;fairflow;valid matching;paper matching;fairness;reviewers;fairir;art matching algorithms;papers;real conference data;reviewing load;paper;new algorithms;constraints;algorithms;rounding technique;higher objective scores;comparison;integer linear program;respect;global objective;compromises;set;loads;state;relaxation"}, "1578fba4a2b2ba819986e32c7da6ebbaf9aacf41": {"ta_keywords": "treebanks;hierarchical neural conditional random field;morphological analysis;syntactic description;morphology;lemmatization;sigmorphon;context;crosslinguality;feature;crf;lemma;model;morpho;task;sequence;paper;eg;shared task;submission", "pdf_keywords": "contextual morphological analysis;entity recognition;machine translation;morphological analysis;morphological feature;multiple related languages;hierarchical neural conditional random \ufb01eld;hierarchical neural model;semantic role labeling;syntactic properties;independent decoders;encoder;prediction;tractable computation time;feature;other features;crf;data sparsity;morpho;model;future work;task;sequence;eg;pos information;several downstream applications;o\ufb02azer;pairwise interactions;hajic;introduction"}, "6e2e7df21a5b5457ea4167133a40bc729028250d": {"ta_keywords": "passage ranking;modern neural rankers;core information retrieval tasks;leaderboards;preference judgments;top item;ms marco datasets;queries;datasets;relevant item;document;workers;dramatic improvements;stack;passage;observation;recent years;pools;enormous gains;runs;development set", "pdf_keywords": "passage ranking;core information retrieval tasks;informational retrieval tasks;top document;sparse labels;leaderboard;top passage;top item;sparse;preference judgments;queries;unprecedented improvements;top;document;substantial new research;shallow pooling;datasets;relevant item;observation;adhoc passage;researchers;core;passage;stack;section;suggestions;workers;abstract recent years;enormous gains;qrel"}, "80257b7d02ad4d6a762ebc0d7f1560e0ef182354": {"ta_keywords": "politeness transfer;polite sentences;politeness;style transfer accuracy;stylistic attributes;content preservation;automatic metrics;source content;other transfer tasks;target style;benchmark evaluations;generate approach;tag;sentence;new task;pipeline;better performance;dataset;art methods;instances;model;meaning;paper;state", "pdf_keywords": "politeness transfer task;politeness domain;politeness;counterfactual modal strategy;popular style transfer tasks;style transfer tasks;enron corpus;stylistic attributes;formal setting;neutral style;sentences;grammaticality;tasks;human evaluations;north american english;attention;1st person plural;target style;email exchanges;subtle concept;notion;content;sentence;second sentence;requirement;source content;\ufb01rst sentence;addressee;pipeline;burden"}, "09093e29b1f705bb7a68ea2e9240b3f122efe92b": {"ta_keywords": "blind source separation;input speech recognition;stereo;sparseness", "pdf_keywords": ""}, "3edfccbe6adf18f5263cd2adf3d977bbc5811e0b": {"ta_keywords": "faster attention learning;automatic speech recognition;asr encoder;novel data augmentation method;model speaker dependencies;machine translation;attention;encoder model;neural text;end asr;speech signals;style data augmentation;e2e;acoustic features;translation technique;asr;text;translation;characters;sequence;end;hidden states;target;computational cost;paper;use;large amount;field;thanks;sub", "pdf_keywords": "asr encoder;asr decoder;neural textto;machine translation;neural text;encoder;end asr;novel data augmentation method;attention;encoder model;translation technique;asr models;synthetic speech;speech processing;asr model;e2e;decoder;automatic speech recognition;translation approach;asr;phoneme conversion;pseudo speech sequences;text;speech system;tte model;style data augmentation;additional training data;tte;speech signals;unpaired text"}, "e6aaac94df717786a467d057cb2157b9d49f0974": {"ta_keywords": "regret algorithms;optimistic mirror descent;regret policies;convergent opponents;social regret;individual regret;adversarial opponents;regret;nash equilibrium;stable games;play converges;sum games;theoretic guarantees;games;equilibrium;prior tuning;learning algorithm;game;concave;knowledge;divergent trajectories;performance;players;desirable properties;others;cyclic;class;best response;terms;sequence", "pdf_keywords": "optimal regret bounds;optimistic dual averaging;online learning;continuous games;optimistic mirror descent;adaptive learning;adaptive learning rate;adaptive algorithms;stable games;nash equilibrium;learning theory;stable game;games;optmd;optda;continuous action spaces;algorithms;equilibrim convergence result;players;knowledge;player;univ;local information;convergence;ds;literature;guan hsieh;concluding;methods;grenoble"}, "efaf07d40b9c5837639bed129794efc00f02e4c3": {"ta_keywords": "authorship attribution;continuous representations;discrete feature representations;gram features;neural network;datasets;classification layer;art;previous work;model;paper;comparable results;experimental results;contrast;state", "pdf_keywords": ""}, "9d9159026023f21e633f84fd61f3efad2e410214": {"ta_keywords": "order logic embeddings;knowledge base completion;plausible inference formulas;many complex reasoning tasks;inference formulas;embeddings;relation extraction;dimensional embeddings;inference problems;matrix factorization;order logic;proof graphs;facts;rows;background facts;training examples;formulas;examples;datasets;structural gradient;columns;artificial intelligence;art baselines;binary matrix;structure;first;information integration;scratch;task;work", "pdf_keywords": ""}, "46f66dd37e6366ce102cfd97e718947151d5b1eb": {"ta_keywords": "fake news detection;news environment perception;news environment perception framework;news environment;external news environment;news posts;fake news fabrication;fake news post;fake news;news post;public attention;social media;recent mainstream media opinion;content;dissemination;unexpected novel content;readers;knowledge sources;misinformation;language patterns;spread;zoom;environmental signals;popular events;information;real ones;nep;greater exposure;wave;important inspiration", "pdf_keywords": "fake news detection;fake news fabrication;contemporary mainstream news data;news environment perception;news environment;news posts;fake news;news environment perception framework;social media;recent mainstream media opinion;online social media;public trust;public attention;misinformation;world threats;dissemination;rundong li;xueyao zhang;qiang sheng;politics;datasets;intelligent information processing;spread;yongchun zhu;\ufb01rst dataset;wang;unexpected novel content;chinese academy;popular events;wide spread"}, "8122eaeb63098e94416108df918c9669e9105e65": {"ta_keywords": "low latency cluster cache;cache;selective replication;intensive clusters;online erasure;memory;severe load imbalance;replicas;writes;servers;object stores;ec;background load imbalance;memory object;erasure;additional bandwidth;reads;popularity;popularity skew;metadata;read latencies;data;server failures;load;small increase;same amount;individual objects;systems;limitations;object", "pdf_keywords": ""}, "8d64be0d3bb2650ff99a4c1ae8049eb5fece27a1": {"ta_keywords": "emotional speech recognition;emotional speech;automatic speech recognition;bottleneck features;emotion adaptation model;deep neural network;features;essential features;bottoleneck sturucture;phoneme;layer;asr;other layer;small number nodes;normal model;improvement results;system;study", "pdf_keywords": ""}, "f8f17f32e651840531276423c7196856d27bcdd0": {"ta_keywords": "semantic web search;natural language;swsnl", "pdf_keywords": ""}, "ee7af49291c030a3e29ad7a9cb5c1975d1b644f4": {"ta_keywords": "antenatal clinic;nutritional supplements;pregnant women;intake;assessment", "pdf_keywords": ""}, "1cbb43b4d7f79d986a4a78ad3b53368c49e496ee": {"ta_keywords": "automatic speech recognition systems;asr system;channel feature enhancement;discriminative training;reverb challenge;deep recurrent neural network;room acoustics;reverb data;channel input;delay beamformer;feature enhancement;utterance;drnn;feature transformations;art speech;channel;improved back;average word error rates;arrival estimation;wers;challenge baseline;output;drastic improvement;adaptation;spectral domain;real evaluation sets;log;system;end side;simple clean", "pdf_keywords": ""}, "d0fbae81d870bbfb34430654f70fd6a21e8bd1cc": {"ta_keywords": "coreference annotations;entity mentions;art reading comprehension model;coreferent dependencies;multiple mentions;nlp;recurrent layer;babi ai tasks;text;training data;same entity;layer;information;wikihop;datasets;external system;same cluster;many problems;lambada;performance;large gains;state", "pdf_keywords": "powerful reading architecture;art reading comprehension model;standard rnn layer;annotations;recurrent layer;nlp;comprehension problems;coreferent recency;babi ai tasks;training data;wikihop dataset;multiple mentions;useful inductive bias;text;wikihop;bias;datasets;information;same entity;layer;data regime;conclusion;results;model;performance;goal;kind;such systems;large gains;introduction"}, "071216d944bcd2f05deafdb94e657167cce148d9": {"ta_keywords": "personal names;sequential classifier;email;newswire text;precision tradeoff;user;task;performance criterion;method", "pdf_keywords": ""}, "1ebf54c0a8b38e8c26ed857cb9d4e565a8f17f17": {"ta_keywords": "entity similarity;enron email corpus;person name disambiguation;similarity metric;graph walk performance;graph walk results;finite random graph;nodes;search;denote entities;such graphs;other corpora;personal information;relations;persons;walk;graph;alias finding;edges;tasks;links;task;messages;other object types;tool;threading;features;terms;researchers;paths", "pdf_keywords": ""}, "72a5c01afe276d06ca9179e24b1c925e206454f3": {"ta_keywords": "knowledge graph entities;personalized pagerank procedure;knowledge graphs;explainable entity;external knowledge;recommendations;explanations;reviews;content;items;many methods;method;paper;scenario;form", "pdf_keywords": "recommender systems;personalized pagerank procedure;knowledge graphs;knowledge graph entities;external knowledge;personal agent;recommendations;dialog model;explanations;movies;list;predictions;interaction;entities;items;accuracy;introduction;method;important research topic;paper;user;scenario;form"}, "f800f60db4427a51e564f1b875ae01d2c642fdce": {"ta_keywords": "minimum possible repair;functional repair;data recovery;repair code;replacement node;exact repair;storage;repair;bandwidth tradeoff;nodes;solomon codes;bandwidth;node;mere transfer;transfer;codes;code;data;reed;tradeoff;separate tradeoff;ability;arbitrary subset;paper;existence;special case;class;addition;subset;case", "pdf_keywords": "helper node pooling;abstract regenerating codes;storage codes;replacement node;minimum possible repair;minimum bandwidth regenerating point;data recovery;repair code;storage;storagebandwidth tradeoff;solomon codes;repair;node network;node;bandwidth tradeoff;code construction;bandwidth;ieee;codes;transfer;data;reed;interior points;arbitrary subset;system;ability;such scenarios;separate tradeoff;tradeoff;special case"}, "b2f46145f2a50b609482a69d0581b218a6767cef": {"ta_keywords": "ranked retrieval methods;information retrieval;deductive databases;textual similarity;knowledge integration system;ir similarity metrics;like queries;conventional databases;database;queries;information access system;many information sources;object identifiers;structured collection;novel logic;web;inference;logic;whirl;text fragments;equality tests;normalization;information;multiple web sites;models;text;keys;ir;extraction;human engineering", "pdf_keywords": ""}, "80fdacd50ba9ad2e594dd2ddb0b1fa0e591f37ea": {"ta_keywords": "biomedical event extraction;backgroundbiomedical event extraction;event extraction;structured prediction;structured prediction framework;classification tasks;complex regulation events;genes;abstracts;molecular biology;bionlp;classifiers;search;substantial attention;full papers;article;task;models;researchers;score;publications;most recent work;points;interactions;submission;systems;paradigms compare;accuracy;context;gains", "pdf_keywords": ""}, "d46ecbacf42748ac9ce1fecd9f1b4ed0b9e34980": {"ta_keywords": "email speech acts;conversational analysis;email messages;intents;act classification;certain intents;gram selection;message exchange;acts;messages;gram sequence;contextual information;email;meeting;task;classification;analysis;careful message;combination;paper", "pdf_keywords": ""}, "b350be3836c3d183464642815b26b061f24e8314": {"ta_keywords": "number embeddings;integer embeddings;embeddings;mathematical knowledge;numerical reasoning tasks;integers;mathematical sequence data;representations;mathematical properties;mathematical applications;concepts;english text corpora;set;work", "pdf_keywords": "integer embeddings;number embeddings;integer representations;embeddings;english word embeddings;integer sequences;mathematical sequence data;number sequences;numerical reasoning tasks;mathematical knowledge;mathematical resources;mathematicians;mathematical regularities;oeis;representations;online encyclopedia;several types;ones;vocabulary;database;text;tasks;data;interest;paper;set;source;better performance;work;properties"}, "e602bde46bca5f424a3d53675c1275386544eb1e": {"ta_keywords": "concept learning;representation shift;analysis", "pdf_keywords": ""}, "7fcc2cc70498e409168a6c3dfd7c59652b1160c2": {"ta_keywords": "single feature transformation matrix frame;multiple transformation matrices;transformation matrices;single transformation matrix;adaptation data;space adaptation framework;efficient adaptation;adaptation;acoustic features;deep neural network;map estimation;space adaptations;posteriori linear regression;feature;matrices;linear regression;gmm framework;same generative model;dnn;prior distributions;frame;fsmaplr;space maximum;alignments;multiplication operation;fmllr;structural maximum;addition;weighted sum;space", "pdf_keywords": ""}, "dda3f2a2803c80e5b3332868bf86901d6239befc": {"ta_keywords": "stochastic optimization methods;new scalable decentralized fault;new optimization methods;compensated sgd;centralized local;gradient compression;sgd;stochastic;iteration complexity;local updates;heterogeneous local functions;error compensation;local;methods;local steps;method;frameworks;ones;new theoretical frameworks;error;thesis;reasonable assumptions;analysis", "pdf_keywords": ""}, "9dc4a5284ecfd37ab8bc8990eddf1b39113e004b": {"ta_keywords": "machine translation;monolingual data;target domain mismatch;target domain mismatch problem;translation;local context;language;different cultures;source;target side;domains;different places;training;empirical evidence;degradation;self;back;world;specific place;metric;effect;many events;day life;concept;existence;work;amount", "pdf_keywords": "low resource machine translation;machine translation;translation task;distant languages;target domain mismatch;local context;language;languages;social media platform;mtnt;wmt;apart regions;low resource settings;uncurated content;datasets;unrelated local events;distinctive cultural traits;source;domains;stdm;smd;world;formal de\ufb01nition;neubig;effect;work;conclusion;consequences;michel;intrinsic property"}, "128610c7df12bff1610949c551b6236cb350dcd9": {"ta_keywords": "automatic speech recognition;attention model;language models;nar ctc;text representations;previous nar systems;attention;novel modality conversion mechanism;recognition accuracy;proposed nar model;logographic languages;english tasks;asr;ctc;speech;bert;models;bottleneck;modality gap;ctc branch;e2e;tokens;relative cer reduction;cache;transformers;speed;inference;parallel;end;paper", "pdf_keywords": "end speech recognition;automatic speech recognition;novel nar ctc;nar models;speech acoustics;nar ctc;attention architecture;attention model;language models;recognition performance;ctc;text representations;recognition accuracy;attention;speech;asr;models;acoustics;e2e;transformers;training ef\ufb01ciency;novel modality conversion mechanism;bottleneck;jan;bert;speed;text modalities;logographic languages;chinese academy;china 2university"}, "4e1d27c68a60bfd8393462107677469bf286f0f8": {"ta_keywords": "pragmatic program synthesizer;program synthesis;program synthesis techniques;program synthesis task;pragmatic communication;pragmatics;recursive reasoning models;program;specification;output examples;rational communication;programs;synthesis problem;particular specification;rational speaker;candidate program;many programs;new inductive bias;user study;user participants;consistency;most specifications;specifications;end;users;insights;user;work", "pdf_keywords": "pragmatic program synthesizer;pragmatic program synthesis system;program synthesis;pragmatic communication;program synthesis task;pragmatics;utterances;synthesis algorithm;recursive reasoning models;informative speakers;computational linguistics;synthesizer;output examples;rational communication;communication;astute listeners;intent;actual human interaction data;new paradigm;new inductive bias;ef\ufb01cient algorithms;forward;like layout domain;ambiguity;ideas;approach;simple grid;insights;kind;study"}, "09e4e0eee756da5658c6d572871130d53a89c72b": {"ta_keywords": "optimal bayesian incentive;bayesian persuasion;optimal bic recommendation policy;action recommendation policy;action recommendation;desirable actions;algorithmic recourse;underlying predictive model;decision subject;linear program;desirable outcome;action space;game;gaming;features;decision;computational complexity;competitive advantage;bic;many situations;maker;observable features;ways;optimization problem;making;chances;such settings;signal;relative size;subjects", "pdf_keywords": "bayesian persuasion;persuasion;persuasion mechanism;optimal signaling policy;favorable decision;decision maker;action recommendation;strategic decision subjects;decision subjects;algorithmic recourse;underlying predictive model;decision subject;desirable ways;utility;policy;information;strategic interaction;natural alternatives;public knowledge;decision;actions;game;knowledge;credit;expectation;home equity line;dataset;features;observable features;recourse"}, "933b03a81110676f4c61c449f1926ebd58bc47f7": {"ta_keywords": "visual user interfaces;dynamic touchscreens;statelens ios application;touchscreens;inaccessible dynamic touchscreens;screen;interactive guidance;interface;statelens;blind users;state diagrams;interface actions;interfaces;reverse engineering solution;flight entertainment systems;underlying state diagrams;multiple different screens;web videos;conversational agents;computer vision pipeline;view videos;user study;interactions;technical evaluation;hand;tasks;subway ticket machines;hybrid crowd;feedback;users", "pdf_keywords": "touchscreen interfaces;touchscreen accessibility;statelens ios application;accessibility;interactive guidance;touchscreen devices;input assistive;interface;blind users;capacitive screen input;state diagrams;interfaces;screen;statelens;interactive feedback;3d;audio guidance;conductive pla accessibility;interface structures;assistive \ufb01nger cap;conversational agents;resistive screen;guidance;computer vision pipeline;system;view usage videos;tasks;prosthetic \ufb01nger;model;task"}, "d462eae8dd5c1415e03651b9fc1c2ca80a69521f": {"ta_keywords": "tutors;world background knowledge;smart authoring;simulated student;complex prior perceptual skills;background knowledge;learning mechanisms;perceptual learning;external world knowledge;extensive understanding;article selection;text;simstudent;semantics;math;task;phrases;english words;english;solving;different task;methods;accuracy;generality;systems;performance;ability;little problem;production rules;domains", "pdf_keywords": ""}, "730e5e83586dd5784051f933e7bb82571cec4c94": {"ta_keywords": "speech separation methods;domain audio separation network;speech separation;end neural speaker diarization;end speaker diarization;speaker counting performance;speech activity;speech signal;separation performance;separation masks;convolutional layer architecture;speakers;encoder;decoder;convolutional time;convtasnet;diarization;librimix dataset show;eend;eda;joint end;attractor calculation;number;\ufb02exible numbers;end;flexible number;baselines;ss;terms;method", "pdf_keywords": "convolutional timedomain audio separation network;speech separation methods;domain audio separation network;end neural speaker diarization;end speaker diarization;speech signal;speech activity;speech signals;convolutional layer architecture;separation;separation masks;encoder;convolutional time;speakers;speech;decoder;convtasnet;tasnet;joint model;joint end;end;eda;conv;attractor calculation;eend;addition;ss;number;method;variable number"}, "1548142a6be92f41e45dcbde9ff8afd71134ac1d": {"ta_keywords": "lung cancer risk;low potential lung cancer risk;inhalation exposure;incremental lung cancer risk;aromatic hydrocarbons;pollution level;pm10 samples;priority pahs;pahs;mean concentrations;united states environmental protection agency;pm10;polycyclic;median values;male adolescents;female adolescents;nanjing;usepa;china;male seniors;female seniors;m3;summer;sources;middle level;female adults;male adults;girls;ng;boys", "pdf_keywords": ""}, "f48792e8a24e369c80e39a2a2b7451d108f02941": {"ta_keywords": "question answering;explainable question answering;other ai applications;qa;xqa system;information;questions;interface;information pollution;xqa;friendly interfaces;web;interfaces;reasoning steps;transparency;learning;core concepts;black boxes;details;challenges;feedbacks;access;answer;context;system;validate provenance;light;computational model;expectations;end", "pdf_keywords": ""}, "642c85d35b4a3cc9648b269e32fe9d0a18907c98": {"ta_keywords": "long recording speech separation;level speech separation;continuous speech separation;separated speech;long recording;speech sources;window processing;recording;conventional utterance;asr evaluation;meetings;consistent wer reduction;relative wer reduction;better wer evaluation;window;online processing;speakers;path models;path modeling;css task;baseline;models;task;straightforward extension;css;libricss;computation amount;capability;number;thanks", "pdf_keywords": "long recording speech separation;speech separation performance;real meeting recordings;automatic speech recognition evaluation;libricss meeting recordings;real meeting scenarios;rnn;short memory;baseline bsltm;word error rate;path transformer;relative wer reduction;path models;convolutional sampling;path modeling;transformer;dp models;path modeling method;blstm;baseline;path;testing set;dp;popular models;different window sizes;paper;css task;experimental results;computation amount;experiments"}, "acf0ccc8b67cc441c51d4281c305359073b9c7cc": {"ta_keywords": "speech translation evaluation campaign;end speech translation systems;end speech translation system;speech transcription;text translation components;speech transcription system;independent neural network systems;encoder;attention;decoder model;transfer;small datasets;espnet;training;iwslt2018;pipeline system;kyoto university submissions;end;jhu;johns hopkins university;comparison;parameters;paper;approach", "pdf_keywords": ""}, "9cfc4e94e76d8025cd86d6652a641b1440681d28": {"ta_keywords": "specific combinatory categorial grammar;linguistic principles;induction algorithm;verbs;sentences;lexicon;language;nouns;ccg;arguments;bisk;system;em;roots;small number", "pdf_keywords": ""}, "d0a6b70c9dc1942169f48211d47843732c57a3a9": {"ta_keywords": "natural language grounded navigation;agnostic multitask learning;multitask navigation model;richer natural language guidance;generalized navigation model;navigation;dialog;navigation model;navigation policy;language navigation;dialog history;unseen environments;vision;natural language instructions;natural language;agnostic representations;ndh task;novel perspectives;tasks;goal progress;training;knowledge;environments;environment;baselines;realistic environments;photo;gap;ndh;relative measure", "pdf_keywords": "navigation tasks;multitask navigation model;richer natural language guidance;multitask learning;generalized navigation model;language navigation;navigation policy;generalized multitask model;agent learning;dialog history;navigation;agnostic learning;natural language;agent;tasks;generalized policies;challenging tasks;knowledge;agnostic representations;transfers knowledge;unseen environments;vision;agents;training;environments;novel perspectives;environment;approaches;space;vln"}, "cdf17da4a7638985cb62a5dbf1161239b315eb85": {"ta_keywords": "topic models;entity link;topics;mixed membership stochastic block models;protein interaction;protein interactions;proteins;entities;entity;enron email corpus;protein;social networks;joint modeling;links;functional category prediction;corpus;latent groups;abstracts;text information;scientific publications;datasets;text;dataset;link;model;data;ppi dataset;observed interactions;perplexity;pairs", "pdf_keywords": ""}, "c0484ac1677b942e8b06ea0ac3cad5b01e52ced4": {"ta_keywords": "relevant context selection;question", "pdf_keywords": ""}, "092b80cc6250f74a2c1e0ba7820c31a8f0153c0a": {"ta_keywords": "postmodern novel invisible cities;literary works;literature;such literary analyses;distant reading;literary critics;literary criticism;invisible cities;literary scholars;imaginary cities;single literary theory;contextualized representations;novel;natural language processing methods;digital humanities;cities;embeddings;categorization;city;short descriptions;italo calvino;thematic groups;unsupervised methods;classification;description;careful reading;large collections;calvino;unique structure;previous work", "pdf_keywords": "postmodern novel invisible cities;literary works;literary criticism;literary critics;literature;distant reading;invisible cities;human readers;imaginary cities;similarity judgments;single literary theory;novel in\ufb01nite jest;close reading;art text representation methods;multiple narrative threads;natural language processing;novel cloud atlas;short descriptions;single book;italo calvino;careful reading;conclusion;abstract;large collections;light;focus;wallace;results;analysis;computational approach"}, "63cd8df0041638b0aa74834a81f99ff136951ff1": {"ta_keywords": "binarygan;novel generative adversarial network;generative adversarial networks;gans;gan objectives;gan;binary neurons;end backpropagation;gradient estimators;mnist digits;end backpropogation;generator;output layer;sigmoid;discrete distributions;gradients;estimators;end;promising direction;whole network;network architectures;model;different types;performance;results;use", "pdf_keywords": "binarygan;training generative adversarial networks;novel generative adversarial network;gans;gan objectives;gan;binary neurons;end backpropagation;end backpropogation;mnist digits;gradient estimators;generator;output layer;gradients;end;estimators;promising direction;model;network architectures;whole network;yi;discrete distributions;hsuan yang research center;different types;abstract;performance;oct;use;results;it innovation"}, "655b842ae905756b2949758bd7e52e5fd32c3642": {"ta_keywords": "large vocabulary continuous speech recognition;speech recognition;most speech recognizers;viterbi beam search;search error risk minimization;beam search;pruning function;pruning step;search error risk;recognition lattices;rich features;rank;lvcsr;training step;heuristic criteria;partial hypotheses;precise decision;complete hypothesis;function;risk;score;partial hypothesis;method;hypothesis;parameters;conventional methods;paper;process", "pdf_keywords": ""}, "28421c7f28adfb9ab8aeb56c196ac3ba326efdbb": {"ta_keywords": "trypsin;active center;studies", "pdf_keywords": ""}, "7c72e63aa112193590861887c5d03b640ce90911": {"ta_keywords": "machine learning;third international conference;proceedings;twenty", "pdf_keywords": ""}, "3a6334953cd2775fab7a8e7b72ed63468c71dee7": {"ta_keywords": "social skills training systems;social skills training system;social skills training;human social skills trainers;social skill training;audiovisual features;audio features;social interaction;social communication difficulties;linguistic features;computer interaction;appropriate skills;superior skills;visual features;human trainers;computers;pitch;result computer;effectiveness;experimental evaluation measures;method;people;yaw;paper;account;ratio;gap;difference;previous works;several parts", "pdf_keywords": ""}, "4e9328b2801e158647dff69606ed47d47045eca8": {"ta_keywords": "datasets;datalab;dataset recommendation;data ecosystem;unified data;data;machine learning;gender bias;data analysis;features;feature functions;tools;different data processing operations;platform;hyponyms replacement;users;researchers;global vision analysis;research;view;crucial role;various analyses;version;characteristics;better view;top;systems;intervention;standardized interface;ongoing proliferation", "pdf_keywords": "natural language processing;nlp researchers;deep learning;tokenization;data diagnostics;machine learning models;machine learning systems;dataset;datalab;deeper understanding;data;learning;machine;models;empirical methods;tasks;uni\ufb01ed platform;outputs;ijcnlp;emnlp;class citizen;9th international joint conference;researchers;various statistical analyses;lipton;november;research;paper;conference;users"}, "1e9771a264334c45020421b1c847f6bcd88adc60": {"ta_keywords": "accurate annotations;ground truth annotations;3d;networks;annotation inaccuracies;annotations;3d structure;deep learning;3d interfaces;active contour models;connectivity;learning;topology;data;large scale;approaches;end;people;paper;trouble;practice;method;part", "pdf_keywords": "annotations;annotation inaccuracies;deep network;original annotations;network;active contour models;computer vision laboratory;joint optimization;imprecise;network parameters;leonardo citraro;doruk oner;node positions;topology;potential errors;same performance;main insight;fua;epfl;computer;end;pascal;paper;communication sciences;terms;school;method;approach"}, "80111013916dae3306316c34e13fe856cb08b87b": {"ta_keywords": "intuitionistic default rulebase;inheritance hierarchies;default rulebase;inheritance network;human common sense reasoning;default rules;classical logic;explicit exceptions;analogous queries;seminormal defaults;general purpose algorithms;exceptions;interpreter;standard examples;adequate proof theory;incompatible systems;topology;advantage;design;alternative technique;case;various strategies;approach;etherington;goal;reiter;paper;literature;claim;recent years", "pdf_keywords": ""}, "69e8c4327193af4549c06809c821c99deb4022cd": {"ta_keywords": "storage;node;symbols;complete data;data;network;several parameter sets;explicit constructions;key additional requirement;paper;problem;interest", "pdf_keywords": ""}, "a77643bff6f50ccc4f80ec081e4d078a2e788ae7": {"ta_keywords": "multilingual benchmark;multilingual representations;subword segmentation;subword regularization methods;multilingual vocabulary;different possible input segmentations;standard segmentation algorithms;probabilistic segmentations;languages;predictors;xtreme;representations;consistent improvements;standard heuristic algorithms;mvr;inputs;full advantage;data;kudo;tuning;results;points;consistency;method;effectiveness;limited amounts", "pdf_keywords": "subword regularization methods;subword segmentation;unigram language models;multilingual representations;multilingual vocabulary;multilingual;common deterministic segmentation methods;sebastian ruder2 graham neubig1 1language technology institute;different possible input segmentations;probabilistic segmentations;different segmentations;probabilistic variants;xtreme benchmark;representations;byte pair encoding;training;ulm;xinyi wang1;tuning discrepancy;\ufb01ne;mvr;empirical examination;full advantage;predictions;variety;apr;kudo;cl;tuning;knowledge"}, "bf50833a46839d3932663b472d6145418f9d0bd6": {"ta_keywords": "microphone arrays;multiple microphone arrays;attention networks;automatic speech recognition;joint connectionist temporal classification;regular attention networks;stream attention;encoder;separate encoders;informative encoders;decoder architecture;decoder;information streams;relative word error rates;asr;datasets;array results;wers;end;ami;ctc;e2e;framework;field robustness;advances;instruction;top;great success;work;reduction", "pdf_keywords": "attention architecture;attention model;stream attention;hierarchical attention mechanism;microphone array situation;attention;end asr framework;ordinary attention;e2e asr;microphones;encoders;decoder;end asr;speech;higherlevel representations;level fusion;arrays;joint ctc;array;posterior combination strategy;wordlevel technique rover;hierarchical connection;joint training;architecture;substantial wer reduction;perencoder ctc;labels;ami;signal;end"}, "d6e21619df572d04b2b2d97b4c5d1fd604f185fb": {"ta_keywords": "faster neural machine translation;neural machine translation;predicted parse;synst decodes;parse tree;autoregressive transformer;standard decoders;synst;transformer;transformers;target tokens;timestep;long outputs;higher bleu scores;inference;shot;baseline;single target;work;series;methods;experiments", "pdf_keywords": "syntactic chunks;predicted parse;external constituency parser;parses;parse decoder;single layer parse decoder;parse tree;chunk sequence;small output vocabulary;latent space;synst;autoregressive transformer;chunks;target tokens;sequence;transformer architecture;transformer;output;training;essential components;simpler model;average chunk size;1source code;bottleneck;model;process;steps;target;terms;\ufb01rst"}, "a5f42552b2368a587aea0a81175b4a79aa614601": {"ta_keywords": "collaborative filtering;classifiers;concept learning;certain machine learning systems;web data;extraction systems;web pages;web;concept;new features;free data;useful information;information;clear semantics;cl;simple method;cf;systems;noise;quality;creation;error rate;human intervention;wide variety;previous work;situations;set;problem;consequence;goal", "pdf_keywords": ""}, "0e61536550b7263d67b2928473355171dc37c0ae": {"ta_keywords": "argument components;structures", "pdf_keywords": ""}, "7f0dbd30dc839fd95ea953a9229c879396ca11c0": {"ta_keywords": "symbolic knowledge base;scalable neural methods;neural modules;matrix implementations;original semantics;large kbs;matrix;kb;representation;entities;facts;reasoning;millions;multiple gpus;novel way;tens;orders;magnitude", "pdf_keywords": "symbolic knowledge base;neural semantic parsing;neural kbqa models;kb relations;symbolic reasoning;symbolic kb;scalable neural methods;kb entity sets;simpler architectures;kb;kb completion;matrix rei\ufb01ed kb;sparse matrices;simple architectures;kbs;realistic kbs;denotations;new architectural component;rei\ufb01ed kb;independent kb;reasoning;matrix implementations;entities;neural network;relations;many relations;naive implementations;encoding;iclr;synthetic tasks"}, "c2c6c9947dc9d28bb4fc6f965310be517f4d8c57": {"ta_keywords": "generative adversarial networks;gans;label based shape synthesis;shape synthesis;shape messages;voxel;wgans;color shapes;text;more distinctive class features;natural language text;complex shapes;synthesis;art method;independent class classifier;generator;lbwgan;descriptions;new structure;novel method;structural integrity;task;exquisite performance;paper;better performance;method;results;work;approach;achievements", "pdf_keywords": ""}, "81dd3faf762ad8f084ab1d7b8fc9e77e9e160f85": {"ta_keywords": "language models;relational knowledge;knowledge;better prompts;prompts;intriguing results;correct profession;profession;lms;prompt;accuracy;inappropriate prompt;obama;lm;lama benchmark;facts;estimate;blanks;extensive experiments;methods;abstract recent work;paper;process", "pdf_keywords": "relational knowledge;language models;paraphrasing;better prompts;factual knowledge;knowledge;lm prompt;gleaning insights;diverse prompts;automatic methods;relation;prompts;query archive;lms;breadth;extensive analysis;methods;conclusion;code;process;quality;mining;ablations;importance;existence;lpaqa;paper;speci\ufb01c pieces;potential directions"}, "2c5a410b781f90c145efac05fea235c5c3e44861": {"ta_keywords": "source voice conversion framework;source voice conversion;speech representation;speech representations;s3prl toolkit;expensive supervised representation;synthesis vc;s3prl;vcc2020;art vc systems;vc;a2a vc;s3r;toolkit;s3r community;vc community;recognition;top systems;self;a2a;subjective evaluation;extensive analysis;a2o;framework;tasks;context;potential;similarity;state;depth analyses", "pdf_keywords": "source voice conversion;source voice;supervised speech representations;s3prl toolkit;s3prl;s3r;vcc2020;comparable performance;vc;a2a vc;top systems;yi lee2;competitive system;chin huang1;subjective evaluation;sd;taiwan 3carnegie mellon university;extension;wen yang2;framework;shu;similarity;model design choice;shinji watanabe3;2national taiwan university;art performance;a2o;terms;tomoki hayashi1;tomoki toda1"}, "3db9649f2ae986cac13f3e748375f8802f9b07fc": {"ta_keywords": "machine translation;translations;deep neural networks;compression techniques;resource constraints;data limitations;memorization;sparsity;capacity;frequent sentences;resource;low frequency attributes;resource regimes;training distribution;art networks;performance;generalization;double bind;english;datasets;infrequent ones;robustness;data;importance;surprising insights;yoruba;magnitude;parameters;task;distribution shifts", "pdf_keywords": "neural machine translation;resource machine translation;transformer nmt models;pruning methods;pruning;nmt models;pruning method;deep neural networks;african languages;vocabulary ratios;languages;masakhane nlp;nmt;low resource;language;models;sentences;english;art networks;german;large scale experiments;morphological features;orevaoghene ahia;test corpora;knowledge;parameters;resource double bind;addition;magnitude;yo"}, "12442420adf1c36887fafd108f4b7f4fc822ae60": {"ta_keywords": "neural sequence generation tasks;complex sequence generation tasks;text summarization benchmarks;standard machine translation;supervised baseline;self;noisy self;unlabeled data;training;input space;empirical study;classification problems;large margin;performance;noise;perturbation;performance gains;states;careful examination;work;mechanism;version", "pdf_keywords": "neural sequence generation tasks;neural sequence generation;text summarization benchmarks;standard machine translation;supervised baseline;self;neural networks;training;iclr;deep;unlabeled data;prediction;noisy self;dropout;dataset;performance;improvement;data;good performance;crucial ingredient;abstract;empirical study;hidden states;pseudo targets accounts;perturbation;model;introduction;conference paper;new york;base model"}, "299ab255f3d940a20891128dfa9e0736d74a936c": {"ta_keywords": "goal directed robotic vision;traditional computer vision pipeline;modern vision architectures;perceptual systems;attention mechanisms;robotics;summary representation;agent;current goal;early fusion;entire scene;specific representations;goal;novel architectures;tight computational budgets;input;more parameter;domain", "pdf_keywords": "vision architectures;earlyfusion vision models;imitation learning;traditional perception pipeline;visual processing pipeline;scene representation;vision;downstream tasks;novel neural architecture;visual stream;objects;object detection;custom representations;goal information;robust learning;early fusion;perceive;action;goal;simulated table clearing task;3d environment;agents;simulated item retrieval problem;paradigm;top row;end;end manner;contributions;work;reason"}, "5c6ff5836639e87e8afeaad47e64d0e2234566e8": {"ta_keywords": "aware fake news detection;fake news detection;aware fake news detection methods;head attentive network;textual claims;fake news;evidence;level attention;external sources;misinformation;check information;public health;recent trend;politics;word;aid explanation;check;urgent need;paper;only word;suboptimal performance;level;model;economics;various domains", "pdf_keywords": "aware fake news detection;fake news detection;aware fake news detection methods;evidencelevel;hierarchical multihead attentive network;textual claims;fake news;head attentive network;level attention;word datasets;evidence;external sources;misinformation;ai;multihead document;check information;recent trend;word;widespread;politics;public health;aid explanation;check;paper;urgent need;level;only word;suboptimal performance;model;abstract"}, "963c62b7c4b44ff1fe6aa1f45fa8a7d62b3d5051": {"ta_keywords": "generic textual entailment system;conceptnet;arc challenge dataset;school science exams;end qa task;science exam questions;large corpus;questions;multiple choice questions;background knowledge;current qa systems;nlp;qa;queries;several strong baselines;grade;ai;text;query;ai methods;results;scitail;essential terms;science;rewriter;progress;random chance;question;original source question;domain question", "pdf_keywords": "automated knowledge base construction;generic textual entailment system;information retrieval;query reformulation;query expansion;nlp;end qa task;ai methods;generalizable decision methodology;textual entailment;ai;answer candidates;qa;background knowledge;generalizability;multiple choice questions;abstract;several strong baselines;domain question;computer science urbana;conference paper;computer science new orleans;arc challenge dataset;essential terms;reformulation;best answer;results;arc dataset;paper;system"}, "e28b9bc26f5f7eb3b0532d823713400202372da2": {"ta_keywords": "critic algorithms;critic algorithm;stackelberg game;reinforcement learning algorithms;critic interaction;theoretic reinforcement learning algorithms;stackelberg actor;critic;leader player;sum game;abstraction;openai gym environments;hierarchical interaction;usual individual gradient;follower structure;leader;game;standard actor;player;actor;objective;total derivative;theoretic interpretation;viewpoint;framework;experiments", "pdf_keywords": "critic reinforcement learning algorithms;stackelberg game;deep deterministic policy gradient;sum stackelberg game;critic interaction;stackelberg gradient dynamics;stackelberg actor;theoretic reinforcement learning algorithms;reinforcement learning algorithms;reinforcement learning;policy player;critic;actor critic;stackelberg;reinforcement learning problem;model player;usual individual gradient dynamics;sum game;hierarchical interaction;follower structure;actor;standard actor;game;player;benjamin chasnov1;leader;zane alumbaugh2;liyuan zheng1;model;theoretic interpretation"}, "b63bd17d4bb28ba90cc6ff66b51ba5b0377467bf": {"ta_keywords": "recurrent neural network language models;neural network language models;minimum word error training;speech recognition;type rnnlm;rnnlms;term memory recurrent;rnnlm;lstm;term memory;word error rate;minimum word error;word probabilities;correct word sequence;mwe training method;cross entropy;significant wer reductions;standard elman;long short;training;performance measure;mwe method;target task;wer;maximum likelihood criterion;advanced model;paper;mwe", "pdf_keywords": ""}, "93d3e45395117e21214d404c8753b578c29266d1": {"ta_keywords": "text question answering;evidence retrieval;open qa;textual data;unstructured text;iterative retriever;open question;answers;bert;scale dataset open table;textual units;qa;ott;tables;text;documents;reader;evidence;most questions;challenge;baseline model;tabular data;retriever;early fusion;task;more context;performance;answer;input;exact match score", "pdf_keywords": "fusion retrieval;text question answering;local sparse attention;textual data;open qa;textual units;early fusion;ott;qa;evidence;scale dataset open table;task1;more context;challenges;retriever;challenge;performance;novel strategies;experiments;sophisticated system;block;second technique;similar model size;\ufb01rst time;novel techniques;\ufb01rst technique;state;art models"}, "a0035379f93e0e95bdadd77a1d8eb27ba89dcf60": {"ta_keywords": "story generation models;story generation;loop story generation;natural language annotations;story continuations;language models;lengthy stories;creative text;enjoyable stories;narrative;character goals;rich enough contexts;evaluation platform;evaluations;models;community;real authors;datasets;dataset;input context;model;author;storium;attributes;robust source;machine;large output space;issues;systems;form", "pdf_keywords": "loop story generation;computational storytelling systems;story generation;natural language;evaluation platform;enjoyable stories;\ufb01negrained structural annotations;stories;storium dataset;real storium authors;community;models;storium platform;dataset;machine;model outputs;storium;rich metadata;web service;platform;asynchronous programming;story;evaluation lifecycle;dedicated web service;use;limitations;latest python web standard;systems;input context;user"}, "3e4d80e43346b9538504c0a7ee5562f3c6a09178": {"ta_keywords": "traditional bandit algorithms results;classical bandit algorithms;reinforcement learning;greedy algorithms;regret;incentives;learning;algorithms;experiments;users;recommendations;upper confidence;epsilon;platform providers;theoretical bounds;users types;ucb;variants;traditional ucb;simulation;poor performance;time;comparison;illustrative example;number;priori;design;problem", "pdf_keywords": ""}, "740ecaa7fc1f4fc02116181b1757f03c815c7ea9": {"ta_keywords": "lstm;recurrent neural networks;length time series;diagnoses;classification;clinical measurements;metrics;strong baseline;novel application;variety;method", "pdf_keywords": "lstm recurrent neural networks;lstm;clinical time series data;clinical time series;lstm rnns;recurrent neural networks;rnns;neural networks;length time series;supervised phenotyping;term memory;health data;diagnoses;recurrent;multivariate picu time series;overall classi\ufb01cation performance;clinical measurements;micro auc macro auc micro f1 macro f1;sequential data;prediction;natural language processing;genomic analysis;hospital la los angeles;handwriting recognition;variable length sequences;picu phenotypes;model;critical care patients;pattern mining;metrics"}, "191ef1408406569f0e9a69344add1ae350365431": {"ta_keywords": "predictive fairness properties;different predictive fairness properties;better fairness properties;predictive bias;fairness;selection decision;multiple predictive models;selective labels;predictions;outcome;good models;models;similar overall performance;data;individual cases;empirical phenomenon;observed data features;model;relevant challenge;audit;rashomon effect;set;framework;setting;different properties;various groups", "pdf_keywords": "predictive fairness properties;predictive disparities;lower predictive disparities;larger predictive disparities;fairness;algorithmic risk assessments;fairs;white defendants;compas risk assessment;scoring dataset;benchmark model;machine learning department;selective labels;outcome regression function;economics;theoretical guarantees;absolute disparity;crime dataset;algorithmic framework;selective labels problem;models;statistical parity;credit;same guarantees;generalization error;regression experiments;conclusion;good models;decisions;mellon university"}, "9eeaeadc1e0e300337b47d867a314caeae5c10a9": {"ta_keywords": "brain age;deep learning;structural magnetic resonance imaging;uniform healthy population", "pdf_keywords": ""}, "9813446d9545b600de9a4972c1382c5e3b22a351": {"ta_keywords": "intelligent tutoring systems;intelligent tutoring system;cognitive tutor;tutor interactions;student modeling;human students;cognitive skills;cognitive model;students performance;simstudent;heavy programming;genuine student;basic idea;evaluation study;log data;tools;correct behavior;paper;observation;second use;errors;problems;performance;correct steps;author;building block;current implementation;time", "pdf_keywords": ""}, "78dadbfb6710ac65f178b5e12bd975184aae62fe": {"ta_keywords": "web information;integration;practical observations", "pdf_keywords": ""}, "241e890c70f6d013de7fe5e174e061ff824dc5e9": {"ta_keywords": "tutoring;teachable agents;simulated students;learning companion systems;learning environment;student input;students;agent;live machine;simstudent;average students;skills;study;error detection items;evaluation study;system;equation;problems;results;performance;paper;overview;number;current study;correct answers;purpose;minutes;average", "pdf_keywords": ""}, "ca00ead4e5ddd14cbbbce03d89a57d14b430e320": {"ta_keywords": "privacy;privacy breach;smart grid;insurance contracts;electricity grid;party insurance companies;networked sensors;energy consumer;customer segmentation;granularity data;consumer;contracts;guarantees;screening mechanism;valuation;probability;order;menu", "pdf_keywords": "privacy;adversary;privacy breaches;privacy breach;private information;adversarial agent;smart grid;insurance contracts;attack model;party insurance companies;estimation theory;nonintrusive load monitoring;customer segmentation;guarantees;attack;energy consumer;contracts;consumers;consumer;screening mechanism;algorithm;probabilities;certain probability;valuation;probability;theoretical results;questions;order;menu;paper"}, "83c7335904002d2b7c7cb403f3538703c9a69025": {"ta_keywords": "nonaudible murmur enhancement system;statistical voice conversion;silent speech communication;nonaudible voice;unvoiced speech;whispered voice;intelligible speech;normal speech;target speech;speech;nam enhancement methods;quiet environment;whisper;noisy environments;nam enhancement;speaker;listener;conversion process;nam;vc;evaluation;method;methods;target;other types;kinds;message;experiments;situation;typical situation", "pdf_keywords": ""}, "9f1a1d2cb6b278b7ee24e67d4c2ac38c1161fa1d": {"ta_keywords": "indonesian ethnic speech data;indonesian ethnic speech corpora;language preservation;ethnic languages;speech translation system;indonesian;cultural preservation;multilingualism;indonesia;vowel analysis;speech;indigenous communities;elders;available technology;communication;english;term development;people;younger people;community;several projects;analysis;preliminary collection;paper;collection;first step;catastrophe;state", "pdf_keywords": ""}, "5bf7f468b763f181c31a5e1edc57bce9a6dbd00c": {"ta_keywords": "critical care patients;available critical care databases;ventilation therapy;mechanical ventilation;risk scores;ventilator use;risk score;risk patients;peer score;patient risk;mortality;ill patients;decompensation indicators;risk group;membranous oxygenation;risk groups;patients;ecmo;cohorts;oxygenation;unspecified pneumonia;survival;risk;decompensation;clinicians;vasopressor;high risk;early planning;surgical cannulation;severe ards", "pdf_keywords": "novel coronavirus pneumonia;novel risk nomogram;risk score;coronavirus disease;sepsis campaign;unspeci ed pneumonia;risk patients;risk nomogram;critical care patients;patient risk;mortality;ill patients;peer score;early prediction;guidelines;high risk;ill adults;nomogram;validation;ecmo;machine;assistive tool;multicenter study;guangdong;decompensation;wuhan;multicenter development;subpopulation;tool;form"}, "ea2b138583e587850153f2825fe9e4339aa5f5f9": {"ta_keywords": "speech separation;separated libricss dataset;diarization;recognition;integration", "pdf_keywords": ""}, "ca1645abedae3b4caa3345aa8720c8b90f7c37db": {"ta_keywords": "dependent scoring rules;voting rules;positional scoring rules;voting compute;scoring rules;votes;scores;rank;score;vote;summation principle;owa;alternative;list;rdsrs;operators;many others;assumption;account;new family", "pdf_keywords": ""}, "b2c3d660aaefb80085fe72c80ce81c5fa71980e9": {"ta_keywords": "other pivot translation approaches;pivot target translation models;pivot translation methods;pivot language words;pivot translation;pivot language;syntactic matching methods;syntactic subtrees;incorrect source target phrase pairs;united nations parallel corpus;source pivot;constituent words;syntactic roles;interlingual di erences;incorrect phrase combinations;intermediate language;source target model;languages;parallel data;semantic ambiguities;equivalents;triangulation approach;english;tree;phrase;combinations;results;combination;method;surface forms", "pdf_keywords": ""}, "b7d6829d9eccdbd3d3a5d6f5321a87158588033b": {"ta_keywords": "chalearn apparent personality trait challenge;pairwise ratings;bias problems;labeling images;labeling;score reconstruction;pattern labeling;worker bias;videos;large scale dataset;few labels;personality traits;short videos;continuous traits;people;humans;calibration;task;accuracy;crowd;camera;patterns;workers;scaling;pairwise;many workers;calibration problems;pairs;pairwise method;empirical law", "pdf_keywords": ""}, "47adb249ce8f7f5f1e92112ba0f3757f8fbfbfc3": {"ta_keywords": "order lexical semantic models;lexical semantic models;question answering;neural network language models;monolingual alignment models;semantic drift;answer texts;term embeddings;term alignment probabilities;encode direct term associations;unstructured text;graph traversal;example;order formalism;traversal;answer pairs;indirect associations;order variants;order approach;direct evidence;task;graphs;relative gains;question;training;important criterion;success;non;robust performance", "pdf_keywords": ""}, "21ac57d41843ac5367e11b8b784aa57f2ef7a1fc": {"ta_keywords": "optimal high probability complexity bounds;convex optimization;optimal iteration;complexity bounds;probability convergence results;scale machine learning models;oracle complexity;theoretical guarantees;suboptimal objective value;noise distribution;several nlp tasks;logarithmic dependence;particular run;algorithm;practical efficiency;existing methods;expectation;random nature;objective value;order methods;noise;paper;power;random behavior;confidence level;additional assumption;practice;second one;heavy;method", "pdf_keywords": "optimal high probability complexity bounds;stochastics;scale machine learning models;order methods;random nature;information transmission problems ras russian federation;noise;near;moscow institute;control sciences ras;data;germany;eduard;weierstrass institute;russian federation;oc;national research university higher school;thanks;economics;applied analysis;jun;practical e\ufb03ciency;heavy;math;institute;physics;technology;abstract"}, "6cdff2505560390b28db5a96c2ae3070712077cf": {"ta_keywords": "policy gradient reinforcement learning;competitive gradient;gradient dynamics;certain online convex optimization;continuous games;local nash equilibria;sum games;competitive agents;learning algorithms;gradient;potential games;bandits;games;smale games;learning;dynamical systems theory;agents;algorithms;like flows;morse;wide breadth;general framework;behavior;new class;lens", "pdf_keywords": "policy gradient;competitive gradient;continuous games;gradient play;classical online optimization;cooperative games;potential games;learning algorithms;games;adversarial networks;learning;generative adversarial networks;gradient;on gradient;gans;generative;stronger convergence guarantees;generative model;game;computer science university;wide breadth;behavior;dynamical systems theory;general framework;computer engineering university;similar analysis tools;addition;electrical engineering;broader class;electrical"}, "7301c7aba3c0824b91f69747e7e50f4db56d7fc1": {"ta_keywords": "paralinguistic translation;speech translation;paralinguistic information;speech;single neural network;digit translation task;neural network model;space translation;acoustic features;dependent models;linear regression model;linear regression;words;model;duration;single model;word;sufficient expressive power;source;continuous space;power;similar results;previous work;work;method", "pdf_keywords": ""}, "8837530b23a2d51054d8752ae2f0ffef8998da8e": {"ta_keywords": "aware collective matrix factorization;location privacy;differential privacy;privacy;interaction data;world datasets;recommendation;data sparsity issue;data;confidence;target domain;real locations;auxiliary domain;users;ccmf;protection mechanism;criterion;framework;user;state;best performance;new method;art baseline methods;extensive experiments;method;efficacy;task;paper;stages", "pdf_keywords": ""}, "cb15c1c51e8a7da42d5b2ebac955bf1cd9dd4022": {"ta_keywords": "such knowledge graphs;knowledge graphs;knowledge graph;graphical knowledge representations;text generation;text generation techniques;novel graph transforming encoder;information extraction system;graph transformers;structured representation;relational structure;texts;document plan;multiple sentences;hierarchical constraints;content;representations;output;complex ideas;computing;distance dependencies;linearization;structural variety;significant challenge;work;problem", "pdf_keywords": "novel graph transforming encoder;knowledge graph;graph encoding;such knowledge graphs;graphwriter;text generation;information extraction system;scienti\ufb01c text;agenda dataset;graph;encoder;relational structure;new attention model;automatic evaluation;generation community;output;abstracts;hierarchical constraints;knowledge;strong baselines;end;decoder setup;new resource;linearization;utility;work;domain;trainable system;problem"}, "a54019645dd8e9cfd8d71ab60155449307de3d83": {"ta_keywords": "crowdsourcing;incentive;multiplicative incentive mechanisms;possible incentive;spammers;simple payment mechanism;data;compatible payment mechanism;machine learning applications;smallest possible payment;quality data;workers;fundamental challenge;mechanism;questions;lunch;requirement;immense popularity;large amounts;compatible mechanisms;nothing;rest;problem", "pdf_keywords": "amazon mechanical turk;crowdsourcing;multiplicative incentive mechanisms;dengyong zhou machine learning department;reward mechanism;quality data;data;machine learning applications;world experiments;microsoft research;algorithm;immense popularity;large amounts;collection;synthetic simulations;potential;nothing;eecs university;abstract;practice;california;setting;section;dec;problem"}, "2cc7db7b17ee7349800334b3a154f708850c6410": {"ta_keywords": "archival storage systems;data storage systems;mds queues;mds queue;data storage methods;simple data replication;data centers;replication;powerful erasure codes;erasure codes;lower storage cost;latency performance;average job latency;latency;cold data;hot data;mds codes;improved reliability;reliability;decentralized versions;data;codes;system;paper;use;key metric;order;theory;upper bounds;same level", "pdf_keywords": ""}, "0ff5b1e61bbebd2f077a4ef24c3afdb344e5b3d4": {"ta_keywords": "vantage", "pdf_keywords": ""}, "8e992116bbc8afb075577a30672de7a90fbeba78": {"ta_keywords": "streaming transformer asr;e2e transformer asr;encoder;monotonic chunkwise attention;automatic speech recognition;attention network;japanese tasks;blockwise synchronous beam search;beam search;synchronous beam search algorithm;neural networks;transformer algorithm;transformer self;asr;feature blocks;blockwise processing;e2e;response time;promising performance;block;sequence;librispeech english;knowledge distillation technique;novel blockwise;boundary detection technique;certain tasks;evaluations;ablation study;conventional online approaches;end", "pdf_keywords": ""}, "3163392f56cdffaa009fbc59f299989a1b8baec1": {"ta_keywords": "unlabeled data reliability;unreliable unlabeled data;binary classification;classification;unlabeled data;class classification;positive unlabeled;class data scientists;other oc algorithms;positive data;pu algorithms;learning;art oc algorithms;algorithms;class;former only learns;data;art pu algorithms;oc;art oc;main practical recommendation;wide list;more data;pu group;pu;pu modifications;state;latter;various scenarios;main approaches", "pdf_keywords": "unlabeled data reliability;unreliable unlabeled data;unlabeled data;binary classi\ufb01cation;other oc algorithms;positive unlabeled;pu algorithms;classi\ufb01cation;art oc algorithms;class classi\ufb01cation;class;learning;data scientists;data;art pu algorithms;oc;art oc;main practical recommendation;wide list;varied reliability;state;various scenarios;abstract;pu;pu modi\ufb01cations;paper;research;cases;farid bagirova;main approaches"}, "73472692b6090a72e36e03127bb99fc2e6bc8de0": {"ta_keywords": "communities;latent networks;current unsupervised machine learning techniques;gaussian mixture models;community relationships;latent network;affinity propagation;nn network modularity maximization;networks;cultural data;community assignments;cultural cognitive mapping;current unsupervised machine;world data sets;socio;behavioral attributes;entities;nature;nn;scm;means;novel methodology;methodology;contrast;novel insight;additional insight;work", "pdf_keywords": ""}, "2f6843f9345ca56af3fd9df5512daa1e7f80bedf": {"ta_keywords": "structured prediction;imitation learning;previous tag predictions;other structure prediction approaches;conditional random fields;level quality estimation;classifier;arbitrary information;error propagation;task organisers;task;structure;word;baseline features;data;submission;sheffield;system;aspects;university;use;approach", "pdf_keywords": ""}, "faa4468f2ad1c7cedaf04bf56ebb20ae4b349952": {"ta_keywords": "recurrent neural network language models;neural network language models;neural network language model;term memory recurrent;lstm;term memory;language models;covariance matrix adaptation evolution strategy;modeling word history information;various speech recognition tasks;rnn;lms;gram;evolutionary optimization;training configurations;cma;tuning;tuning process;expert knowledge;es;many trials;parameters;ability;better performance;intensive effort;study;complex network structure;superior performance;art performance;state", "pdf_keywords": ""}, "872c2d9d8b27ff49367854a7cf67b5dff2010406": {"ta_keywords": "biomedical event extraction;event detection task;bionlp;single theme event classes;training data;reasonable recall;precisions;domain;system", "pdf_keywords": ""}, "c6713071291729386955586c6309778b1637b852": {"ta_keywords": "hvac resource allocation;dynamic game;selfish agents;standard dynamic game theory;pricing mechanisms;quadratic game;feedback control strategy;resource allocation;social planner;uncoupled social planner;neighborhood;control actions;buildings;agent;game;cost function;quadratic dependence;scalable framework;simplification;paper;problem;context;use;means", "pdf_keywords": ""}, "d5084f48212bed80e8c11e1e69669deea3ba2f83": {"ta_keywords": "parallel script corpus;nlp community;video captions;procedural language;procedural details;corpora;tasks;pasta;pasta dish;kidscook;task;tools;events;temporal relations;example;models;concrete instructions;people;paper;use", "pdf_keywords": ""}, "8451d8e20bb9a94c6a576e52ca1a63470f8d2390": {"ta_keywords": "convex composite optimization problem;sliding algorithm;optimization;free method;order oracle calls;lower bounds;convergence rate;order method;node;new method;lan;bounds;order;method;corresponding rate;communication;terms;paper;factor;number;similar state;art;space;dimension", "pdf_keywords": ""}, "a6a9c06d138537002aaca79dba359cc320b951df": {"ta_keywords": "bayesian speech;bayesian approach;language processing", "pdf_keywords": ""}, "03bbbaa03cb57413c2581cc8dc5cbfa532bbea15": {"ta_keywords": "channel eegs;user identification performance;grade eeg device;brain waves;dimensionality reduction technique;user identification;identification accuracy;machine learning techniques;ms erp epoch;classification algorithm;erp;p300 component;authentication;data;event;statistical significance;subjects;potential;experimental results;various different combinations;consumer;capabilities;variety", "pdf_keywords": ""}, "73e1dcf5f0f3cf4e645b0bba62d9b1e2ef47b706": {"ta_keywords": "semantic parsing;natural language understanding;lexical class identification;semantic knowledge;lexical classes;semantic analysis;semantic tags;free grammars;grammars;utterance;speech;artificial intelligence;human communication;ai;computer communication;context;nlu;human;communication medium;computer model;computer;main algorithm;implementation;introduction;tree;process;meaning;challenging topics;stochastic method;paper", "pdf_keywords": ""}, "122b75042daae44f93153dedda15b0fb11b3f279": {"ta_keywords": "question answering datasets;popular qa datasets;qa datasets;bert;models learn;questions;datasets;models;responses;qa;domain examples;task;squad;variations;popular question;humans;generalizability;question;incorrect information;paper;ability;superhuman performance", "pdf_keywords": "bert models;future qa datasets;individual qa datasets;\ufb01ve qa datasets;qa datasets;qa models;comprehension;new qa model;question variations;questions;bert;dataset examples;datasets;new datasets;models;responses;robustness probes;dataset;multiple relevant datasets;\ufb01ve datasets;model performance;simple generalization;domain examples;single dataset;negation;heuristics;context overlaps;variations;generalizability;\ufb01ller words"}, "e6602786132e040e02df93f729f737f65a116677": {"ta_keywords": "field speech recognition;digital home assistants;speech processing;microphone array processing;key speech processing algorithms;spoken language interface;quality speech synthesis;multichannel acoustic echo cancellation;free speech interaction;speech;reliable wake;signal processing;interaction detection;heterogeneous training data;signal enhancement;sophisticated statistical models;device;machine;nonspecialist;hands;maec;fetched technology forecasts;language;technologies;futuristic science fiction;ubiquitous commodity today;major advancements;end;commands;techniques", "pdf_keywords": ""}, "d8682a269523a868f2bc9714b00f0519aa0e931f": {"ta_keywords": "deductive databases;ranked retrieval methods;information retrieval;ir similarity metrics;conventional databases;like queries;database;queries;structured collection;information sources;novel logic;object identifiers;whirl;text fragments;inference;new integration system;information;whirl approach;normalization;equality tests;text;integration;overview;operations;extraction;keys;small fragments;style", "pdf_keywords": ""}, "8cb74fe4f598699c9c24d88acd4906e2489267af": {"ta_keywords": "adaptive mapping;simple robots;navigation;teams", "pdf_keywords": ""}, "48aced0919e29722d6eed9544353d5507c541cfc": {"ta_keywords": "drosophila gene name recognition;drosophila articles;gene name recognition;gene names;baseline anaphora resolution algorithm;named entities;sequence ontology;anaphoric linking;flybase;information;score;recognition;products;preliminary experiment;extant approach;paper", "pdf_keywords": ""}, "b3d9a0308ba6c4ca583a2b4e5be2b3eed466ccbc": {"ta_keywords": "d2d channel;d2d channels;d2d channel condition;observable markov decision process;channel information;communication path;channel quality;mmwave;millimeter wave;network environments;optimal threshold policy;stationary threshold policy;dynamic obstacles;d2d;communication;good relay;obstacles;severe penetration losses;pomdp;finite horizon;successive acknowledgement failures;delay;current relay link;uncertainty;base station;best possible decision;locality;sight;devices;ii", "pdf_keywords": "relay selection;millimeter wave d2d communication;good relay;other relay link;mmwave;millimeter wave;d2d channels;current relay link;stationary threshold policy;communication path;optimal policy checks;dynamic obstacles;channel quality;severe penetration losses;network environments;successive ack failures;obstacles;observable markov decision process;communication;successive acknowledgement failures;simple stationary policy;delay;threshold;best possible decision;simulations;d2d;locality;sight;ii;objective"}, "fc8e226c20800c8ccc095bb6a3c0f8dcb637b683": {"ta_keywords": "lung metastases;rectal cancer cases;rectal cancer;colorectal cancer;colon cancer;clinical trials;multidisciplinary therapy;oncologists;current research reports;clinical experiences;crc;clinical practice;extensive discussion;diagnosis;level evidences;consensus;china;expert consensus;general guidelines;mdt;proportion;western countries;differential diagnosis;management;detailed approaches;higher incidence;experts;edition;knowledge", "pdf_keywords": ""}, "6c0a3029afd65c83982b3fb96f623da382344286": {"ta_keywords": "tensor factorization methods;tensor factorization theory;matrix factorization methods;recent nlp applications;topic models;transductive learning;natural language processing;tensor;dependency parsing;information extraction;lexical semantics;convex surrogates;neural networks;knowledge base population;matrix;advanced topics;other popular methods;basics;alternative losses;attention;first part;second part;optimization;methods;thanks;lot;connections;successful applications", "pdf_keywords": ""}, "928f942baf03dd56aae662fa94d85d22b5600f83": {"ta_keywords": "paraphrase pairs;paraphrases;translation memories;parallel corpora;sentences;input sentences;texts;tms;useful tools;statistical framework;narrow domains;same meaning;system;use", "pdf_keywords": ""}, "e30b22e692b3c7d2653832bf2901abd8a9375b6e": {"ta_keywords": "optimal content placement;cache;cellular network;cellular networks;simple sequential content update rules;optimal placement;neighboring base stations;content;mobile users;base stations;popularity distribution;base station;memory space;gibbsian on;gibbs;downloads;contents;cell;strategy;other cells;knowledge;ideas;finite collection;paper;download;techniques;backhaul;rate;situation;user", "pdf_keywords": "content caching;cache content update;cache;cellular networks;cellular network;cache update;caches;backhaul network state evolution;gibbsian on;gibbs;algorithms;optimal placement;neighbouring bss;update scheme;contents;formulation;strategy;paper;techniques;rate;knowledge;section iii;nov;arpan chattopadhyay;section vi;approach;bart\u0142omiej b\u0142aszczyszyn;line;conclusion;abstract"}, "2406cf39805c70264c4226b7325a09b506c70921": {"ta_keywords": "neural sql executor;synthetic corpus;language models;wikisql denotation accuracy;table pre;wikitablequestions denotation accuracy;tables;table;natural language sentences;executable sql queries;previous table;datasets;tabfact accuracy;sqa denotation accuracy;downstream tasks;low data quality;approach tapex;tapex;performance;large margin;recent years;model;paper;art results;new state;experimental results;success", "pdf_keywords": "neural sql executor;synthetic corpus;data scarcity challenge;highquality synthetic corpus;unstructured textual data;table pretraining;language model;tables;sql execution engine;executable sql queries;sql queries;sql executor;structural reasoning process;recent progress;tapex;abstract;paper;conference paper;wzchen;execution outputs;tapex addresses;scale;behavior;mar;jian;great success"}, "3ee38da21d8cf9cb7d4077b729e57f68e9c8d671": {"ta_keywords": "offline reinforcement learning;text generation;machine translation;policy learning;question generation;policy gradient;expert demonstrations;confident tokens;summarization;human evaluation;history distributions;importance weighting;quality samples;generation;prior rl approaches;histories;gold;mle;demonstrations;models;training;autoregressive models;evaluation;reference;rl;likelihood;maximum likelihood estimation;model;online data collection;goal", "pdf_keywords": "text generation;mle training;autoregressive models;mle;precision models;iclr;train;training;policy rl;gold;gold history;inference;tions;data science;promising framework;model;test objectives;evaluation;maximum likelihood estimation;algorithms;quality;current approaches;ef\ufb01cient algorithm;likelihood;test discrepancies;optimization advantages;richard yuanzhe pang;history;conference paper;abstract"}, "fdaad09b1a897c0a04b9a9579081d542e2b4546c": {"ta_keywords": "vaccination;breakthrough infection;infection interval;sars;other variants", "pdf_keywords": ""}, "74276a37bfa50f90dfae37f767b2b67784bd402a": {"ta_keywords": "language nlp tasks;text transfer transformer;text transformer;multilingual variant;unified text;accidental translation;new common crawl;languages;text;wrong language;generative model;dataset;mt5;text format;t5;prediction;art results;shot setting;scale;paper;wide variety;simple technique;state", "pdf_keywords": "generative multilingual language models;multilingual variants;multilingual variant;multilingual setting;languages;new common crawl;public common crawl web scrape;c4 dataset;wrong language;t5 recipe;dataset;t5;natural text;mt5;benchmarks;t5 model;prediction;diverse set;mc4;strong performance;shot setting;part;paper;conclusion;problematic behavior"}, "00b2afaf5935b4dea41f134fe11a21a1ed56fa0e": {"ta_keywords": "supervised sentiment analysis;czech social media", "pdf_keywords": ""}, "1bf36cb3453b51550ebadd904a840c75d59f171b": {"ta_keywords": "robust asr research;robust speech recognition;asr;robustness issues;deep learning era;neural networks;signal processing;variables;common notations;network;basic formulations;overview;general background;advanced topics;equations;chapter;brief history;new era;later chapters;several studies", "pdf_keywords": ""}, "8b20173b98914f36302389e4c761c334fe867dcd": {"ta_keywords": "dependency treebanks;robust parsers;dependency parse;morphosyntactic rules;morphosyntactic well;machine translation;text generation systems;generated texts;morphosyntax;rich languages;language;text;systems;noisy outputs;various rules;diachronic study;metric;simple methodology;task;way;effectiveness;paper", "pdf_keywords": "more robust dependency parsers;treebanks;machine translation;natural language processing;morphological feature taggers;morphosyntactic wellformedness;natural language generation;nlg;morphosyntactic rules;nlp;dependency parse;morphosyntactic errors;summarization;language;interpretability;text;dialogue;diachronic comparison;wmt;wmt systems;metric;diachronic study;mt systems;tasks;systems;rule;lambre;task;introduction;median score"}, "3dcba175248d0e8d2da44e3731e4adbfb9f00e97": {"ta_keywords": "open information extraction;external knowledge bases;large corpus;level tuple extractions;corpus;individual sentences;supervision framework;relation phrases;local context information;world corpora;level extractions;entity;relation tuples;quality sentence;sentence;local context;remine;novel open ie system;subtasks;global structural signals;local context signals;supervision;tuples;current open ie systems;subtask;open ie systems;objective;global cohesiveness;fact;facts", "pdf_keywords": "open information extraction;massive text corpora;massive corpora;entities;global structural signals;supervision framework;relation tuples;local context;global cohesiveness;relations;local context signals;uni ed objective;interests;prede ned schema;novel open ie framework;candidate tuples;text;remine;many domains;languages;many challenges understanding;uni ed;emergence;novel open ie system;introduction;tuple quality;insights;1university;abstract;important task"}, "96dbffb71e4d62a985f826197845623b1415c267": {"ta_keywords": "metacognitive learning;better metacognition;future learning;human learning;learners;better learning strategy;free grammar induction algorithm;learning process;stronger prior knowledge;synthetic student;knowledge;students;deep features;probabilistic context;computational model;model;challenges;paper;others;preliminary results;possible future studies", "pdf_keywords": ""}, "ce9919ffb9dab701babd67a945b1590917345789": {"ta_keywords": "multiple inconsistent explanation problem;multiple explanations;training example;learning;formalization;training instance;knowledge;theories;formal analysis;abductive explanation;domain theory;explanation;negative examples;techniques;ebl;level ebl;possible explanations;certain type;problem;ts;extension;solution;set;paper;convergence properties", "pdf_keywords": ""}, "53e161d4434576355fc5f63fe56afd8e135174b2": {"ta_keywords": "scripts generation;script generation;neural language models;language generation;language models;quality scripts;narratives;scripts;standardized event sequences;script;events;text;structure prediction;unordered events;models;everyday scenarios;proscript;typical everyday activities;lms;information;cake;expectations;prior datasets;levels;complementary tasks;granularity;order;pre;scenario;edge prediction", "pdf_keywords": "script generation;entire script generation;neural language models;script knowledge;partial order scripts;script edge prediction;quality scripts;temporal ordering;tasks;events;models;cake;granularity;everyday scenarios;levels;data;\ufb01rst time;complementary tasks;lms;conclusions;wide range;application;work;new research direction;speci\ufb01c"}, "6c59a6ad00d82ca9f76fef92232ff3e2f3c1acc8": {"ta_keywords": "speaker diarization;speaker voice activity detection;aware diarization outputs;such diarization systems;region proposal networks;ensemble techniques;wise incremental label mapping strategy;graph matching;global cost tensor;natural language tasks;speech;clustering;libricss datasets;overlap;diverse systems;pair;single best system;algorithm;majority voting;outputs;dover;approximation algorithm;lap;target;mapping;ami;several advances;method;strength", "pdf_keywords": "speaker voice activity detection;multichannel diarization;array microphones;diarization systems;early fusion methods;meeting datasets;label voting;region proposal networks;late fusion;overlap awareness;diverse systems;cost tensor;clustering;diarization hypothesis;libricss datasets;multiple systems;single best system;incremental pair;overlap handling;global mapping strategy;wise mapping;outputs;dover;libricss;target;lap;vad;robust method;ts;dl"}, "a5881560968963d0c845c468a273261fde0b7248": {"ta_keywords": "natural language model predictions;relative word importance scores;trustworthy nlp applications;adversarial perturbations;interpretability methods;simple word perturbations;different nlp datasets;words;fragile interpretations;interpretations;sota interpretation methods;word;similar interpretations;text;rank order correlation;good quality metrics;popular transformer models;integrated gradient;finance;level swaps;candidates;input text;popular choices;medicine;small portion;lime;seed input;stake areas;paper;via", "pdf_keywords": "natural language model predictions;interpretability methods;fragile interpretations;deep natural language processing;box interpretability approaches;relative word importance scores;nlp models;misleading interpretations;interpretations;small word;integrated gradient;text examples;objective metrics;inputs;lime;input manipulation;l2 norm;fragility;objective metric;constraints;manipulations;delta lom;yanjun qi department;different models;explainfooler;virginia charlottesville;sep;va;yangfeng ji;arshdeep sekhon"}, "3004a3e4d8969dc3c36c9274b0f76ecc874f2e6a": {"ta_keywords": "speech separation;speech recognition outputs;deep recurrent neural networks;bidirectional recurrent networks;noisy spectrum;spectral input features;deep network;reconstructed signal;speech;noise ratio;separation;masking function;recognition;snr;sensitive objective function;sdr;phase;objective function;signal;distortion ratio;alignment vectors;modeling;tighter integration;dynamics;dramatic improvements;challenging problem;approximation;further improvements;better results;promising future direction", "pdf_keywords": ""}, "e29e43d9c0772d44cff53044484970599db30d5f": {"ta_keywords": "domain adaptation;domain differential adaptation;neural machine translation;other alternative adaptation strategies;target domains;different domains;consistent improvements;domains;domain;dda;neural networks;tasks;models;global distribution statistics;generalization;differences;source;related task;data;multiple experimental settings;drawback;large quantities;difference;strategy;statistics;common strategy;effectiveness;framework;experimental results;paper", "pdf_keywords": "domain adaptation;domain differential adaptation;different unsupervised domain adaptation settings;neural machine translation;new unsupervised adaptation framework;machine translation;domain differences;domain data;several alternative adaptation strategies;neural models;dda;domains;graham neubig language technologies institute;nmt model;domain;nmt;language pairs;neural networks;differences;models;words;higher accuracy;yi dou;subword;difference;related task;zdou;zi;level evaluation metrics;data"}, "f6eafb82d2450f28f668443b689c91e896a0d63e": {"ta_keywords": "thompson sampling;linear bandits;web advertisement;adaptive machine learning winter;variants;analysis;lecture;problem;context;several works;faulty analysis;introduction;literature;depth;property;fine detail;section;special care", "pdf_keywords": ""}, "8225b047e0fe90c2d5f9bb77fd94396a9d0fd21e": {"ta_keywords": "entity recognition;gene identifiers;geneid ranking problem;possible gene identifiers;gene synonyms;geneid;model organism database curation process;identifier;entity;soft dictionary;ranking approach;gene;ranking;search framework;ranked list;learning method;multiple ner systems;documents;component ner systems;finding;ner;graph;information;conclusionthe utility;article;other sources;learning;measure performance;level f1 performance;common performance measure", "pdf_keywords": ""}, "3873e60de2d20aa33829e2d3d79221e716785546": {"ta_keywords": "discriminative language modeling;discriminative language models;unlabeled conversations;gram features;unlabeled speech;label propagation;discriminative model;perceptron algorithm;asr systems;conversation;perceptron;oracle;features;data;algorithm;confidences;similarities;best hypothesis;graph;paper;simplest version;errors;weight;hypothesis;framework;proximity;output;ssl;form;sense", "pdf_keywords": ""}, "229c0c13e5c2d8e189efccf77b8179ec16500212": {"ta_keywords": "string machine translation;englishjapanese machine translation;tree transducers;different syntactic parsers;decoder;translation;rule extraction;training pipeline;forest;string mt pipeline;popular moses decoder;alignment techniques;entire forest;travatar;model training;hypergraph mert;moses;evaluation;phrase;sparse;training;greater accuracy;online learning;tuning;auxiliary results;mt;engine;process;validation experiment;options", "pdf_keywords": ""}, "14fce3cfa503894f244fc6ea8a7a00fa0ddfd94e": {"ta_keywords": "computer ethics;science fiction;cacm research highlights;submission", "pdf_keywords": ""}, "a54a3a7b02cacd92b3bc633be7ea54e4f365fa65": {"ta_keywords": "malware communities;computer malware features;malware;remote access trojan family;binary communities;program features;cultural cognitive mapping;remote program functions;adversary;latent spatial domain;features;consensus graph representation;deep neural network;socio;detection system;scm;sakula;data;analysis;attributes;interactive commands;variation;berlin;work;saxe", "pdf_keywords": ""}, "935c275868bec7301f4bd254159978d8ded138b9": {"ta_keywords": "xylazole exerts anesthesia;analgesia;fetal rat nerve cells;cgmp;pathway", "pdf_keywords": ""}, "b9f0c7e99bcc94c2cd75fd8e1cef45188f51270e": {"ta_keywords": "extended graph temporal classification;connectionist temporal classification loss;automatic speech recognition;temporal classification;speaker information;label transitions;transcriptions;end asr;graph;neural network;labels;asr outputs;nodes;asr;supervision;transitions;classical benchmarks;librispeech;example;gtc;tasks;best list;posteriors;task;extension;paper;evaluation;generalized form;performance;systems", "pdf_keywords": "speech processing;speaker transition;speaker asr;label transitions;speaker end;neural networks;speech;posterior predictions;end asr;neural network;posterior probabilities;gtc;ctc ground truth;extended gtc approach;labels;temporal classi\ufb01cation method;beam search;posteriors;example;challenging task;tasks;graph;extension;conclusion;multi;alignment;paper;example application;similar way;wider range"}, "dfa34a10e2ba861545549c3188ef245b1e69bcdf": {"ta_keywords": "event extraction;biological networks;ofwords;scientific literature;words;word;text;latest word;features;bag;result;baseline;distributional characteristics;introduction;bow;art solution;methods;study;important phase;goal;state", "pdf_keywords": ""}, "2ea5b0f5e476ddc00ae4450f2888a51fa25dd1d3": {"ta_keywords": "many nlp tasks;shot learning;task augmentation;unlabeled texts;language models;shot benchmarks;training examples;unlabeled data;task;training;better few;self;sample efficiency;task fine;shot settings;target;key ideas;shortcoming;strong base model;data;pseudo;strata;novel technique;effective leverage;tuning;broad distribution;handful;experiments;recent successes;large amount", "pdf_keywords": "generative language model;domain nli training data;nli data generation model;natural language inference;task augmentation;nli data generator;domain training data;nlp benchmarks;language model;auxiliary task;speci\ufb01c unlabeled texts;task model;unlabeled texts;domain auxiliary;selftraining;data generation;target task;mnli dataset;text;unlabeled data;auxiliary;training;labeled data;teacher model;task;nli;inference;models;synthetic;student model"}, "92f93c0014ba4da59180c4cd141ad0dcaad5803f": {"ta_keywords": "multilingual transfer learning;multilingual deep retrieval;transfer learning;target language;language improvement;direct vocabulary overlap;multilingual setting;auxiliary languages;languages;auxiliary language;instance;pooled data;vocabulary;improvement;performance;single model;target;natural explanation;plausible conjecture;data;fact;kind;simplest type", "pdf_keywords": "multilingual vocabulary embeddings;transfer learning;deep retrieval;next sentence prediction;target languages;sentence prediction;siamese network;embeddings;languages;multilingual setting;direct vocabulary overlap;inverse cloze;catalan;transfer improvement;transfer;instance;ukrainian;tasks;positive transfer;performance;large scale;next;google research;inverse;objective functions;end;space;nsp;table;conclusion"}, "4a9c80e263fd0a88ad8220aa076ede4a3e77fcc1": {"ta_keywords": "deep testing methods;various adversarial samples;adversarial samples;adversarial attacks;dnn models;deep neural networks;dnn systems;model mutation testing;dnn;higher diversity;vulnerability;cifar10;models;lack diversity;detection;model;svhn;ggt;graph characteristics;software engineering;confidence;experiments;real applications;number;graph;wide application;effectiveness;mmt;efficiency;different kinds", "pdf_keywords": "deep testing methods;adversarial sample detection;various adversarial samples;adversarial samples;adversarial attacks;model mutation testing;dnn architecture;dnn model;dnn systems;testing;vulnerability;relational graphs;relational graph;software engineering;graph characteristics;models;model;graph;cifar10;challenges;racy;svhn;ggt;short aspl;small ad;mapping;higher diversity;accuracy;number;guide"}, "885fe11ed7ab81c8609ccddb3e10f62577c04ab9": {"ta_keywords": "thompson sampling;dialogue systems;common exploration strategies;exploration;learning;monte carlo samples;replay buffer;reward;agents;boltzmann;neural network;backprop;few successful episodes;bayes;experiences;efficiency;ones;new algorithm;algorithm", "pdf_keywords": "deep reinforcement learning;deep qnetworks;reinforcement learning;thompson sampling;bayesian neural networks;dialogue systems;bayesian neural network;monte carlo samples;agents;bbqn;agent;learning;exploration;ef\ufb01cient exploration;networks;amazon ai;selection;backprop;explores;bbq;user simulator;bayes;action;task;redmond;palo alto;pittsburgh;several areas;network;carnegie mellon university"}, "a1340029d8a5c57bee8a5995ac3beafd3d0ba96c": {"ta_keywords": "sensor subset selection;consensus filtering;tracking systems;active sensing;process estimation;wireless sensors;active sensors;stochastic approximation;sensor activation constraint;markov chain;sensors;kalman;neighbouring nodes;communication constraints;algorithms;node;algorithm;estimates;gibbs;computing;process;squared error;energy;efficient operation;error performance;presence;measurements;collection;key tools;need", "pdf_keywords": ""}, "c6854064cb5053e67d23394eee6d1646108f6d56": {"ta_keywords": "novel textual entailment task;textual entailment;standard textual entailment;trivial lexical inferences;multiple premise sentences;multiple premise task;inference;several strong neural baselines;everyday events;task;knowledge;new dataset;challenging setting", "pdf_keywords": "several strong neural entailment baselines;novel textual entailment task;standard textual entailment task;textual entailment;separate premise sentences;standard textual entailment;multiple premise sentences;multiple independent premise sentences;trivial lexical inferences;realistic entailment problem;multiple premise task;longer premise texts;premise text;sentences;several strong neural baselines;inference;task;everyday events;examples;dataset;new dataset;information;conclusion;knowledge;challenging setting;same scene;results;aggregation;predictions;variant"}, "74b05adf1ec74849a4f7963fe3f17fd61b92af4b": {"ta_keywords": "like query languages;natural language interfaces;query intents;query languages;query analysis;queries;query scenarios;multiple queries;contextual information;databases;natural language;weakly supervised max;nlidb;sql;ranking model;novel approach fanda;typical contextual understanding problem;margin learning;considerable attention;quality datasets;users;recent work;ubiquity;lack;paper;primary obstacles;structures;account;spite;multifarious nature", "pdf_keywords": "natural language interfaces;weakly supervised max;new followup dataset;query analysis;like query languages;ranking model;queries;natural language;query scenarios;nlidb;query triples;databases;considerable attention;sql;followup;novel approach fanda;margin learning;fanda;multiple baselines;recent work;tables;typical contextual understanding problem;jan;jian;users;superiority;abstract;novel approach;beijing;multiple metrics"}, "a5f214e23b8cd35a370a182c155ef333d77c5bb2": {"ta_keywords": "natural speech;stance;phonetic correlates;collaborative conversational tasks;stance strength;speech rate;phonetic properties;corpus;speaker;acoustic indicators;discussion;attitudes;polarity;pitch;same acoustic channels;complex activity;topic;presentation;dyads;analysis;computational models;several other types;preliminary analysis;opinions;taking;tasks;ranges;none;meaning;hand", "pdf_keywords": ""}, "b33caf27fe5584b9b773c75fc35ee0e8b1421864": {"ta_keywords": "wardrop equilibrium;potential game;continuous population;equilibrium;potential games;population mass;strategies;population member;distribution;relative preference;specific potential function;type;type space corresponds;model;type vector encodes;dimension;means;extension;subset;elements;difference", "pdf_keywords": ""}, "5ee96dd7e3395d8a53d6d3ceb62593477a4e0fe1": {"ta_keywords": "automatic colorization;colorizations;captions;descriptive color words;colorized image;different captions;color;greyscale images;language;experiments;users;process", "pdf_keywords": "automatic colorization;colorization;\ufb01nal colorized art;colorist;colorization metric;color speci\ufb01cations;color;neural architectures;convolutional model;representations;natural language;language;image captions;comic book artwork;palette;greyscale images;penciller;accuracy;example;task;computer science;script;agnostic model;umiacs allen institute;unexplored source;process;massachusetts;maryland;apr;sanity check"}, "53f1fb4dc887540ef134a8d08c152789c313aa5c": {"ta_keywords": "end speech recognition systems;phoneme transcripts;character transcripts;multilingual end;connectionist temporal classification;corpus;performance feature extraction;phonemic representation;csj bottleneck features;input language;bottleneck features;end asr system;encoder;japanese asr recipe;triphone;kaldi toolkit;csj bottleneck;features;decoder;language;posterior features;dnn;csj;attention;pca;character;end system;end;model;pure end", "pdf_keywords": ""}, "7262bc3674c4c063526eaf4d2dcf54eecea7bf77": {"ta_keywords": "english sentential paraphrase pairs;paraphrase generation;paraphrastic sentence embeddings;neural machine translation;semantic textual similarity competition;large parallel corpus;machine translations;millions;pairs;english;semeval;dataset;supervised systems;wieting et al;addition;limits;utility", "pdf_keywords": "paraphrastic sentence embeddings;paraphrases;embeddings;sentences;sentence pair;lexical resources;paranmt;standard english wikipedia;grammar correction;supervised training data;data augmentation;dataset;word;supervised systems;simple english;trigram;sts tasks;similarities;learning framework;usefulness;results;code;wieting et al;coster;model;kauchak;joint modeling;simpwiki;robustness;utility"}, "6d2d86cf5e80b58a03360559095ea3603548248f": {"ta_keywords": "prior algorithms;gradient descent;efficient algorithms;statistical seriation;statistical seriation problem;continuous regularization term;combinatorial permutation constraint;algorithm;global minimum;local minimum;unknown permutation;squares estimator;rankedness;noiseless setting;rows;noisy setting;consistent improvement;same shape constraint;matrix;permutation;heuristic;noise ratio;underlying model;columns;desirable properties;initialization;different initializations;certain special cases;simplistic parametric assumptions;signal", "pdf_keywords": ""}, "2d9769ce319a8acbe97438b45b0d381db2a538d1": {"ta_keywords": "espnet2;pretrained model;shinji watanabe;lang", "pdf_keywords": ""}, "c143d2b09bdfc0dff784dce2668fd5657806dbf2": {"ta_keywords": "explanation regeneration tasks participants;inference speed;challenging scientific topics;core scientific knowledge;knowledge base;challenge task;explanations;explanation regeneration;shared task;standardized science exam questions;participants;task;world knowledge;training;evaluation data;difficulty;facts;teams;models;explanation;explanation graph;second iteration;fact;mean average precision;terms;art performance;question;correct answer;size;average", "pdf_keywords": ""}, "2873053aa18059a61ead5880d449f5bccda2d213": {"ta_keywords": "interdependent scheduling games;nash dynamics;welfare maximization;nash equilibria;interdependent services;services;own services;predecessor services;reward;game;players;planning;scale infrastructures;staff;player;crisis;different agencies;medical care;theoretic analysis;electricity;natural disaster;computation;existence;same player;equipment;delivery;medicine;time;problems;model", "pdf_keywords": "interdependent scheduling games;nash dynamics;welfare maximization;nash equilibria;humanitarian logistics;joint deployment schedule;game;independent decision makers;services;players;scale infrastructure restoration;theoretic analysis;existence;pnes;questions;many important questions;computation;novel abstract model;best responses;conclusions;issues;paper;theoretic lens;setting;classic questions;problem;class;studies"}, "fee62123e1d2ac56065675983475b079e1e9106f": {"ta_keywords": "neural sequence models;greedy decoding;typical cross entropy training procedures;beam search;sequence tasks;entity recognition;cross entropy;ccg supertagging;end training;beam;new training;baselines;simpler greedy methods;final loss;new training procedure;end;models;continuous relaxation;novel continuous approximation;search errors;objective yields;better results;algorithm;order;time;test;experiments;method;use;approach", "pdf_keywords": "neural sequence models;beam search;greedy decoding;sequence tasks;entity recognition;beam;ccg supertagging;deepmind;end training;simpler greedy methods;baselines;\ufb01nal evaluation loss;new training;continuous relaxation;model parameters;end;objective yields;search errors;novel continuous approximation;cross entropy;better results;algorithm;taylor berg;test;novel method;paper;graham neubig;kartik goyal;abstract;experiments"}, "a96e05353032cc6f3d72eb5eca192295beac065e": {"ta_keywords": "stacked graphical learning;graphical learning;base learner;markov random fields;instance;other related instances;short inhomogeneous markov chains;inference;dependencies;features;predictions;scheme;kind", "pdf_keywords": ""}, "c52ac453e154953abdb06fc041023e327ea609a4": {"ta_keywords": "lstms;acoustic modeling;attention memory;attention;acoustic signal;context range;gaussian biasing approach;models;sequence length;local context;sequences;network;position information;model;strong baseline;other representations;discrete sequences;vectors;downsampling technique;hybrid models;network connections;modeling issues;self;several improvements;pairwise similarities;importance;explicit control;paper;previous approaches;end", "pdf_keywords": "attentional architectures;acoustic modeling;attentional architectures work;attention memory;attention;spell model;context range;acoustic signal;gaussian biases;gaussian biasing approach;pyramidal encoder component;models;local context;other representations;model;modeling reasons;hybrid model architecture;sequence length;hybrid models;position information;modeling issues;self;discrete sequences;explicit control;importance;several improvements;downsampling technique;conclusion;paper;previous approaches"}, "7ac4227d0b4d38b16da27ed55bd53ce240a32404": {"ta_keywords": "automatic speech recognition;end speech translation;autoregressive modelings;autoregressive baselines;nar models;text generation;nar asr;various nar modeling methods;ar models;form utterances;inference speed;speech;nar end;asr;nar;models;sequence;accuracy;accuracy drop;performance gap;cost;multiple outputs;great potential;speed trade;various tasks;time applications;end;further improvement;robustness;number", "pdf_keywords": "autoregressive baselines;language modeling;text generation;nar models;inference speed;speech;standard connectionist temporal classi\ufb01cation;models;regularization techniques;ar models;intermediate ctc;modeling;comparable performances;performance gap;nar;ar performance;model;accuracy drop;best performance;sequence;ctc;time applications;na;re\ufb01nement training;nanxin chen2;insertion;improved mask;mask;multiple outputs;self"}, "2f153172b92ea32f242d9cb6b94d162e52ef5f0b": {"ta_keywords": "dual dfa learning problem;functionfree prolog clauses;dfa paclearning problem;natural learning problems;formal problems;description logic classic;dfas;partial traces;programming;ground clauses;strings;straightline programs;abstract;inputoutput pairs traces;hardness results;string;order representations;examples;alphabet;hardness;output pairs;demonstration;problems;operator;concepts;arity;subconcepts;dual version;set;area", "pdf_keywords": ""}, "4a348e4725a2bc677e4aa40aa63c1421e8f335c9": {"ta_keywords": "multilabel classification;binary classifier;binary classification;classifier;classifier outputs;optimal f1 score;best achievable f1 score;optimal threshold;f1 score;average f1 scores;f1 scores;threshold;optimal behavior;precision;optimum;conditional probabilities;recall;class;harmonic mean;output;decision;micro;special case;examples;instance;success;context;paper;new insight;relationship", "pdf_keywords": "rare labels;optimal threshold;recall;optimal thresholding;multilabel classi\ufb01cation;random guesses;threshold optimization;prediction;optimal decision;label;predictive features;multilabel;threshold;best achievable f1 score;perfect predictions;binary classi\ufb01cation;predictions;binary classi\ufb01er;feature selection;classi\ufb01er;optimum;batch;instances;other examples;probabilities;precision;over\ufb01tting;f1 score;example;class"}, "c2a79e2a65b721d4de5f6d4806323174b9f8f393": {"ta_keywords": "real human annotations;unsupervised data generation;fewshot inference;label learning;quality training data;natural language processing;training data creation procedure;language models;strong baseline models;synthetic data;nlp;fewshot prompts;training;data;human;models;specific models;udg;task;novel approach;comparable results;paper;recent success;framework;method;core", "pdf_keywords": "human annotated label;real human annotations;nlp models;unsupervised data generation;quality training data;label learning;language models;shot example creators;synthetic data;training data creation procedure;strong baseline models;nlp;fewshot inference;label;data;unsupervised manner;fewshot prompts;strong results;training procedure;human;future transfer;task;udg;novel approach;promising direction;speci\ufb01c models;comparable results;quality;paper;recent success"}, "3b00e642de51d0f8378c7c35eca89f2ecb6f3af8": {"ta_keywords": "microdeletion syndrome region;de novo microduplications;velocardiofacial microdeletion region;familial cases;parental dna samples;congenital anomalies;microduplication;microduplications;clinical features;duplication boundaries;clinical records;clinical relevance;clinical correlations;careful parental assessments;developmental delay;de novo;mental retardation;variable phenotypes;lcrs distal;deletions;parent;identification;molecular data;individuals;testing;cases;shared characteristics;problems;preponderance;subjects", "pdf_keywords": ""}, "7a6c61b57bac074f7cd85963fd13da8f3321e087": {"ta_keywords": "unsupervised topic discovery;topic discovery;topics;influential blogs;influential blog postings;blog data;blogs;topical relationship;hyperlinks;linking;unsupervised model;topic;hyperlink;lda;interesting visualizations;same topic;generative model;specific influence;other documents;document;documents;link;extension;model;interest;fienberg;framework;new model;side;plsa", "pdf_keywords": ""}, "8c25e1c223fc70509172a32111c91fe4b9f86a56": {"ta_keywords": "virtualizable wireless networking;future programmable wireless networks;programmable wireless networks;cognitive wireless networking;programmable routers;traditional internet architecture;sdn;wireless networking;cognitive radio;wireless community;programmable mac processor;architectural ossification;networking;level programmability solutions;network device;original internet design;architectural survey;programmability;significant architectural innovations;decentralized network operations;network;sdr;vwn;cloud;radio;traditional architectures;broad realization;cbwn;software;innovation", "pdf_keywords": "programmable wireless networks;cognitive radio networking;cognitive wireless networking;cognitive radio networks;virtualizable networks;sdn;programmable wireless processors;networking;networks;radio;software;architectures;new framework;broad overview;crn principles;disparate schemes;new use cases;common goal;paper;popular techniques;literature;fact"}, "4a36a00db217fd98f1bd943aa2f2d6303adbc456": {"ta_keywords": "fair principal component analysis;fair pca subject;fair pca;mmd constraints;riemannian exact penalty method;pca;efficient mmd;fairness;stiefel manifold;mmd;optimization;tractable mathematical formulation;dimensionality;maximum mean discrepancy;smoothing;conditional distributions;good statistical properties;classes;liu;repms;paper;problem;incorporation;boumal", "pdf_keywords": "fair principal component analysis;fair pca;fair pca subject;riemannian exact penalty method;mmd constraints;pca;constrained optimization;ef\ufb01cient mmd;stiefel manifold;optimization;tractable mathematical formulation;mmd;fairness;maximum mean discrepancy;dimensionality;conditional distributions;computer engineering;good statistical properties;smoothing;daejeon;electrical engineering;classes;runtime;kim jaechul graduate school;department;university;jh lee00;liu;junghyun;empirical discussions"}, "101d619b5911e9c2fda6f02365c593ae61617cb6": {"ta_keywords": "cooperative persuasive dialogue system policies;cooperative persuasive dialogue systems;persuasive dialogue;persuasive dialogues;reinforcement learning;user simulator;user simulators;framing;reward functions;policy;humans;human interlocutors;experiments;corpus;experimental evaluation;paper;use;statements;effect;real users;construction;method;order", "pdf_keywords": ""}, "d4762619b55c65120307ceebe4a0646984f6045a": {"ta_keywords": "statistical machine translation;dependent translation model;translation probabilities;translation patterns;readable transcripts;manual transcripts;automatic speech recognition;transcript;asr results;asr errors;asr;japanese diet;colloquial expressions;traditional modeling techniques;novel modeling techniques;style text;context;meetings;accuracy;joint probabilities;log;linear interpolation;evaluation;disfluencies;results;smt;usage;national congress;approach;higher priority", "pdf_keywords": ""}, "50ec3d960ac458573a1e4a1556420c5e96d58609": {"ta_keywords": "evidence annotation;intermediate evidence annotations;evidence retrieval enables question;such intermediate annotations;answer labels;large corpus;additional annotation cost;neural approaches;model training;evidence;answers;only distant supervision;likely evidence;models;novel approach;distdr;answer pairs;training;weak retriever;model;question;methods;paper investigates;date model;state;domain question;common setting;art", "pdf_keywords": "evidence reranking;supervised odqa;large corpus;evidence labels;corpus;dense retriever;useful evidence;span extraction;distant supervision;evidence;weak retriever;\ufb01nd evidence;model training;accurate evidence;hop qa benchmarks;odqa system;singlehop qa benchmarks;model improvements;reader;span;likely evidence;preliminary;distdr;step;sota approaches;par;conclusion;novel approach;next iteration;section"}, "d59c7b1c85f8c459863762361f251575785347a8": {"ta_keywords": "polydisperse pores;porous membranes;pore size distribution;diffusion mechanism;molecular dynamics simulations;mean permeability;permeability;single pore area;small particles;cylindrical pores;hard spheres;total pore area;collision dynamics;individual pores;membrane;separation performance;smaller particle;binary mixtures;nonequilibrium event;separation;size exclusion;average;permeabilities;minimal model;size;such size;selectivity;fraction;law;study", "pdf_keywords": ""}, "35750f1908f405bb38b0708972f33fe07b378b64": {"ta_keywords": "modal propositional logic;interpretability logic il;provability predicate;interpretability logic;system ilm;modal operator;unary modal operator;propositional calculus;axioms;system gl;propositional letters p0;g\u00f6del;tautologies;l\u00f6b;language;same priority;p1;idea", "pdf_keywords": ""}, "90766546b29836eb96f54fe8fd70ec51a3e699ba": {"ta_keywords": "previous 3d cnn;3d molecular structures;3d voronoi tessellation;protein structures;deep convolutional neural network;voronoi tessellation;cnn;proteins;vorocnn;protein;complexes;precomputed descriptors;3d;recognition;convolution;structures;computational prediction;native structures;data representation;network;prediction results;evolutionary information;computational models;irregular data domain;accuracy;tremendous progress;interfaces;end;results;art", "pdf_keywords": "3d protein folds;3d macromolecular data;3d molecular structures;3d voronoi tessellations;3d voronoi tessellation;protein structures;voronoi tessellation;convolutional networks;deep convolutional neural network;vorocnn;cnn;kliment olechnovic3;graph;sergei grudinin1;ilia;results;contact;c\u02c7 eslovas venclovas3;maria;work;applicability;novel way;\ufb01rst time;conclusion"}, "7181a5139301c8a407da75a105dd457bf03d7057": {"ta_keywords": "stochastic network optimization problems;such network optimization;wadrop equilibrium principle;dynamic programming;heterogeneous planning time windows;dynamic stochastic extension;numerical algorithms;flow;extensive numerical experiments;game;gurobi;commercial software;applications;solutions;dual pair;variable amount;theoretic settings;art;state;features;novel class;order", "pdf_keywords": ""}, "af553d6121d338fc74dbd5faa43d5383a222198d": {"ta_keywords": "autism;communication skills;social skills;communication difficulties;social;minute learning session;training tool;training;difficulties;nocoa;improvement;use;computer;people;number;members;results;relationship;paper;general population;quotient;objective;real world;reasons;variety", "pdf_keywords": ""}, "a8315b5d3ff1b834fb58420397b13b9d169efad1": {"ta_keywords": "name disambiguation mechanism;citation records;multiple publication attributes;soft clustering;author names;similar entities;citation problem;metadata;clustering;name ambiguity;publication venues;hybrid clustering mechanism;similarity;various entities;entities;attributes;titles;split;information;algorithm;paper;experimental results;efficiency;basis;major operations;quantum;important role;great extent;first stage", "pdf_keywords": ""}, "83ddc47f6dd0434c12eff9e4e42b727217a200a8": {"ta_keywords": "learning dynamics;uniform learning rates;stable local nash equilibrium;local convergence guarantees;high probability agents;continuous games;stochastic settings;learning;stochastic case;convergence rates;unbiased estimator;agents;gradient;optimization;deterministic settings;finite time;neighborhood;convergence;concentration;convergence analysis;oracle access;class;region;rate;other works;vector field;other hand;attraction;ii;turn", "pdf_keywords": "online optimization;stable local nash equilibrium;uniform learning rate setting;continuous games;learning algorithms;adversarial learning;different learning rates;learning path;local convergence guarantees;gradient;numerical optimization;games;convergence;neighborhood;asymptotic convergence;vector \ufb01eld dynamics;dynamical systems theory;broad class;player;class;approaches;university;washington;discussion;wide variety;tools;computer engineering;abstract;framework;electrical"}, "48ea80b65f42e9fbb96b856286d12347d1df52d2": {"ta_keywords": "novel commonsense reasoning dataset;reasoning models;commonsense reasoning;tiered reasoning;better language understanding;underlying reasoning process;dense annotations;reasoning process;reasoning;language understanding;end task performance;intuitive physics;machines;verifiable evaluation;large lms;trip;evaluations;future research;high end performance;trip dataset;evidence;predictions;empirical results;performance;importance;true ability;addition;little light;baseline results;paper", "pdf_keywords": "novel commonsense reasoning dataset;tiered reasoning;toward veri\ufb01able commonsense language understanding;commonsense reasoning;better language understanding;language understanding tasks;reasoning models;language understanding;underlying reasoning process;dense annotations;language models;intuitive physics;reasoning;reasoning process;machines;end task performance;future research;level performance;breadth;large lms;veri\ufb01able evaluation;high end performance;engineering;trip;predictions;lms;empirical results;evaluations;trip dataset;engineering division"}, "fa2657c0d66f048dee6b080536abbd1f947e822f": {"ta_keywords": "brain age predictions;brain age estimation;brain age;superior age estimation performance;age estimation accuracy;chronological brain age;deep learning;structural brain mris;cognitive decline;deep learning model;age range;valuable biomarker;frontal lobe;neuropsychological measures;span evaluation dataset;years;predictive value;various neurological diseases;previous studies;data;numerous studies;training;previous study;feature;extensive ablation tests;healthy populations;mae;mean absolute error;healthy population;statistical models", "pdf_keywords": "estimating brain age;brain age predictions;aging brain;brain age;age estimation framework;chronological brain age;aging;disease neuroimaging initiative1;alzheimer;routine structural neuroimaging;lifespan;cognitive decline;structural brain mris;ageing2;uniform age distribution;even age distribution;chronological age;australian imaging biomarkers;age;valuable biomarker;structural mri volumes;adult age span;deep convolutional neural network;structural mri protocols;deep learning;neurology;age range;structural mri;neuropsychological measures;deep learning model"}, "eb1b89751cac821792df36d3a1a2fb01dc4db2d1": {"ta_keywords": "", "pdf_keywords": ""}, "120839995e64f8ed734b5249ab681328c4955f5d": {"ta_keywords": "mdp congestion games;congestion game;toll design problem;toll synthesis problem;congested stochastic network;markov decision process;optimal strategy;optimal strategies;tolls;online constraint satisfaction;bilevel optimization problem;decision makers;game designer;mdp;equilibrium distribution;strategies;designer;parties;design specifications;current system state;lower level;set", "pdf_keywords": ""}, "4d16a47fb6708704b155855045c9e5d2ea380bb0": {"ta_keywords": "social media corpus;current sentiment analysis research;sentiment analysis;czech social media;social media dataset;czech language;product reviews;evaluation datasets;machine learning methods;czech;popular domains;languages;english;chinese;results;various domains;article;commercial solutions;further research;movie;competition;end;case;issue;production;art;field;systematical research;long history;addition", "pdf_keywords": ""}, "7212cca9be971997434c2b3a27411a163bbd89c3": {"ta_keywords": "intermediate conditioning;new conditioning methods;tractable conditioning framework;improved ctc inference;intermediate prediction;next inference;intermediate predictions;better conditioning;previous inference;inference;predictions;latent representation;probabilistic model;ctc;beam;search;intermediates;new approaches;\ufb01nal performance;new formulation;self;paper;original self;method;paper \ufb01rst", "pdf_keywords": "improved ctc inference;ctc inference;intermediate conditioning;new conditioning methods;tractable conditioning framework;intermediate prediction;next inference;ctc baseline;intermediate predictions;previous inference;ctc;inference;predictions;latent representation;better intermediates;probabilistic model;intermediates;beam;search;new formulation;shinji watanabe3;yusuke fujita1;further improvement;jaesong lee2;lukas lee2;apr;paper;tatsuya komatsu1;method;2naver corporation"}, "6bb2b856d9a9b873259ba9dc48bc450c96eb3318": {"ta_keywords": "time", "pdf_keywords": "speech transcripts;transcripts;ongoing transcription;ongoing transcription process;transcript;particular transcriber;cost models;sensitive correction;transcriber;manual correction;cost model;agnostic cost model;initial cost model;e\ufb03cient supervised language annotation;cost;realistic user study;simulated study;annotation e\ufb03ciency;improvements;enrollment;faster algorithm;data;e\ufb03ciency improvements;participants;segments;tation;optimization framework sesla;correction;new dynamic updating framework;actual remaining time"}, "79b8ef3905a42b771248719495a2117271906445": {"ta_keywords": "carbon footprint;carbon emissions;energy efficiency;energy cost;large neural network training;energy use;neural architecture search;carbon;dense dnns;energy;equivalent emissions;computation demand;several recent large models;free energy;dnns;evolved transformer;greener strategies;environmental impact;machine learning;ml workload scheduling;accuracy;costs;daniel rothchild;earlier estimates;co;more parameters;ml;david patterson;davidpatterson;pattrsn", "pdf_keywords": "neural architecture search;energy efficiency;carbon footprint;energy usage;energy use;dense dnns;energy;large nlp models;global climate change;several recent large models;co2e;co2e3;evolved transformer;models;equivalent emissions;dnns;datacenters;mlperf developers;other cloud companies;accuracy;environment;ml community;algorithms;hardware;more parameters;standard benchmark;estimates;ml;key metric;t5"}, "1c709eef701d933af1383c790c13209f06806b60": {"ta_keywords": "sequence models;greedy rationalization;language modeling;sequential rationales;greedy rationales;machine translation;model explanations;human rationales;modern nlp systems;individual model predictions;sequential objective;rationales;best rationale;full sequence;predictions;combinatorial optimization;faithful rationales;context;baselines;subsets;input tokens;smallest subset;critical component;new dataset;same output", "pdf_keywords": "language modeling;model explanations;biases;language model;attention;greedy rationalization;machine translation;intractable marginalization step;models;training data;context subsets;conditioning;prediction;greedy algorithm;optimization;model;rationales;compatible distributions;variety;researcher;justi\ufb01cations;diagnostic model;experiments;company;methods;doctor;compatibility;\ufb01ne;decision;settings"}, "0de86afbf91d0cf3e595a23a5b7a4d19deefb891": {"ta_keywords": "model bifurcations;bifurcation diagram;bifurcation measure;differential equation models;parameter inference;parameter regimes;synthetic biology;models;parameters;optimisers;pitchfork diagrams;cost function;algorithms;gradients;solver;minimal models;differential equations;gradient;quantitative time;diagram;series data;cost landscape;saddle;genetic toggle switch;estimation;node;operations;need;terms;space", "pdf_keywords": "bifurcations;speci\ufb01ed bifurcation diagram;synthetic biology;differential equation models;parameter inference;parameters;pitchfork diagrams;parameter space;computational bottleneck;genetic toggle switch;differential equations;ordinary differential equations;minimal models;saddle;system behaviour;implicit layers;gradients;jacobian determinant;gradient;control condition;cost landscape;implementation;topological equivalence;novel way;qualitative changes;summary;differentiable method;end;speci\ufb01ed locations;strategy"}, "4f02d8775123624088a91fcfff20625463e5239a": {"ta_keywords": "intelligent learning analytics;learning analytics;collaborative filtering;collaborative filtering algorithm;education data;large education data set;logistic regression;individual learner;prediction performance;prediction;english language learning;test outcomes;test responses;regression;interpretability;education;experts;mobile applications;algorithms;next generation;machine;variety;recent years;many tasks;utmost importance;record;new model;approaches;work;enormous amount", "pdf_keywords": ""}, "614dc4001ad68cac31484887f16542f04693eca4": {"ta_keywords": "bribery criteria;voter;probabilistic environment;formal complexity analysis;complexity;stochastic environment;formal model;probability;terms;evaluation criteria;models;paper;preferences;actor;distinct models;problems;multiple issues;issue;order;different effects", "pdf_keywords": ""}, "3261728694c0a53a2e8f95326f94147a28e03a83": {"ta_keywords": "deep quantization;layer quantization bitwidth;multiple quantization parameterization;quantization;deep networks;novel sinusoidal regularization;deep neural networks;heterogeneous bitwidth assignment;sinareq balance compute efficiency;training algorithms;network weights;sinareq;bitwidth;homogenous bitwidths;bit assignment;bits;training;alexnet;mobilenet;wrpn;sinusoidal functions;network;sinusoidal function;sinusoidal properties;gradient;training process;compute efficiency;accuracy;levels;operations", "pdf_keywords": "layer quantization bitwidth;multiple quantization parameterization;quantization;sinusoidal regularization;deep networks;sinusoidal regularizations;novel sinusoidal regularization;network weights;heterogeneous bitwidth assignment;bitwidth levels;weights;waveq;layers;sinusoidal functions;mobilenet;gradient;sinusoidal function;optimization;training;alexnet;sinusoidal properties;training process;compute ef\ufb01ciency;1department;levels;values;large variety;computer engineering;local convexity;accuracy"}, "80ef8b8a1284790e0d8f7cbf9727c9e0b2a89332": {"ta_keywords": "arbitrary black box predictors;black box shift estimation;classifiers;better predictors;label shift;predictors;tighter estimates;distribution shift;shift correction;shift;label;bbse;labels;test distribution;medical diagnosis;test;training;confusion matrices;diseases;observations;statistical test;consistency;targets;dimensionality;symptoms;error", "pdf_keywords": "black box shift estimation;black box predictors;arbitrary black box predictors;improved prediction;distribution shift;label shift;shift;shift correction;natural images;labels;dimensional datasets;accurate estimates;pneumonia;training;test;model;dimensionality;statistical test;classi\ufb01ers;correcting;bbse;consistency;experiments;abstract;jul;yu;faced;error"}, "843966d4b567033abff9775c5958f7be4db5c0ad": {"ta_keywords": "bereavement;disaster;families;children", "pdf_keywords": ""}}